<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="295.787" tests="7" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter1972256131336052956.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-02-08T21-01-29_049-jvmRun1 surefire981943972541737633tmp surefire_203504271406205916584tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.51.1/grpc-netty-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.51.1/grpc-core-1.51.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.86.Final/netty-codec-http2-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.86.Final/netty-common-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.86.Final/netty-buffer-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.86.Final/netty-codec-http-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.86.Final/netty-handler-proxy-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.86.Final/netty-codec-socks-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.54.Final/netty-tcnative-classes-2.0.54.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.54.Final/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/org/awaitility/awaitility/4.2.0/awaitility-4.2.0.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest/2.1/hamcrest-2.1.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.6.21/kotlin-stdlib-common-1.6.21.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/rocksdb-checkpoint-differ/1.4.0-SNAPSHOT/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.49.v20220914/jetty-client-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.2/jakarta.activation-api-1.2.2.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.51.1/grpc-protobuf-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.51.1/grpc-api-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.51.1/grpc-context-1.51.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.51.1/grpc-protobuf-lite-1.51.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.51.1/grpc-stub-1.51.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.86.Final/netty-transport-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.86.Final/netty-resolver-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.86.Final/netty-transport-native-epoll-4.1.86.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.86.Final/netty-transport-classes-epoll-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.86.Final/netty-transport-native-unix-common-4.1.86.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.10.6/joda-time-2.10.6.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.86.Final/netty-codec-4.1.86.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.86.Final/netty-handler-4.1.86.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="skip.installnpx" value="true"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter1972256131336052956.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_362-b09"/>
    <property name="skip.npx" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1031-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="4231a3b2e4cb8548a412a789936d640a97b1aa0a"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="java.version" value="1.8.0_362"/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.362-b09"/>
    <property name="java.specification.maintenance.version" value="4"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="57.545"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="51.5"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="37.567"/>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="37.842"/>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="55.592">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-02-08 09:34:32,395

"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-9"  prio=5 tid=5659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 37321" daemon prio=5 tid=5398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=3629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2639-thread-1"  prio=5 tid=5816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 37099" daemon prio=5 tid=5476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-7"  prio=5 tid=5645 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1691-thread-1"  prio=5 tid=3939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1488-thread-1"  prio=5 tid=3433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6178 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5829 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-SegmentedRaftLogWorker"  prio=5 tid=3911 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6315 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5461" daemon prio=5 tid=5461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37321" daemon prio=5 tid=5383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp429946212-5674" daemon prio=5 tid=5674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 44737" daemon prio=5 tid=4240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5971f4d7" daemon prio=5 tid=3591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 44737" daemon prio=5 tid=4238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 43069" daemon prio=5 tid=6195 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"ChunkWriter-0-0" daemon prio=5 tid=5878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5202 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=5339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1123259274-4849" daemon prio=5 tid=4849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 42297" daemon prio=5 tid=3551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 43809" daemon prio=5 tid=5411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 37321" daemon prio=5 tid=5382 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=5909 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37099" daemon prio=5 tid=5473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4919 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@5b3ce811" daemon prio=5 tid=4774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 46229" daemon prio=5 tid=5375 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 42297" daemon prio=5 tid=3543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3769 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5169 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4827 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2459-thread-1"  prio=5 tid=5931 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager" daemon prio=5 tid=6317 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6194 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"BlockDeletingService#0" daemon prio=5 tid=4809 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1063c7ef-1"  prio=5 tid=3611 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1020-thread-1"  prio=5 tid=2363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37099" daemon prio=5 tid=5479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3049b512" daemon prio=5 tid=5512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5790" daemon prio=5 tid=5790 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-4"  prio=5 tid=5603 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-68135EC56940-LeaderStateImpl" daemon prio=5 tid=5079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp2132414949-3573" daemon prio=5 tid=3573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-5"  prio=5 tid=5608 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 43069" daemon prio=5 tid=6246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"RatisPipelineUtilsThread - 0"  prio=5 tid=4185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1608454883.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 44881" daemon prio=5 tid=4272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 44737" daemon prio=5 tid=4233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4794 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 44737" daemon prio=5 tid=4236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4135 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 43069"  prio=5 tid=6196 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 43809" daemon prio=5 tid=5412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 39055" daemon prio=5 tid=4451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@14c6bc53" daemon prio=5 tid=4704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 42297" daemon prio=5 tid=3549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5131 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1513-thread-1"  prio=5 tid=3450 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 39055" daemon prio=5 tid=4444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 44881" daemon prio=5 tid=4277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4793 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5357 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp55342505-4597" daemon prio=5 tid=4597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4490" daemon prio=5 tid=4490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a1e0311" daemon prio=5 tid=3818 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5446 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1828687139-5498" daemon prio=5 tid=5498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35685" daemon prio=5 tid=6259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"grpc-default-executor-3" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6306 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43809" daemon prio=5 tid=5419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=4407 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Command processor thread" daemon prio=5 tid=4764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3680" daemon prio=5 tid=3680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 35685" daemon prio=5 tid=6269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-StateMachineUpdater" daemon prio=5 tid=5922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-1710-thread-1" daemon prio=5 tid=3786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=5919 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-5"  prio=5 tid=5609 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=3525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-StateMachineUpdater" daemon prio=5 tid=5981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 43809" daemon prio=5 tid=5410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 42297" daemon prio=5 tid=3547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@440faf0f" daemon prio=5 tid=3772 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=4620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F->9b379e2d-f792-462b-ba37-42e93604c872-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6118 runnable
java.lang.Thread.State: RUNNABLE
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@45783fe2" daemon prio=5 tid=3751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1788cd17" daemon prio=5 tid=4564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5344 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"pool-2452-thread-1" daemon prio=5 tid=5538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5462" daemon prio=5 tid=5462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5835 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5580" daemon prio=5 tid=5580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer6" daemon prio=5 tid=710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 17 on default port 39055" daemon prio=5 tid=4459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=5585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1608454883.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4824" daemon prio=5 tid=4824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5821" daemon prio=5 tid=5821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37321" daemon prio=5 tid=5388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5174 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@60c5b8fc" daemon prio=5 tid=4591 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d-impl-thread1"  prio=5 tid=5493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5341 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Over Replicated Processor" daemon prio=5 tid=6189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5862 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1587-thread-1"  prio=5 tid=3910 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=6176 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-3B0E36956B86-StateMachineUpdater" daemon prio=5 tid=4976 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3652" daemon prio=5 tid=3652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-710D643B4E75-SegmentedRaftLogWorker"  prio=5 tid=5010 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37099" daemon prio=5 tid=5445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker"  prio=5 tid=5939 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5719 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 35677" daemon prio=5 tid=6215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-4"  prio=5 tid=3523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-1994-thread-1" daemon prio=5 tid=4587 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5734 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-29CE992F551B-LeaderStateImpl" daemon prio=5 tid=4037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 13 on default port 35677" daemon prio=5 tid=6228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor41" daemon prio=5 tid=4424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3624 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5702 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-774de403-1"  prio=5 tid=5504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 42297" daemon prio=5 tid=3555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-AC5FEBAEEB47-SegmentedRaftLogWorker"  prio=5 tid=5002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 38487" daemon prio=5 tid=4259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5133 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=4956 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-68135EC56940-StateMachineUpdater" daemon prio=5 tid=4992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5741" daemon prio=5 tid=5741 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d-server-thread1" daemon prio=5 tid=6171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93-impl-thread1"  prio=5 tid=5785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4932 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5657 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer5" daemon prio=5 tid=709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3257 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5549" daemon prio=5 tid=5549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 46229" daemon prio=5 tid=5370 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1905-thread-1"  prio=5 tid=4430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-0"  prio=5 tid=5331 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5170 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 44737" daemon prio=5 tid=4241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5562 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1775990862-3760" daemon prio=5 tid=3760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 44737" daemon prio=5 tid=4243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=3894 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4585 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 46229" daemon prio=5 tid=5363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1839728377-3650-acceptor-0@5b8fc675-ServerConnector@78b083d8{HTTP/1.1, (http/1.1)}{0.0.0.0:44463}" daemon prio=3 tid=3650 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37099" daemon prio=5 tid=5483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 38487" daemon prio=5 tid=4252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker"  prio=5 tid=5966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4749" daemon prio=5 tid=4749 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3682" daemon prio=5 tid=3682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=6291 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4293" daemon prio=5 tid=4293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5697 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3655" daemon prio=5 tid=3655 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5885 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6305 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-31df626e-1"  prio=5 tid=5796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4818" daemon prio=5 tid=4818 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-33-thread-1"  prio=5 tid=125 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-8" daemon prio=5 tid=1104 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5774 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3533" daemon prio=5 tid=3533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState" daemon prio=5 tid=6114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server listener on 0" daemon prio=5 tid=4200 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-DED267486FAA-SegmentedRaftLogWorker"  prio=5 tid=3952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-StateMachineUpdater" daemon prio=5 tid=5929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5911 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2583-thread-1"  prio=5 tid=5949 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4936 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 43809" daemon prio=5 tid=5416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4436" daemon prio=5 tid=4436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4560 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3607" daemon prio=5 tid=3607 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4660 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-3B0E36956B86-StateMachineUpdater" daemon prio=5 tid=4964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4899 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37099" daemon prio=5 tid=5484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5907 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor47" daemon prio=5 tid=4925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 37321" daemon prio=5 tid=5397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4404 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"d483f22f-9e25-4e72-9070-8c514e67a945-server-thread2" daemon prio=5 tid=5114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 42297" daemon prio=5 tid=3553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3282 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2473cb26-1"  prio=5 tid=4784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater" daemon prio=5 tid=3935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@54591dac" daemon prio=5 tid=5542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-706B5600CFDC-StateMachineUpdater" daemon prio=5 tid=5008 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@536f15f6" daemon prio=5 tid=5564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4935 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 46229" daemon prio=5 tid=5372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3633 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 43069" daemon prio=5 tid=6252 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@4dd4c851" daemon prio=5 tid=5806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3691 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 35677" daemon prio=5 tid=6231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=4800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3845 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5f174735-1"  prio=5 tid=3537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4439" daemon prio=5 tid=4439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3778 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5567 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4192 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5558 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5884 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"Datanode State Machine Task Thread - 0"  prio=5 tid=4874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3625 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3588 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-1"  prio=5 tid=5586 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4433-acceptor-0@433a98c0-ServerConnector@7aaded08{HTTP/1.1, (http/1.1)}{0.0.0.0:39399}" daemon prio=3 tid=4433 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3574" daemon prio=5 tid=3574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4196 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3567 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor52" daemon prio=5 tid=5701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4920 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 127.0.0.1/37099"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:237)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$340/1926027290.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896-server-thread3" daemon prio=5 tid=5116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"675cd09c-5451-427a-be54-02ea82412c70@group-48BDBC021DAE-FollowerState" daemon prio=5 tid=3973 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3349bf9e" daemon prio=5 tid=5494 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 37099" daemon prio=5 tid=5472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1-client-thread1" daemon prio=5 tid=5128 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-AC5FEBAEEB47-StateMachineUpdater" daemon prio=5 tid=5004 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-679-thread-1"  prio=5 tid=1528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3892 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 39055" daemon prio=5 tid=4454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@6682839" daemon prio=5 tid=3665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 42297" daemon prio=5 tid=3548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker"  prio=5 tid=5923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderStateImpl" daemon prio=5 tid=6331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 0 on default port 38487" daemon prio=5 tid=4245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 35677" daemon prio=5 tid=6216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 44737" daemon prio=5 tid=4232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3710 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6180 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5818-acceptor-0@1f9ef0ec-ServerConnector@5ed1eaca{HTTP/1.1, (http/1.1)}{0.0.0.0:41655}" daemon prio=3 tid=5818 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=5336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3844 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5890 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bbdaa27" daemon prio=5 tid=4834 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3589 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 42297" daemon prio=5 tid=3517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"KeyDeletingService#0" daemon prio=5 tid=3524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@16faf34f" daemon prio=5 tid=4873 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4867 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5834 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-71F94BFB4678-LeaderStateImpl" daemon prio=5 tid=5045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp429946212-5675" daemon prio=5 tid=5675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater" daemon prio=5 tid=3922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 35685" daemon prio=5 tid=6270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp63361978-6280" daemon prio=5 tid=6280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker"  prio=5 tid=5927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2098 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3666 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor57" daemon prio=5 tid=5894 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35685" daemon prio=5 tid=6273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5848 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 43069" daemon prio=5 tid=6250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 0"  prio=5 tid=4405 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"BlockDeletingService#1" daemon prio=5 tid=3831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB->09413839-b23a-4aca-94dd-890763e4f20d-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4488" daemon prio=5 tid=4488 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5552" daemon prio=5 tid=5552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3885 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2147-thread-1"  prio=5 tid=4775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 37321" daemon prio=5 tid=5389 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3659 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4862 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35677" daemon prio=5 tid=6225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 37321" daemon prio=5 tid=5390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1527033392-3608" daemon prio=5 tid=3608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-1"  prio=5 tid=5328 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-AC5FEBAEEB47-FollowerState" daemon prio=5 tid=5107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"JvmPauseMonitor39" daemon prio=5 tid=3880 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@647ba41b" daemon prio=5 tid=3647 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5892 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3145 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4292" daemon prio=5 tid=4292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker"  prio=5 tid=5932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-3"  prio=5 tid=5599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4561 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 43069" daemon prio=5 tid=6235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 18 on default port 44881" daemon prio=5 tid=4283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1828687139-5497-acceptor-0@2824f233-ServerConnector@2202c29{HTTP/1.1, (http/1.1)}{0.0.0.0:33523}" daemon prio=3 tid=5497 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@407e21c7" daemon prio=5 tid=4641 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1775990862-3756" daemon prio=5 tid=3756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6340 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2617-thread-1"  prio=5 tid=5787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3688 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3660 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5839 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 43809" daemon prio=5 tid=5413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@77d3d0f6" daemon prio=5 tid=4738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4802 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6313 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 43809" daemon prio=5 tid=5404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 37321" daemon prio=5 tid=5387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-8"  prio=5 tid=5651 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5551" daemon prio=5 tid=5551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@33858ec0" daemon prio=5 tid=5624 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1688558704) connection to 0.0.0.0/0.0.0.0:44881 from runner" daemon prio=5 tid=4796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"OpenKeyCleanupService#0" daemon prio=5 tid=4428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4890 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2541-thread-1" daemon prio=5 tid=5658 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3584 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@15d5dabf" daemon prio=5 tid=3674 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3536" daemon prio=5 tid=3536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37099" daemon prio=5 tid=5475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp63361978-6284" daemon prio=5 tid=6284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2445-thread-1"  prio=5 tid=5495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3530-acceptor-0@7e93f180-ServerConnector@5e6ede3{HTTP/1.1, (http/1.1)}{0.0.0.0:38131}" daemon prio=3 tid=3530 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3610" daemon prio=5 tid=3610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6341 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2139-thread-1"  prio=5 tid=5001 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3572-acceptor-0@2e6a48d1-ServerConnector@7c614dfc{HTTP/1.1, (http/1.1)}{0.0.0.0:43433}" daemon prio=3 tid=3572 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5579" daemon prio=5 tid=5579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4491" daemon prio=5 tid=4491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5173 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4777-acceptor-0@2a3c7011-ServerConnector@5549b77d{HTTP/1.1, (http/1.1)}{0.0.0.0:36585}" daemon prio=3 tid=4777 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 37099" daemon prio=5 tid=5466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 13 on default port 35685" daemon prio=5 tid=6268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"9b379e2d-f792-462b-ba37-42e93604c872-server-thread1" daemon prio=5 tid=6120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4804 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4670" daemon prio=5 tid=4670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4669" daemon prio=5 tid=4669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5347 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3529" daemon prio=5 tid=3529 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5788" daemon prio=5 tid=5788 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor42" daemon prio=5 tid=4807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5705 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-51af8bba-1"  prio=5 tid=4853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6314 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4665-acceptor-0@39f2d1a9-ServerConnector@4673a7c4{HTTP/1.1, (http/1.1)}{0.0.0.0:45895}" daemon prio=3 tid=4665 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4896 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5895 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5139 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"57e34f8d-7b3e-4914-b42b-53a5fc13ebf8-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4841 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5168 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=6175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6307 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3599 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5803 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4705 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 42297" daemon prio=5 tid=3550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 39055" daemon prio=5 tid=4452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5886 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5210 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4911 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5842 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3590 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 38487" daemon prio=5 tid=4253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-AC5FEBAEEB47-SegmentedRaftLogWorker"  prio=5 tid=4997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5762 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker"  prio=5 tid=5920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 38487" daemon prio=5 tid=4247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3890 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread1" daemon prio=5 tid=6334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 38487" daemon prio=5 tid=4258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-StateMachineUpdater" daemon prio=5 tid=5961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-3B0E36956B86-SegmentedRaftLogWorker"  prio=5 tid=4974 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 44737" daemon prio=5 tid=4242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp63361978-6285" daemon prio=5 tid=6285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-29CE992F551B-SegmentedRaftLogWorker"  prio=5 tid=3962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5349 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 42297" daemon prio=5 tid=3556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp687067551-5427" daemon prio=5 tid=5427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 46229" daemon prio=5 tid=5362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5830 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-8"  prio=5 tid=5654 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3807" daemon prio=5 tid=3807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3585 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1851-thread-1"  prio=5 tid=4314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@8af0a01" daemon prio=5 tid=3630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 38487" daemon prio=5 tid=4251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"IPC Server idle connection scanner for port 44881" daemon prio=5 tid=4194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3658 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 46229" daemon prio=5 tid=5374 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4921 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6292 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2493-thread-1"  prio=5 tid=5926 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35677" daemon prio=5 tid=6218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor56" daemon prio=5 tid=5882 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6324 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3888 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-A6A3CB186384-SegmentedRaftLogWorker"  prio=5 tid=4959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-1" daemon prio=5 tid=6325 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderStateImpl" daemon prio=5 tid=6124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"d483f22f-9e25-4e72-9070-8c514e67a945-server-thread1" daemon prio=5 tid=5113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4886 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 38487" daemon prio=5 tid=4263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderStateImpl" daemon prio=5 tid=6116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"pool-2559-thread-1"  prio=5 tid=5671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-11" daemon prio=5 tid=3265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=3519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5b80fb7c-1"  prio=5 tid=4826 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5819" daemon prio=5 tid=5819 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3897 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor37" daemon prio=5 tid=3849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3959 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5464" daemon prio=5 tid=5464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 43809" daemon prio=5 tid=5421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=5351 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"JvmPauseMonitor43" daemon prio=5 tid=4860 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4495" daemon prio=5 tid=4495 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 39055" daemon prio=5 tid=4443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2132414949-3571" daemon prio=5 tid=3571 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor33" daemon prio=5 tid=3522 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4666" daemon prio=5 tid=4666 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2956 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState" daemon prio=5 tid=6166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"DatanodeAdminManager-0" daemon prio=5 tid=4191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5773 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-41b191a9-1"  prio=5 tid=4296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 38487" daemon prio=5 tid=4257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@515d5320" daemon prio=5 tid=3558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-FollowerState" daemon prio=5 tid=3977 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-LeaderStateImpl" daemon prio=5 tid=4009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#3" daemon prio=5 tid=6350 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4435" daemon prio=5 tid=4435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=3583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4c9a03c3" daemon prio=5 tid=5670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3592 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 43809" daemon prio=5 tid=5409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 11 on default port 46229" daemon prio=5 tid=5373 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp62694296-4825" daemon prio=5 tid=4825 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-DED267486FAA-StateMachineUpdater" daemon prio=5 tid=3954 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 35685" daemon prio=5 tid=6260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp429946212-5673-acceptor-0@46255534-ServerConnector@2d8f01d7{HTTP/1.1, (http/1.1)}{0.0.0.0:46033}" daemon prio=3 tid=5673 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4821" daemon prio=5 tid=4821 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3576" daemon prio=5 tid=3576 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4492" daemon prio=5 tid=4492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=6211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-13" daemon prio=5 tid=6144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4906 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor53" daemon prio=5 tid=5771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3594 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=4915 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp63361978-6283" daemon prio=5 tid=6283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2165-thread-1"  prio=5 tid=4996 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=4903 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2e2a2b07-1"  prio=5 tid=6286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 43069" daemon prio=5 tid=6242 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp604936234-3800" daemon prio=5 tid=3800 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5897 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5430" daemon prio=5 tid=5430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-StateMachineUpdater" daemon prio=5 tid=5934 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor54" daemon prio=5 tid=5832 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5428" daemon prio=5 tid=5428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5463" daemon prio=5 tid=5463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=4186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3702 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-5" daemon prio=5 tid=569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 39055" daemon prio=5 tid=4449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 0"  prio=5 tid=4197 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"BlockDeletingService#0" daemon prio=5 tid=4939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4776" daemon prio=5 tid=4776 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp63361978-6281" daemon prio=5 tid=6281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37321" daemon prio=5 tid=5393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=5443 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 16 on default port 44881" daemon prio=5 tid=4281 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5508 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37099" daemon prio=5 tid=5485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"675cd09c-5451-427a-be54-02ea82412c70@group-48BDBC021DAE-SegmentedRaftLogWorker"  prio=5 tid=3916 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 42297" daemon prio=5 tid=3552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 46229" daemon prio=5 tid=5377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 7 on default port 35677" daemon prio=5 tid=6222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-68ebfbe5-1"  prio=5 tid=3761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 37099" daemon prio=5 tid=5471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4901 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=6209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-AC5FEBAEEB47-LeaderStateImpl" daemon prio=5 tid=5109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Parameter Sending Thread #1" daemon prio=5 tid=1524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2437-thread-1"  prio=5 tid=5918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37099" daemon prio=5 tid=5478 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5132 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b-server-thread1" daemon prio=5 tid=5042 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 44737" daemon prio=5 tid=4234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 44737" daemon prio=5 tid=4235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=3847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5432" daemon prio=5 tid=5432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@410ee058" daemon prio=5 tid=3692 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4892 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872-server-thread2" daemon prio=5 tid=6122 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3654" daemon prio=5 tid=3654 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e-server-thread2" daemon prio=5 tid=5041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 35685" daemon prio=5 tid=6272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5857 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-9"  prio=5 tid=5652 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-4"  prio=5 tid=5605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=5129 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-AC5FEBAEEB47-FollowerState" daemon prio=5 tid=5108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2089 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-3B0E36956B86-FollowerState" daemon prio=5 tid=5035 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=4205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"675cd09c-5451-427a-be54-02ea82412c70@group-3E290E99B399-SegmentedRaftLogWorker"  prio=5 tid=3923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43069" daemon prio=5 tid=6236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp429946212-5678" daemon prio=5 tid=5678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=3515 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"pool-2158-thread-1" daemon prio=5 tid=4806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1932-thread-1" daemon prio=5 tid=4481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1835-thread-1"  prio=5 tid=4287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 44737" daemon prio=5 tid=4230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1573-thread-1"  prio=5 tid=3570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 44737" daemon prio=5 tid=4202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-1617-thread-1"  prio=5 tid=3648 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread1" daemon prio=5 tid=6119 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3686 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526-server-thread2" daemon prio=5 tid=3980 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5458-acceptor-0@59099d55-ServerConnector@4a3aa919{HTTP/1.1, (http/1.1)}{0.0.0.0:34653}" daemon prio=3 tid=5458 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37321" daemon prio=5 tid=5384 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp429946212-5679" daemon prio=5 tid=5679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4859 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3762 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderStateImpl" daemon prio=5 tid=6097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Over Replicated Processor" daemon prio=5 tid=5337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 37321" daemon prio=5 tid=5401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderStateImpl" daemon prio=5 tid=6136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5621 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@32ff6345" daemon prio=5 tid=4662 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 44881" daemon prio=5 tid=4275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=6287 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-0"  prio=5 tid=5327 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5792" daemon prio=5 tid=5792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE-LeaderStateImpl" daemon prio=5 tid=3974 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-6"  prio=5 tid=5641 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4893 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2486-thread-1" daemon prio=5 tid=5569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 35677" daemon prio=5 tid=6229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=6210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5548" daemon prio=5 tid=5548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5838 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-4"  prio=5 tid=5607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4907 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6303 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4933 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 39055" daemon prio=5 tid=4456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-710D643B4E75-StateMachineUpdater" daemon prio=5 tid=5012 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3802" daemon prio=5 tid=3802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4884 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread2" daemon prio=5 tid=6121 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-9"  prio=5 tid=5650 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6198 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4832 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=4211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5571 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 37321" daemon prio=5 tid=5395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5356 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=4913 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 35677" daemon prio=5 tid=6201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5695 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-7"  prio=5 tid=5643 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3649" daemon prio=5 tid=3649 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5881 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3681" daemon prio=5 tid=3681 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 42297" daemon prio=5 tid=3557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e-server-thread1" daemon prio=5 tid=5040 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 35677" daemon prio=5 tid=6224 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@693bfe94" daemon prio=5 tid=4816 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6347 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 37321" daemon prio=5 tid=5400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3535" daemon prio=5 tid=3535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 37099" daemon prio=5 tid=5481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-68135EC56940-SegmentedRaftLogWorker"  prio=5 tid=4990 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3806324c" daemon prio=5 tid=5714 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=4426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-105b9839-1"  prio=5 tid=4757 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4772 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5863 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-StateMachineUpdater" daemon prio=5 tid=5957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 43069" daemon prio=5 tid=6254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OpenKeyCleanupService#0" daemon prio=5 tid=5454 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4869 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4201 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server Responder" daemon prio=5 tid=4203 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp63361978-6282" daemon prio=5 tid=6282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4897 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5500" daemon prio=5 tid=5500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4883 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2110-thread-1" daemon prio=5 tid=4717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 39055" daemon prio=5 tid=4457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-3cc5a47d-1"  prio=5 tid=4500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3631 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5804 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4728 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-3B0E36956B86-SegmentedRaftLogWorker"  prio=5 tid=4962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 38487" daemon prio=5 tid=4255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 37099" daemon prio=5 tid=5480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=5187 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 44737" daemon prio=5 tid=4227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1775990862-3753" daemon prio=5 tid=3753 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5345 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 8 on default port 42297" daemon prio=5 tid=3546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 46229" daemon prio=5 tid=5350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 6 on default port 39055" daemon prio=5 tid=4448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor48" daemon prio=5 tid=4937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 43069" daemon prio=5 tid=6251 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@53f2e891" daemon prio=5 tid=5573 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35685" daemon prio=5 tid=6266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1674118296-4750-acceptor-0@43485d24-ServerConnector@71bd9d6a{HTTP/1.1, (http/1.1)}{0.0.0.0:34275}" daemon prio=3 tid=4750 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-3B0E36956B86-FollowerState" daemon prio=5 tid=5036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=4209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3605" daemon prio=5 tid=3605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Command processor thread" daemon prio=5 tid=5805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp55342505-4600" daemon prio=5 tid=4600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3830 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7875e820-1"  prio=5 tid=5433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43809" daemon prio=5 tid=5342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 14 on default port 46229" daemon prio=5 tid=5376 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4700 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4668" daemon prio=5 tid=4668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4489-acceptor-0@1c3b6bd2-ServerConnector@7572756b{HTTP/1.1, (http/1.1)}{0.0.0.0:42919}" daemon prio=3 tid=4489 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5492 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4437" daemon prio=5 tid=4437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5903 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=4188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1058298062.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5205 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@60d6fe6c" daemon prio=5 tid=5815 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-214AFAC73B05-StateMachineUpdater" daemon prio=5 tid=3906 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=5439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5891 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-StateMachineUpdater" daemon prio=5 tid=5938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 37321" daemon prio=5 tid=5396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=5778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 35677" daemon prio=5 tid=6220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker"  prio=5 tid=5943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf-client-thread1" daemon prio=5 tid=5325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=6183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4754" daemon prio=5 tid=4754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2046-thread-1" daemon prio=5 tid=4653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=5915 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6304 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp55342505-4595-acceptor-0@4f1b9b2b-ServerConnector@173f0b8d{HTTP/1.1, (http/1.1)}{0.0.0.0:39751}" daemon prio=3 tid=4595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3664 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 44881" daemon prio=5 tid=4269 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp416885486-5794" daemon prio=5 tid=5794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@343f1dae" daemon prio=5 tid=5786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3848 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 43809" daemon prio=5 tid=5402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@75d9116a" daemon prio=5 tid=5845 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 46229" daemon prio=5 tid=5371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=6300 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker"  prio=5 tid=5972 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-AC5FEBAEEB47-StateMachineUpdater" daemon prio=5 tid=4999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5791" daemon prio=5 tid=5791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4819-acceptor-0@2d6627d9-ServerConnector@2352f924{HTTP/1.1, (http/1.1)}{0.0.0.0:35113}" daemon prio=3 tid=4819 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-StateMachineUpdater" daemon prio=5 tid=5952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5547" daemon prio=5 tid=5547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1dac7616" daemon prio=5 tid=4765 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 39055" daemon prio=5 tid=4458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Mini-Cluster-Provider-Reap"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$reapClusters$0(MiniOzoneClusterProvider.java:199)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$341/1837601499.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-2" daemon prio=5 tid=556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5795" daemon prio=5 tid=5795 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4780" daemon prio=5 tid=4780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 38487" daemon prio=5 tid=4246 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp687067551-5426-acceptor-0@2c580ca4-ServerConnector@18374338{HTTP/1.1, (http/1.1)}{0.0.0.0:42225}" daemon prio=3 tid=5426 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"d483f22f-9e25-4e72-9070-8c514e67a945-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4814 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3957 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5545-acceptor-0@22fac46a-ServerConnector@39fb117b{HTTP/1.1, (http/1.1)}{0.0.0.0:45607}" daemon prio=3 tid=5545 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5502" daemon prio=5 tid=5502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5352 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4855 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1647-thread-1"  prio=5 tid=3675 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2398-thread-1"  prio=5 tid=5424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-A6A3CB186384-StateMachineUpdater" daemon prio=5 tid=4961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6309 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4926 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-DED267486FAA-LeaderStateImpl" daemon prio=5 tid=4033 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-1-0" daemon prio=5 tid=5768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5550" daemon prio=5 tid=5550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 37099" daemon prio=5 tid=5467 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=6185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4781" daemon prio=5 tid=4781 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1952-thread-1"  prio=5 tid=4487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 35677" daemon prio=5 tid=6221 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4e322624" daemon prio=5 tid=5736 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5784 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-1D6529F2DD3F-SegmentedRaftLogWorker"  prio=5 tid=4986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5807 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=6208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=6184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$412/1608454883.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4894 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 44881" daemon prio=5 tid=4268 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6351 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB->89a22697-0d01-4b31-a0d7-1bc78e753416-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-1"  prio=5 tid=5587 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4d509881" daemon prio=5 tid=3798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 0.0.0.0/35677"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
        at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
        at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$164/391877669.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall$$Lambda$165/1462044018.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$$Lambda$322/2694936.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$1230/1452722471.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1371957475.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1876682596.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1565740893.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/2067180044.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1371957475.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1876682596.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1565740893.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/2067180044.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1371957475.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/1876682596.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1565740893.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$220/1973233403.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"qtp549850773-5581" daemon prio=5 tid=5581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 44881" daemon prio=5 tid=4273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 39055" daemon prio=5 tid=4446 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DirectoryDeletingService#0" daemon prio=5 tid=5453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-214AFAC73B05-SegmentedRaftLogWorker"  prio=5 tid=3904 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 43069" daemon prio=5 tid=6197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-2602-thread-1" daemon prio=5 tid=5780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5622 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6308 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5840 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=5438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$543/1595429823.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState" daemon prio=5 tid=6330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"BlockDeletingService#2" daemon prio=5 tid=5138 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 37099" daemon prio=5 tid=5468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=4954 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5201 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4934 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4432" daemon prio=5 tid=4432 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-1725-thread-1"  prio=5 tid=3799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 43809" daemon prio=5 tid=5414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=703 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater" daemon prio=5 tid=5964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5348 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"57e34f8d-7b3e-4914-b42b-53a5fc13ebf8@group-37989A005FFA-SegmentedRaftLogWorker"  prio=5 tid=5014 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp429946212-5677" daemon prio=5 tid=5677 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=4958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 46229" daemon prio=5 tid=5380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=4208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=3518 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server listener on 35677" daemon prio=5 tid=6199 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6312 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1943-thread-1"  prio=5 tid=4957 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5912 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5511 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-53ab1255-1"  prio=5 tid=5746 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5668 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4434" daemon prio=5 tid=4434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4927 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=723 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread3" daemon prio=5 tid=6338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 44737" daemon prio=5 tid=4226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor45" daemon prio=5 tid=4895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 46229" daemon prio=5 tid=5366 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp55342505-4598" daemon prio=5 tid=4598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37099" daemon prio=5 tid=5470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5295 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 43069" daemon prio=5 tid=6239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2957 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4752" daemon prio=5 tid=4752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=4207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 35685" daemon prio=5 tid=6193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4889 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 38487" daemon prio=5 tid=4250 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-5c8b68f6-1"  prio=5 tid=4673 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1775990862-3755" daemon prio=5 tid=3755 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2631-thread-1"  prio=5 tid=5978 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-78facbff-1"  prio=5 tid=5553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5575" daemon prio=5 tid=5575 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-SegmentedRaftLogWorker"  prio=5 tid=3920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3707 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-7"  prio=5 tid=5644 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp55342505-4594" daemon prio=5 tid=4594 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 43809" daemon prio=5 tid=5405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 44737" daemon prio=5 tid=4239 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 46229" daemon prio=5 tid=5381 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 37321" daemon prio=5 tid=5392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=3882 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5444 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"SstFilteringService#0" daemon prio=5 tid=4429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3577" daemon prio=5 tid=3577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1602-thread-1" daemon prio=5 tid=3635 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5506 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5789-acceptor-0@4eebe097-ServerConnector@634cf432{HTTP/1.1, (http/1.1)}{0.0.0.0:44085}" daemon prio=3 tid=5789 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp63361978-6279-acceptor-0@108e6f9e-ServerConnector@42a198dd{HTTP/1.1, (http/1.1)}{0.0.0.0:34655}" daemon prio=3 tid=6279 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5836 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5618 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=140 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3672 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4922 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderStateImpl" daemon prio=5 tid=6106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#3" daemon prio=5 tid=6348 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5772 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5343 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ChunkWriter-3-0" daemon prio=5 tid=3879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5893 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2576-thread-1" daemon prio=5 tid=5720 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5460" daemon prio=5 tid=5460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3609" daemon prio=5 tid=3609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4636 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 44881" daemon prio=5 tid=4265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=3878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 43069" daemon prio=5 tid=6248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ReplicationMonitor" daemon prio=5 tid=6187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1058298062.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5910 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor51" daemon prio=5 tid=5450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4856 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-790f842d-1"  prio=5 tid=3657 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-706B5600CFDC-SegmentedRaftLogWorker"  prio=5 tid=5006 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-AC5FEBAEEB47-SegmentedRaftLogWorker"  prio=5 tid=4993 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3884 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5429" daemon prio=5 tid=5429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4664" daemon prio=5 tid=4664 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3603" daemon prio=5 tid=3603 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-AC5FEBAEEB47->f322f364-3549-40ba-952a-b6c14b6ec896-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3796 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 39055" daemon prio=5 tid=4447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor40" daemon prio=5 tid=3893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4799 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=4206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-396c51b0-1"  prio=5 tid=5825 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5619 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b-server-thread2" daemon prio=5 tid=5043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2121 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2180-thread-1" daemon prio=5 tid=4839 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"675cd09c-5451-427a-be54-02ea82412c70-server-thread1" daemon prio=5 tid=3979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3813 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5810 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 37321" daemon prio=5 tid=5399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"5ef0eb67-7d25-4fae-babe-11dd56e72526-server-thread3" daemon prio=5 tid=3982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor55" daemon prio=5 tid=5859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37321" daemon prio=5 tid=5385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5742" daemon prio=5 tid=5742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35677" daemon prio=5 tid=6234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp429946212-5672" daemon prio=5 tid=5672 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4823" daemon prio=5 tid=4823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2624-thread-1" daemon prio=5 tid=5811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4783" daemon prio=5 tid=4783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4479 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3626 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5831 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F->24a09729-c961-4f74-a8da-1db1f23bfb93-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6117 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2125-thread-1"  prio=5 tid=4739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3850 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 35677" daemon prio=5 tid=6230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1527033392-3606" daemon prio=5 tid=3606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-StateMachineUpdater" daemon prio=5 tid=5974 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5206 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 35685" daemon prio=5 tid=6256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread2" daemon prio=5 tid=6173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e@group-A6A3CB186384-LeaderStateImpl" daemon prio=5 tid=5031 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#0" daemon prio=5 tid=3829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 35685" daemon prio=5 tid=6257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=4213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-14" daemon prio=5 tid=6152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=5452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6326 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.PriorityBlockingQueue.take(PriorityBlockingQueue.java:549)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416-impl-thread1"  prio=5 tid=5572 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3679" daemon prio=5 tid=3679 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3651" daemon prio=5 tid=3651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-StateMachineUpdater" daemon prio=5 tid=5925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=5914 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5513 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 37099" daemon prio=5 tid=5469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=4187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor36" daemon prio=5 tid=3827 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 35677" daemon prio=5 tid=6227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-5076b095-1"  prio=5 tid=5680 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 46229" daemon prio=5 tid=5367 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp62694296-4822" daemon prio=5 tid=4822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3575" daemon prio=5 tid=3575 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35677" daemon prio=5 tid=6226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=6288 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 43069" daemon prio=5 tid=6238 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 44737" daemon prio=5 tid=4225 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=4879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-5"  prio=5 tid=4425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3763 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5820" daemon prio=5 tid=5820 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-StateMachineUpdater" daemon prio=5 tid=5977 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2430-thread-1" daemon prio=5 tid=5490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3694 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1688558704) connection to 0.0.0.0/0.0.0.0:35685 from runner" daemon prio=5 tid=6182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"IPC Server handler 18 on default port 43809" daemon prio=5 tid=5420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState" daemon prio=5 tid=6115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"JvmPauseMonitor44" daemon prio=5 tid=4881 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5190 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4931 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1123259274-4848" daemon prio=5 tid=4848 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4559 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 43069" daemon prio=5 tid=6243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Client (1688558704) connection to 0.0.0.0/0.0.0.0:43809 from runner" daemon prio=5 tid=5696 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-6"  prio=5 tid=5642 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=6290 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3656" daemon prio=5 tid=3656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-706B5600CFDC-LeaderStateImpl" daemon prio=5 tid=5087 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5764 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1580-thread-1" daemon prio=5 tid=3596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5501" daemon prio=5 tid=5501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderStateImpl" daemon prio=5 tid=6167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1249251933-4291" daemon prio=5 tid=4291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 38487" daemon prio=5 tid=4260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5879 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 38487" daemon prio=5 tid=4262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6344 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5496" daemon prio=5 tid=5496 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2425-thread-1"  prio=5 tid=5456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@4c00b36" daemon prio=5 tid=4792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=6301 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3812 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5510 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4493" daemon prio=5 tid=4493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5801 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4880 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5711 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-2"  prio=5 tid=5598 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4762 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 35677" daemon prio=5 tid=6223 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE-SegmentedRaftLogWorker"  prio=5 tid=3907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 44881" daemon prio=5 tid=4271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Timer-6"  prio=5 tid=5451 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 3 on default port 44737" daemon prio=5 tid=4228 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1775990862-3757-acceptor-0@1da63772-ServerConnector@715dc22{HTTP/1.1, (http/1.1)}{0.0.0.0:34617}" daemon prio=3 tid=3757 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=6206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 44881" daemon prio=5 tid=4266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=6302 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4289-acceptor-0@5556e74b-ServerConnector@6f023f55{HTTP/1.1, (http/1.1)}{0.0.0.0:41061}" daemon prio=3 tid=4289 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 43069" daemon prio=5 tid=6245 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=5340 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 7 on default port 46229" daemon prio=5 tid=5369 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4152 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-3"  prio=5 tid=5601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 35677" daemon prio=5 tid=6217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=6207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3883 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-286-thread-1"  prio=5 tid=690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"61e2ac77-ead7-4e07-97d9-f28a506a07a9@group-AC5FEBAEEB47->d483f22f-9e25-4e72-9070-8c514e67a945-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5135 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1632-thread-1" daemon prio=5 tid=3670 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 38487" daemon prio=5 tid=4261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3828 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3815 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3806" daemon prio=5 tid=3806 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896-server-thread2" daemon prio=5 tid=5115 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 39055" daemon prio=5 tid=4442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3846 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5188 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1684-thread-1" daemon prio=5 tid=3737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5713 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5296 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 46229" daemon prio=5 tid=5364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 38487" daemon prio=5 tid=4264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3662 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=4189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"pool-2010-thread-1"  prio=5 tid=4593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35685" daemon prio=5 tid=6265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2467-thread-1"  prio=5 tid=5543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor35" daemon prio=5 tid=3777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=3521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState" daemon prio=5 tid=6335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 18 on default port 39055" daemon prio=5 tid=4460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=4204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@431f9a9c" daemon prio=5 tid=5423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-1609-thread-1"  prio=5 tid=3915 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2001-thread-1"  prio=5 tid=4965 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3814 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5913 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5738" daemon prio=5 tid=5738 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2353f450-1"  prio=5 tid=5583 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-1D6529F2DD3F-StateMachineUpdater" daemon prio=5 tid=4988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 39055" daemon prio=5 tid=4406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1123259274-4850" daemon prio=5 tid=4850 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5743" daemon prio=5 tid=5743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 44881" daemon prio=5 tid=4280 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1123259274-4847" daemon prio=5 tid=4847 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp63361978-6278" daemon prio=5 tid=6278 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-SegmentedRaftLogWorker"  prio=5 tid=3933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 43809" daemon prio=5 tid=5415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1595-thread-1"  prio=5 tid=3602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4756" daemon prio=5 tid=4756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4634 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=2086 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker"  prio=5 tid=5936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1839728377-3653" daemon prio=5 tid=3653 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3586 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5425" daemon prio=5 tid=5425 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=4916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=5851 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4778" daemon prio=5 tid=4778 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3804" daemon prio=5 tid=3804 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor34" daemon prio=5 tid=3706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2067-thread-1"  prio=5 tid=4663 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 44881" daemon prio=5 tid=4276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5744" daemon prio=5 tid=5744 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6316 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3843 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7b76724e" daemon prio=5 tid=4286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-3B0E36956B86->d7e32a70-9f0d-4f10-913d-abe3b834186e-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4861 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-214AFAC73B05-LeaderStateImpl" daemon prio=5 tid=3984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 9 on default port 35685" daemon prio=5 tid=6264 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2423-thread-1"  prio=5 tid=5440 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4288" daemon prio=5 tid=4288 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 39055" daemon prio=5 tid=4461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=4184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3146 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-2"  prio=5 tid=5596 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4565 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"675cd09c-5451-427a-be54-02ea82412c70@group-3E290E99B399-LeaderStateImpl" daemon prio=5 tid=3992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 2 on default port 44881" daemon prio=5 tid=4267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=3770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 35685" daemon prio=5 tid=6271 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4835 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=6186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5196 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1946881053-5544" daemon prio=5 tid=5544 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4290" daemon prio=5 tid=4290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6349 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1775990862-3758" daemon prio=5 tid=3758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4810 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$415/1143321331.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=4955 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1717-thread-1"  prio=5 tid=3961 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ed2a30c" daemon prio=5 tid=6276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp387085649-4496" daemon prio=5 tid=4496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5561 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 44737" daemon prio=5 tid=4229 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4151 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 35677" daemon prio=5 tid=6232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3875 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5560 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5281 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5883 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3143 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 37321" daemon prio=5 tid=5386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 38487" daemon prio=5 tid=4249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 43809" daemon prio=5 tid=5418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer4" daemon prio=5 tid=566 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-1878-thread-1"  prio=5 tid=4354 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6179 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 43069" daemon prio=5 tid=6247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderStateImpl" daemon prio=5 tid=6134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=5447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5854 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp416885486-5793" daemon prio=5 tid=5793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 37321" daemon prio=5 tid=5394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5740" daemon prio=5 tid=5740 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=5850 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 42297" daemon prio=5 tid=3545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3248 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1639-thread-1"  prio=5 tid=3932 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4558 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6342 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5833 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread1" daemon prio=5 tid=6170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3f325510-1"  prio=5 tid=3579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=4420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE-StateMachineUpdater" daemon prio=5 tid=3909 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=473 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-29CE992F551B-StateMachineUpdater" daemon prio=5 tid=3964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 44881" daemon prio=5 tid=4282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1775990862-3754" daemon prio=5 tid=3754 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-2"  prio=5 tid=5597 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-StateMachineUpdater" daemon prio=5 tid=5941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 43809" daemon prio=5 tid=5407 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"grpc-default-executor-7" daemon prio=5 tid=571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"prometheus" daemon prio=5 tid=6214 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.util.regex.Pattern$GroupHead.match(Pattern.java:4672)
        at java.util.regex.Pattern$NotBehind.match(Pattern.java:5216)
        at java.util.regex.Pattern$Branch.match(Pattern.java:4618)
        at java.util.regex.Pattern$Start.match(Pattern.java:3475)
        at java.util.regex.Matcher.search(Matcher.java:1248)
        at java.util.regex.Matcher.find(Matcher.java:637)
        at java.util.regex.Pattern.split(Pattern.java:1209)
        at java.util.regex.Pattern.split(Pattern.java:1273)
        at org.apache.hadoop.hdds.utils.PrometheusMetricsSinkUtil.normalizeName(PrometheusMetricsSinkUtil.java:102)
        at org.apache.hadoop.hdds.utils.PrometheusMetricsSinkUtil.prometheusName(PrometheusMetricsSinkUtil.java:93)
        at org.apache.hadoop.hdds.server.http.PrometheusMetricsSink.putMetrics(PrometheusMetricsSink.java:69)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:184)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.consume(MetricsSinkAdapter.java:43)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:87)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"IPC Server Responder" daemon prio=5 tid=4195 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Under Replicated Processor" daemon prio=5 tid=6188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=4098 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5849 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-3B0E36956B86->87fc5ae4-06d7-4dd6-a957-d888d3372c6b-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4294" daemon prio=5 tid=4294 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-12" daemon prio=5 tid=3636 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=6213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkReader-ELG-0" daemon prio=5 tid=4882 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp55342505-4596" daemon prio=5 tid=4596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread1" daemon prio=5 tid=6337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35685" daemon prio=5 tid=6258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1674118296-4751" daemon prio=5 tid=4751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"f322f364-3549-40ba-952a-b6c14b6ec896@group-AC5FEBAEEB47-StateMachineUpdater" daemon prio=5 tid=4995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3801-acceptor-0@3fd81316-ServerConnector@5a7d992{HTTP/1.1, (http/1.1)}{0.0.0.0:36481}" daemon prio=3 tid=3801 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5503" daemon prio=5 tid=5503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35677" daemon prio=5 tid=6233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp521996155-4671" daemon prio=5 tid=4671 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4702 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4909 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 39055" daemon prio=5 tid=4455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 3 on default port 42297" daemon prio=5 tid=3541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3824 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 43069" daemon prio=5 tid=6244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2173-thread-1"  prio=5 tid=4817 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3663 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=3448 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$543/1595429823.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-StateMachineUpdater" daemon prio=5 tid=5948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 46229" daemon prio=5 tid=5365 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp604936234-3803" daemon prio=5 tid=3803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5823" daemon prio=5 tid=5823 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4639 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=475 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5822" daemon prio=5 tid=5822 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-71F94BFB4678-StateMachineUpdater" daemon prio=5 tid=4985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp2132414949-3578" daemon prio=5 tid=3578 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 43069" daemon prio=5 tid=6249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6345 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker"  prio=5 tid=5975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5847 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=4190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:136)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4930 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=4285 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5739-acceptor-0@46034267-ServerConnector@5f99f66b{HTTP/1.1, (http/1.1)}{0.0.0.0:42345}" daemon prio=3 tid=5739 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5459" daemon prio=5 tid=5459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-3"  prio=5 tid=5600 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4928 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872-impl-thread1"  prio=5 tid=5735 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=4210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker"  prio=5 tid=5950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp62694296-4820" daemon prio=5 tid=4820 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-71F94BFB4678-SegmentedRaftLogWorker"  prio=5 tid=4983 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3960 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3678" daemon prio=5 tid=3678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5576-acceptor-0@2cf9c294-ServerConnector@3a317763{HTTP/1.1, (http/1.1)}{0.0.0.0:40403}" daemon prio=3 tid=5576 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=4351 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:615)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:258)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$543/1595429823.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5578" daemon prio=5 tid=5578 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 38487" daemon prio=5 tid=4248 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=3881 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-2757-thread-1"  prio=5 tid=6277 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 37321" daemon prio=5 tid=5391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"79dbe8b6-7eb3-4f40-885c-9b270e3bff9d-impl-thread1"  prio=5 tid=5814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 37321" daemon prio=5 tid=5346 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#2" daemon prio=5 tid=6310 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3703 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4878 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-StateMachineUpdater" daemon prio=5 tid=5945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=4212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 43069" daemon prio=5 tid=6237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp55342505-4599" daemon prio=5 tid=4599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 35677"  prio=5 tid=6200 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"ReplicationMonitor" daemon prio=5 tid=5335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:667)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$422/1058298062.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5209 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 35685"  prio=5 tid=6192 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"EventQueue-DatanodeCommandQueueUpdatedForDatanodeCommandCountUpdatedHandler" daemon prio=5 tid=5916 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor58" daemon prio=5 tid=5908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-5"  prio=5 tid=5604 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp687067551-5431" daemon prio=5 tid=5431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2132-thread-1" daemon prio=5 tid=4770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 43069" daemon prio=5 tid=6253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1699-thread-1"  prio=5 tid=3752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=6275 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1123259274-4851" daemon prio=5 tid=4851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24-impl-thread1"  prio=5 tid=5541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5817" daemon prio=5 tid=5817 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 37099" daemon prio=5 tid=5474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@a602aaf" daemon prio=5 tid=3569 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#3" daemon prio=5 tid=6346 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 35685" daemon prio=5 tid=6267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-78c55d8a-1"  prio=5 tid=3808 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4779" daemon prio=5 tid=4779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-0"  prio=5 tid=5330 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker"  prio=5 tid=5946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4589 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5899 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=5852 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp499537176-5824" daemon prio=5 tid=5824 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4193 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 13 on default port 44881" daemon prio=5 tid=4278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 38487" daemon prio=5 tid=4198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"d483f22f-9e25-4e72-9070-8c514e67a945@group-710D643B4E75-LeaderStateImpl" daemon prio=5 tid=5089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=6204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 43069" daemon prio=5 tid=6241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 44881" daemon prio=5 tid=4274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"null-request--thread1" daemon prio=5 tid=5326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3811 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=5455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=3516 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=5449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 46229" daemon prio=5 tid=5378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4904 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2195-thread-1"  prio=5 tid=4844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->675cd09c-5451-427a-be54-02ea82412c70-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3976 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-1D6529F2DD3F-LeaderStateImpl" daemon prio=5 tid=5050 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Command processor thread" daemon prio=5 tid=4833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 44737" daemon prio=5 tid=4244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp956311744-3676" daemon prio=5 tid=3676 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread2" daemon prio=5 tid=6336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 35685" daemon prio=5 tid=6255 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1123259274-4845" daemon prio=5 tid=4845 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-299db5f9-1"  prio=5 tid=3684 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5905 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3144 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1123259274-4852" daemon prio=5 tid=4852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1558-thread-1" daemon prio=5 tid=3565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ecb32549-f2ba-48dc-a0ed-8802c582cc24-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5540 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3531" daemon prio=5 tid=3531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2059-thread-1"  prio=5 tid=4978 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4885 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 35685" daemon prio=5 tid=6191 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderStateImpl" daemon prio=5 tid=6095 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp55342505-4601" daemon prio=5 tid=4601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1115/122963824.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5656 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-LeaderStateImpl" daemon prio=5 tid=3988 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-8"  prio=5 tid=5649 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1668724731-4782" daemon prio=5 tid=4782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3771 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3775 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1608061230-5457" daemon prio=5 tid=5457 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/692596438.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 44881" daemon prio=5 tid=4270 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"675cd09c-5451-427a-be54-02ea82412c70@group-48BDBC021DAE-StateMachineUpdater" daemon prio=5 tid=3918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5860 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 38487" daemon prio=5 tid=4254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 37099" daemon prio=5 tid=5477 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 6 on default port 46229" daemon prio=5 tid=5368 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4828 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 44737" daemon prio=5 tid=4231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2591-thread-1"  prio=5 tid=5737 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5758 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4761 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d-server-thread3" daemon prio=5 tid=6174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 42297" daemon prio=5 tid=3544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@469373f1" daemon prio=5 tid=4462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3819 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5625 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3677-acceptor-0@2ef06007-ServerConnector@28312150{HTTP/1.1, (http/1.1)}{0.0.0.0:46193}" daemon prio=3 tid=3677 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35677" daemon prio=5 tid=6219 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#3" daemon prio=5 tid=6343 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4753" daemon prio=5 tid=4753 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp521996155-4667" daemon prio=5 tid=4667 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2550-thread-1"  prio=5 tid=5942 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3712 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-b532d524-ffe1-4d4a-8932-48bdbc021dae-6"  prio=5 tid=5640 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 44737" daemon prio=5 tid=4237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"675cd09c-5451-427a-be54-02ea82412c70@group-3E290E99B399-StateMachineUpdater" daemon prio=5 tid=3925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4870 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2187-thread-1"  prio=5 tid=5013 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 42297" daemon prio=5 tid=3540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1775990862-3759" daemon prio=5 tid=3759 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:35685 - 0 "  prio=5 tid=3695 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp604936234-3805" daemon prio=5 tid=3805 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"SstFilteringService#0" daemon prio=5 tid=3527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1527033392-3604-acceptor-0@b3a9e47-ServerConnector@5fe51e61{HTTP/1.1, (http/1.1)}{0.0.0.0:43879}" daemon prio=3 tid=3604 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5858 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 43809" daemon prio=5 tid=5406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4910 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2609-thread-1"  prio=5 tid=5954 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5505 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1553-thread-1"  prio=5 tid=3528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 35685" daemon prio=5 tid=6261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=4563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 43809" daemon prio=5 tid=5408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 0 on default port 42297" daemon prio=5 tid=3538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:44881 - 0 "  prio=5 tid=4795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread2" daemon prio=5 tid=6339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=6203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@54ce1345" daemon prio=5 tid=5763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4923 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5582" daemon prio=5 tid=5582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5130 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1367866487-4438" daemon prio=5 tid=4438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp6210460-3532" daemon prio=5 tid=3532 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2117-thread-1"  prio=5 tid=4989 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3749 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=6202 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"79dbe8b6-7eb3-4f40-885c-9b270e3bff9d-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5813 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"d7e32a70-9f0d-4f10-913d-abe3b834186e-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4483 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 42297" daemon prio=5 tid=3539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2501-thread-1"  prio=5 tid=5574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState" daemon prio=5 tid=6165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"675cd09c-5451-427a-be54-02ea82412c70-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3645 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-StateMachineUpdater" daemon prio=5 tid=5968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5846 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 44881" daemon prio=5 tid=4279 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2400-thread-1"  prio=5 tid=5437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@14c11d2e" daemon prio=5 tid=4486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3587 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 38487" daemon prio=5 tid=4256 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 43069" daemon prio=5 tid=6240 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker"  prio=5 tid=5979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5853 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1249251933-4295" daemon prio=5 tid=4295 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 42297" daemon prio=5 tid=3542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=5703 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"57e34f8d-7b3e-4914-b42b-53a5fc13ebf8@group-37989A005FFA-StateMachineUpdater" daemon prio=5 tid=5016 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 39055" daemon prio=5 tid=4453 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3690 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderStateImpl" daemon prio=5 tid=6132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=4914 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-3B0E36956B86-SegmentedRaftLogWorker"  prio=5 tid=4979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"8f2e834d-419f-4eeb-b382-a8e6a25122f3-impl-thread1"  prio=5 tid=5669 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=6289 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor46" daemon prio=5 tid=4908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$749/233478659.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3874 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 39055" daemon prio=5 tid=4445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=3876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5888 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=5167 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"675cd09c-5451-427a-be54-02ea82412c70-server-thread2" daemon prio=5 tid=3981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp549850773-5577" daemon prio=5 tid=5577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=6212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4787 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5709 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1828687139-5499" daemon prio=5 tid=5499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4650 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=4427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3898 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5776 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 43809" daemon prio=5 tid=5417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3685 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=6205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1674118296-4755" daemon prio=5 tid=4755 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@76dbd36" daemon prio=5 tid=3601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp921813639-5745" daemon prio=5 tid=5745 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"57e34f8d-7b3e-4914-b42b-53a5fc13ebf8@group-37989A005FFA-LeaderStateImpl" daemon prio=5 tid=5091 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Session-HouseKeeper-1086d3d6-1"  prio=5 tid=5465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4199 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ChunkWriter-2-0" daemon prio=5 tid=5906 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5800 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=4918 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 44881" daemon prio=5 tid=4284 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 42297" daemon prio=5 tid=3554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5799 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-71747a0c-1"  prio=5 tid=4440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1123259274-4846-acceptor-0@ff28918-ServerConnector@18eaf923{HTTP/1.1, (http/1.1)}{0.0.0.0:41757}" daemon prio=3 tid=4846 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"abab8a6e-4db0-471c-b862-cc66e458241d@group-3B0E36956B86-LeaderStateImpl" daemon prio=5 tid=5037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp6210460-3534" daemon prio=5 tid=3534 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4640 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:648)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$818/2143369816.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-541d68a8-1"  prio=5 tid=4602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=3526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp429946212-5676" daemon prio=5 tid=5676 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35685" daemon prio=5 tid=6274 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"09413839-b23a-4aca-94dd-890763e4f20d-server-thread2" daemon prio=5 tid=6172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker"  prio=5 tid=5962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5706 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3693 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5694 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2099 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker"  prio=5 tid=5955 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4905 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp956311744-3683" daemon prio=5 tid=3683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker"  prio=5 tid=5959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$708/119213351.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater" daemon prio=5 tid=3913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=5136 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4697 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:336)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:517)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$816/484635452.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 43809" daemon prio=5 tid=5403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:43809 - 0 "  prio=5 tid=5877 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1565-thread-1"  prio=5 tid=3902 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4808 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3809 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 39055" daemon prio=5 tid=4450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"timer7" daemon prio=5 tid=711 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6d2d42d4" daemon prio=5 tid=4843 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4715 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5837 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"87fc5ae4-06d7-4dd6-a957-d888d3372c6b@group-3B0E36956B86-StateMachineUpdater" daemon prio=5 tid=4981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 37099" daemon prio=5 tid=5482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 35685" daemon prio=5 tid=6263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=6190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e59d0d2" daemon prio=5 tid=5486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=4423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 46229" daemon prio=5 tid=5379 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4938 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4638 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 35685" daemon prio=5 tid=6262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=6311 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6177 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5904 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5565 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5507 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2023-02-08 21:33:36,927 [Listener at 127.0.0.1/39055] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:36,931 [Listener at 127.0.0.1/39055] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:36,931 [Listener at 127.0.0.1/39055] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-08 21:33:36,931 [Listener at 127.0.0.1/39055] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-08 21:33:36,932 [Listener at 127.0.0.1/39055] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:36,932 [Listener at 127.0.0.1/39055] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:36,964 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:36,964 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:36,965 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-02-08 21:33:36,971 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:36,971 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-02-08 21:33:36,971 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:36,971 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-02-08 21:33:36,975 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-02-08 21:33:36,975 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:36,992 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 168
2023-02-08 21:33:36,992 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:168)
2023-02-08 21:33:37,007 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(476)) - Creating Volume: vol1, with user44681 as owner and space quota set to -1 bytes, counts quota set to -1
2023-02-08 21:33:37,023 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user44681
2023-02-08 21:33:37,034 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(699)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false, Replication Type set to server-side default replication type, Namespace Quota set to -1, Space Quota set to -1 
2023-02-08 21:33:37,037 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(263)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-02-08 21:33:37,042 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 168
2023-02-08 21:33:37,042 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 168
2023-02-08 21:33:37,042 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-08 21:33:37,042 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(541)) - Stopping OMDoubleBuffer flush thread
2023-02-08 21:33:37,042 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(626)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-02-08 21:33:37,048 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 168
2023-02-08 21:33:37,063 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:37,072 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:37,072 [IPC Server handler 1 on default port 43069] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-02-08 21:33:37,073 [IPC Server handler 1 on default port 43069] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-02-08 21:33:37,073 [IPC Server handler 1 on default port 43069] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-02-08 21:33:37,073 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-02-08 21:33:37,075 [JvmPauseMonitor25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-02-08 21:33:37,075 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-08 21:33:37,075 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(550)) - OMDoubleBuffer flush thread is not running.
2023-02-08 21:33:37,075 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-02-08 21:33:37,076 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-02-08 21:33:37,090 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-02-08 21:33:37,091 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-02-08 21:33:37,101 [Listener at 127.0.0.1/39055] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-08 21:33:37,101 [Listener at 127.0.0.1/39055] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-08 21:33:37,103 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@40498c8c{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-08 21:33:37,104 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@31691e6d{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:37,104 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:37,107 [Listener at 127.0.0.1/39055] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:37,107 [Listener at 127.0.0.1/39055] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:37,107 [Listener at 127.0.0.1/39055] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:37,110 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@18381bc4{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-08 21:33:37,110 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1995db10{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:37,134 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-02-08 21:33:37,136 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:37,136 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - edc82fe3-b222-4615-9e9d-46c7efcf8b1b: close
2023-02-08 21:33:37,136 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - edc82fe3-b222-4615-9e9d-46c7efcf8b1b: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:37,136 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - edc82fe3-b222-4615-9e9d-46c7efcf8b1b: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:37,137 [edc82fe3-b222-4615-9e9d-46c7efcf8b1b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xceeb679b, L:/0:0:0:0:0:0:0:0:42839] CLOSE
2023-02-08 21:33:37,137 [edc82fe3-b222-4615-9e9d-46c7efcf8b1b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xceeb679b, L:/0:0:0:0:0:0:0:0:42839] INACTIVE
2023-02-08 21:33:37,137 [edc82fe3-b222-4615-9e9d-46c7efcf8b1b-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xceeb679b, L:/0:0:0:0:0:0:0:0:42839] UNREGISTERED
2023-02-08 21:33:37,144 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-edc82fe3-b222-4615-9e9d-46c7efcf8b1b: Stopped
2023-02-08 21:33:37,176 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:37,191 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - a7bbced2-9033-4c12-a554-3fc75927eea0: close
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7: shutdown
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBD5BDFE09D7,id=a7bbced2-9033-4c12-a554-3fc75927eea0
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a7bbced2-9033-4c12-a554-3fc75927eea0: shutdown a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-FollowerState
2023-02-08 21:33:37,205 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - a7bbced2-9033-4c12-a554-3fc75927eea0: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70: shutdown
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-45D369A96D70,id=a7bbced2-9033-4c12-a554-3fc75927eea0
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - a7bbced2-9033-4c12-a554-3fc75927eea0: shutdown a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-LeaderStateImpl
2023-02-08 21:33:37,205 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:37,206 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:37,211 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-FollowerState was interrupted
2023-02-08 21:33:37,211 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DBD5BDFE09D7: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-1/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35
2023-02-08 21:33:37,212 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-45D369A96D70: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-1/data/ratis/7d85cdec-ca2a-4102-b671-45d369a96d70/sm/snapshot.1_0
2023-02-08 21:33:37,212 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - a7bbced2-9033-4c12-a554-3fc75927eea0: installSnapshot onError, lastRequest: 28ccfb07-ee71-476a-89f2-90668a6b099c->a7bbced2-9033-4c12-a554-3fc75927eea0#216-t1,previous=(t:1, i:34),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:35), METADATAENTRY(c:34): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:37,213 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DBD5BDFE09D7: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-1/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35 took: 3 ms
2023-02-08 21:33:37,213 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater: Took a snapshot at index 35
2023-02-08 21:33:37,214 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-02-08 21:33:37,212 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - a7bbced2-9033-4c12-a554-3fc75927eea0: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:37,215 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-StateMachineUpdater: set stopIndex = 35
2023-02-08 21:33:37,215 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7: closes. applyIndex: 35
2023-02-08 21:33:37,215 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:37,215 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-DBD5BDFE09D7-SegmentedRaftLogWorker close()
2023-02-08 21:33:37,212 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:33:37,219 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-45D369A96D70: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-1/data/ratis/7d85cdec-ca2a-4102-b671-45d369a96d70/sm/snapshot.1_0 took: 13 ms
2023-02-08 21:33:37,219 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 36 -> 35
2023-02-08 21:33:37,219 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:37,213 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:33:37,220 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:33:37,212 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - a7bbced2-9033-4c12-a554-3fc75927eea0: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:37,220 [a7bbced2-9033-4c12-a554-3fc75927eea0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb4b544f0, L:/0:0:0:0:0:0:0:0:43315] CLOSE
2023-02-08 21:33:37,220 [a7bbced2-9033-4c12-a554-3fc75927eea0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb4b544f0, L:/0:0:0:0:0:0:0:0:43315] INACTIVE
2023-02-08 21:33:37,220 [a7bbced2-9033-4c12-a554-3fc75927eea0-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb4b544f0, L:/0:0:0:0:0:0:0:0:43315] UNREGISTERED
2023-02-08 21:33:37,219 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:37,221 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70: closes. applyIndex: 0
2023-02-08 21:33:37,226 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:37,226 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:33:37,226 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:37,226 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 34 -> 33
2023-02-08 21:33:37,244 [a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:37,244 [a7bbced2-9033-4c12-a554-3fc75927eea0-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - a7bbced2-9033-4c12-a554-3fc75927eea0@group-45D369A96D70-SegmentedRaftLogWorker close()
2023-02-08 21:33:37,249 [JvmPauseMonitor27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-a7bbced2-9033-4c12-a554-3fc75927eea0: Stopped
2023-02-08 21:33:37,324 [Listener at 127.0.0.1/39055] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 216 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:37,328 [Listener at 127.0.0.1/39055] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-02-08 21:33:37,328 [Listener at 127.0.0.1/39055] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-02-08 21:33:37,328 [Listener at 127.0.0.1/39055] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-02-08 21:33:37,328 [Listener at 127.0.0.1/39055] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-08 21:33:37,340 [Listener at 127.0.0.1/39055] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-08 21:33:37,347 [Listener at 127.0.0.1/39055] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-08 21:33:37,348 [Listener at 127.0.0.1/39055] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-08 21:33:37,353 [Listener at 127.0.0.1/39055] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-08 21:33:37,353 [Listener at 127.0.0.1/39055] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-08 21:33:37,353 [Listener at 127.0.0.1/39055] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:33:37,353 [Listener at 127.0.0.1/39055] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-08 21:33:37,354 [Listener at 127.0.0.1/39055] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-08 21:33:37,354 [Listener at 127.0.0.1/39055] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-08 21:33:37,354 [Listener at 127.0.0.1/39055] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-08 21:33:37,355 [Listener at 127.0.0.1/39055] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-08 21:33:37,356 [Listener at 127.0.0.1/39055] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-02-08 21:33:37,356 [Listener at 127.0.0.1/39055] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-02-08 21:33:37,356 [Listener at 127.0.0.1/39055] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-02-08 21:33:37,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:37,363 [Listener at 127.0.0.1/39055] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:37,363 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-08 21:33:37,364 [Listener at 0.0.0.0/43809] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:37,365 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-08 21:33:37,366 [Listener at 0.0.0.0/37321] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:37,381 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-08 21:33:37,388 [Listener at 0.0.0.0/46229] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-08 21:33:37,388 [Listener at 0.0.0.0/46229] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-08 21:33:37,388 [Listener at 0.0.0.0/46229] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-08 21:33:37,388 [Listener at 0.0.0.0/46229] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:46229
2023-02-08 21:33:37,388 [Listener at 0.0.0.0/46229] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-02-08 21:33:37,400 [Listener at 0.0.0.0/46229] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:46229
2023-02-08 21:33:37,400 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:37,404 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-08 21:33:37,411 [Listener at 0.0.0.0/46229] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:37321
2023-02-08 21:33:37,411 [Listener at 0.0.0.0/46229] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:37321
2023-02-08 21:33:37,411 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:37,411 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-08 21:33:37,417 [Listener at 0.0.0.0/46229] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:43809
2023-02-08 21:33:37,417 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:37,417 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-08 21:33:37,425 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@431f9a9c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:37,426 [Listener at 0.0.0.0/46229] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-02-08 21:33:37,426 [Listener at 0.0.0.0/46229] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:37,426 [Listener at 0.0.0.0/46229] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:37,427 [Listener at 0.0.0.0/46229] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42225
2023-02-08 21:33:37,428 [Listener at 0.0.0.0/46229] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:37,429 [Listener at 0.0.0.0/46229] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:37,429 [Listener at 0.0.0.0/46229] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:37,430 [Listener at 0.0.0.0/46229] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-08 21:33:37,430 [Listener at 0.0.0.0/46229] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6438fcfa{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:37,430 [Listener at 0.0.0.0/46229] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@70df912{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-08 21:33:37,436 [Listener at 0.0.0.0/46229] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6890f8f4{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:33:37,440 [Listener at 0.0.0.0/46229] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@18374338{HTTP/1.1, (http/1.1)}{0.0.0.0:42225}
2023-02-08 21:33:37,440 [Listener at 0.0.0.0/46229] INFO  server.Server (Server.java:doStart(415)) - Started @186433ms
2023-02-08 21:33:37,440 [Listener at 0.0.0.0/46229] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:37,441 [Listener at 0.0.0.0/46229] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:42225
2023-02-08 21:33:37,441 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:37,442 [Listener at 0.0.0.0/46229] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-02-08 21:33:37,443 [Listener at 0.0.0.0/46229] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-02-08 21:33:37,443 [Listener at 0.0.0.0/46229] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-02-08 21:33:37,443 [Listener at 0.0.0.0/46229] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-02-08 21:33:37,443 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:37,443 [Listener at 0.0.0.0/46229] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-02-08 21:33:37,472 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:37,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:37,472 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:37,540 [Listener at 0.0.0.0/46229] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 96 ms to scan 2 urls, producing 160 keys and 447 values [using 2 cores]
2023-02-08 21:33:37,540 [Listener at 0.0.0.0/46229] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-02-08 21:33:37,541 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:37,541 [Listener at 0.0.0.0/46229] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:37321]
2023-02-08 21:33:37,542 [Listener at 0.0.0.0/46229] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:37321]
2023-02-08 21:33:37,559 [Listener at 0.0.0.0/46229] INFO  om.OzoneManager (OzoneManager.java:<init>(612)) - OM start with adminUsers: [runner]
2023-02-08 21:33:37,560 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:37,560 [Listener at 0.0.0.0/46229] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-02-08 21:33:37,560 [Listener at 0.0.0.0/46229] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-02-08 21:33:37,741 [Listener at 0.0.0.0/46229] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(740)) - S3 Multi-Tenancy is disabled
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4110)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(436)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:37,748 [Listener at 0.0.0.0/46229] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-02-08 21:33:37,749 [Listener at 0.0.0.0/46229] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(160)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:42965
2023-02-08 21:33:37,749 [Listener at 0.0.0.0/46229] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 42965 (fallback to raft.grpc.server.port)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 42965 (fallback to raft.grpc.server.port)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 42965 (custom)
2023-02-08 21:33:37,751 [Listener at 0.0.0.0/46229] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:37,752 [Listener at 0.0.0.0/46229] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = DISABLED (default)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:37,753 [Listener at 0.0.0.0/46229] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis] (custom)
2023-02-08 21:33:37,754 [Listener at 0.0.0.0/46229] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:42965|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@3de3ecbc[Not completed]
2023-02-08 21:33:37,754 [Listener at 0.0.0.0/46229] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(2068)) - OzoneManager Ratis server initialized at port 42965
2023-02-08 21:33:37,754 [Listener at 0.0.0.0/46229] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1120)) - Creating RPC Server
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:42965|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:42965|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:37,754 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis] (custom)
2023-02-08 21:33:37,755 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:37,755 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:37,755 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-02-08 21:33:37,755 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-02-08 21:33:37,755 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:37,757 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:37,757 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:37,757 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:37,757 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:37,757 [pool-2423-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:38,357 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 139285650ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,357 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-57e34f8d-7b3e-4914-b42b-53a5fc13ebf8: Detected pause in JVM or host machine (eg GC): pause of approximately 196634253ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,357 [JvmPauseMonitor39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-feb16a71-ed08-43b3-b68b-8905cd82796b: Detected pause in JVM or host machine (eg GC): pause of approximately 199083714ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,357 [JvmPauseMonitor38] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-cf311c28-b71f-4054-8501-4b3584e1b394: Detected pause in JVM or host machine (eg GC): pause of approximately 199174015ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,357 [JvmPauseMonitor35] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-5ef0eb67-7d25-4fae-babe-11dd56e72526: Detected pause in JVM or host machine (eg GC): pause of approximately 199255918ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,357 [JvmPauseMonitor40] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-712f2f09-531f-4a9c-a178-4f5e906f6733: Detected pause in JVM or host machine (eg GC): pause of approximately 200274542ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor28] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: Detected pause in JVM or host machine (eg GC): pause of approximately 200331944ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor37] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-51a90d96-5277-44ed-beb8-25e5b922217c: Detected pause in JVM or host machine (eg GC): pause of approximately 200387345ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor26] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-28ccfb07-ee71-476a-89f2-90668a6b099c: Detected pause in JVM or host machine (eg GC): pause of approximately 200459148ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor33] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 200818356ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-675cd09c-5451-427a-be54-02ea82412c70: Detected pause in JVM or host machine (eg GC): pause of approximately 216759547ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor32] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-bf7e9559-dd59-4a20-a97c-cd7084a338be: Detected pause in JVM or host machine (eg GC): pause of approximately 216896150ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor29] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1207ef06-85db-4c1a-b277-21f94a0a5063: Detected pause in JVM or host machine (eg GC): pause of approximately 217046953ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor31] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d8e3aff9-c084-4a9b-80b3-0f0f848c063d: Detected pause in JVM or host machine (eg GC): pause of approximately 217159056ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,358 [JvmPauseMonitor34] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1ea3a110-dd3d-4689-8865-83ed09c3caaf: Detected pause in JVM or host machine (eg GC): pause of approximately 217253659ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,359 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-87fc5ae4-06d7-4dd6-a957-d888d3372c6b: Detected pause in JVM or host machine (eg GC): pause of approximately 235084894ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,359 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-f322f364-3549-40ba-952a-b6c14b6ec896: Detected pause in JVM or host machine (eg GC): pause of approximately 246363071ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,360 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-abab8a6e-4db0-471c-b862-cc66e458241d: Detected pause in JVM or host machine (eg GC): pause of approximately 247932209ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 2 containers.
2023-02-08 21:33:38,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:38,361 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d7e32a70-9f0d-4f10-913d-abe3b834186e: Detected pause in JVM or host machine (eg GC): pause of approximately 290129743ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,364 [JvmPauseMonitor46] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-61e2ac77-ead7-4e07-97d9-f28a506a07a9: Detected pause in JVM or host machine (eg GC): pause of approximately 399258714ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:38,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:38,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-08 21:33:38,365 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 7, replicaIndex: 2, force: true] for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=3bb5c58a-1b34-4b84-9865-58cef4b6f75c, stateEnterTime=2023-02-08T21:33:01.360Z, owner=om1} to bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:38,365 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 8, replicaIndex: 4, force: true] for container ContainerInfo{id=#8, state=CLOSED, pipelineID=PipelineID=76636527-b77f-451d-8523-9624b6d4b7b5, stateEnterTime=2023-02-08T21:33:01.778Z, owner=om1} to a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:38,365 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 9, replicaIndex: 3, force: true] for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=f6241e4e-e339-473c-9c52-50c3deddb661, stateEnterTime=2023-02-08T21:33:01.969Z, owner=om1} to edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:38,365 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 10, replicaIndex: 5, force: true] for container ContainerInfo{id=#10, state=CLOSED, pipelineID=PipelineID=134fdd5a-d2c1-4ce7-bd6e-7f95c54aaa38, stateEnterTime=2023-02-08T21:33:02.092Z, owner=om1} to edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:38,366 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(431)) - Sending command [deleteContainerCommand: containerID: 11, replicaIndex: 1, force: true] for container ContainerInfo{id=#11, state=CLOSED, pipelineID=PipelineID=09bc0d44-b511-457f-9214-822554fa9b35, stateEnterTime=2023-02-08T21:33:02.214Z, owner=om1} to edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:38,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 5 containers with health state counts {OVER_REPLICATED=5},failed processing 0
2023-02-08 21:33:38,366 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:38,368 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d483f22f-9e25-4e72-9070-8c514e67a945: Detected pause in JVM or host machine (eg GC): pause of approximately 574454603ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=473ms
GC pool 'PS Scavenge' had collection(s): count=1 time=89ms
2023-02-08 21:33:38,472 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:38,472 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:38,472 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:38,609 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:38,610 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 33 -> 32
2023-02-08 21:33:38,610 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:38,610 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 32 -> 31
2023-02-08 21:33:38,619 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:38,620 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 32 -> 31
2023-02-08 21:33:38,620 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:38,620 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 31 -> 30
2023-02-08 21:33:38,724 [Listener at 0.0.0.0/46229] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 970 ms to scan 19 urls, producing 69 keys and 4757 values [using 2 cores]
2023-02-08 21:33:38,725 [Listener at 0.0.0.0/46229] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:38,726 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-02-08 21:33:38,746 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-02-08 21:33:38,757 [Listener at 127.0.0.1/37099] INFO  om.OzoneManager (OzoneManager.java:start(1536)) - OzoneManager RPC server is listening at localhost/127.0.0.1:37099
2023-02-08 21:33:38,757 [Listener at 127.0.0.1/37099] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(555)) - Starting OzoneManagerRatisServer om1 at port 42965
2023-02-08 21:33:38,757 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-02-08 21:33:38,758 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:38,759 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:38,760 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:38,761 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:38,762 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-02-08 21:33:38,762 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:42965|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-02-08 21:33:38,768 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-02-08 21:33:38,769 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:38,769 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-02-08 21:33:38,769 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-02-08 21:33:38,769 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-02-08 21:33:38,769 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:38,769 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:38,769 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-02-08 21:33:38,770 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 42965
2023-02-08 21:33:38,770 [Listener at 127.0.0.1/37099] INFO  om.OzoneManager (OzoneManager.java:start(1552)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-02-08 21:33:38,771 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-02-08 21:33:38,772 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-02-08 21:33:38,772 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:38,773 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:38,776 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:38,777 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:38,779 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-02-08 21:33:38,779 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:38,779 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:38,779 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34653
2023-02-08 21:33:38,779 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:38,785 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:38,785 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:38,785 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:38,786 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5412d43d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:38,786 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@579bd66{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-08 21:33:38,788 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@a9ffda1{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-08 21:33:38,792 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@4a3aa919{HTTP/1.1, (http/1.1)}{0.0.0.0:34653}
2023-02-08 21:33:38,792 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @187785ms
2023-02-08 21:33:38,792 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:38,793 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of ozoneManager listening at http://0.0.0.0:34653
2023-02-08 21:33:38,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:38,793 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-02-08 21:33:38,800 [Listener at 127.0.0.1/37099] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(2012)) - Trash Interval set to 0. Files deleted won't move to trash
2023-02-08 21:33:38,800 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3e59d0d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:38,815 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:38,816 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:38,816 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:38,828 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:38,847 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:38,897 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 49 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:38,898 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:38,899 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:38,900 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:38,900 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds
2023-02-08 21:33:38,902 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds
2023-02-08 21:33:38,912 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis to VolumeSet
2023-02-08 21:33:38,912 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis
2023-02-08 21:33:38,912 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis
2023-02-08 21:33:38,922 [Thread-3190] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds
2023-02-08 21:33:38,923 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:38,924 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:38,925 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:38,926 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:38,927 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:38,927 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:38,927 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:38,928 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis] (custom)
2023-02-08 21:33:38,928 [09413839-b23a-4aca-94dd-890763e4f20d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb9200c95] REGISTERED
2023-02-08 21:33:38,929 [09413839-b23a-4aca-94dd-890763e4f20d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb9200c95] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:38,929 [09413839-b23a-4aca-94dd-890763e4f20d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb9200c95, L:/0:0:0:0:0:0:0:0:44623] ACTIVE
2023-02-08 21:33:38,930 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:38,932 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:38,932 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:38,933 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:38,933 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:38,934 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:38,934 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:38,935 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:38,935 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:38,935 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 33523
2023-02-08 21:33:38,935 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:38,936 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:38,936 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:38,936 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-08 21:33:38,937 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@63198ef9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:38,937 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@727484c9{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:39,108 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7ff80d38{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-33523-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7666976953492691839/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:39,113 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2202c29{HTTP/1.1, (http/1.1)}{0.0.0.0:33523}
2023-02-08 21:33:39,113 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @188106ms
2023-02-08 21:33:39,113 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:39,114 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:33523
2023-02-08 21:33:39,114 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:39,114 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:39,114 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:39,114 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:39,127 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:39,127 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3049b512] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:39,131 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/meta/datanode.id
2023-02-08 21:33:39,147 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:39,182 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-4/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-6f262058-1a66-43ac-8b49-e90be4fbc807/container.db for volume DS-6f262058-1a66-43ac-8b49-e90be4fbc807
2023-02-08 21:33:39,184 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:39,184 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:39,190 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:39,203 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@89178b4{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:39,206 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@67521a79{HTTP/1.1, (http/1.1)}{0.0.0.0:41881}
2023-02-08 21:33:39,206 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:39,208 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4d3bde85{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:39,211 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5e8a678a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:39,217 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:39,227 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 1207ef06-85db-4c1a-b277-21f94a0a5063: close
2023-02-08 21:33:39,228 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 1207ef06-85db-4c1a-b277-21f94a0a5063: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:39,228 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04: shutdown
2023-02-08 21:33:39,236 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - edc82fe3-b222-4615-9e9d-46c7efcf8b1b Close channels
2023-02-08 21:33:39,236 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d Close channels
2023-02-08 21:33:39,237 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CB1F603DAA04,id=1207ef06-85db-4c1a-b277-21f94a0a5063
2023-02-08 21:33:39,237 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1207ef06-85db-4c1a-b277-21f94a0a5063: shutdown 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-LeaderStateImpl
2023-02-08 21:33:39,237 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:39,237 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:39,237 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-CB1F603DAA04: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-3/data/ratis/af681b93-3d56-4a30-9b10-cb1f603daa04/sm/snapshot.1_0
2023-02-08 21:33:39,239 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-CB1F603DAA04: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-3/data/ratis/af681b93-3d56-4a30-9b10-cb1f603daa04/sm/snapshot.1_0 took: 2 ms
2023-02-08 21:33:39,240 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:39,240 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:39,240 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04: closes. applyIndex: 0
2023-02-08 21:33:39,240 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:39,240 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-CB1F603DAA04-SegmentedRaftLogWorker close()
2023-02-08 21:33:39,248 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4: shutdown
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8A54AAA19D4,id=1207ef06-85db-4c1a-b277-21f94a0a5063
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 1207ef06-85db-4c1a-b277-21f94a0a5063: shutdown 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-LeaderStateImpl
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-E8A54AAA19D4: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-3/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0
2023-02-08 21:33:39,249 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:39,250 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: Completed APPEND_ENTRIES, lastRequest: 1207ef06-85db-4c1a-b277-21f94a0a5063->d8e3aff9-c084-4a9b-80b3-0f0f848c063d#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "d8e3aff9-c084-4a9b-80b3-0f0f848c063d"
address: "10.1.0.108:33215"
dataStreamAddress: "10.1.0.108:45127"
clientAddress: "10.1.0.108:33215"
adminAddress: "10.1.0.108:33215"
startupRole: FOLLOWER
,id: "bf7e9559-dd59-4a20-a97c-cd7084a338be"
address: "10.1.0.108:33027"
dataStreamAddress: "10.1.0.108:44847"
clientAddress: "10.1.0.108:33027"
adminAddress: "10.1.0.108:33027"
startupRole: FOLLOWER
,id: "1207ef06-85db-4c1a-b277-21f94a0a5063"
address: "10.1.0.108:36325"
priority: 1
dataStreamAddress: "10.1.0.108:35823"
clientAddress: "10.1.0.108:36325"
adminAddress: "10.1.0.108:36325"
startupRole: FOLLOWER
, old:)
2023-02-08 21:33:39,250 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-E8A54AAA19D4: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-3/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0 took: 0 ms
2023-02-08 21:33:39,250 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:39,250 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:39,250 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: Completed APPEND_ENTRIES, lastRequest: null
2023-02-08 21:33:39,250 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:33:39,251 [grpc-default-executor-8] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: Completed APPEND_ENTRIES, lastRequest: null
2023-02-08 21:33:39,251 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:33:39,251 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:33:39,251 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be: nextIndex: updateUnconditionally 1 -> 0
2023-02-08 21:33:39,252 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: Completed APPEND_ENTRIES, lastRequest: 1207ef06-85db-4c1a-b277-21f94a0a5063->bf7e9559-dd59-4a20-a97c-cd7084a338be#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "d8e3aff9-c084-4a9b-80b3-0f0f848c063d"
address: "10.1.0.108:33215"
dataStreamAddress: "10.1.0.108:45127"
clientAddress: "10.1.0.108:33215"
adminAddress: "10.1.0.108:33215"
startupRole: FOLLOWER
,id: "bf7e9559-dd59-4a20-a97c-cd7084a338be"
address: "10.1.0.108:33027"
dataStreamAddress: "10.1.0.108:44847"
clientAddress: "10.1.0.108:33027"
adminAddress: "10.1.0.108:33027"
startupRole: FOLLOWER
,id: "1207ef06-85db-4c1a-b277-21f94a0a5063"
address: "10.1.0.108:36325"
priority: 1
dataStreamAddress: "10.1.0.108:35823"
clientAddress: "10.1.0.108:36325"
adminAddress: "10.1.0.108:36325"
startupRole: FOLLOWER
, old:)
2023-02-08 21:33:39,252 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:33:39,252 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->bf7e9559-dd59-4a20-a97c-cd7084a338be: nextIndex: updateUnconditionally 0 -> 0
2023-02-08 21:33:39,258 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-GrpcLogAppender: Failed to getClient for d8e3aff9-c084-4a9b-80b3-0f0f848c063d
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1207ef06-85db-4c1a-b277-21f94a0a5063 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:39,258 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - bf7e9559-dd59-4a20-a97c-cd7084a338be Close channels
2023-02-08 21:33:39,258 [grpc-default-executor-3] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4->d8e3aff9-c084-4a9b-80b3-0f0f848c063d-GrpcLogAppender: Failed to getClient for d8e3aff9-c084-4a9b-80b3-0f0f848c063d
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1207ef06-85db-4c1a-b277-21f94a0a5063 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:432)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:465)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:39,259 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4: closes. applyIndex: 0
2023-02-08 21:33:39,259 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 1207ef06-85db-4c1a-b277-21f94a0a5063: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:39,264 [1207ef06-85db-4c1a-b277-21f94a0a5063-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x257e2b5d, L:/0:0:0:0:0:0:0:0:35823] CLOSE
2023-02-08 21:33:39,264 [1207ef06-85db-4c1a-b277-21f94a0a5063-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x257e2b5d, L:/0:0:0:0:0:0:0:0:35823] INACTIVE
2023-02-08 21:33:39,264 [1207ef06-85db-4c1a-b277-21f94a0a5063-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x257e2b5d, L:/0:0:0:0:0:0:0:0:35823] UNREGISTERED
2023-02-08 21:33:39,274 [1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:39,274 [1207ef06-85db-4c1a-b277-21f94a0a5063-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 1207ef06-85db-4c1a-b277-21f94a0a5063@group-E8A54AAA19D4-SegmentedRaftLogWorker close()
2023-02-08 21:33:39,274 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-1/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-92e99181-9c4e-41b7-8620-eebae41740a6/container.db for volume DS-92e99181-9c4e-41b7-8620-eebae41740a6
2023-02-08 21:33:39,274 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:39,275 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:39,276 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:39,285 [JvmPauseMonitor29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-1207ef06-85db-4c1a-b277-21f94a0a5063: Stopped
2023-02-08 21:33:39,296 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2f9da656{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:39,297 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@44b3c57a{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:39,297 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:39,302 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1cb15163{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:39,306 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@430f9f84{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:39,308 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 160 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:39,312 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:39,313 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: close
2023-02-08 21:33:39,313 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9: shutdown
2023-02-08 21:33:39,313 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FF4A69801AA9,id=c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: shutdown c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-LeaderStateImpl
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:39,314 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-FF4A69801AA9: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-2/data/ratis/08981a6a-869a-4b16-a2ce-ff4a69801aa9/sm/snapshot.1_0
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7: shutdown
2023-02-08 21:33:39,314 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBD5BDFE09D7,id=c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97
2023-02-08 21:33:39,315 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: shutdown c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-FollowerState
2023-02-08 21:33:39,315 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-FollowerState was interrupted
2023-02-08 21:33:39,315 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater: set stopIndex = 35
2023-02-08 21:33:39,315 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DBD5BDFE09D7: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-2/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35
2023-02-08 21:33:39,316 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-FF4A69801AA9: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-2/data/ratis/08981a6a-869a-4b16-a2ce-ff4a69801aa9/sm/snapshot.1_0 took: 1 ms
2023-02-08 21:33:39,316 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:39,316 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: installSnapshot onError, lastRequest: 28ccfb07-ee71-476a-89f2-90668a6b099c->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97#212-t1,previous=(t:1, i:34),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:35), METADATAENTRY(c:34): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:39,316 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:39,316 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:39,317 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:39,317 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DBD5BDFE09D7: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-2/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35 took: 2 ms
2023-02-08 21:33:39,317 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater: Took a snapshot at index 35
2023-02-08 21:33:39,317 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-02-08 21:33:39,316 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x91975399, L:/0:0:0:0:0:0:0:0:42405] CLOSE
2023-02-08 21:33:39,318 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x91975399, L:/0:0:0:0:0:0:0:0:42405] INACTIVE
2023-02-08 21:33:39,318 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x91975399, L:/0:0:0:0:0:0:0:0:42405] UNREGISTERED
2023-02-08 21:33:39,316 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:33:39,319 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:33:39,319 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9: closes. applyIndex: 0
2023-02-08 21:33:39,319 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7: closes. applyIndex: 35
2023-02-08 21:33:39,320 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 36 -> 35
2023-02-08 21:33:39,320 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:33:39,322 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:39,327 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:39,327 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,327 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:39,327 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds
2023-02-08 21:33:39,328 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:33:39,327 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,328 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 34 -> 33
2023-02-08 21:33:39,330 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:39,330 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds
2023-02-08 21:33:39,330 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:39,330 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-DBD5BDFE09D7-SegmentedRaftLogWorker close()
2023-02-08 21:33:39,330 [c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97@group-FF4A69801AA9-SegmentedRaftLogWorker close()
2023-02-08 21:33:39,331 [JvmPauseMonitor28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: Stopped
2023-02-08 21:33:39,345 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis to VolumeSet
2023-02-08 21:33:39,345 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis
2023-02-08 21:33:39,345 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis
2023-02-08 21:33:39,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:39,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 2 containers.
2023-02-08 21:33:39,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,366 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-02-08 21:33:39,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,372 [Thread-3224] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds
2023-02-08 21:33:39,372 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:39,373 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:39,373 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:39,374 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:39,375 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:39,375 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:39,375 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:39,375 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:39,375 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:39,376 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:39,377 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:39,377 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:39,377 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:39,377 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:39,377 [ecb32549-f2ba-48dc-a0ed-8802c582cc24-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x35909229] REGISTERED
2023-02-08 21:33:39,377 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis] (custom)
2023-02-08 21:33:39,377 [ecb32549-f2ba-48dc-a0ed-8802c582cc24-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x35909229] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:39,377 [ecb32549-f2ba-48dc-a0ed-8802c582cc24-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x35909229, L:/0:0:0:0:0:0:0:0:37507] ACTIVE
2023-02-08 21:33:39,379 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:39,383 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:39,383 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:39,383 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:39,384 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 45607
2023-02-08 21:33:39,385 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:39,395 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:39,395 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:39,395 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:39,396 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@48e772a2{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:39,396 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@74930a81{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:39,472 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,473 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:39,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-08 21:33:39,573 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7, PipelineID=7d85cdec-ca2a-4102-b671-45d369a96d70]
2023-02-08 21:33:39,573 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7
2023-02-08 21:33:39,573 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #4 closed for pipeline=PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7
2023-02-08 21:33:39,574 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7
2023-02-08 21:33:39,574 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 0d5db105-6a57-4e00-a034-dbd5bdfe09d7, Nodes: a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:28ccfb07-ee71-476a-89f2-90668a6b099c, CreationTimestamp2023-02-08T21:31:42.134Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:39,574 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 7d85cdec-ca2a-4102-b671-45d369a96d70, Nodes: a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:a7bbced2-9033-4c12-a554-3fc75927eea0, CreationTimestamp2023-02-08T21:31:41.683Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:39,574 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #3, current state: CLOSING
2023-02-08 21:33:39,574 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #4, current state: CLOSING
2023-02-08 21:33:39,574 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #6, current state: CLOSING
2023-02-08 21:33:39,639 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@53488db7{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45607-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9121233850715988690/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:39,644 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@39fb117b{HTTP/1.1, (http/1.1)}{0.0.0.0:45607}
2023-02-08 21:33:39,644 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @188637ms
2023-02-08 21:33:39,644 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:39,645 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45607
2023-02-08 21:33:39,645 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:39,645 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:39,645 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:39,645 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:39,659 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:39,664 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@536f15f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:39,666 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/meta/datanode.id
2023-02-08 21:33:39,679 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:39,724 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:39,726 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:39,727 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:39,727 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:39,727 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds
2023-02-08 21:33:39,727 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds
2023-02-08 21:33:39,738 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis to VolumeSet
2023-02-08 21:33:39,738 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis
2023-02-08 21:33:39,738 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis
2023-02-08 21:33:39,749 [Thread-3238] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds
2023-02-08 21:33:39,749 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:39,750 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:39,751 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:39,751 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:39,751 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:39,751 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:39,752 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:39,753 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:39,754 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis] (custom)
2023-02-08 21:33:39,754 [89a22697-0d01-4b31-a0d7-1bc78e753416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb82397c6] REGISTERED
2023-02-08 21:33:39,754 [89a22697-0d01-4b31-a0d7-1bc78e753416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb82397c6] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:39,754 [89a22697-0d01-4b31-a0d7-1bc78e753416-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb82397c6, L:/0:0:0:0:0:0:0:0:33585] ACTIVE
2023-02-08 21:33:39,755 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:39,758 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:39,758 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:39,758 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:39,760 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:39,761 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:39,761 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:39,761 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:39,761 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:39,762 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 40403
2023-02-08 21:33:39,762 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:39,773 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=866b2529-b6a1-4f7a-80e4-2833be99757e]
2023-02-08 21:33:39,773 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 866b2529-b6a1-4f7a-80e4-2833be99757e, Nodes: edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:35.863Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:39,780 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:39,780 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:39,780 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-08 21:33:39,781 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@646ddece{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:39,781 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6dbe535a{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:39,811 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1042651024ns, electionTimeout:1042ms
2023-02-08 21:33:39,811 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-02-08 21:33:39,811 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:39,811 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:39,811 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection97
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection97 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:42965|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection97 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection97
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 2066ms
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-02-08 21:33:39,821 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-02-08 21:33:39,822 [om1@group-C5BA1605619E-LeaderElection97] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:39,833 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-02-08 21:33:39,850 [om1@group-C5BA1605619E-LeaderElection97] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:42965|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:39,853 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:42965"
startupRole: FOLLOWER
]
2023-02-08 21:33:39,860 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,860 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,860 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 30 -> 29
2023-02-08 21:33:39,861 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 29 -> 28
2023-02-08 21:33:39,875 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,875 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 29 -> 28
2023-02-08 21:33:39,875 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:39,876 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 28 -> 27
2023-02-08 21:33:40,221 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@70554bf8{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-40403-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6190306396185239721/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:40,229 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@3a317763{HTTP/1.1, (http/1.1)}{0.0.0.0:40403}
2023-02-08 21:33:40,229 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @189222ms
2023-02-08 21:33:40,229 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:40,230 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:40403
2023-02-08 21:33:40,231 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:40,231 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:40,231 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:40,231 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:40,243 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:40,259 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@33858ec0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:40,263 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/meta/datanode.id
2023-02-08 21:33:40,272 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:40,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:40,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:40,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,366 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:40,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-02-08 21:33:40,368 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:40,473 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,473 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:40,505 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 229 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:40,511 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:40,519 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:40,519 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:40,519 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds
2023-02-08 21:33:40,522 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds
2023-02-08 21:33:40,573 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis to VolumeSet
2023-02-08 21:33:40,573 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis
2023-02-08 21:33:40,577 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis
2023-02-08 21:33:40,630 [Thread-3261] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds
2023-02-08 21:33:40,630 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:40,631 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:40,631 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:40,631 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:40,631 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:40,632 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:40,636 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:40,637 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:40,637 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:40,637 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:40,637 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:40,638 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:40,638 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:40,639 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:40,639 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:40,640 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis] (custom)
2023-02-08 21:33:40,641 [8f2e834d-419f-4eeb-b382-a8e6a25122f3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x276ffbb9] REGISTERED
2023-02-08 21:33:40,641 [8f2e834d-419f-4eeb-b382-a8e6a25122f3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x276ffbb9] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:40,641 [8f2e834d-419f-4eeb-b382-a8e6a25122f3-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x276ffbb9, L:/0:0:0:0:0:0:0:0:34443] ACTIVE
2023-02-08 21:33:40,646 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:40,663 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:40,663 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:40,665 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:40,669 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:40,670 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:40,671 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:40,671 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:40,671 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:40,671 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 46033
2023-02-08 21:33:40,671 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:40,672 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:40,672 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:40,672 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-02-08 21:33:40,673 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@a5414eb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:40,673 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@10e048dc{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:41,081 [IPC Server handler 14 on default port 35677] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:41,086 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to HEALTHY state.
2023-02-08 21:33:41,087 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:41,087 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-08 21:33:41,110 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,110 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 27 -> 26
2023-02-08 21:33:41,111 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,111 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 26 -> 25
2023-02-08 21:33:41,113 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,113 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 33 -> 32
2023-02-08 21:33:41,113 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,113 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 32 -> 31
2023-02-08 21:33:41,120 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,121 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 26 -> 25
2023-02-08 21:33:41,121 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,121 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 25 -> 24
2023-02-08 21:33:41,123 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,123 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 32 -> 31
2023-02-08 21:33:41,123 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,123 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 31 -> 30
2023-02-08 21:33:41,187 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-93b25946-35df-414f-9274-848507897245/container.db to cache
2023-02-08 21:33:41,187 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-93b25946-35df-414f-9274-848507897245/container.db for volume DS-93b25946-35df-414f-9274-848507897245
2023-02-08 21:33:41,187 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:41,187 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:41,188 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 33005
2023-02-08 21:33:41,188 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:41,202 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 09413839-b23a-4aca-94dd-890763e4f20d: start RPC server
2023-02-08 21:33:41,203 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 09413839-b23a-4aca-94dd-890763e4f20d: GrpcService started, listening on 37223
2023-02-08 21:33:41,204 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 09413839-b23a-4aca-94dd-890763e4f20d is started using port 37223 for RATIS
2023-02-08 21:33:41,204 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 09413839-b23a-4aca-94dd-890763e4f20d is started using port 37223 for RATIS_ADMIN
2023-02-08 21:33:41,204 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 09413839-b23a-4aca-94dd-890763e4f20d is started using port 37223 for RATIS_SERVER
2023-02-08 21:33:41,204 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 09413839-b23a-4aca-94dd-890763e4f20d is started using port 44623 for RATIS_DATASTREAM
2023-02-08 21:33:41,204 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-09413839-b23a-4aca-94dd-890763e4f20d: Started
2023-02-08 21:33:41,208 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 09413839-b23a-4aca-94dd-890763e4f20d is started using port 36895
2023-02-08 21:33:41,215 [IPC Server handler 12 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-08 21:33:41,234 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@43f2cc9b{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-46033-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7346231057853759900/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:41,239 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@2d8f01d7{HTTP/1.1, (http/1.1)}{0.0.0.0:46033}
2023-02-08 21:33:41,239 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @190231ms
2023-02-08 21:33:41,239 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:41,239 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:46033
2023-02-08 21:33:41,240 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:41,240 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:41,240 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:41,246 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:41,251 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:41,251 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3806324c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:41,253 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/meta/datanode.id
2023-02-08 21:33:41,269 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:41,316 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 46 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:41,319 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:41,321 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:41,321 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:41,322 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds
2023-02-08 21:33:41,328 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds
2023-02-08 21:33:41,331 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-3/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-e4a607fd-5db1-45c7-b830-aeb60ecead40/container.db for volume DS-e4a607fd-5db1-45c7-b830-aeb60ecead40
2023-02-08 21:33:41,331 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:41,332 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:41,334 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:41,345 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2b902972{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:41,345 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@4a8584ab{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:41,346 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:41,349 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5061aea1{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:41,352 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2f8eb592{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:41,357 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis to VolumeSet
2023-02-08 21:33:41,360 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis
2023-02-08 21:33:41,360 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis
2023-02-08 21:33:41,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:41,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:41,363 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:41,363 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: close
2023-02-08 21:33:41,365 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879: shutdown
2023-02-08 21:33:41,365 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D98F02883879,id=bf7e9559-dd59-4a20-a97c-cd7084a338be
2023-02-08 21:33:41,365 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4: shutdown
2023-02-08 21:33:41,365 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:41,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,366 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8A54AAA19D4,id=bf7e9559-dd59-4a20-a97c-cd7084a338be
2023-02-08 21:33:41,366 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: shutdown bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-FollowerState
2023-02-08 21:33:41,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,366 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-FollowerState was interrupted
2023-02-08 21:33:41,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,366 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: shutdown bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-LeaderStateImpl
2023-02-08 21:33:41,366 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - bf7e9559-dd59-4a20-a97c-cd7084a338be: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:41,367 [bf7e9559-dd59-4a20-a97c-cd7084a338be-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9b04646f, L:/0:0:0:0:0:0:0:0:44847] CLOSE
2023-02-08 21:33:41,367 [bf7e9559-dd59-4a20-a97c-cd7084a338be-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9b04646f, L:/0:0:0:0:0:0:0:0:44847] INACTIVE
2023-02-08 21:33:41,367 [bf7e9559-dd59-4a20-a97c-cd7084a338be-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9b04646f, L:/0:0:0:0:0:0:0:0:44847] UNREGISTERED
2023-02-08 21:33:41,367 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-E8A54AAA19D4: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-6/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0
2023-02-08 21:33:41,367 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:41,368 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:41,368 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,368 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,369 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,368 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-D98F02883879: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-6/data/ratis/6e465395-6b66-49c1-9d90-d98f02883879/sm/snapshot.1_0
2023-02-08 21:33:41,369 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,370 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-E8A54AAA19D4: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-6/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0 took: 3 ms
2023-02-08 21:33:41,370 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,370 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,371 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-D98F02883879: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-6/data/ratis/6e465395-6b66-49c1-9d90-d98f02883879/sm/snapshot.1_0 took: 2 ms
2023-02-08 21:33:41,371 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,371 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:41,372 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:41,371 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,371 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:41,372 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:41,372 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,372 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:41,372 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879: closes. applyIndex: 0
2023-02-08 21:33:41,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 5 milliseconds for processing 11 containers.
2023-02-08 21:33:41,373 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:41,373 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4: closes. applyIndex: 0
2023-02-08 21:33:41,373 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:41,374 [bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:41,374 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-D98F02883879-SegmentedRaftLogWorker close()
2023-02-08 21:33:41,374 [bf7e9559-dd59-4a20-a97c-cd7084a338be-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - bf7e9559-dd59-4a20-a97c-cd7084a338be@group-E8A54AAA19D4-SegmentedRaftLogWorker close()
2023-02-08 21:33:41,399 [Thread-3291] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds
2023-02-08 21:33:41,399 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:41,401 [JvmPauseMonitor32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-bf7e9559-dd59-4a20-a97c-cd7084a338be: Stopped
2023-02-08 21:33:41,401 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:41,401 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:41,401 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:41,401 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:41,401 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:41,402 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:41,405 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:41,405 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:41,406 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:41,407 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis] (custom)
2023-02-08 21:33:41,408 [9b379e2d-f792-462b-ba37-42e93604c872-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x93f8f373] REGISTERED
2023-02-08 21:33:41,408 [9b379e2d-f792-462b-ba37-42e93604c872-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x93f8f373] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:41,408 [9b379e2d-f792-462b-ba37-42e93604c872-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x93f8f373, L:/0:0:0:0:0:0:0:0:38853] ACTIVE
2023-02-08 21:33:41,409 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:41,413 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:41,413 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:41,414 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:41,416 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:41,417 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:41,418 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:41,418 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:41,418 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:41,418 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42345
2023-02-08 21:33:41,418 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:41,424 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-2/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-4d57ebc3-151d-4003-aa62-5ffd4e3fe28a/container.db for volume DS-4d57ebc3-151d-4003-aa62-5ffd4e3fe28a
2023-02-08 21:33:41,424 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:41,429 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:41,429 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:41,429 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:41,430 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4e24693d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:41,430 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@c14048d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:41,431 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:41,434 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:41,435 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,435 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 31 -> 30
2023-02-08 21:33:41,436 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,436 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97: nextIndex: updateUnconditionally 30 -> 29
2023-02-08 21:33:41,440 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,440 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 25 -> 24
2023-02-08 21:33:41,441 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:33:41,441 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0: nextIndex: updateUnconditionally 24 -> 23
2023-02-08 21:33:41,449 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@3cd24e09{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:41,449 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@9144487{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:41,449 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:41,456 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4416aaa2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:41,459 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4d675339{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:41,463 [Command processor thread] ERROR commandhandler.CloseContainerCommandHandler (CloseContainerCommandHandler.java:handle(133)) - Can't close container #3
java.io.IOException
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:631)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CloseContainerCommandHandler.handle(CloseContainerCommandHandler.java:105)
	at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.CommandDispatcher.handle(CommandDispatcher.java:99)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:641)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.InterruptedException
	at java.util.concurrent.CompletableFuture.reportGet(CompletableFuture.java:347)
	at java.util.concurrent.CompletableFuture.get(CompletableFuture.java:1928)
	at org.apache.hadoop.ozone.container.common.transport.server.ratis.XceiverServerRatis.submitRequest(XceiverServerRatis.java:626)
	... 4 more
2023-02-08 21:33:41,464 [ForkJoinPool.commonPool-worker-1] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:41,467 [ForkJoinPool.commonPool-worker-1] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 28ccfb07-ee71-476a-89f2-90668a6b099c: close
2023-02-08 21:33:41,467 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 28ccfb07-ee71-476a-89f2-90668a6b099c: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:41,467 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A: shutdown
2023-02-08 21:33:41,472 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-48B30799489A,id=28ccfb07-ee71-476a-89f2-90668a6b099c
2023-02-08 21:33:41,472 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7: shutdown
2023-02-08 21:33:41,470 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97 Close channels
2023-02-08 21:33:41,473 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - a7bbced2-9033-4c12-a554-3fc75927eea0 Close channels
2023-02-08 21:33:41,473 [ForkJoinPool.commonPool-worker-1] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 28ccfb07-ee71-476a-89f2-90668a6b099c: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:41,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:41,473 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-DBD5BDFE09D7,id=28ccfb07-ee71-476a-89f2-90668a6b099c
2023-02-08 21:33:41,473 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 28ccfb07-ee71-476a-89f2-90668a6b099c: shutdown 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-LeaderStateImpl
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 28ccfb07-ee71-476a-89f2-90668a6b099c: shutdown 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-LeaderStateImpl
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1b727f04, L:/0:0:0:0:0:0:0:0:32793] CLOSE
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1b727f04, L:/0:0:0:0:0:0:0:0:32793] INACTIVE
2023-02-08 21:33:41,474 [28ccfb07-ee71-476a-89f2-90668a6b099c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1b727f04, L:/0:0:0:0:0:0:0:0:32793] UNREGISTERED
2023-02-08 21:33:41,473 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:41,474 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:41,474 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7->a7bbced2-9033-4c12-a554-3fc75927eea0-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:41,474 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-48B30799489A: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-0/data/ratis/43997954-936b-4022-be04-48b30799489a/sm/snapshot.1_0
2023-02-08 21:33:41,474 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:41,477 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-DBD5BDFE09D7: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-0/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35
2023-02-08 21:33:41,480 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater: set stopIndex = 35
2023-02-08 21:33:41,481 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-DBD5BDFE09D7: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-0/data/ratis/0d5db105-6a57-4e00-a034-dbd5bdfe09d7/sm/snapshot.1_35 took: 4 ms
2023-02-08 21:33:41,481 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-48B30799489A: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-0/data/ratis/43997954-936b-4022-be04-48b30799489a/sm/snapshot.1_0 took: 7 ms
2023-02-08 21:33:41,482 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater: Took a snapshot at index 35
2023-02-08 21:33:41,482 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:41,482 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:41,484 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-02-08 21:33:41,489 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7: closes. applyIndex: 35
2023-02-08 21:33:41,489 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:41,489 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-DBD5BDFE09D7-SegmentedRaftLogWorker close()
2023-02-08 21:33:41,489 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A: closes. applyIndex: 0
2023-02-08 21:33:41,490 [28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:41,490 [28ccfb07-ee71-476a-89f2-90668a6b099c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 28ccfb07-ee71-476a-89f2-90668a6b099c@group-48B30799489A-SegmentedRaftLogWorker close()
2023-02-08 21:33:41,491 [JvmPauseMonitor26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-28ccfb07-ee71-476a-89f2-90668a6b099c: Stopped
2023-02-08 21:33:41,517 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=08981a6a-869a-4b16-a2ce-ff4a69801aa9, PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7]
2023-02-08 21:33:41,517 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 08981a6a-869a-4b16-a2ce-ff4a69801aa9, Nodes: c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97, CreationTimestamp2023-02-08T21:31:42.134Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:41,617 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=af681b93-3d56-4a30-9b10-cb1f603daa04, PipelineID=d8218293-d620-43ac-ae6b-e8a54aaa19d4]
2023-02-08 21:33:41,617 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: af681b93-3d56-4a30-9b10-cb1f603daa04, Nodes: 1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:1207ef06-85db-4c1a-b277-21f94a0a5063, CreationTimestamp2023-02-08T21:31:42.469Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:41,618 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: d8218293-d620-43ac-ae6b-e8a54aaa19d4, Nodes: d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:1207ef06-85db-4c1a-b277-21f94a0a5063, CreationTimestamp2023-02-08T21:33:07.459Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:41,645 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@13b653bf{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-42345-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-8207555045394225944/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:41,650 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5f99f66b{HTTP/1.1, (http/1.1)}{0.0.0.0:42345}
2023-02-08 21:33:41,650 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @190642ms
2023-02-08 21:33:41,650 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:41,650 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42345
2023-02-08 21:33:41,650 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:41,652 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:41,661 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:41,663 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54ce1345] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:41,665 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/meta/datanode.id
2023-02-08 21:33:41,687 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:41,695 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-bc04206b-15e5-4bd7-9d27-77a9e6c2d8fe/container.db to cache
2023-02-08 21:33:41,695 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-bc04206b-15e5-4bd7-9d27-77a9e6c2d8fe/container.db for volume DS-bc04206b-15e5-4bd7-9d27-77a9e6c2d8fe
2023-02-08 21:33:41,696 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:41,696 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:41,696 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 40383
2023-02-08 21:33:41,696 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start RPC server
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: GrpcService started, listening on 44471
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ecb32549-f2ba-48dc-a0ed-8802c582cc24 is started using port 44471 for RATIS
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ecb32549-f2ba-48dc-a0ed-8802c582cc24 is started using port 44471 for RATIS_ADMIN
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ecb32549-f2ba-48dc-a0ed-8802c582cc24 is started using port 44471 for RATIS_SERVER
2023-02-08 21:33:41,703 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis ecb32549-f2ba-48dc-a0ed-8802c582cc24 is started using port 37507 for RATIS_DATASTREAM
2023-02-08 21:33:41,704 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-ecb32549-f2ba-48dc-a0ed-8802c582cc24: Started
2023-02-08 21:33:41,704 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc ecb32549-f2ba-48dc-a0ed-8802c582cc24 is started using port 42801
2023-02-08 21:33:41,748 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 60 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:41,749 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:41,750 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:41,751 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:41,751 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds
2023-02-08 21:33:41,758 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds
2023-02-08 21:33:41,772 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis to VolumeSet
2023-02-08 21:33:41,772 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis
2023-02-08 21:33:41,778 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis
2023-02-08 21:33:41,789 [Thread-3328] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds
2023-02-08 21:33:41,789 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:41,790 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:41,791 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:41,792 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:41,793 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:41,794 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis] (custom)
2023-02-08 21:33:41,795 [24a09729-c961-4f74-a8da-1db1f23bfb93-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdeb90a39] REGISTERED
2023-02-08 21:33:41,795 [24a09729-c961-4f74-a8da-1db1f23bfb93-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdeb90a39] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:41,795 [24a09729-c961-4f74-a8da-1db1f23bfb93-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdeb90a39, L:/0:0:0:0:0:0:0:0:36089] ACTIVE
2023-02-08 21:33:41,797 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:41,800 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:41,800 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:41,801 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:41,803 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:41,803 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:41,804 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:41,804 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:41,804 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:41,804 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 44085
2023-02-08 21:33:41,804 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:41,805 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:41,805 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:41,806 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:41,806 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@40569fc5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:41,806 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@72c05113{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:41,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(326)) - Waiting for pipelines to close for cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). There are 2 pipelines
2023-02-08 21:33:41,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:41,880 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Finalizing its pipelines [PipelineID=40a514ee-1e76-44b9-8977-cc8bfe1f6416, PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a]
2023-02-08 21:33:41,881 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 40a514ee-1e76-44b9-8977-cc8bfe1f6416, Nodes: cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:cf311c28-b71f-4054-8501-4b3584e1b394, CreationTimestamp2023-02-08T21:32:32.743Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:41,881 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=40a514ee-1e76-44b9-8977-cc8bfe1f6416 close command to datanode cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:41,886 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 40a514ee-1e76-44b9-8977-cc8bfe1f6416, Nodes: cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:cf311c28-b71f-4054-8501-4b3584e1b394, CreationTimestamp2023-02-08T21:32:32.743Z[Etc/UTC]] removed.
2023-02-08 21:33:41,886 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:41,886 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #1, current state: CLOSING
2023-02-08 21:33:41,887 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #3 closed for pipeline=PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:41,887 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #3, current state: CLOSING
2023-02-08 21:33:41,888 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:41,888 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 02876667-1e39-4447-8a1a-f29750d2b72a, Nodes: feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:cf311c28-b71f-4054-8501-4b3584e1b394, CreationTimestamp2023-02-08T21:32:33.292Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:41,888 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a close command to datanode feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:41,890 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #6, current state: CLOSING
2023-02-08 21:33:41,890 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a close command to datanode 51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:33:41,890 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a close command to datanode cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:41,890 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 02876667-1e39-4447-8a1a-f29750d2b72a, Nodes: feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:cf311c28-b71f-4054-8501-4b3584e1b394, CreationTimestamp2023-02-08T21:32:33.292Z[Etc/UTC]] removed.
2023-02-08 21:33:42,002 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5fe0e7ab{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-44085-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-1603641865275250573/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:42,007 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@634cf432{HTTP/1.1, (http/1.1)}{0.0.0.0:44085}
2023-02-08 21:33:42,007 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @191000ms
2023-02-08 21:33:42,007 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:42,008 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:44085
2023-02-08 21:33:42,008 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:42,008 [Listener at 127.0.0.1/37099] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-02-08 21:33:42,008 [Listener at 127.0.0.1/37099] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-02-08 21:33:42,012 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:42,019 [Listener at 127.0.0.1/37099] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(228)) - HddsDatanodeService host:fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net ip:10.1.0.108
2023-02-08 21:33:42,020 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4dd4c851] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:42,022 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/meta/datanode.id
2023-02-08 21:33:42,041 [Listener at 127.0.0.1/37099] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:42,087 [Listener at 127.0.0.1/37099] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:42,088 [Listener at 127.0.0.1/37099] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(260)) - Datanode State Machine Task Thread Pool size 2
2023-02-08 21:33:42,089 [Listener at 127.0.0.1/37099] INFO  volume.HddsVolume (HddsVolume.java:<init>(122)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-02-08 21:33:42,089 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds to VolumeSet
2023-02-08 21:33:42,089 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds
2023-02-08 21:33:42,090 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds
2023-02-08 21:33:42,100 [Listener at 127.0.0.1/37099] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis to VolumeSet
2023-02-08 21:33:42,100 [Listener at 127.0.0.1/37099] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis
2023-02-08 21:33:42,101 [Listener at 127.0.0.1/37099] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis
2023-02-08 21:33:42,111 [Thread-3344] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds
2023-02-08 21:33:42,111 [Listener at 127.0.0.1/37099] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(304)) - Build ContainerSet costs 0s
2023-02-08 21:33:42,112 [Listener at 127.0.0.1/37099] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-02-08 21:33:42,112 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-02-08 21:33:42,113 [Listener at 127.0.0.1/37099] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-02-08 21:33:42,114 [Listener at 127.0.0.1/37099] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-02-08 21:33:42,114 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-02-08 21:33:42,115 [Listener at 127.0.0.1/37099] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-02-08 21:33:42,116 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-02-08 21:33:42,116 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-02-08 21:33:42,116 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:42,116 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:42,116 [Listener at 127.0.0.1/37099] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis] (custom)
2023-02-08 21:33:42,116 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb8d10460] REGISTERED
2023-02-08 21:33:42,116 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb8d10460] BIND: 0.0.0.0/0.0.0.0:0
2023-02-08 21:33:42,117 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xb8d10460, L:/0:0:0:0:0:0:0:0:35793] ACTIVE
2023-02-08 21:33:42,118 [Listener at 127.0.0.1/37099] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-02-08 21:33:42,121 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-02-08 21:33:42,121 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:42,122 [Listener at 127.0.0.1/37099] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:42,127 [Listener at 127.0.0.1/37099] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:42,128 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:42,128 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-02-08 21:33:42,129 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:42,129 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:42,129 [Listener at 127.0.0.1/37099] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41655
2023-02-08 21:33:42,129 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:42,139 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:42,139 [Listener at 127.0.0.1/37099] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:42,139 [Listener at 127.0.0.1/37099] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:42,139 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@41a9565b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:42,140 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@7bc4c0be{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-02-08 21:33:42,213 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:42,215 [IPC Server handler 12 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (IN_SERVICE, 0) does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-02-08 21:33:42,216 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=40a514ee-1e76-44b9-8977-cc8bfe1f6416 is not found
2023-02-08 21:33:42,216 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:42,216 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:42,301 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-687e9de5-48d0-49eb-8db2-606b73b48d39/container.db to cache
2023-02-08 21:33:42,301 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-687e9de5-48d0-49eb-8db2-606b73b48d39/container.db for volume DS-687e9de5-48d0-49eb-8db2-606b73b48d39
2023-02-08 21:33:42,301 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:42,302 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:42,302 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 45353
2023-02-08 21:33:42,302 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start RPC server
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: GrpcService started, listening on 38561
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 89a22697-0d01-4b31-a0d7-1bc78e753416 is started using port 38561 for RATIS
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 89a22697-0d01-4b31-a0d7-1bc78e753416 is started using port 38561 for RATIS_ADMIN
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 89a22697-0d01-4b31-a0d7-1bc78e753416 is started using port 38561 for RATIS_SERVER
2023-02-08 21:33:42,314 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 89a22697-0d01-4b31-a0d7-1bc78e753416 is started using port 33585 for RATIS_DATASTREAM
2023-02-08 21:33:42,316 [JvmPauseMonitor54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-89a22697-0d01-4b31-a0d7-1bc78e753416: Started
2023-02-08 21:33:42,318 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 89a22697-0d01-4b31-a0d7-1bc78e753416 is started using port 33619
2023-02-08 21:33:42,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:42,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,370 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,373 [Listener at 127.0.0.1/37099] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@73f5c3b7{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-41655-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9018612540684338962/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:42,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-02-08 21:33:42,384 [Listener at 127.0.0.1/37099] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5ed1eaca{HTTP/1.1, (http/1.1)}{0.0.0.0:41655}
2023-02-08 21:33:42,385 [Listener at 127.0.0.1/37099] INFO  server.Server (Server.java:doStart(415)) - Started @191377ms
2023-02-08 21:33:42,385 [Listener at 127.0.0.1/37099] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:42,385 [Listener at 127.0.0.1/37099] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:41655
2023-02-08 21:33:42,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-08 21:33:42,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:42,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:42,386 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(516)) - Ozone container server started.
2023-02-08 21:33:42,396 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75d9116a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:42,397 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/meta/datanode.id
2023-02-08 21:33:42,473 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:42,473 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,473 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:42,619 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:42,619 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7 close command to datanode a7bbced2-9033-4c12-a554-3fc75927eea0
2023-02-08 21:33:42,619 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7 close command to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97
2023-02-08 21:33:42,619 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=0d5db105-6a57-4e00-a034-dbd5bdfe09d7 close command to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c
2023-02-08 21:33:42,619 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 0d5db105-6a57-4e00-a034-dbd5bdfe09d7, Nodes: a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:28ccfb07-ee71-476a-89f2-90668a6b099c, CreationTimestamp2023-02-08T21:31:42.134Z[Etc/UTC]] removed.
2023-02-08 21:33:42,620 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7d85cdec-ca2a-4102-b671-45d369a96d70 close command to datanode a7bbced2-9033-4c12-a554-3fc75927eea0
2023-02-08 21:33:42,620 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 7d85cdec-ca2a-4102-b671-45d369a96d70, Nodes: a7bbced2-9033-4c12-a554-3fc75927eea0(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:a7bbced2-9033-4c12-a554-3fc75927eea0, CreationTimestamp2023-02-08T21:31:41.683Z[Etc/UTC]] removed.
2023-02-08 21:33:42,620 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/a7bbced2-9033-4c12-a554-3fc75927eea0
2023-02-08 21:33:42,819 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:42,819 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=866b2529-b6a1-4f7a-80e4-2833be99757e close command to datanode edc82fe3-b222-4615-9e9d-46c7efcf8b1b
2023-02-08 21:33:42,820 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 866b2529-b6a1-4f7a-80e4-2833be99757e, Nodes: edc82fe3-b222-4615-9e9d-46c7efcf8b1b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:, CreationTimestamp2023-02-08T21:33:35.863Z[Etc/UTC]] removed.
2023-02-08 21:33:42,820 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/edc82fe3-b222-4615-9e9d-46c7efcf8b1b
2023-02-08 21:33:42,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:43,132 [IPC Server handler 2 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:43,132 [IPC Server handler 2 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 09413839-b23a-4aca-94dd-890763e4f20d{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=33005, RATIS=37223, RATIS_ADMIN=37223, RATIS_SERVER=37223, RATIS_DATASTREAM=44623, STANDALONE=36895], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:43,139 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:43,139 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-08 21:33:43,139 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=202ccef1-f8e2-414e-94de-6900ed06dd98 to datanode:09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:43,139 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-08 21:33:43,143 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 202ccef1-f8e2-414e-94de-6900ed06dd98, Nodes: 09413839-b23a-4aca-94dd-890763e4f20d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:43.139Z[Etc/UTC]].
2023-02-08 21:33:43,145 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-08 21:33:43,280 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-fd22c771-027e-428f-996e-f7a99820af76/container.db to cache
2023-02-08 21:33:43,280 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-fd22c771-027e-428f-996e-f7a99820af76/container.db for volume DS-fd22c771-027e-428f-996e-f7a99820af76
2023-02-08 21:33:43,280 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:43,280 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:43,284 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 38881
2023-02-08 21:33:43,284 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:43,289 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start RPC server
2023-02-08 21:33:43,290 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: GrpcService started, listening on 43271
2023-02-08 21:33:43,290 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 8f2e834d-419f-4eeb-b382-a8e6a25122f3 is started using port 43271 for RATIS
2023-02-08 21:33:43,290 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 8f2e834d-419f-4eeb-b382-a8e6a25122f3 is started using port 43271 for RATIS_ADMIN
2023-02-08 21:33:43,290 [JvmPauseMonitor55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-8f2e834d-419f-4eeb-b382-a8e6a25122f3: Started
2023-02-08 21:33:43,290 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 8f2e834d-419f-4eeb-b382-a8e6a25122f3 is started using port 43271 for RATIS_SERVER
2023-02-08 21:33:43,290 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 8f2e834d-419f-4eeb-b382-a8e6a25122f3 is started using port 34443 for RATIS_DATASTREAM
2023-02-08 21:33:43,291 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 8f2e834d-419f-4eeb-b382-a8e6a25122f3 is started using port 33175
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,363 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:33:43,366 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,370 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 2, replicaIndex: 0, sourceNodes: [bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,375 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:33:43,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 5, replicaIndex: 0, sourceNodes: [bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:43,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:43,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 2 milliseconds for processing 11 containers.
2023-02-08 21:33:43,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-02-08 21:33:43,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:43,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:43,420 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=6e465395-6b66-49c1-9d90-d98f02883879, PipelineID=d8218293-d620-43ac-ae6b-e8a54aaa19d4]
2023-02-08 21:33:43,420 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 6e465395-6b66-49c1-9d90-d98f02883879, Nodes: bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:bf7e9559-dd59-4a20-a97c-cd7084a338be, CreationTimestamp2023-02-08T21:31:43.691Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:43,421 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-6/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-62c952e8-7863-4775-880c-eb6a89336a75/container.db for volume DS-62c952e8-7863-4775-880c-eb6a89336a75
2023-02-08 21:33:43,421 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:43,429 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:43,430 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:43,442 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@564ed7ab{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:43,442 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@12778969{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:43,442 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:43,445 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@78807dda{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:43,448 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@78a9798a{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:43,452 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:43,453 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: close
2023-02-08 21:33:43,453 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838: shutdown
2023-02-08 21:33:43,453 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-75A28D761838,id=d8e3aff9-c084-4a9b-80b3-0f0f848c063d
2023-02-08 21:33:43,453 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: shutdown d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-LeaderStateImpl
2023-02-08 21:33:43,455 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:43,456 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-75A28D761838: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-5/data/ratis/548e84bd-ef6f-45a2-a298-75a28d761838/sm/snapshot.1_0
2023-02-08 21:33:43,456 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:43,457 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-75A28D761838: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-5/data/ratis/548e84bd-ef6f-45a2-a298-75a28d761838/sm/snapshot.1_0 took: 2 ms
2023-02-08 21:33:43,457 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:43,458 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:43,458 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838: closes. applyIndex: 0
2023-02-08 21:33:43,459 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:43,459 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4: shutdown
2023-02-08 21:33:43,459 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:43,459 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E8A54AAA19D4,id=d8e3aff9-c084-4a9b-80b3-0f0f848c063d
2023-02-08 21:33:43,459 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:33:43,460 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8670e021, L:/0:0:0:0:0:0:0:0:45127] CLOSE
2023-02-08 21:33:43,460 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-75A28D761838-SegmentedRaftLogWorker close()
2023-02-08 21:33:43,460 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8670e021, L:/0:0:0:0:0:0:0:0:45127] INACTIVE
2023-02-08 21:33:43,460 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x8670e021, L:/0:0:0:0:0:0:0:0:45127] UNREGISTERED
2023-02-08 21:33:43,461 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d: shutdown d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-FollowerState
2023-02-08 21:33:43,461 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-FollowerState was interrupted
2023-02-08 21:33:43,462 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-E8A54AAA19D4: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-5/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0
2023-02-08 21:33:43,462 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:43,462 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-E8A54AAA19D4: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-5/data/ratis/d8218293-d620-43ac-ae6b-e8a54aaa19d4/sm/snapshot.1_0 took: 1 ms
2023-02-08 21:33:43,462 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:43,463 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:43,463 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4: closes. applyIndex: 0
2023-02-08 21:33:43,467 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:43,467 [d8e3aff9-c084-4a9b-80b3-0f0f848c063d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - d8e3aff9-c084-4a9b-80b3-0f0f848c063d@group-E8A54AAA19D4-SegmentedRaftLogWorker close()
2023-02-08 21:33:43,470 [JvmPauseMonitor31] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-d8e3aff9-c084-4a9b-80b3-0f0f848c063d: Stopped
2023-02-08 21:33:43,473 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,473 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:43,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:43,497 [ForkJoinPool.commonPool-worker-1] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-0/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-accbd410-7c56-4957-b61f-8806e70911af/container.db for volume DS-accbd410-7c56-4957-b61f-8806e70911af
2023-02-08 21:33:43,497 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:43,498 [ForkJoinPool.commonPool-worker-1] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:43,499 [ForkJoinPool.commonPool-worker-1] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:43,510 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@35445d16{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:43,510 [ForkJoinPool.commonPool-worker-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@137e0187{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:43,511 [ForkJoinPool.commonPool-worker-1] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:43,511 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@3684bdf2{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:43,511 [ForkJoinPool.commonPool-worker-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@39a293ab{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:43,664 [IPC Server handler 2 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:43,664 [IPC Server handler 2 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : ecb32549-f2ba-48dc-a0ed-8802c582cc24{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=40383, RATIS=44471, RATIS_ADMIN=44471, RATIS_SERVER=44471, RATIS_DATASTREAM=37507, STANDALONE=42801], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:43,664 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:43,668 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-08 21:33:43,669 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f to datanode:ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:43,669 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f, Nodes: ecb32549-f2ba-48dc-a0ed-8802c582cc24(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:43.669Z[Etc/UTC]].
2023-02-08 21:33:43,701 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-f2f0ab00-4669-49d6-9f9f-e1a6d64fddc8/container.db to cache
2023-02-08 21:33:43,701 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-f2f0ab00-4669-49d6-9f9f-e1a6d64fddc8/container.db for volume DS-f2f0ab00-4669-49d6-9f9f-e1a6d64fddc8
2023-02-08 21:33:43,701 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:43,701 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:43,702 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 43493
2023-02-08 21:33:43,702 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:43,706 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 9b379e2d-f792-462b-ba37-42e93604c872: start RPC server
2023-02-08 21:33:43,706 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 9b379e2d-f792-462b-ba37-42e93604c872: GrpcService started, listening on 44179
2023-02-08 21:33:43,707 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9b379e2d-f792-462b-ba37-42e93604c872 is started using port 44179 for RATIS
2023-02-08 21:33:43,707 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9b379e2d-f792-462b-ba37-42e93604c872 is started using port 44179 for RATIS_ADMIN
2023-02-08 21:33:43,707 [JvmPauseMonitor56] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-9b379e2d-f792-462b-ba37-42e93604c872: Started
2023-02-08 21:33:43,707 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9b379e2d-f792-462b-ba37-42e93604c872 is started using port 44179 for RATIS_SERVER
2023-02-08 21:33:43,707 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 9b379e2d-f792-462b-ba37-42e93604c872 is started using port 38853 for RATIS_DATASTREAM
2023-02-08 21:33:43,707 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 9b379e2d-f792-462b-ba37-42e93604c872 is started using port 40257
2023-02-08 21:33:43,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-02-08 21:33:43,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #6 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=34, keyCount=3, bytesUsed=57},ContainerReplica{containerID=#6, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=34, keyCount=3, bytesUsed=57}}
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=41, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=41, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=41, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #3 Container State: CLOSING Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=41, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=41, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#3, state=OPEN, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=41, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) has 0 sufficientlyReplicated, 3 underReplicated and 3 unhealthy containers
2023-02-08 21:33:43,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:44,052 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-b0b28dae-c950-4c00-9bed-6b88dfc8906b/container.db to cache
2023-02-08 21:33:44,053 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-b0b28dae-c950-4c00-9bed-6b88dfc8906b/container.db for volume DS-b0b28dae-c950-4c00-9bed-6b88dfc8906b
2023-02-08 21:33:44,053 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:44,053 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:44,053 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 39807
2023-02-08 21:33:44,053 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:44,059 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start RPC server
2023-02-08 21:33:44,059 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: GrpcService started, listening on 42777
2023-02-08 21:33:44,060 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 24a09729-c961-4f74-a8da-1db1f23bfb93 is started using port 42777 for RATIS
2023-02-08 21:33:44,060 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 24a09729-c961-4f74-a8da-1db1f23bfb93 is started using port 42777 for RATIS_ADMIN
2023-02-08 21:33:44,060 [JvmPauseMonitor57] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-24a09729-c961-4f74-a8da-1db1f23bfb93: Started
2023-02-08 21:33:44,060 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 24a09729-c961-4f74-a8da-1db1f23bfb93 is started using port 42777 for RATIS_SERVER
2023-02-08 21:33:44,060 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 24a09729-c961-4f74-a8da-1db1f23bfb93 is started using port 36089 for RATIS_DATASTREAM
2023-02-08 21:33:44,060 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 24a09729-c961-4f74-a8da-1db1f23bfb93 is started using port 44315
2023-02-08 21:33:44,232 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - cf311c28-b71f-4054-8501-4b3584e1b394: remove    LEADER cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416:t1, leader=cf311c28-b71f-4054-8501-4b3584e1b394, voted=cf311c28-b71f-4054-8501-4b3584e1b394, raftlog=Memoized:cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-SegmentedRaftLog:OPENED:c0, conf=0: peers:[cf311c28-b71f-4054-8501-4b3584e1b394|rpc:10.1.0.108:44567|dataStream:10.1.0.108:43631|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-08 21:33:44,233 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416: shutdown
2023-02-08 21:33:44,233 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC8BFE1F6416,id=cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:44,233 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - cf311c28-b71f-4054-8501-4b3584e1b394: shutdown cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-LeaderStateImpl
2023-02-08 21:33:44,233 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:44,233 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:33:44,236 [cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-CC8BFE1F6416: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/40a514ee-1e76-44b9-8977-cc8bfe1f6416/sm/snapshot.1_0
2023-02-08 21:33:44,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:44,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=40a514ee-1e76-44b9-8977-cc8bfe1f6416 is not found
2023-02-08 21:33:44,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:44,237 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:44,239 [cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-CC8BFE1F6416: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/40a514ee-1e76-44b9-8977-cc8bfe1f6416/sm/snapshot.1_0 took: 3 ms
2023-02-08 21:33:44,239 [cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:33:44,239 [cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:33:44,245 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416: closes. applyIndex: 0
2023-02-08 21:33:44,249 [cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:44,250 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416-SegmentedRaftLogWorker close()
2023-02-08 21:33:44,250 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-CC8BFE1F6416: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/40a514ee-1e76-44b9-8977-cc8bfe1f6416
2023-02-08 21:33:44,250 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=40a514ee-1e76-44b9-8977-cc8bfe1f6416 command on datanode cf311c28-b71f-4054-8501-4b3584e1b394.
2023-02-08 21:33:44,252 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - feb16a71-ed08-43b3-b68b-8905cd82796b: remove  FOLLOWER feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A:t3, leader=cf311c28-b71f-4054-8501-4b3584e1b394, voted=cf311c28-b71f-4054-8501-4b3584e1b394, raftlog=Memoized:feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-SegmentedRaftLog:OPENED:c43, conf=0: peers:[cf311c28-b71f-4054-8501-4b3584e1b394|rpc:10.1.0.108:44567|dataStream:10.1.0.108:43631|priority:1|startupRole:FOLLOWER, 51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:0|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-08 21:33:44,252 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A: shutdown
2023-02-08 21:33:44,252 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F29750D2B72A,id=feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:44,252 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-FollowerState
2023-02-08 21:33:44,252 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-FollowerState was interrupted
2023-02-08 21:33:44,252 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater: set stopIndex = 43
2023-02-08 21:33:44,252 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F29750D2B72A: Taking a snapshot at:(t:3, i:43) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43
2023-02-08 21:33:44,254 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#618-t3,previous=(t:3, i:43),leaderCommit=43,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:44,256 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F29750D2B72A: Finished taking a snapshot at:(t:3, i:43) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43 took: 4 ms
2023-02-08 21:33:44,257 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater: Took a snapshot at index 43
2023-02-08 21:33:44,257 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 43
2023-02-08 21:33:44,258 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A: closes. applyIndex: 43
2023-02-08 21:33:44,259 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:44,259 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A-SegmentedRaftLogWorker close()
2023-02-08 21:33:44,260 [IPC Server handler 6 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:44,260 [IPC Server handler 6 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 89a22697-0d01-4b31-a0d7-1bc78e753416{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=45353, RATIS=38561, RATIS_ADMIN=38561, RATIS_SERVER=38561, RATIS_DATASTREAM=33585, STANDALONE=33619], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:44,261 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:44,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-08 21:33:44,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-08 21:33:44,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-08 21:33:44,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-08 21:33:44,261 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:44,261 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=a0765bab-a8c5-42f8-a64c-dea8d11df8ce to datanode:89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:44,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: a0765bab-a8c5-42f8-a64c-dea8d11df8ce, Nodes: 89a22697-0d01-4b31-a0d7-1bc78e753416(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:44.261Z[Etc/UTC]].
2023-02-08 21:33:44,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=8e2086ac-90a8-4e0d-b40e-8e5757024bcb to datanode:09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:44,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=8e2086ac-90a8-4e0d-b40e-8e5757024bcb to datanode:89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:44,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=8e2086ac-90a8-4e0d-b40e-8e5757024bcb to datanode:ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:44,262 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 8e2086ac-90a8-4e0d-b40e-8e5757024bcb, Nodes: 09413839-b23a-4aca-94dd-890763e4f20d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)89a22697-0d01-4b31-a0d7-1bc78e753416(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)ecb32549-f2ba-48dc-a0ed-8802c582cc24(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:44.262Z[Etc/UTC]].
2023-02-08 21:33:44,265 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-08 21:33:44,266 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:44,266 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 46 -> 44
2023-02-08 21:33:44,267 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 51a90d96-5277-44ed-beb8-25e5b922217c: remove  FOLLOWER 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A:t3, leader=cf311c28-b71f-4054-8501-4b3584e1b394, voted=cf311c28-b71f-4054-8501-4b3584e1b394, raftlog=Memoized:51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-SegmentedRaftLog:OPENED:c44, conf=0: peers:[cf311c28-b71f-4054-8501-4b3584e1b394|rpc:10.1.0.108:44567|dataStream:10.1.0.108:43631|priority:1|startupRole:FOLLOWER, 51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:0|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-08 21:33:44,267 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A: shutdown
2023-02-08 21:33:44,267 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F29750D2B72A,id=51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:33:44,267 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-FollowerState
2023-02-08 21:33:44,267 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater: set stopIndex = 44
2023-02-08 21:33:44,267 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-FollowerState was interrupted
2023-02-08 21:33:44,267 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F29750D2B72A: Taking a snapshot at:(t:3, i:43) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43
2023-02-08 21:33:44,268 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F29750D2B72A: Finished taking a snapshot at:(t:3, i:43) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43 took: 0 ms
2023-02-08 21:33:44,268 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater: Took a snapshot at index 43
2023-02-08 21:33:44,268 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 43
2023-02-08 21:33:44,268 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F29750D2B72A: Taking a snapshot at:(t:3, i:43) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43
2023-02-08 21:33:44,269 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F29750D2B72A: Finished taking a snapshot at:(t:3, i:43) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_43 took: 1 ms
2023-02-08 21:33:44,269 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater: Took a snapshot at index 43
2023-02-08 21:33:44,269 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-StateMachineUpdater: snapshotIndex: updateIncreasingly 43 -> 43
2023-02-08 21:33:44,269 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#621-t3,previous=(t:3, i:43),leaderCommit=44,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:44,285 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:44,285 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 45 -> 44
2023-02-08 21:33:44,288 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A: closes. applyIndex: 43
2023-02-08 21:33:44,289 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:44,289 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A-SegmentedRaftLogWorker close()
2023-02-08 21:33:44,293 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,293 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,296 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 37.
2023-02-08 21:33:44,297 [FixedThreadPoolWithAffinityExecutor-9-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(292)) - Moving container #1 to CLOSED state, datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) reported CLOSED replica.
2023-02-08 21:33:44,299 [grpc-default-executor-12] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 51a90d96-5277-44ed-beb8-25e5b922217c: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->51a90d96-5277-44ed-beb8-25e5b922217c#618-t3,previous=(t:3, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:3, i:46), STATEMACHINELOGENTRY, 114@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:44,301 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#622-t3,previous=(t:3, i:43),leaderCommit=44,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:44,303 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:44,306 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 45 -> 44
2023-02-08 21:33:44,308 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:44,308 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c: nextIndex: updateUnconditionally 47 -> 46
2023-02-08 21:33:44,309 [grpc-default-executor-7] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 51a90d96-5277-44ed-beb8-25e5b922217c: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->51a90d96-5277-44ed-beb8-25e5b922217c#619-t3,previous=(t:3, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:3, i:46), STATEMACHINELOGENTRY, 114@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:44,312 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:44,312 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c: nextIndex: updateUnconditionally 47 -> 46
2023-02-08 21:33:44,315 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,315 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,318 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:44,318 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:44,325 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:44,325 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:44,325 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #3 to QUASI_CLOSED state, datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) reported QUASI_CLOSED replica.
2023-02-08 21:33:44,327 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F29750D2B72A: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:44,327 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a command on datanode feb16a71-ed08-43b3-b68b-8905cd82796b.
2023-02-08 21:33:44,327 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #6 to QUASI_CLOSED state, datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) reported QUASI_CLOSED replica.
2023-02-08 21:33:44,346 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,347 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:44,348 [ContainerOp-02876667-1e39-4447-8a1a-f29750d2b72a-2] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 37.
2023-02-08 21:33:44,349 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:44,349 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:44,351 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:44,351 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:44,352 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F29750D2B72A: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:44,352 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a command on datanode 51a90d96-5277-44ed-beb8-25e5b922217c.
2023-02-08 21:33:44,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #3 with BCSID 41, which is in QUASI_CLOSED state.
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #6 with BCSID 34, which is in QUASI_CLOSED state.
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:44,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:44,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:44,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:44,370 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {4=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=4},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:44,370 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #7 is under replicated, but no commands were created to correct it
2023-02-08 21:33:44,370 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #11, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 2. Available sources are: {3=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=4, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0), 5=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=28ccfb07-ee71-476a-89f2-90668a6b099c, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #11 is under replicated, but no commands were created to correct it
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {3=(ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=2, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #10 is under replicated, but no commands were created to correct it
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {1=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=5, bytesUsed=95,replicaIndex=1},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #9 is under replicated, but no commands were created to correct it
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #8, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {5=(ContainerReplica{containerID=#8, state=CLOSED, datanodeDetails=28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=28ccfb07-ee71-476a-89f2-90668a6b099c, sequenceId=0, keyCount=5, bytesUsed=95,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:44,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #8 is under replicated, but no commands were created to correct it
2023-02-08 21:33:44,371 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 5 containers with health state counts {UNDER_REPLICATED=5},failed processing 0
2023-02-08 21:33:44,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:33:44,376 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:44,376 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2250)) - Cannot replicate container #2, no healthy datanodes with replica found.
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2250)) - Cannot replicate container #5, no healthy datanodes with replica found.
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:44,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-02-08 21:33:44,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-02-08 21:33:44,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:44,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-87109c7d-2b6d-49ce-9a5f-b48db569b4ee/container.db to cache
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(331)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data-0/containers/hdds/5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/DS-87109c7d-2b6d-49ce-9a5f-b48db569b4ee/container.db for volume DS-87109c7d-2b6d-49ce-9a5f-b48db569b4ee
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(398)) - Attempting to start container services.
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(315)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(109)) - ReplicationServer is started using port 40821
2023-02-08 21:33:44,432 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(518)) - Starting XceiverServerRatis 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d
2023-02-08 21:33:44,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:44,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=08981a6a-869a-4b16-a2ce-ff4a69801aa9 close command to datanode c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97
2023-02-08 21:33:44,436 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 08981a6a-869a-4b16-a2ce-ff4a69801aa9, Nodes: c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97, CreationTimestamp2023-02-08T21:31:42.134Z[Etc/UTC]] removed.
2023-02-08 21:33:44,437 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/c3e96786-01a0-4dbb-9b6a-7dc9dd0ccb97
2023-02-08 21:33:44,437 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: start RPC server
2023-02-08 21:33:44,438 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: GrpcService started, listening on 34151
2023-02-08 21:33:44,438 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d is started using port 34151 for RATIS
2023-02-08 21:33:44,438 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d is started using port 34151 for RATIS_ADMIN
2023-02-08 21:33:44,438 [JvmPauseMonitor58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: Started
2023-02-08 21:33:44,438 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d is started using port 34151 for RATIS_SERVER
2023-02-08 21:33:44,438 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(544)) - XceiverServerRatis 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d is started using port 35793 for RATIS_DATASTREAM
2023-02-08 21:33:44,439 [EndpointStateMachine task thread for /0.0.0.0:43809 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d is started using port 37183
2023-02-08 21:33:44,474 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:44,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:44,474 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:44,536 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines [PipelineID=43997954-936b-4022-be04-48b30799489a]
2023-02-08 21:33:44,536 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 43997954-936b-4022-be04-48b30799489a, Nodes: 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:28ccfb07-ee71-476a-89f2-90668a6b099c, CreationTimestamp2023-02-08T21:31:41.025Z[Etc/UTC]] moved to CLOSED state
2023-02-08 21:33:44,636 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:44,636 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=af681b93-3d56-4a30-9b10-cb1f603daa04 close command to datanode 1207ef06-85db-4c1a-b277-21f94a0a5063
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: af681b93-3d56-4a30-9b10-cb1f603daa04, Nodes: 1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:1207ef06-85db-4c1a-b277-21f94a0a5063, CreationTimestamp2023-02-08T21:31:42.469Z[Etc/UTC]] removed.
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d8218293-d620-43ac-ae6b-e8a54aaa19d4 close command to datanode d8e3aff9-c084-4a9b-80b3-0f0f848c063d
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d8218293-d620-43ac-ae6b-e8a54aaa19d4 close command to datanode bf7e9559-dd59-4a20-a97c-cd7084a338be
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=d8218293-d620-43ac-ae6b-e8a54aaa19d4 close command to datanode 1207ef06-85db-4c1a-b277-21f94a0a5063
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: d8218293-d620-43ac-ae6b-e8a54aaa19d4, Nodes: d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)bf7e9559-dd59-4a20-a97c-cd7084a338be(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)1207ef06-85db-4c1a-b277-21f94a0a5063(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:1207ef06-85db-4c1a-b277-21f94a0a5063, CreationTimestamp2023-02-08T21:33:07.459Z[Etc/UTC]] removed.
2023-02-08 21:33:44,637 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/1207ef06-85db-4c1a-b277-21f94a0a5063
2023-02-08 21:33:44,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:44,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:44,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) has 2 sufficientlyReplicated, 1 underReplicated and 1 unhealthy containers
2023-02-08 21:33:44,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:45,256 [IPC Server handler 1 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:45,256 [IPC Server handler 1 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 8f2e834d-419f-4eeb-b382-a8e6a25122f3{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=38881, RATIS=43271, RATIS_ADMIN=43271, RATIS_SERVER=43271, RATIS_DATASTREAM=34443, STANDALONE=33175], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:45,256 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:45,256 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=82abf6f5-6b80-4084-bbd8-401d273438e5 to datanode:8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:45,257 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 82abf6f5-6b80-4084-bbd8-401d273438e5, Nodes: 8f2e834d-419f-4eeb-b382-a8e6a25122f3(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:45.256Z[Etc/UTC]].
2023-02-08 21:33:45,257 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-08 21:33:45,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #1 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #3 with BCSID 41, which is in QUASI_CLOSED state.
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1113)) - Force closing container #6 with BCSID 34, which is in QUASI_CLOSED state.
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:33:45,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:45,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:45,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {4=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=4, bytesUsed=76,replicaIndex=4},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #7 is under replicated, but no commands were created to correct it
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #11, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {3=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=4, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #11 is under replicated, but no commands were created to correct it
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {3=(ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=2, bytesUsed=0,replicaIndex=3},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:45,371 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #10 is under replicated, but no commands were created to correct it
2023-02-08 21:33:45,372 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #9, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {1=(ContainerReplica{containerID=#9, state=CLOSED, datanodeDetails=d8e3aff9-c084-4a9b-80b3-0f0f848c063d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=d8e3aff9-c084-4a9b-80b3-0f0f848c063d, sequenceId=0, keyCount=5, bytesUsed=95,replicaIndex=1},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-02-08 21:33:45,372 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #9 is under replicated, but no commands were created to correct it
2023-02-08 21:33:45,372 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(322)) - Cannot proceed for EC container reconstruction for #8, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-02-08 21:33:45,372 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(220)) - Container #8 is under replicated, but no commands were created to correct it
2023-02-08 21:33:45,372 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 5 containers with health state counts {UNDER_REPLICATED=5},failed processing 0
2023-02-08 21:33:45,378 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(218)) - No healthy node found to allocate container.
2023-02-08 21:33:45,378 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2255)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:219)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:185)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:127)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.replicateAnyWithTopology(LegacyReplicationManager.java:2218)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedHealthy(LegacyReplicationManager.java:1159)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:547)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:349)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:666)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:45,382 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2250)) - Cannot replicate container #2, no healthy datanodes with replica found.
2023-02-08 21:33:45,382 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,382 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #4 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,382 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2250)) - Cannot replicate container #5, no healthy datanodes with replica found.
2023-02-08 21:33:45,382 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 28ccfb07-ee71-476a-89f2-90668a6b099c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:45,382 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 5 milliseconds for processing 11 containers.
2023-02-08 21:33:45,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 4 of 7 DN Heartbeats.
2023-02-08 21:33:45,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:45,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:45,474 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:45,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:45,474 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:45,488 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-9878c477-a508-4349-a06e-3f7b79b504a3/datanode-5/data-0/containers/hdds/9878c477-a508-4349-a06e-3f7b79b504a3/DS-06c652f1-f898-4dc5-90ff-f0fb72de8cae/container.db for volume DS-06c652f1-f898-4dc5-90ff-f0fb72de8cae
2023-02-08 21:33:45,488 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:33:45,494 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:33:45,495 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:33:45,510 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@7d5096fd{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:33:45,511 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@339b2cc5{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:45,511 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:45,511 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5a3f5dc5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:33:45,511 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@b146929{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:45,513 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(539)) - Stopping the StorageContainerManager
2023-02-08 21:33:45,513 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-08 21:33:45,513 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-08 21:33:45,513 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-08 21:33:45,513 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-08 21:33:45,513 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-08 21:33:45,515 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-08 21:33:45,515 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-08 21:33:45,515 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-08 21:33:45,515 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-02-08 21:33:45,517 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 45635
2023-02-08 21:33:45,518 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:45,521 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:45,537 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-08 21:33:45,537 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-08 21:33:45,537 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-08 21:33:45,539 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 36905
2023-02-08 21:33:45,540 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:45,541 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-08 21:33:45,541 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2023-02-08 21:33:45,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:45,544 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42709
2023-02-08 21:33:45,548 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:45,550 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:45,550 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-08 21:33:45,551 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@d42f3aa{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:33:45,551 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6d3ce953{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:45,551 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:45,553 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@797965b4{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-08 21:33:45,553 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@5586ee71{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:45,558 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-08 21:33:45,558 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-08 21:33:45,558 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:45,558 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:45,558 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-08 21:33:45,561 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-08 21:33:45,561 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-08 21:33:45,562 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-08 21:33:45,562 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-08 21:33:45,562 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-08 21:33:45,562 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-02-08 21:33:45,581 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-02-08 21:33:45,581 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-02-08 21:33:45,581 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-08 21:33:45,581 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-08 21:33:45,582 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-08 21:33:45,582 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:33:45,582 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:45,582 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-08 21:33:45,582 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-08 21:33:45,582 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-08 21:33:45,667 [IPC Server handler 0 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:45,667 [IPC Server handler 0 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 9b379e2d-f792-462b-ba37-42e93604c872{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=43493, RATIS=44179, RATIS_ADMIN=44179, RATIS_SERVER=44179, RATIS_DATASTREAM=38853, STANDALONE=40257], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:45,667 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:45,667 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=4cd17f11-0436-4150-b4d7-e439a001d452 to datanode:9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:45,668 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 4cd17f11-0436-4150-b4d7-e439a001d452, Nodes: 9b379e2d-f792-462b-ba37-42e93604c872(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:45.667Z[Etc/UTC]].
2023-02-08 21:33:45,668 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-02-08 21:33:45,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(357)) - Under Replicated Container #1 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:45,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(368)) - Unhealthy Container #1 Container State: CLOSED Replica Count: 3 Healthy Count: 2 Unhealthy Count: 0 Decommission Count: 0 Maintenance Count: 1 inFlightAdd Count: 0 inFightDel Count: 0 ReplicationFactor: 3 minMaintenance Count: 2; Replicas{ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=51a90d96-5277-44ed-beb8-25e5b922217c, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=QUASI_CLOSED, datanodeDetails=feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=feb16a71-ed08-43b3-b68b-8905cd82796b, sequenceId=37, keyCount=4, bytesUsed=76},ContainerReplica{containerID=#1, state=CLOSED, datanodeDetails=cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), placeOfBirth=cf311c28-b71f-4054-8501-4b3584e1b394, sequenceId=37, keyCount=4, bytesUsed=76}}
2023-02-08 21:33:45,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) has 2 sufficientlyReplicated, 1 underReplicated and 1 unhealthy containers
2023-02-08 21:33:45,880 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:46,025 [IPC Server handler 4 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:46,025 [IPC Server handler 4 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 24a09729-c961-4f74-a8da-1db1f23bfb93{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=39807, RATIS=42777, RATIS_ADMIN=42777, RATIS_SERVER=42777, RATIS_DATASTREAM=36089, STANDALONE=44315], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:46,026 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:46,026 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=547c2429-9afa-4aa1-9126-e3a80fa5816e to datanode:24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:46,026 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 547c2429-9afa-4aa1-9126-e3a80fa5816e, Nodes: 24a09729-c961-4f74-a8da-1db1f23bfb93(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:46.026Z[Etc/UTC]].
2023-02-08 21:33:46,027 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f80424e4-b1a0-4cfc-929e-a0b7d618926f to datanode:9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:46,027 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f80424e4-b1a0-4cfc-929e-a0b7d618926f to datanode:24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:46,027 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f80424e4-b1a0-4cfc-929e-a0b7d618926f to datanode:8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:46,027 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: f80424e4-b1a0-4cfc-929e-a0b7d618926f, Nodes: 9b379e2d-f792-462b-ba37-42e93604c872(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)24a09729-c961-4f74-a8da-1db1f23bfb93(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)8f2e834d-419f-4eeb-b382-a8e6a25122f3(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:46.027Z[Etc/UTC]].
2023-02-08 21:33:46,027 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-08 21:33:46,046 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#624-t3,previous=(t:3, i:43),leaderCommit=44,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:46,047 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:46,048 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 45 -> 44
2023-02-08 21:33:46,128 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 09413839-b23a-4aca-94dd-890763e4f20d: addNew group-6900ED06DD98:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER] returns group-6900ED06DD98:java.util.concurrent.CompletableFuture@dc193d2[Not completed]
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 09413839-b23a-4aca-94dd-890763e4f20d: new RaftServerImpl for group-6900ED06DD98:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: ConfigurationManager, init=-1: peers:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:46,129 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis] (custom)
2023-02-08 21:33:46,130 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:46,130 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:46,130 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:46,130 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:46,130 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:46,131 [pool-2437-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/202ccef1-f8e2-414e-94de-6900ed06dd98 does not exist. Creating ...
2023-02-08 21:33:46,135 [pool-2437-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/202ccef1-f8e2-414e-94de-6900ed06dd98/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:46,136 [pool-2437-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/202ccef1-f8e2-414e-94de-6900ed06dd98 has been successfully formatted.
2023-02-08 21:33:46,136 [pool-2437-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-6900ED06DD98: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:46,136 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:46,136 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:46,136 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,137 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:46,137 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 202ccef1-f8e2-414e-94de-6900ed06dd98, Nodes: 09413839-b23a-4aca-94dd-890763e4f20d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:09413839-b23a-4aca-94dd-890763e4f20d, CreationTimestamp2023-02-08T21:33:43.139Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:46,137 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:46,137 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,144 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/202ccef1-f8e2-414e-94de-6900ed06dd98
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:46,145 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:46,146 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:46,147 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,183 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:46,199 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:46,202 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:46,202 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:46,202 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,202 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: start as a follower, conf=-1: peers:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6900ED06DD98,id=09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:46,203 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:46,203 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:46,203 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:46,204 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=202ccef1-f8e2-414e-94de-6900ed06dd98
2023-02-08 21:33:46,204 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=202ccef1-f8e2-414e-94de-6900ed06dd98.
2023-02-08 21:33:46,204 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 09413839-b23a-4aca-94dd-890763e4f20d: addNew group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] returns group-8E5757024BCB:java.util.concurrent.CompletableFuture@9fe16b2[Not completed]
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 09413839-b23a-4aca-94dd-890763e4f20d: new RaftServerImpl for group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: ConfigurationManager, init=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:46,205 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis] (custom)
2023-02-08 21:33:46,206 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:46,206 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:46,206 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:46,206 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:46,206 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:46,207 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:46,207 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:46,207 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:46,208 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:46,208 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:46,208 [pool-2437-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb does not exist. Creating ...
2023-02-08 21:33:46,209 [pool-2437-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:46,210 [pool-2437-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb has been successfully formatted.
2023-02-08 21:33:46,210 [pool-2437-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-8E5757024BCB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,211 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:46,211 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:46,212 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:46,214 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:46,214 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,223 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: start as a follower, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:33:46,224 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E5757024BCB,id=09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:46,224 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:46,224 [pool-2437-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:46,225 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=8e2086ac-90a8-4e0d-b40e-8e5757024bcb
2023-02-08 21:33:46,232 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: addNew group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] returns group-8E5757024BCB:java.util.concurrent.CompletableFuture@9bfba46[Not completed]
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: new RaftServerImpl for group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: ConfigurationManager, init=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis] (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:46,233 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:46,235 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:46,235 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:46,235 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:46,237 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:46,237 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:46,237 [pool-2493-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb does not exist. Creating ...
2023-02-08 21:33:46,238 [pool-2493-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:46,239 [pool-2493-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb has been successfully formatted.
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-8E5757024BCB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:46,240 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:46,241 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:46,242 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:46,242 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:46,242 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:46,243 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:46,243 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: start as a follower, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:33:46,249 [pool-2493-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E5757024BCB,id=89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:46,249 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:46,250 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:46,250 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:46,250 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:46,250 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:46,250 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:46,260 [grpc-default-executor-5] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: addNew group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] returns group-8E5757024BCB:java.util.concurrent.CompletableFuture@29ffa18b[Not completed]
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: new RaftServerImpl for group-8E5757024BCB:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: ConfigurationManager, init=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis] (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:46,261 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:46,263 [pool-2459-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb does not exist. Creating ...
2023-02-08 21:33:46,264 [pool-2459-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:46,265 [pool-2459-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb has been successfully formatted.
2023-02-08 21:33:46,265 [pool-2459-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-8E5757024BCB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:46,265 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:46,266 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:46,266 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,266 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:46,266 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:46,266 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:46,267 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:46,268 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:46,268 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,273 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:46,273 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:46,273 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: start as a follower, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8E5757024BCB,id=ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:46,274 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:46,274 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:46,275 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:46,274 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:46,275 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:46,277 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=8e2086ac-90a8-4e0d-b40e-8e5757024bcb.
2023-02-08 21:33:46,298 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:46,341 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:46,341 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 1 is synced with bcsId 37.
2023-02-08 21:33:46,342 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 1 is closed with bcsId 37.
2023-02-08 21:33:46,343 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:46,343 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:46,344 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 3 is closed with bcsId 41.
2023-02-08 21:33:46,344 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:46,344 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:46,345 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #3 to CLOSED state, datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) reported CLOSED replica.
2023-02-08 21:33:46,345 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 6 is closed with bcsId 34.
2023-02-08 21:33:46,348 [FixedThreadPoolWithAffinityExecutor-8-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #6 to CLOSED state, datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) reported CLOSED replica.
2023-02-08 21:33:46,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:46,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:46,365 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #3 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:46,366 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:46,366 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1435)) - Sending close container command for container #6 to datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108).
2023-02-08 21:33:46,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:33:46,366 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:46,366 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:46,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:46,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:46,368 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 3 is closed with bcsId 41.
2023-02-08 21:33:46,369 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:46,369 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:46,378 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(354)) - Container 6 is closed with bcsId 34.
2023-02-08 21:33:46,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-02-08 21:33:46,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:46,386 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:46,397 [IPC Server handler 7 on default port 43809] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/79dbe8b6-7eb3-4f40-885c-9b270e3bff9d
2023-02-08 21:33:46,397 [IPC Server handler 7 on default port 43809] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=40821, RATIS=34151, RATIS_ADMIN=34151, RATIS_SERVER=34151, RATIS_DATASTREAM=35793, STANDALONE=37183], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:46,397 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:46,397 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=34ecd522-f903-41b8-b504-320922442f2e to datanode:79dbe8b6-7eb3-4f40-885c-9b270e3bff9d
2023-02-08 21:33:46,398 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 34ecd522-f903-41b8-b504-320922442f2e, Nodes: 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:46.397Z[Etc/UTC]].
2023-02-08 21:33:46,398 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-02-08 21:33:46,474 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:46,474 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:46,474 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:46,664 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: addNew group-DED1D9622C8F:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER] returns group-DED1D9622C8F:java.util.concurrent.CompletableFuture@1bdbfdaf[Not completed]
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: new RaftServerImpl for group-DED1D9622C8F:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: ConfigurationManager, init=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis] (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:46,665 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:46,667 [pool-2459-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f does not exist. Creating ...
2023-02-08 21:33:46,668 [pool-2459-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:46,669 [pool-2459-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f has been successfully formatted.
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-DED1D9622C8F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:46,670 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:46,670 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f, Nodes: ecb32549-f2ba-48dc-a0ed-8802c582cc24(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ecb32549-f2ba-48dc-a0ed-8802c582cc24, CreationTimestamp2023-02-08T21:33:43.669Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:46,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:46,671 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:46,672 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:46,673 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:46,674 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: start as a follower, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:46,679 [pool-2459-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState
2023-02-08 21:33:46,680 [pool-2459-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DED1D9622C8F,id=ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:46,680 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:46,680 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:46,680 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:46,680 [pool-2459-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:46,685 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:46,685 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:46,688 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f
2023-02-08 21:33:46,688 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f.
2023-02-08 21:33:46,770 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 51a90d96-5277-44ed-beb8-25e5b922217c: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->51a90d96-5277-44ed-beb8-25e5b922217c#621-t3,previous=(t:3, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:3, i:46), STATEMACHINELOGENTRY, 114@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:46,772 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:46,772 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c: nextIndex: updateUnconditionally 47 -> 46
2023-02-08 21:33:46,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(378)) - cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-02-08 21:33:46,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(422)) - Datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) has entered maintenance
2023-02-08 21:33:46,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:46,879 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to HEALTHY state.
2023-02-08 21:33:46,879 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:46,880 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131 to datanode:51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:33:46,880 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131 to datanode:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:46,880 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131 to datanode:712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:33:46,880 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: b6d535dc-4ea0-45d1-872d-f95237308131, Nodes: 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)712f2f09-531f-4a9c-a178-4f5e906f6733(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-02-08T21:33:46.880Z[Etc/UTC]].
2023-02-08 21:33:46,881 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-08 21:33:47,212 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:47,259 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: addNew group-DEA8D11DF8CE:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER] returns group-DEA8D11DF8CE:java.util.concurrent.CompletableFuture@4482468e[Not completed]
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: new RaftServerImpl for group-DEA8D11DF8CE:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:47,259 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: ConfigurationManager, init=-1: peers:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis] (custom)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:47,260 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:47,261 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:47,261 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:47,261 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:47,261 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:47,261 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:47,262 [pool-2493-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/a0765bab-a8c5-42f8-a64c-dea8d11df8ce does not exist. Creating ...
2023-02-08 21:33:47,263 [pool-2493-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/a0765bab-a8c5-42f8-a64c-dea8d11df8ce/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:47,264 [pool-2493-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/a0765bab-a8c5-42f8-a64c-dea8d11df8ce has been successfully formatted.
2023-02-08 21:33:47,264 [pool-2493-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-DEA8D11DF8CE: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:47,264 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:47,264 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:47,265 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: a0765bab-a8c5-42f8-a64c-dea8d11df8ce, Nodes: 89a22697-0d01-4b31-a0d7-1bc78e753416(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:89a22697-0d01-4b31-a0d7-1bc78e753416, CreationTimestamp2023-02-08T21:33:44.261Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:47,265 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:47,265 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:47,265 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:47,265 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:47,265 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/a0765bab-a8c5-42f8-a64c-dea8d11df8ce
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:47,266 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:47,267 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:47,268 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:47,272 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:47,272 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: start as a follower, conf=-1: peers:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-DEA8D11DF8CE,id=89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:47,273 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:47,273 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:47,273 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:47,274 [pool-2493-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:47,274 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=a0765bab-a8c5-42f8-a64c-dea8d11df8ce
2023-02-08 21:33:47,274 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=a0765bab-a8c5-42f8-a64c-dea8d11df8ce.
2023-02-08 21:33:47,296 [grpc-default-executor-12] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#626-t3,previous=(t:3, i:43),leaderCommit=44,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:47,298 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:47,298 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 45 -> 44
2023-02-08 21:33:47,300 [IPC Server handler 10 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:47,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:47,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:47,367 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:47,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:47,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:47,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:47,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:47,474 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:47,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:47,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:47,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:47,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:48,020 [grpc-default-executor-7] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 51a90d96-5277-44ed-beb8-25e5b922217c: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->51a90d96-5277-44ed-beb8-25e5b922217c#623-t3,previous=(t:3, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:3, i:46), STATEMACHINELOGENTRY, 114@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:48,032 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:48,032 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c: nextIndex: updateUnconditionally 47 -> 46
2023-02-08 21:33:48,212 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,252 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: addNew group-401D273438E5:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] returns group-401D273438E5:java.util.concurrent.CompletableFuture@2488dc60[Not completed]
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: new RaftServerImpl for group-401D273438E5:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: ConfigurationManager, init=-1: peers:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,253 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis] (custom)
2023-02-08 21:33:48,254 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,254 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,254 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,254 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,254 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,255 [pool-2550-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/82abf6f5-6b80-4084-bbd8-401d273438e5 does not exist. Creating ...
2023-02-08 21:33:48,257 [pool-2550-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/82abf6f5-6b80-4084-bbd8-401d273438e5/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,258 [pool-2550-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/82abf6f5-6b80-4084-bbd8-401d273438e5 has been successfully formatted.
2023-02-08 21:33:48,258 [pool-2550-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-401D273438E5: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,260 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 82abf6f5-6b80-4084-bbd8-401d273438e5, Nodes: 8f2e834d-419f-4eeb-b382-a8e6a25122f3(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8f2e834d-419f-4eeb-b382-a8e6a25122f3, CreationTimestamp2023-02-08T21:33:45.256Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:48,260 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,261 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,261 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,261 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,261 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,261 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,261 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/82abf6f5-6b80-4084-bbd8-401d273438e5
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,262 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,263 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,264 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,269 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,269 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,269 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: start as a follower, conf=-1: peers:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-401D273438E5,id=8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:48,270 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,270 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,270 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,271 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,271 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=82abf6f5-6b80-4084-bbd8-401d273438e5
2023-02-08 21:33:48,271 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=82abf6f5-6b80-4084-bbd8-401d273438e5.
2023-02-08 21:33:48,271 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: addNew group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] returns group-A0B7D618926F:java.util.concurrent.CompletableFuture@20b74c29[Not completed]
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: new RaftServerImpl for group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: ConfigurationManager, init=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis] (custom)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,272 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,273 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,273 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,273 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,274 [pool-2550-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f does not exist. Creating ...
2023-02-08 21:33:48,275 [pool-2550-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,281 [pool-2550-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f has been successfully formatted.
2023-02-08 21:33:48,282 [pool-2550-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-A0B7D618926F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,282 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,282 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,283 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,284 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,284 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,284 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,284 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,284 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,285 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,285 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,290 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,290 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,290 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,290 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: start as a follower, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0B7D618926F,id=8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,291 [pool-2550-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,292 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=f80424e4-b1a0-4cfc-929e-a0b7d618926f
2023-02-08 21:33:48,292 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,292 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,296 [grpc-default-executor-7] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9b379e2d-f792-462b-ba37-42e93604c872: addNew group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] returns group-A0B7D618926F:java.util.concurrent.CompletableFuture@5bd65811[Not completed]
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9b379e2d-f792-462b-ba37-42e93604c872: new RaftServerImpl for group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: ConfigurationManager, init=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis] (custom)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,297 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,298 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,298 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,298 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,298 [IPC Server handler 11 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:48,299 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a is not found
2023-02-08 21:33:48,299 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,299 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,299 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,300 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,300 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,300 [pool-2583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f does not exist. Creating ...
2023-02-08 21:33:48,301 [pool-2583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,301 [pool-2583-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f has been successfully formatted.
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-A0B7D618926F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,302 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,303 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,304 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,305 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,310 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,310 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,310 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,310 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,310 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: start as a follower, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b379e2d-f792-462b-ba37-42e93604c872: start 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0B7D618926F,id=9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:48,311 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,311 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,311 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,318 [grpc-default-executor-7] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: addNew group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] returns group-A0B7D618926F:java.util.concurrent.CompletableFuture@47638202[Not completed]
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: new RaftServerImpl for group-A0B7D618926F:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: ConfigurationManager, init=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis] (custom)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,319 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,320 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,320 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,320 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,321 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,321 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,321 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,321 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,321 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,322 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f does not exist. Creating ...
2023-02-08 21:33:48,323 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,324 [pool-2609-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f has been successfully formatted.
2023-02-08 21:33:48,324 [pool-2609-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-A0B7D618926F: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,326 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,327 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,328 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,329 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: start as a follower, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-A0B7D618926F,id=24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,335 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,336 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,336 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,336 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,336 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,344 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - feb16a71-ed08-43b3-b68b-8905cd82796b: addNew group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] returns group-F95237308131:java.util.concurrent.CompletableFuture@719f3dcb[Not completed]
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - feb16a71-ed08-43b3-b68b-8905cd82796b: new RaftServerImpl for group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: ConfigurationManager, init=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,344 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis] (custom)
2023-02-08 21:33:48,345 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,345 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,345 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,345 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,345 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,346 [pool-1691-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 does not exist. Creating ...
2023-02-08 21:33:48,348 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=f80424e4-b1a0-4cfc-929e-a0b7d618926f.
2023-02-08 21:33:48,348 [pool-1691-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,349 [pool-1691-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 has been successfully formatted.
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-F95237308131: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,350 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,351 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,352 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,352 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: start as a follower, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F95237308131,id=feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:48,358 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,358 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,359 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131
2023-02-08 21:33:48,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:48,366 [grpc-default-executor-7] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 51a90d96-5277-44ed-beb8-25e5b922217c: addNew group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] returns group-F95237308131:java.util.concurrent.CompletableFuture@7a45fc83[Not completed]
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 51a90d96-5277-44ed-beb8-25e5b922217c: new RaftServerImpl for group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,366 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: ConfigurationManager, init=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis] (custom)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,367 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,367 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:48,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:48,368 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,369 [pool-1639-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 does not exist. Creating ...
2023-02-08 21:33:48,370 [pool-1639-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,371 [pool-1639-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 has been successfully formatted.
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-F95237308131: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,372 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,373 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,374 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,374 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,377 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: addNew group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] returns group-F95237308131:java.util.concurrent.CompletableFuture@16cdaf1b[Not completed]
2023-02-08 21:33:48,377 [pool-1717-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: new RaftServerImpl for group-F95237308131:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: ConfigurationManager, init=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis] (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,378 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,380 [pool-1717-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 does not exist. Creating ...
2023-02-08 21:33:48,380 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,380 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,380 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,381 [pool-1717-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: start as a follower, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F95237308131,id=51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:33:48,381 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,381 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,381 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,382 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,382 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,382 [pool-1639-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,382 [pool-1717-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131 has been successfully formatted.
2023-02-08 21:33:48,382 [pool-1717-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-F95237308131: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,382 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,382 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131
2023-02-08 21:33:48,383 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,384 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:48,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:48,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:48,462 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,463 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: start as a follower, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,470 [pool-1717-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:33:48,471 [pool-1717-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F95237308131,id=712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:33:48,471 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,471 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,471 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,471 [pool-1717-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,472 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,472 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,472 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131
2023-02-08 21:33:48,474 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:48,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:48,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:48,496 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131.
2023-02-08 21:33:48,505 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=b6d535dc-4ea0-45d1-872d-f95237308131.
2023-02-08 21:33:48,547 [grpc-default-executor-12] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->feb16a71-ed08-43b3-b68b-8905cd82796b#628-t3,previous=(t:3, i:43),leaderCommit=44,initializing? true,entries: size=1, first=(t:3, i:44), STATEMACHINELOGENTRY, 110@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:48,549 [grpc-default-executor-12] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: feb16a71-ed08-43b3-b68b-8905cd82796b: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:48,549 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 45 -> 44
2023-02-08 21:33:48,663 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 9b379e2d-f792-462b-ba37-42e93604c872: addNew group-E439A001D452:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER] returns group-E439A001D452:java.util.concurrent.CompletableFuture@66bcd3a4[Not completed]
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 9b379e2d-f792-462b-ba37-42e93604c872: new RaftServerImpl for group-E439A001D452:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: ConfigurationManager, init=-1: peers:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis] (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:48,664 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:48,666 [pool-2583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/4cd17f11-0436-4150-b4d7-e439a001d452 does not exist. Creating ...
2023-02-08 21:33:48,667 [pool-2583-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/4cd17f11-0436-4150-b4d7-e439a001d452/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:48,668 [pool-2583-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/4cd17f11-0436-4150-b4d7-e439a001d452 has been successfully formatted.
2023-02-08 21:33:48,668 [pool-2583-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-E439A001D452: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:48,668 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:48,669 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:48,669 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,669 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:48,669 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:48,669 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 4cd17f11-0436-4150-b4d7-e439a001d452, Nodes: 9b379e2d-f792-462b-ba37-42e93604c872(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:9b379e2d-f792-462b-ba37-42e93604c872, CreationTimestamp2023-02-08T21:33:45.667Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:48,669 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,669 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/4cd17f11-0436-4150-b4d7-e439a001d452
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:48,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:48,670 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:48,671 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:48,671 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:48,671 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:48,672 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:48,672 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:48,677 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:48,677 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: start as a follower, conf=-1: peers:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b379e2d-f792-462b-ba37-42e93604c872: start 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E439A001D452,id=9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:48,678 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:48,678 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:48,678 [pool-2583-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:48,679 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=4cd17f11-0436-4150-b4d7-e439a001d452
2023-02-08 21:33:48,679 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=4cd17f11-0436-4150-b4d7-e439a001d452.
2023-02-08 21:33:48,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:49,021 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: addNew group-E3A80FA5816E:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER] returns group-E3A80FA5816E:java.util.concurrent.CompletableFuture@31dc46fc[Not completed]
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: new RaftServerImpl for group-E3A80FA5816E:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: ConfigurationManager, init=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis] (custom)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:49,022 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:49,023 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:49,023 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:49,023 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:49,024 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/547c2429-9afa-4aa1-9126-e3a80fa5816e does not exist. Creating ...
2023-02-08 21:33:49,025 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/547c2429-9afa-4aa1-9126-e3a80fa5816e/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:49,026 [pool-2609-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/547c2429-9afa-4aa1-9126-e3a80fa5816e has been successfully formatted.
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-E3A80FA5816E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:49,027 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/547c2429-9afa-4aa1-9126-e3a80fa5816e
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:49,027 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 547c2429-9afa-4aa1-9126-e3a80fa5816e, Nodes: 24a09729-c961-4f74-a8da-1db1f23bfb93(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:24a09729-c961-4f74-a8da-1db1f23bfb93, CreationTimestamp2023-02-08T21:33:46.026Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:49,028 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:49,028 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:49,029 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:49,030 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: start as a follower, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:49,035 [pool-2609-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState
2023-02-08 21:33:49,036 [pool-2609-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E3A80FA5816E,id=24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:49,036 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:49,036 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:49,036 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:49,036 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:49,036 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:49,036 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:49,037 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=547c2429-9afa-4aa1-9126-e3a80fa5816e
2023-02-08 21:33:49,037 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=547c2429-9afa-4aa1-9126-e3a80fa5816e.
2023-02-08 21:33:49,271 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(124)) - 51a90d96-5277-44ed-beb8-25e5b922217c: Failed APPEND_ENTRIES request cf311c28-b71f-4054-8501-4b3584e1b394->51a90d96-5277-44ed-beb8-25e5b922217c#625-t3,previous=(t:3, i:45),leaderCommit=45,initializing? true,entries: size=1, first=(t:3, i:46), STATEMACHINELOGENTRY, 114@client-EA0D6FD822F2
java.util.concurrent.CompletionException: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:292)
	at java.util.concurrent.CompletableFuture.uniComposeStage(CompletableFuture.java:989)
	at java.util.concurrent.CompletableFuture.thenCompose(CompletableFuture.java:2137)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:630)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	... 13 more
2023-02-08 21:33:49,275 [grpc-default-executor-7] WARN  server.GrpcLogAppender (LogUtils.java:warn(124)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-AppendLogResponseHandler: Failed appendEntries
org.apache.ratis.protocol.exceptions.GroupMismatchException: 51a90d96-5277-44ed-beb8-25e5b922217c: group-F29750D2B72A not found.
	at org.apache.ratis.server.impl.RaftServerProxy$ImplMap.get(RaftServerProxy.java:150)
	at org.apache.ratis.server.impl.RaftServerProxy.getImplFuture(RaftServerProxy.java:351)
	at org.apache.ratis.server.impl.RaftServerProxy.appendEntriesAsync(RaftServerProxy.java:629)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:205)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$1.process(GrpcServerProtocolService.java:202)
	at org.apache.ratis.grpc.server.GrpcServerProtocolService$ServerRequestStreamObserver.onNext(GrpcServerProtocolService.java:124)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$StreamingServerCallHandler$StreamingServerCallListener.onMessage(ServerCalls.java:262)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onMessage(ForwardingServerCallListener.java:33)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailableInternal(ServerCallImpl.java:332)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.messagesAvailable(ServerCallImpl.java:315)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1MessagesAvailable.runInContext(ServerImpl.java:834)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:33:49,275 [grpc-default-executor-7] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c: nextIndex: updateUnconditionally 47 -> 46
2023-02-08 21:33:49,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:49,298 [IPC Server handler 11 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:49,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:49,368 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:49,369 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:49,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:33:49,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:49,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:49,387 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:49,397 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: addNew group-320922442F2E:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER] returns group-320922442F2E:java.util.concurrent.CompletableFuture@5439c63b[Not completed]
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: new RaftServerImpl for group-320922442F2E:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-02-08 21:33:49,398 [pool-2631-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: ConfigurationManager, init=-1: peers:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis] (custom)
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-02-08 21:33:49,399 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-02-08 21:33:49,400 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:49,400 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-02-08 21:33:49,400 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-02-08 21:33:49,401 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-02-08 21:33:49,401 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-02-08 21:33:49,401 [pool-2631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis/34ecd522-f903-41b8-b504-320922442f2e does not exist. Creating ...
2023-02-08 21:33:49,402 [pool-2631-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis/34ecd522-f903-41b8-b504-320922442f2e/in_use.lock acquired by nodename 58949@fv-az214-81
2023-02-08 21:33:49,403 [pool-2631-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis/34ecd522-f903-41b8-b504-320922442f2e has been successfully formatted.
2023-02-08 21:33:49,403 [pool-2631-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-320922442F2E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-02-08 21:33:49,403 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-02-08 21:33:49,404 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-02-08 21:33:49,404 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:49,404 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-02-08 21:33:49,404 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-02-08 21:33:49,404 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 34ecd522-f903-41b8-b504-320922442f2e, Nodes: 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:79dbe8b6-7eb3-4f40-885c-9b270e3bff9d, CreationTimestamp2023-02-08T21:33:46.397Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:49,404 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:49,404 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis/34ecd522-f903-41b8-b504-320922442f2e
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-02-08 21:33:49,405 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-02-08 21:33:49,406 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-02-08 21:33:49,407 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:49,412 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-02-08 21:33:49,412 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-02-08 21:33:49,412 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-02-08 21:33:49,412 [pool-2631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:49,412 [pool-2631-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: start as a follower, conf=-1: peers:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: start 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-320922442F2E,id=79dbe8b6-7eb3-4f40-885c-9b270e3bff9d
2023-02-08 21:33:49,413 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-02-08 21:33:49,413 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-02-08 21:33:49,413 [pool-2631-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-02-08 21:33:49,414 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(807)) - Created group PipelineID=34ecd522-f903-41b8-b504-320922442f2e
2023-02-08 21:33:49,414 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=34ecd522-f903-41b8-b504-320922442f2e.
2023-02-08 21:33:49,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:49,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:49,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:49,500 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:checkLeadership(1021)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl: Lost leadership on term: 3. Election timeout: 5200ms. In charge for: 58696ms. Conf: 0: peers:[cf311c28-b71f-4054-8501-4b3584e1b394|rpc:10.1.0.108:44567|dataStream:10.1.0.108:43631|priority:1|startupRole:FOLLOWER, 51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:0|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1025)) - Follower cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c(c44,m45,n46, attendVote=true, lastRpcSendTime=229, lastRpcResponseTime=5242)
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] WARN  server.RaftServer$Division (LeaderStateImpl.java:lambda$checkLeadership$17(1025)) - Follower cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b(c43,m43,n44, attendVote=true, lastRpcSendTime=954, lastRpcResponseTime=5966)
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A: changes role from    LEADER to FOLLOWER at term 3 for StepDownReason:LOST_MAJORITY_HEARTBEATS
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - cf311c28-b71f-4054-8501-4b3584e1b394: shutdown cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:49,501 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-PendingRequests: sendNotLeaderResponses
2023-02-08 21:33:49,502 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-LeaderStateImpl] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - cf311c28-b71f-4054-8501-4b3584e1b394: start cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-FollowerState
2023-02-08 21:33:49,502 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:33:49,507 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - cf311c28-b71f-4054-8501-4b3584e1b394: remove  FOLLOWER cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A:t3, leader=cf311c28-b71f-4054-8501-4b3584e1b394, voted=cf311c28-b71f-4054-8501-4b3584e1b394, raftlog=Memoized:cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-SegmentedRaftLog:OPENED:c45, conf=0: peers:[cf311c28-b71f-4054-8501-4b3584e1b394|rpc:10.1.0.108:44567|dataStream:10.1.0.108:43631|priority:1|startupRole:FOLLOWER, 51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:0|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-02-08 21:33:49,507 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A: shutdown
2023-02-08 21:33:49,507 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F29750D2B72A,id=cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:49,507 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - cf311c28-b71f-4054-8501-4b3584e1b394: shutdown cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-FollowerState
2023-02-08 21:33:49,507 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater: set stopIndex = 45
2023-02-08 21:33:49,508 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F29750D2B72A: Taking a snapshot at:(t:3, i:45) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_45
2023-02-08 21:33:49,509 [IPC Server handler 5 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:49,509 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F29750D2B72A: Finished taking a snapshot at:(t:3, i:45) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a/sm/snapshot.3_45 took: 1 ms
2023-02-08 21:33:49,509 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater: Took a snapshot at index 45
2023-02-08 21:33:49,509 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 45
2023-02-08 21:33:49,510 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A: closes. applyIndex: 45
2023-02-08 21:33:49,510 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:33:49,510 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-SegmentedRaftLogWorker close()
2023-02-08 21:33:49,515 [cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-FollowerState] INFO  impl.FollowerState (FollowerState.java:shouldRun(117)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A-FollowerState: Stopping now (isRunning? false, role = FOLLOWER)
2023-02-08 21:33:49,543 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:49,543 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 3 is synced with bcsId 41.
2023-02-08 21:33:49,544 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:49,544 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(439)) - Container 6 is synced with bcsId 34.
2023-02-08 21:33:49,545 [IPC Server handler 1 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:49,546 [IPC Server handler 13 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) as the reported value (ENTERING_MAINTENANCE, 0) does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-02-08 21:33:49,546 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data/ratis/02876667-1e39-4447-8a1a-f29750d2b72a
2023-02-08 21:33:49,546 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=02876667-1e39-4447-8a1a-f29750d2b72a command on datanode cf311c28-b71f-4054-8501-4b3584e1b394.
2023-02-08 21:33:49,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:49,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:49,879 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:50,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:50,212 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:50,264 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:50,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:50,368 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:50,369 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:50,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:50,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:50,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:50,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:50,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:50,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:50,475 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:50,669 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:50,689 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-02-08 21:33:50,689 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-08 21:33:50,689 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-08 21:33:50,689 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-08 21:33:50,690 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-08 21:33:50,690 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-08 21:33:50,694 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-08 21:33:50,694 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-08 21:33:50,694 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-08 21:33:50,694 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-02-08 21:33:50,697 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35685
2023-02-08 21:33:50,699 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:50,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:50,764 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-08 21:33:50,764 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-08 21:33:50,765 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-08 21:33:50,768 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 43069
2023-02-08 21:33:50,772 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-08 21:33:50,772 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:50,772 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:50,772 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2023-02-08 21:33:50,774 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35677
2023-02-08 21:33:50,780 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:33:50,780 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-08 21:33:50,781 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@199867e1{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:33:50,781 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:33:50,782 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@78e5afaa{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:33:50,782 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:33:50,782 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@768e0fe1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-08 21:33:50,784 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7e78721{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:33:50,786 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-08 21:33:50,786 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-08 21:33:50,786 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:50,786 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:50,786 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-08 21:33:50,790 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-08 21:33:50,790 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-08 21:33:50,790 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-08 21:33:50,791 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-08 21:33:50,791 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-08 21:33:50,791 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - HddsDatanode metrics system stopped (again)
2023-02-08 21:33:50,791 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-08 21:33:50,791 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-08 21:33:50,791 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:33:50,791 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:33:50,792 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-08 21:33:50,792 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-08 21:33:50,792 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-08 21:33:50,792 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-08 21:33:50,793 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:50,794 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-08 21:33:50,794 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-08 21:33:50,794 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:50,795 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:33:50,823 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-08 21:33:50,823 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-08 21:33:50,825 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:33:50,871 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:33:50,872 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-08 21:33:50,873 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-08 21:33:50,873 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-08 21:33:50,873 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:33:50,875 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-08 21:33:50,876 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:33:50,876 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-08 21:33:50,876 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-08 21:33:50,877 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-08 21:33:50,878 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-08 21:33:50,878 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:33:50,879 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-08 21:33:50,881 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-08 21:33:50,881 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-08 21:33:50,882 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-08 21:33:50,883 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-08 21:33:50,884 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-02-08 21:33:50,884 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-02-08 21:33:50,884 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-02-08 21:33:50,885 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:50,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:50,891 [Socket Reader #1 for port 35685] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35685
2023-02-08 21:33:50,891 [Listener at 0.0.0.0/35685] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:50,895 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 43069
2023-02-08 21:33:50,896 [Listener at 0.0.0.0/43069] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:33:50,896 [Socket Reader #1 for port 35677] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35677
2023-02-08 21:33:50,913 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-08 21:33:50,913 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-08 21:33:50,913 [Listener at 0.0.0.0/35677] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-08 21:33:50,914 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35677
2023-02-08 21:33:50,915 [Listener at 0.0.0.0/35677] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-02-08 21:33:50,917 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-02-08 21:33:50,917 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-02-08 21:33:50,931 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-02-08 21:33:50,931 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-02-08 21:33:50,977 [Listener at 0.0.0.0/35677] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:35677
2023-02-08 21:33:50,977 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:50,978 [IPC Server listener on 35677] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35677: starting
2023-02-08 21:33:50,979 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:43069
2023-02-08 21:33:50,979 [Listener at 0.0.0.0/35677] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:43069
2023-02-08 21:33:50,980 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:50,980 [IPC Server listener on 43069] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 43069: starting
2023-02-08 21:33:50,981 [Listener at 0.0.0.0/35677] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:35685
2023-02-08 21:33:50,982 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:33:50,982 [IPC Server listener on 35685] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35685: starting
2023-02-08 21:33:50,984 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f0b5d79] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:33:50,988 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:34655
2023-02-08 21:33:50,988 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:33:50,991 [Listener at 0.0.0.0/35677] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:33:50,994 [Listener at 0.0.0.0/35677] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:33:50,995 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:33:50,995 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-08 21:33:50,995 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:33:50,995 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:33:50,996 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34655
2023-02-08 21:33:50,996 [Listener at 0.0.0.0/35677] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:33:50,997 [Listener at 0.0.0.0/35677] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:33:50,997 [Listener at 0.0.0.0/35677] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:33:50,997 [Listener at 0.0.0.0/35677] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:33:50,998 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@27d44578{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:33:50,998 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@8dd0c70{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-08 21:33:51,005 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6ad4ef13{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:33:51,008 [Listener at 0.0.0.0/35677] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5f93ec02{HTTP/1.1, (http/1.1)}{0.0.0.0:34655}
2023-02-08 21:33:51,008 [Listener at 0.0.0.0/35677] INFO  server.Server (Server.java:doStart(415)) - Started @200001ms
2023-02-08 21:33:51,008 [Listener at 0.0.0.0/35677] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:33:51,009 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:34655
2023-02-08 21:33:51,009 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-08 21:33:51,009 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:51,009 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:51,027 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,130 [EndpointStateMachine task thread for /0.0.0.0:35685 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:35685 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az214-81/10.1.0.108"; destination host is: "0.0.0.0":35685; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy55.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-02-08 21:33:51,141 [IPC Server handler 0 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5ef0eb67-7d25-4fae-babe-11dd56e72526(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,144 [IPC Server handler 1 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 675cd09c-5451-427a-be54-02ea82412c70(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,212 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,252 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5002707325ns, electionTimeout:5002ms
2023-02-08 21:33:51,252 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,252 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:51,252 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:51,252 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98
2023-02-08 21:33:51,254 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,255 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:51,255 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:51,255 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:51,255 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:51,260 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: receive requestVote(ELECTION, 89a22697-0d01-4b31-a0d7-1bc78e753416, group-8E5757024BCB, 1, (t:0, i:0))
2023-02-08 21:33:51,260 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(49)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FOLLOWER: accept ELECTION from 89a22697-0d01-4b31-a0d7-1bc78e753416: our priority 0 <= candidate's priority 0
2023-02-08 21:33:51,260 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:51,260 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,260 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,262 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:33:51,266 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB replies to ELECTION vote request: 89a22697-0d01-4b31-a0d7-1bc78e753416<-09413839-b23a-4aca-94dd-890763e4f20d#0:OK-t1. Peer's state: 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB:t1, leader=null, voted=89a22697-0d01-4b31-a0d7-1bc78e753416, raftlog=Memoized:09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,267 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: receive requestVote(ELECTION, 89a22697-0d01-4b31-a0d7-1bc78e753416, group-8E5757024BCB, 1, (t:0, i:0))
2023-02-08 21:33:51,268 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(49)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FOLLOWER: reject ELECTION from 89a22697-0d01-4b31-a0d7-1bc78e753416: our priority 1 > candidate's priority 0
2023-02-08 21:33:51,268 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:51,268 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,268 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,268 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:33:51,268 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:51,270 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,270 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB replies to ELECTION vote request: 89a22697-0d01-4b31-a0d7-1bc78e753416<-ecb32549-f2ba-48dc-a0ed-8802c582cc24#0:FAIL-t1. Peer's state: ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB:t1, leader=null, voted=null, raftlog=Memoized:ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,271 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 89a22697-0d01-4b31-a0d7-1bc78e753416<-ecb32549-f2ba-48dc-a0ed-8802c582cc24#0:FAIL-t1
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 89a22697-0d01-4b31-a0d7-1bc78e753416<-09413839-b23a-4aca-94dd-890763e4f20d#0:OK-t1
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98 ELECTION round 0: result REJECTED
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-02-08 21:33:51,271 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:51,271 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98
2023-02-08 21:33:51,271 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:51,272 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-LeaderElection98] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:33:51,275 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:51,275 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:51,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,284 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5081501358ns, electionTimeout:5081ms
2023-02-08 21:33:51,284 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState
2023-02-08 21:33:51,285 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:51,285 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:51,285 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99 ELECTION round 0: submit vote requests at term 1 for -1: peers:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-6900ED06DD98 with new leaderId: 09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: change Leader from null to 09413839-b23a-4aca-94dd-890763e4f20d at term 1 for becomeLeader, leader elected after 5156ms
2023-02-08 21:33:51,286 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:51,287 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:51,287 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,287 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:51,292 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:51,292 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:51,292 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:51,293 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:51,293 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:51,293 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderStateImpl
2023-02-08 21:33:51,293 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:51,294 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/202ccef1-f8e2-414e-94de-6900ed06dd98/current/log_inprogress_0
2023-02-08 21:33:51,299 [09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98-LeaderElection99] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-6900ED06DD98: set configuration 0: peers:[09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,350 [IPC Server handler 2 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:51,373 [IPC Server handler 3 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,383 [IPC Server handler 4 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 712f2f09-531f-4a9c-a178-4f5e906f6733(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:51,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:51,388 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:51,404 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:51,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:51,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:51,549 [IPC Server handler 5 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:51,670 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,812 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5132294104ns, electionTimeout:5127ms
2023-02-08 21:33:51,812 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState
2023-02-08 21:33:51,812 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:51,812 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:51,812 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100
2023-02-08 21:33:51,814 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-DED1D9622C8F with new leaderId: ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: change Leader from null to ecb32549-f2ba-48dc-a0ed-8802c582cc24 at term 1 for becomeLeader, leader elected after 5149ms
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:51,815 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:51,816 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderStateImpl
2023-02-08 21:33:51,816 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:51,820 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-LeaderElection100] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F: set configuration 0: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:51,821 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-DED1D9622C8F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/c5db0a0a-e15f-4ec3-a29d-ded1d9622c8f/current/log_inprogress_0
2023-02-08 21:33:51,890 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:52,009 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-02-08 21:33:52,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:52,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:52,127 [IPC Server handler 0 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 1ea3a110-dd3d-4689-8865-83ed09c3caaf(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:33:52,136 [IPC Server handler 1 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5ef0eb67-7d25-4fae-babe-11dd56e72526
2023-02-08 21:33:52,137 [IPC Server handler 1 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 5ef0eb67-7d25-4fae-babe-11dd56e72526{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=39233, RATIS=38265, RATIS_ADMIN=38265, RATIS_SERVER=38265, RATIS_DATASTREAM=36283, STANDALONE=40689], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,149 [IPC Server handler 2 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/675cd09c-5451-427a-be54-02ea82412c70
2023-02-08 21:33:52,164 [IPC Server handler 2 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 675cd09c-5451-427a-be54-02ea82412c70{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=40493, RATIS=38791, RATIS_ADMIN=38791, RATIS_SERVER=38791, RATIS_DATASTREAM=34463, STANDALONE=42829], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,152 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-02-08 21:33:52,152 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-02-08 21:33:52,164 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-08 21:33:52,152 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-08 21:33:52,179 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-08 21:33:52,152 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,180 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,172 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,171 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-02-08 21:33:52,180 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,287 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,351 [IPC Server handler 3 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:52,351 [IPC Server handler 3 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : feb16a71-ed08-43b3-b68b-8905cd82796b{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36413, RATIS=33409, RATIS_ADMIN=33409, RATIS_SERVER=33409, RATIS_DATASTREAM=44183, STANDALONE=34765], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,351 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,351 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-08 21:33:52,351 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-02-08 21:33:52,355 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-08 21:33:52,355 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-08 21:33:52,355 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-08 21:33:52,355 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,355 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-08 21:33:52,356 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:52,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5097501235ns, electionTimeout:5097ms
2023-02-08 21:33:52,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState
2023-02-08 21:33:52,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:52,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:52,372 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101
2023-02-08 21:33:52,372 [IPC Server handler 4 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:33:52,373 [IPC Server handler 4 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 51a90d96-5277-44ed-beb8-25e5b922217c{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36087, RATIS=40693, RATIS_ADMIN=40693, RATIS_SERVER=40693, RATIS_DATASTREAM=43653, STANDALONE=41023], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,373 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101 ELECTION round 0: submit vote requests at term 1 for -1: peers:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101
2023-02-08 21:33:52,380 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-DEA8D11DF8CE with new leaderId: 89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: change Leader from null to 89a22697-0d01-4b31-a0d7-1bc78e753416 at term 1 for becomeLeader, leader elected after 5120ms
2023-02-08 21:33:52,380 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:52,381 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:52,381 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderStateImpl
2023-02-08 21:33:52,382 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:52,386 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-LeaderElection101] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE: set configuration 0: peers:[89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:52,388 [IPC Server handler 5 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:33:52,388 [IPC Server handler 5 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 712f2f09-531f-4a9c-a178-4f5e906f6733{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36515, RATIS=42811, RATIS_ADMIN=42811, RATIS_SERVER=42811, RATIS_DATASTREAM=40781, STANDALONE=42209], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:52,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:52,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:52,389 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,389 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,390 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-DEA8D11DF8CE-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/a0765bab-a8c5-42f8-a64c-dea8d11df8ce/current/log_inprogress_0
2023-02-08 21:33:52,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:52,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:52,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:52,549 [IPC Server handler 6 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:52,549 [IPC Server handler 6 on default port 35685] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-02-08 21:33:52,549 [IPC Server handler 6 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : cf311c28-b71f-4054-8501-4b3584e1b394{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=43443, RATIS=44567, RATIS_ADMIN=44567, RATIS_SERVER=44567, RATIS_DATASTREAM=43631, STANDALONE=36983], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:52,549 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:52,553 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:52,669 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,817 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:52,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:52,885 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Finalizing its pipelines []
2023-02-08 21:33:52,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:53,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-02-08 21:33:53,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:53,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:53,028 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:53,127 [IPC Server handler 0 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1ea3a110-dd3d-4689-8865-83ed09c3caaf
2023-02-08 21:33:53,127 [IPC Server handler 0 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 1ea3a110-dd3d-4689-8865-83ed09c3caaf{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=35771, RATIS=44759, RATIS_ADMIN=44759, RATIS_SERVER=44759, RATIS_DATASTREAM=36743, STANDALONE=42231], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:33:53,128 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:53,128 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-08 21:33:53,128 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-08 21:33:53,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-08 21:33:53,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-08 21:33:53,129 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-08 21:33:53,282 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:53,363 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5072520073ns, electionTimeout:5071ms
2023-02-08 21:33:53,364 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: shutdown 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState
2023-02-08 21:33:53,364 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:53,364 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:53,364 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102
2023-02-08 21:33:53,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:53,366 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102 ELECTION round 0: submit vote requests at term 1 for -1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,366 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,366 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,366 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:53,367 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:53,378 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: receive requestVote(ELECTION, 8f2e834d-419f-4eeb-b382-a8e6a25122f3, group-A0B7D618926F, 1, (t:0, i:0))
2023-02-08 21:33:53,378 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(49)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FOLLOWER: accept ELECTION from 8f2e834d-419f-4eeb-b382-a8e6a25122f3: our priority 0 <= candidate's priority 1
2023-02-08 21:33:53,378 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,379 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b379e2d-f792-462b-ba37-42e93604c872: shutdown 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState
2023-02-08 21:33:53,379 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b379e2d-f792-462b-ba37-42e93604c872: start 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState
2023-02-08 21:33:53,379 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState was interrupted
2023-02-08 21:33:53,385 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: receive requestVote(ELECTION, 8f2e834d-419f-4eeb-b382-a8e6a25122f3, group-A0B7D618926F, 1, (t:0, i:0))
2023-02-08 21:33:53,385 [grpc-default-executor-5] INFO  impl.VoteContext (VoteContext.java:log(49)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FOLLOWER: accept ELECTION from 8f2e834d-419f-4eeb-b382-a8e6a25122f3: our priority 0 <= candidate's priority 1
2023-02-08 21:33:53,385 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,385 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: shutdown 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState
2023-02-08 21:33:53,385 [grpc-default-executor-5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState
2023-02-08 21:33:53,386 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F replies to ELECTION vote request: 8f2e834d-419f-4eeb-b382-a8e6a25122f3<-9b379e2d-f792-462b-ba37-42e93604c872#0:OK-t1. Peer's state: 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F:t1, leader=null, voted=8f2e834d-419f-4eeb-b382-a8e6a25122f3, raftlog=Memoized:9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,387 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState was interrupted
2023-02-08 21:33:53,387 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:33:53,387 [grpc-default-executor-5] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F replies to ELECTION vote request: 8f2e834d-419f-4eeb-b382-a8e6a25122f3<-24a09729-c961-4f74-a8da-1db1f23bfb93#0:OK-t1. Peer's state: 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F:t1, leader=null, voted=8f2e834d-419f-4eeb-b382-a8e6a25122f3, raftlog=Memoized:24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:53,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Waiting for cluster to exit safe mode
2023-02-08 21:33:53,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:53,389 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-08 21:33:53,389 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8f2e834d-419f-4eeb-b382-a8e6a25122f3<-9b379e2d-f792-462b-ba37-42e93604c872#0:OK-t1
2023-02-08 21:33:53,389 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102 ELECTION round 0: result PASSED
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: shutdown 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-A0B7D618926F with new leaderId: 8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: change Leader from null to 8f2e834d-419f-4eeb-b382-a8e6a25122f3 at term 1 for becomeLeader, leader elected after 5117ms
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,390 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:53,391 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,391 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,391 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,391 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,391 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:33:53,391 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:53,391 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:33:53,391 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:33:53,392 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:53,392 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:53,392 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:53,392 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:33:53,393 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: f80424e4-b1a0-4cfc-929e-a0b7d618926f, Nodes: 9b379e2d-f792-462b-ba37-42e93604c872(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)24a09729-c961-4f74-a8da-1db1f23bfb93(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)8f2e834d-419f-4eeb-b382-a8e6a25122f3(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:8f2e834d-419f-4eeb-b382-a8e6a25122f3, CreationTimestamp2023-02-08T21:33:46.027Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-08 21:33:53,393 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:33:53,394 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:33:53,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-08 21:33:53,394 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-08 21:33:53,394 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-08 21:33:53,394 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderStateImpl
2023-02-08 21:33:53,394 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-08 21:33:53,394 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:53,395 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/current/log_inprogress_0
2023-02-08 21:33:53,399 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F-LeaderElection102] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-A0B7D618926F: set configuration 0: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,407 [24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-A0B7D618926F with new leaderId: 8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,407 [24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: change Leader from null to 8f2e834d-419f-4eeb-b382-a8e6a25122f3 at term 1 for appendEntries, leader elected after 5085ms
2023-02-08 21:33:53,407 [9b379e2d-f792-462b-ba37-42e93604c872-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-A0B7D618926F with new leaderId: 8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,407 [9b379e2d-f792-462b-ba37-42e93604c872-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: change Leader from null to 8f2e834d-419f-4eeb-b382-a8e6a25122f3 at term 1 for appendEntries, leader elected after 5109ms
2023-02-08 21:33:53,418 [24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F: set configuration 0: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,419 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5148709134ns, electionTimeout:5144ms
2023-02-08 21:33:53,419 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: shutdown 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState
2023-02-08 21:33:53,419 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:53,419 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:53,419 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103
2023-02-08 21:33:53,419 [24a09729-c961-4f74-a8da-1db1f23bfb93-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:53,426 [9b379e2d-f792-462b-ba37-42e93604c872-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F: set configuration 0: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:0|startupRole:FOLLOWER, 9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:0|startupRole:FOLLOWER, 8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,427 [9b379e2d-f792-462b-ba37-42e93604c872-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:53,427 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-A0B7D618926F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/current/log_inprogress_0
2023-02-08 21:33:53,428 [9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-A0B7D618926F-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/f80424e4-b1a0-4cfc-929e-a0b7d618926f/current/log_inprogress_0
2023-02-08 21:33:53,430 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,430 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:53,430 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: shutdown 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103
2023-02-08 21:33:53,430 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:53,430 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-401D273438E5 with new leaderId: 8f2e834d-419f-4eeb-b382-a8e6a25122f3
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: change Leader from null to 8f2e834d-419f-4eeb-b382-a8e6a25122f3 at term 1 for becomeLeader, leader elected after 5176ms
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:53,431 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:53,432 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:53,432 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,432 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:53,432 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3: start 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderStateImpl
2023-02-08 21:33:53,432 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:53,434 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-3/data/ratis/82abf6f5-6b80-4084-bbd8-401d273438e5/current/log_inprogress_0
2023-02-08 21:33:53,438 [8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 8f2e834d-419f-4eeb-b382-a8e6a25122f3@group-401D273438E5: set configuration 0: peers:[8f2e834d-419f-4eeb-b382-a8e6a25122f3|rpc:10.1.0.108:43271|dataStream:10.1.0.108:34443|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:53,475 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:53,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:53,510 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5152371409ns, electionTimeout:5152ms
2023-02-08 21:33:53,510 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:33:53,511 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:53,511 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:53,511 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104
2023-02-08 21:33:53,512 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104 ELECTION round 0: submit vote requests at term 1 for -1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,513 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,513 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,513 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:33:53,513 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 1, (t:0, i:0))
2023-02-08 21:33:53,514 [grpc-default-executor-12] INFO  impl.VoteContext (VoteContext.java:log(49)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FOLLOWER: reject ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 1 > candidate's priority 0
2023-02-08 21:33:53,514 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:53,514 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:33:53,514 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:33:53,514 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState was interrupted
2023-02-08 21:33:53,516 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,516 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,518 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 1, (t:0, i:0))
2023-02-08 21:33:53,518 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(49)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FOLLOWER: accept ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 0 <= candidate's priority 0
2023-02-08 21:33:53,518 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:53,518 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: shutdown 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:33:53,518 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:33:53,518 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState was interrupted
2023-02-08 21:33:53,518 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t1. Peer's state: 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131:t1, leader=null, voted=null, raftlog=Memoized:51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,519 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,519 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,519 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t1
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104 ELECTION round 0: result REJECTED
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:53,520 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:53,521 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t1. Peer's state: 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131:t1, leader=null, voted=feb16a71-ed08-43b3-b68b-8905cd82796b, raftlog=Memoized:712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,696 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5017525873ns, electionTimeout:5017ms
2023-02-08 21:33:53,696 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 9b379e2d-f792-462b-ba37-42e93604c872: shutdown 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState
2023-02-08 21:33:53,696 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:53,696 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:53,697 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b379e2d-f792-462b-ba37-42e93604c872: start 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105
2023-02-08 21:33:53,698 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105 ELECTION round 0: submit vote requests at term 1 for -1: peers:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,698 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:53,698 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 9b379e2d-f792-462b-ba37-42e93604c872: shutdown 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-E439A001D452 with new leaderId: 9b379e2d-f792-462b-ba37-42e93604c872
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: change Leader from null to 9b379e2d-f792-462b-ba37-42e93604c872 at term 1 for becomeLeader, leader elected after 5034ms
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,699 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:53,700 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:53,700 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:53,701 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:53,701 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:53,701 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:53,701 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 9b379e2d-f792-462b-ba37-42e93604c872: start 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderStateImpl
2023-02-08 21:33:53,701 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:53,704 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-4/data/ratis/4cd17f11-0436-4150-b4d7-e439a001d452/current/log_inprogress_0
2023-02-08 21:33:53,712 [9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 9b379e2d-f792-462b-ba37-42e93604c872@group-E439A001D452: set configuration 0: peers:[9b379e2d-f792-462b-ba37-42e93604c872|rpc:10.1.0.108:44179|dataStream:10.1.0.108:38853|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:53,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:53,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:54,010 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:54,011 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-02-08 21:33:54,011 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:54,013 [Listener at 0.0.0.0/35677] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:33:54,014 [Listener at 0.0.0.0/35677] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - cf311c28-b71f-4054-8501-4b3584e1b394: close
2023-02-08 21:33:54,014 [Listener at 0.0.0.0/35677] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - cf311c28-b71f-4054-8501-4b3584e1b394: shutdown server GrpcServerProtocolService now
2023-02-08 21:33:54,021 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 51a90d96-5277-44ed-beb8-25e5b922217c Close channels
2023-02-08 21:33:54,076 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5040686685ns, electionTimeout:5040ms
2023-02-08 21:33:54,077 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: shutdown 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState
2023-02-08 21:33:54,077 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:54,077 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:54,077 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106
2023-02-08 21:33:54,078 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106 ELECTION round 0: submit vote requests at term 1 for -1: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:54,078 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: shutdown 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-E3A80FA5816E with new leaderId: 24a09729-c961-4f74-a8da-1db1f23bfb93
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: change Leader from null to 24a09729-c961-4f74-a8da-1db1f23bfb93 at term 1 for becomeLeader, leader elected after 5056ms
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:54,079 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 24a09729-c961-4f74-a8da-1db1f23bfb93: start 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderStateImpl
2023-02-08 21:33:54,080 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:54,081 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-5/data/ratis/547c2429-9afa-4aa1-9126-e3a80fa5816e/current/log_inprogress_0
2023-02-08 21:33:54,091 [24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E-LeaderElection106] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 24a09729-c961-4f74-a8da-1db1f23bfb93@group-E3A80FA5816E: set configuration 0: peers:[24a09729-c961-4f74-a8da-1db1f23bfb93|rpc:10.1.0.108:42777|dataStream:10.1.0.108:36089|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:54,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:54,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(218)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-02-08 21:33:54,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(221)) - Cluster exits safe mode
2023-02-08 21:33:54,389 [Listener at 127.0.0.1/37099] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(223)) - SCM became leader
2023-02-08 21:33:54,475 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:54,476 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:54,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:54,487 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5074648556ns, electionTimeout:5074ms
2023-02-08 21:33:54,488 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: shutdown 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState
2023-02-08 21:33:54,488 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-02-08 21:33:54,488 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:54,488 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: start 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107
2023-02-08 21:33:54,489 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107 ELECTION round 0: submit vote requests at term 1 for -1: peers:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107 ELECTION round 0: result PASSED (term=1)
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: shutdown 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-320922442F2E with new leaderId: 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: change Leader from null to 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d at term 1 for becomeLeader, leader elected after 5090ms
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:54,490 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: start 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderStateImpl
2023-02-08 21:33:54,491 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:33:54,495 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-LeaderElection107] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E: set configuration 0: peers:[79dbe8b6-7eb3-4f40-885c-9b270e3bff9d|rpc:10.1.0.108:34151|dataStream:10.1.0.108:35793|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:54,496 [79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 79dbe8b6-7eb3-4f40-885c-9b270e3bff9d@group-320922442F2E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-6/data/ratis/34ecd522-f903-41b8-b504-320922442f2e/current/log_inprogress_0
2023-02-08 21:33:54,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:54,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:55,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:55,476 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:55,476 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:55,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:55,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:55,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:56,302 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5035835930ns, electionTimeout:5030ms
2023-02-08 21:33:56,302 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,302 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-02-08 21:33:56,302 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:56,302 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108
2023-02-08 21:33:56,304 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108 ELECTION round 0: submit vote requests at term 2 for -1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:56,305 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:56,305 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:33:56,305 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:56,305 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:33:56,317 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: receive requestVote(ELECTION, 09413839-b23a-4aca-94dd-890763e4f20d, group-8E5757024BCB, 2, (t:0, i:0))
2023-02-08 21:33:56,317 [grpc-default-executor-7] INFO  impl.VoteContext (VoteContext.java:log(49)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FOLLOWER: accept ELECTION from 09413839-b23a-4aca-94dd-890763e4f20d: our priority 0 <= candidate's priority 0
2023-02-08 21:33:56,318 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:56,318 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,318 [grpc-default-executor-7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,318 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:33:56,324 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:56,324 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: receive requestVote(ELECTION, 09413839-b23a-4aca-94dd-890763e4f20d, group-8E5757024BCB, 2, (t:0, i:0))
2023-02-08 21:33:56,324 [grpc-default-executor-12] INFO  impl.VoteContext (VoteContext.java:log(49)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FOLLOWER: reject ELECTION from 09413839-b23a-4aca-94dd-890763e4f20d: our priority 1 > candidate's priority 0
2023-02-08 21:33:56,324 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:33:56,325 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,325 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,325 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:33:56,324 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:56,325 [grpc-default-executor-7] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB replies to ELECTION vote request: 09413839-b23a-4aca-94dd-890763e4f20d<-89a22697-0d01-4b31-a0d7-1bc78e753416#0:OK-t2. Peer's state: 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB:t2, leader=null, voted=09413839-b23a-4aca-94dd-890763e4f20d, raftlog=Memoized:89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:56,325 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:56,326 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:56,326 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB replies to ELECTION vote request: 09413839-b23a-4aca-94dd-890763e4f20d<-ecb32549-f2ba-48dc-a0ed-8802c582cc24#0:FAIL-t2. Peer's state: ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB:t2, leader=null, voted=null, raftlog=Memoized:ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 09413839-b23a-4aca-94dd-890763e4f20d<-ecb32549-f2ba-48dc-a0ed-8802c582cc24#0:FAIL-t2
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 09413839-b23a-4aca-94dd-890763e4f20d<-89a22697-0d01-4b31-a0d7-1bc78e753416#0:OK-t2
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108 ELECTION round 0: result REJECTED
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108
2023-02-08 21:33:56,327 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-LeaderElection108] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:33:56,330 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:56,330 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:56,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:33:56,476 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:56,476 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:56,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:56,586 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108) moved to stale state. Finalizing its pipelines []
2023-02-08 21:33:56,884 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:56,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:56,891 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:56,891 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:57,021 [ForkJoinPool.commonPool-worker-0] WARN  grpc.GrpcUtil (GrpcUtil.java:shutdownManagedChannel(223)) - Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=2415, target=10.1.0.108:40693}}. 
2023-02-08 21:33:57,021 [grpc-default-executor-12] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender is already stopped
2023-02-08 21:33:57,021 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender is already stopped
2023-02-08 21:33:57,021 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender is already stopped
2023-02-08 21:33:57,021 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender is already stopped
2023-02-08 21:33:57,022 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->51a90d96-5277-44ed-beb8-25e5b922217c-GrpcLogAppender is already stopped
2023-02-08 21:33:57,022 [grpc-default-executor-8] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 51a90d96-5277-44ed-beb8-25e5b922217c: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:57,022 [grpc-default-executor-7] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 51a90d96-5277-44ed-beb8-25e5b922217c: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:57,022 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 51a90d96-5277-44ed-beb8-25e5b922217c: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:57,023 [grpc-default-executor-11] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 51a90d96-5277-44ed-beb8-25e5b922217c: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:57,026 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - feb16a71-ed08-43b3-b68b-8905cd82796b Close channels
2023-02-08 21:33:57,028 [grpc-default-executor-13] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 51a90d96-5277-44ed-beb8-25e5b922217c: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:33:57,357 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,357 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:57,476 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,476 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,476 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:57,884 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:57,891 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:57,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:58,357 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,358 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:58,476 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,476 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:58,524 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5004496116ns, electionTimeout:5004ms
2023-02-08 21:33:58,524 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:33:58,524 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-02-08 21:33:58,524 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:33:58,524 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109
2023-02-08 21:33:58,526 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109 ELECTION round 0: submit vote requests at term 2 for -1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:58,527 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:58,527 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:58,527 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 2, (t:0, i:0))
2023-02-08 21:33:58,527 [grpc-default-executor-13] INFO  impl.VoteContext (VoteContext.java:log(49)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FOLLOWER: reject ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 1 > candidate's priority 0
2023-02-08 21:33:58,527 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:58,528 [grpc-default-executor-13] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:33:58,528 [grpc-default-executor-13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:33:58,528 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState was interrupted
2023-02-08 21:33:58,530 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:58,530 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:58,531 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t2. Peer's state: 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131:t2, leader=null, voted=null, raftlog=Memoized:51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:58,531 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-02-08 21:33:58,531 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t2
2023-02-08 21:33:58,531 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109 ELECTION round 0: result REJECTED
2023-02-08 21:33:58,531 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2023-02-08 21:33:58,531 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109
2023-02-08 21:33:58,532 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection109] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:33:58,532 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:58,532 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:58,535 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 2, (t:0, i:0))
2023-02-08 21:33:58,535 [grpc-default-executor-13] INFO  impl.VoteContext (VoteContext.java:log(49)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FOLLOWER: accept ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 0 <= candidate's priority 0
2023-02-08 21:33:58,535 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:33:58,535 [grpc-default-executor-13] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: shutdown 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:33:58,535 [grpc-default-executor-13] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:33:58,535 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState was interrupted
2023-02-08 21:33:58,535 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:33:58,535 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:33:58,536 [grpc-default-executor-13] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t2. Peer's state: 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131:t2, leader=null, voted=feb16a71-ed08-43b3-b68b-8905cd82796b, raftlog=Memoized:712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:33:58,884 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:58,891 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:58,892 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:33:59,357 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,358 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,366 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:59,477 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,477 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:33:59,589 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. cf311c28-b71f-4054-8501-4b3584e1b394(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:33:59,590 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/cf311c28-b71f-4054-8501-4b3584e1b394
2023-02-08 21:33:59,884 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:33:59,892 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:33:59,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:00,026 [ForkJoinPool.commonPool-worker-0] WARN  grpc.GrpcUtil (GrpcUtil.java:shutdownManagedChannel(223)) - Timed out gracefully shutting down connection: ManagedChannelOrphanWrapper{delegate=ManagedChannelImpl{logId=2410, target=10.1.0.108:33409}}. 
2023-02-08 21:34:00,027 [grpc-default-executor-12] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-11] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-5] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,027 [grpc-default-executor-13] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-11] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,027 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-7] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onError(404)) - cf311c28-b71f-4054-8501-4b3584e1b394@group-F29750D2B72A->feb16a71-ed08-43b3-b68b-8905cd82796b-GrpcLogAppender is already stopped
2023-02-08 21:34:00,027 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,028 [grpc-default-executor-11] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,028 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,028 [Listener at 0.0.0.0/35677] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - cf311c28-b71f-4054-8501-4b3584e1b394: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:34:00,028 [grpc-default-executor-14] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - feb16a71-ed08-43b3-b68b-8905cd82796b: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:00,028 [cf311c28-b71f-4054-8501-4b3584e1b394-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcda8d579, L:/0:0:0:0:0:0:0:0:43631] CLOSE
2023-02-08 21:34:00,029 [cf311c28-b71f-4054-8501-4b3584e1b394-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcda8d579, L:/0:0:0:0:0:0:0:0:43631] INACTIVE
2023-02-08 21:34:00,029 [cf311c28-b71f-4054-8501-4b3584e1b394-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xcda8d579, L:/0:0:0:0:0:0:0:0:43631] UNREGISTERED
2023-02-08 21:34:00,038 [JvmPauseMonitor38] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-cf311c28-b71f-4054-8501-4b3584e1b394: Stopped
2023-02-08 21:34:00,358 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,358 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:00,477 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,477 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,477 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:00,884 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:34:00,892 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:00,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:01,358 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,359 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:01,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:01,371 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:01,437 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5112414436ns, electionTimeout:5111ms
2023-02-08 21:34:01,437 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState
2023-02-08 21:34:01,437 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-02-08 21:34:01,437 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:34:01,437 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110
2023-02-08 21:34:01,439 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110 ELECTION round 0: submit vote requests at term 3 for -1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,439 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:01,439 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 89a22697-0d01-4b31-a0d7-1bc78e753416
2023-02-08 21:34:01,440 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:01,440 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 09413839-b23a-4aca-94dd-890763e4f20d
2023-02-08 21:34:01,444 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: receive requestVote(ELECTION, ecb32549-f2ba-48dc-a0ed-8802c582cc24, group-8E5757024BCB, 3, (t:0, i:0))
2023-02-08 21:34:01,445 [grpc-default-executor-14] INFO  impl.VoteContext (VoteContext.java:log(49)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FOLLOWER: accept ELECTION from ecb32549-f2ba-48dc-a0ed-8802c582cc24: our priority 0 <= candidate's priority 1
2023-02-08 21:34:01,445 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:34:01,445 [grpc-default-executor-14] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 09413839-b23a-4aca-94dd-890763e4f20d: shutdown 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:34:01,445 [grpc-default-executor-14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 09413839-b23a-4aca-94dd-890763e4f20d: start 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState
2023-02-08 21:34:01,445 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:34:01,446 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: receive requestVote(ELECTION, ecb32549-f2ba-48dc-a0ed-8802c582cc24, group-8E5757024BCB, 3, (t:0, i:0))
2023-02-08 21:34:01,446 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:01,446 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FOLLOWER: accept ELECTION from ecb32549-f2ba-48dc-a0ed-8802c582cc24: our priority 0 <= candidate's priority 1
2023-02-08 21:34:01,446 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:34:01,446 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: shutdown 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:34:01,446 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 89a22697-0d01-4b31-a0d7-1bc78e753416: start 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState
2023-02-08 21:34:01,446 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState was interrupted
2023-02-08 21:34:01,447 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB replies to ELECTION vote request: ecb32549-f2ba-48dc-a0ed-8802c582cc24<-09413839-b23a-4aca-94dd-890763e4f20d#0:OK-t3. Peer's state: 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB:t3, leader=null, voted=ecb32549-f2ba-48dc-a0ed-8802c582cc24, raftlog=Memoized:09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,447 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:01,447 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: ecb32549-f2ba-48dc-a0ed-8802c582cc24<-09413839-b23a-4aca-94dd-890763e4f20d#0:OK-t3
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110 ELECTION round 0: result PASSED
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: shutdown ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2023-02-08 21:34:01,447 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-8E5757024BCB with new leaderId: ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:34:01,448 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB replies to ELECTION vote request: ecb32549-f2ba-48dc-a0ed-8802c582cc24<-89a22697-0d01-4b31-a0d7-1bc78e753416#0:OK-t3. Peer's state: 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB:t3, leader=null, voted=ecb32549-f2ba-48dc-a0ed-8802c582cc24, raftlog=Memoized:89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,446 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:01,448 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: change Leader from null to ecb32549-f2ba-48dc-a0ed-8802c582cc24 at term 3 for becomeLeader, leader elected after 15186ms
2023-02-08 21:34:01,448 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:34:01,448 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:34:01,448 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 8e2086ac-90a8-4e0d-b40e-8e5757024bcb, Nodes: 09413839-b23a-4aca-94dd-890763e4f20d(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)89a22697-0d01-4b31-a0d7-1bc78e753416(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)ecb32549-f2ba-48dc-a0ed-8802c582cc24(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:ecb32549-f2ba-48dc-a0ed-8802c582cc24, CreationTimestamp2023-02-08T21:33:44.262Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:34:01,448 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:34:01,449 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:34:01,449 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:34:01,449 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:34:01,449 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:34:01,449 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:34:01,450 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:34:01,451 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:34:01,451 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24: start ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderStateImpl
2023-02-08 21:34:01,452 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:01,454 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-1/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/current/log_inprogress_0
2023-02-08 21:34:01,458 [ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB-LeaderElection110] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - ecb32549-f2ba-48dc-a0ed-8802c582cc24@group-8E5757024BCB: set configuration 0: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,474 [89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-8E5757024BCB with new leaderId: ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:34:01,474 [89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: change Leader from null to ecb32549-f2ba-48dc-a0ed-8802c582cc24 at term 3 for appendEntries, leader elected after 15240ms
2023-02-08 21:34:01,474 [09413839-b23a-4aca-94dd-890763e4f20d-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-8E5757024BCB with new leaderId: ecb32549-f2ba-48dc-a0ed-8802c582cc24
2023-02-08 21:34:01,475 [09413839-b23a-4aca-94dd-890763e4f20d-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: change Leader from null to ecb32549-f2ba-48dc-a0ed-8802c582cc24 at term 3 for appendEntries, leader elected after 15268ms
2023-02-08 21:34:01,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:01,478 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,478 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,478 [09413839-b23a-4aca-94dd-890763e4f20d-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB: set configuration 0: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,479 [09413839-b23a-4aca-94dd-890763e4f20d-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:01,484 [89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB: set configuration 0: peers:[ecb32549-f2ba-48dc-a0ed-8802c582cc24|rpc:10.1.0.108:44471|dataStream:10.1.0.108:37507|priority:1|startupRole:FOLLOWER, 89a22697-0d01-4b31-a0d7-1bc78e753416|rpc:10.1.0.108:38561|dataStream:10.1.0.108:33585|priority:0|startupRole:FOLLOWER, 09413839-b23a-4aca-94dd-890763e4f20d|rpc:10.1.0.108:37223|dataStream:10.1.0.108:44623|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:01,484 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-0/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/current/log_inprogress_0
2023-02-08 21:34:01,485 [89a22697-0d01-4b31-a0d7-1bc78e753416-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:01,486 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-5342b01b-8b22-4ff6-8e3b-d1fc75aec39e/datanode-2/data/ratis/8e2086ac-90a8-4e0d-b40e-8e5757024bcb/current/log_inprogress_0
2023-02-08 21:34:01,885 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(170)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-02-08 21:34:01,885 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,892 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:01,893 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:02,054 [Listener at 0.0.0.0/35677] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(362)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-4/data-0/containers/hdds/3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/DS-20ba754c-74ce-4d13-a838-84ce0e768a8f/container.db for volume DS-20ba754c-74ce-4d13-a838-84ce0e768a8f
2023-02-08 21:34:02,056 [Listener at 0.0.0.0/35677] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-02-08 21:34:02,057 [Listener at 0.0.0.0/35677] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-02-08 21:34:02,060 [Listener at 0.0.0.0/35677] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(600)) - Ozone container server stopped.
2023-02-08 21:34:02,069 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2f71df6d{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-02-08 21:34:02,072 [Listener at 0.0.0.0/35677] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@728a9314{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:34:02,072 [Listener at 0.0.0.0/35677] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:34:02,072 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@58c3549d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-02-08 21:34:02,073 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4f29dcf4{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:34:02,074 [Listener at 0.0.0.0/35677] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(351)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1535)) - Container Balancer is not running.
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1542)) - Stopping Replication Manager Service.
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  replication.ReplicationManager (ReplicationManager.java:stop(294)) - Stopping Replication Monitor Thread.
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1549)) - Stopping the Datanode Admin Monitor.
2023-02-08 21:34:02,075 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Over Replicated Processor interrupted. Exiting...
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1556)) - Stopping datanode service RPC server
2023-02-08 21:34:02,075 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(142)) - Under Replicated Processor interrupted. Exiting...
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(424)) - Stopping the RPC server for DataNodes
2023-02-08 21:34:02,075 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(671)) - Replication Monitor Thread is stopped
2023-02-08 21:34:02,075 [Listener at 0.0.0.0/35677] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35685
2023-02-08 21:34:02,080 [IPC Server listener on 35685] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 35685
2023-02-08 21:34:02,081 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:34:02,094 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-02-08 21:34:02,094 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1564)) - Stopping block service RPC server
2023-02-08 21:34:02,095 [Listener at 0.0.0.0/35677] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-02-08 21:34:02,095 [Listener at 0.0.0.0/35677] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 43069
2023-02-08 21:34:02,102 [IPC Server listener on 43069] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 43069
2023-02-08 21:34:02,103 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1571)) - Stopping the StorageContainerLocationProtocol RPC server
2023-02-08 21:34:02,103 [Listener at 0.0.0.0/35677] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(178)) - Stopping the RPC server for Client Protocol
2023-02-08 21:34:02,103 [Listener at 0.0.0.0/35677] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35677
2023-02-08 21:34:02,103 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:34:02,108 [IPC Server listener on 35677] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 35677
2023-02-08 21:34:02,110 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1578)) - Stopping Storage Container Manager HTTP server.
2023-02-08 21:34:02,110 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@6ad4ef13{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:34:02,111 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:34:02,111 [Listener at 0.0.0.0/35677] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5f93ec02{HTTP/1.1, (http/1.1)}{0.0.0.0:34655}
2023-02-08 21:34:02,111 [Listener at 0.0.0.0/35677] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:34:02,111 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@8dd0c70{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-08 21:34:02,111 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@27d44578{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:34:02,112 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1584)) - Stopping SCM LayoutVersionManager Service.
2023-02-08 21:34:02,112 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1592)) - Stopping Block Manager Service.
2023-02-08 21:34:02,112 [Listener at 0.0.0.0/35677] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:34:02,112 [Listener at 0.0.0.0/35677] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:34:02,113 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1614)) - Stopping SCM Event Queue.
2023-02-08 21:34:02,115 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1625)) - Stopping SCM HA services.
2023-02-08 21:34:02,116 [Listener at 0.0.0.0/35677] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-02-08 21:34:02,116 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-02-08 21:34:02,116 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-02-08 21:34:02,116 [Listener at 0.0.0.0/35677] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-02-08 21:34:02,116 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-02-08 21:34:02,121 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-02-08 21:34:02,121 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-02-08 21:34:02,121 [Listener at 0.0.0.0/35677] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-02-08 21:34:02,121 [Listener at 0.0.0.0/35677] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-02-08 21:34:02,121 [Listener at 0.0.0.0/35677] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:34:02,121 [Listener at 0.0.0.0/35677] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-02-08 21:34:02,121 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-02-08 21:34:02,122 [Listener at 0.0.0.0/35677] INFO  replication.ReplicationManager (ReplicationManager.java:stop(302)) - Replication Monitor Thread is not running.
2023-02-08 21:34:02,122 [Listener at 0.0.0.0/35677] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-02-08 21:34:02,122 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1643)) - Stopping SCM MetadataStore.
2023-02-08 21:34:02,123 [Listener at 0.0.0.0/35677] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:34:02,123 [Listener at 0.0.0.0/35677] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-02-08 21:34:02,124 [Listener at 0.0.0.0/35677] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-02-08 21:34:02,124 [Listener at 0.0.0.0/35677] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:34:02,125 [Listener at 0.0.0.0/35677] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(172)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-02-08 21:34:02,129 [EndpointStateMachine task thread for /0.0.0.0:35685 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:35685 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az214-81/10.1.0.108"; destination host is: "0.0.0.0":35685; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy55.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-02-08 21:34:02,159 [Listener at 0.0.0.0/35677] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-02-08 21:34:02,159 [Listener at 0.0.0.0/35677] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-02-08 21:34:02,170 [Listener at 0.0.0.0/35677] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-02-08 21:34:02,217 [Listener at 0.0.0.0/35677] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 150 keys and 363 values 
2023-02-08 21:34:02,218 [Listener at 0.0.0.0/35677] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-02-08 21:34:02,219 [Listener at 0.0.0.0/35677] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-02-08 21:34:02,219 [Listener at 0.0.0.0/35677] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-02-08 21:34:02,219 [Listener at 0.0.0.0/35677] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:34:02,220 [Listener at 0.0.0.0/35677] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-02-08 21:34:02,220 [Listener at 0.0.0.0/35677] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-02-08 21:34:02,220 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-02-08 21:34:02,221 [Listener at 0.0.0.0/35677] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-02-08 21:34:02,221 [Listener at 0.0.0.0/35677] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-02-08 21:34:02,221 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-02-08 21:34:02,221 [Listener at 0.0.0.0/35677] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-02-08 21:34:02,221 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-02-08 21:34:02,223 [Listener at 0.0.0.0/35677] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-02-08 21:34:02,223 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-02-08 21:34:02,224 [Listener at 0.0.0.0/35677] INFO  replication.ReplicationManager (ReplicationManager.java:start(263)) - Starting Replication Monitor Thread.
2023-02-08 21:34:02,224 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-02-08 21:34:02,225 [Listener at 0.0.0.0/35677] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-02-08 21:34:02,225 [Listener at 0.0.0.0/35677] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-02-08 21:34:02,225 [Listener at 0.0.0.0/35677] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-02-08 21:34:02,225 [Listener at 0.0.0.0/35677] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:34:02,226 [Socket Reader #1 for port 35685] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35685
2023-02-08 21:34:02,226 [Listener at 0.0.0.0/35685] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:34:02,227 [Listener at 0.0.0.0/43069] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-02-08 21:34:02,227 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 43069
2023-02-08 21:34:02,228 [Socket Reader #1 for port 35677] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 35677
2023-02-08 21:34:02,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:34:02,236 [Listener at 0.0.0.0/35677] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-02-08 21:34:02,236 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(401)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-02-08 21:34:02,236 [Listener at 0.0.0.0/35677] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-02-08 21:34:02,236 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1440)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:35677
2023-02-08 21:34:02,238 [Listener at 0.0.0.0/35677] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-02-08 21:34:02,238 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-02-08 21:34:02,238 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-02-08 21:34:02,247 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-02-08 21:34:02,247 [Listener at 0.0.0.0/35677] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-02-08 21:34:02,269 [Listener at 0.0.0.0/35677] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(169)) - RPC server for Client  is listening at /0.0.0.0:35677
2023-02-08 21:34:02,269 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:34:02,269 [IPC Server listener on 35677] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35677: starting
2023-02-08 21:34:02,292 [Listener at 0.0.0.0/35677] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1454)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:43069
2023-02-08 21:34:02,292 [Listener at 0.0.0.0/35677] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:43069
2023-02-08 21:34:02,293 [IPC Server listener on 43069] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 43069: starting
2023-02-08 21:34:02,293 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:34:02,294 [Listener at 0.0.0.0/35677] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(193)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:35685
2023-02-08 21:34:02,295 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-02-08 21:34:02,295 [IPC Server listener on 35685] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 35685: starting
2023-02-08 21:34:02,303 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:34655
2023-02-08 21:34:02,303 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-02-08 21:34:02,304 [Listener at 0.0.0.0/35677] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-02-08 21:34:02,304 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ed2a30c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-02-08 21:34:02,304 [Listener at 0.0.0.0/35677] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-02-08 21:34:02,305 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-02-08 21:34:02,306 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-02-08 21:34:02,306 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-02-08 21:34:02,306 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-02-08 21:34:02,309 [Listener at 0.0.0.0/35677] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34655
2023-02-08 21:34:02,309 [Listener at 0.0.0.0/35677] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_362-b09
2023-02-08 21:34:02,312 [Listener at 0.0.0.0/35677] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-02-08 21:34:02,313 [Listener at 0.0.0.0/35677] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-02-08 21:34:02,313 [Listener at 0.0.0.0/35677] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-02-08 21:34:02,313 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@22cca101{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-02-08 21:34:02,314 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@307ba188{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-02-08 21:34:02,316 [Listener at 0.0.0.0/35677] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@186fc6e{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-02-08 21:34:02,318 [Listener at 0.0.0.0/35677] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@42a198dd{HTTP/1.1, (http/1.1)}{0.0.0.0:34655}
2023-02-08 21:34:02,319 [Listener at 0.0.0.0/35677] INFO  server.Server (Server.java:doStart(415)) - Started @211311ms
2023-02-08 21:34:02,319 [Listener at 0.0.0.0/35677] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-02-08 21:34:02,319 [Listener at 0.0.0.0/35677] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:34655
2023-02-08 21:34:02,358 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:02,359 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:02,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:02,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:02,478 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:02,478 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:03,138 [EndpointStateMachine task thread for /0.0.0.0:35685 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:35685. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-02-08 21:34:03,146 [IPC Server handler 0 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5ef0eb67-7d25-4fae-babe-11dd56e72526(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,146 [IPC Server handler 1 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 712f2f09-531f-4a9c-a178-4f5e906f6733(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,147 [IPC Server handler 2 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 1ea3a110-dd3d-4689-8865-83ed09c3caaf(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,147 [IPC Server handler 3 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,147 [IPC Server handler 4 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,148 [IPC Server handler 5 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 675cd09c-5451-427a-be54-02ea82412c70(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,150 [IPC Server handler 6 on default port 35685] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 5ef0eb67-7d25-4fae-babe-11dd56e72526(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108). Asking datanode to re-register.
2023-02-08 21:34:03,157 [IPC Server handler 7 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/675cd09c-5451-427a-be54-02ea82412c70
2023-02-08 21:34:03,157 [IPC Server handler 7 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 675cd09c-5451-427a-be54-02ea82412c70{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=40493, RATIS=38791, RATIS_ADMIN=38791, RATIS_SERVER=38791, RATIS_DATASTREAM=34463, STANDALONE=42829], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:03,161 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-02-08 21:34:03,161 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-02-08 21:34:03,161 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-02-08 21:34:03,161 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-02-08 21:34:03,167 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:03,173 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:03,234 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:34:03,351 [IPC Server handler 0 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:34:03,351 [IPC Server handler 0 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : feb16a71-ed08-43b3-b68b-8905cd82796b{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36413, RATIS=33409, RATIS_ADMIN=33409, RATIS_SERVER=33409, RATIS_DATASTREAM=44183, STANDALONE=34765], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:03,351 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:03,351 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-02-08 21:34:03,352 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-02-08 21:34:03,352 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:03,355 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-02-08 21:34:03,358 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:03,359 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:03,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:03,375 [IPC Server handler 1 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:03,375 [IPC Server handler 1 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 51a90d96-5277-44ed-beb8-25e5b922217c{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36087, RATIS=40693, RATIS_ADMIN=40693, RATIS_SERVER=40693, RATIS_DATASTREAM=43653, STANDALONE=41023], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:03,378 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-02-08 21:34:03,378 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-02-08 21:34:03,378 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-02-08 21:34:03,378 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-02-08 21:34:03,378 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:03,378 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:03,384 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:03,393 [IPC Server handler 2 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:34:03,393 [IPC Server handler 2 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 712f2f09-531f-4a9c-a178-4f5e906f6733{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=36515, RATIS=42811, RATIS_ADMIN=42811, RATIS_SERVER=42811, RATIS_DATASTREAM=40781, STANDALONE=42209], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:03,393 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:03,395 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:03,478 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:03,479 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:03,478 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:03,612 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:03,613 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:03,613 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5081372732ns, electionTimeout:5081ms
2023-02-08 21:34:03,613 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:03,613 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-02-08 21:34:03,613 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:34:03,613 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111
2023-02-08 21:34:03,615 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111 ELECTION round 0: submit vote requests at term 3 for -1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:03,616 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:03,616 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:03,619 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 3, (t:0, i:0))
2023-02-08 21:34:03,619 [grpc-default-executor-12] INFO  impl.VoteContext (VoteContext.java:log(49)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FOLLOWER: accept ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 0 <= candidate's priority 0
2023-02-08 21:34:03,619 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:34:03,619 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: shutdown 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:03,619 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:03,619 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:03,624 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 3, (t:0, i:0))
2023-02-08 21:34:03,625 [grpc-default-executor-11] INFO  impl.VoteContext (VoteContext.java:log(49)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FOLLOWER: reject ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 1 > candidate's priority 0
2023-02-08 21:34:03,625 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:34:03,625 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:34:03,628 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:03,629 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:34:03,629 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:03,629 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:03,629 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:03,629 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:03,630 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t3. Peer's state: 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131:t3, leader=null, voted=feb16a71-ed08-43b3-b68b-8905cd82796b, raftlog=Memoized:712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:03,630 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t3. Peer's state: 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131:t3, leader=null, voted=null, raftlog=Memoized:51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t3
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t3
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111 ELECTION round 0: result REJECTED
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111
2023-02-08 21:34:03,631 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection111] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:03,632 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:03,633 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:04,128 [IPC Server handler 3 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1ea3a110-dd3d-4689-8865-83ed09c3caaf
2023-02-08 21:34:04,129 [IPC Server handler 3 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 1ea3a110-dd3d-4689-8865-83ed09c3caaf{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=35771, RATIS=44759, RATIS_ADMIN=44759, RATIS_SERVER=44759, RATIS_DATASTREAM=36743, STANDALONE=42231], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:04,129 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:04,133 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:04,139 [IPC Server handler 5 on default port 35685] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/5ef0eb67-7d25-4fae-babe-11dd56e72526
2023-02-08 21:34:04,139 [IPC Server handler 5 on default port 35685] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 5ef0eb67-7d25-4fae-babe-11dd56e72526{ip: 10.1.0.108, host: fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net, ports: [REPLICATION=39233, RATIS=38265, RATIS_ADMIN=38265, RATIS_SERVER=38265, RATIS_DATASTREAM=36283, STANDALONE=40689], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-02-08 21:34:04,140 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-02-08 21:34:04,140 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(937)) - Service ReplicationManager transitions to RUNNING.
2023-02-08 21:34:04,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-02-08 21:34:04,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:34:04,358 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:04,359 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:04,367 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:04,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:04,479 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:04,479 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:05,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:34:05,359 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:05,360 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:05,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:05,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:05,479 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:05,479 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:06,235 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(334)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-02-08 21:34:06,359 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:06,360 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:06,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:06,479 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:06,480 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:06,480 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,230 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,236 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:34:07,236 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to 712f2f09-531f-4a9c-a178-4f5e906f6733(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:34:07,236 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #3 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:34:07,236 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to 1ea3a110-dd3d-4689-8865-83ed09c3caaf(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:34:07,237 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:replicateAnyWithTopology(2221)) - Container #6 is under replicated. Expected replica count is 3, but found 2.
2023-02-08 21:34:07,237 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1490)) - Sending replicateContainerCommand: containerId: 6, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL to 1ea3a110-dd3d-4689-8865-83ed09c3caaf(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)
2023-02-08 21:34:07,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 2 milliseconds for processing 6 containers.
2023-02-08 21:34:07,359 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,360 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:07,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:07,480 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:07,480 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,230 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,237 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:08,359 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,360 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,368 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:08,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:08,480 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,480 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:08,630 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:08,631 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:08,642 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5010562175ns, electionTimeout:5009ms
2023-02-08 21:34:08,642 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:08,642 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2023-02-08 21:34:08,642 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:34:08,642 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112
2023-02-08 21:34:08,644 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112 ELECTION round 0: submit vote requests at term 4 for -1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:08,645 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:08,645 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:08,645 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 4, (t:0, i:0))
2023-02-08 21:34:08,646 [grpc-default-executor-11] INFO  impl.VoteContext (VoteContext.java:log(49)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FOLLOWER: reject ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 1 > candidate's priority 0
2023-02-08 21:34:08,646 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:34:08,646 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:34:08,646 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:34:08,646 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:08,647 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:08,647 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:08,647 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: receive requestVote(ELECTION, feb16a71-ed08-43b3-b68b-8905cd82796b, group-F95237308131, 4, (t:0, i:0))
2023-02-08 21:34:08,647 [grpc-default-executor-12] INFO  impl.VoteContext (VoteContext.java:log(49)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FOLLOWER: accept ELECTION from feb16a71-ed08-43b3-b68b-8905cd82796b: our priority 0 <= candidate's priority 0
2023-02-08 21:34:08,647 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:feb16a71-ed08-43b3-b68b-8905cd82796b
2023-02-08 21:34:08,647 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: shutdown 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:08,647 [grpc-default-executor-12] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:08,647 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:08,648 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t4. Peer's state: 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131:t4, leader=null, voted=null, raftlog=Memoized:51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:08,649 [grpc-default-executor-12] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131 replies to ELECTION vote request: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t4. Peer's state: 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131:t4, leader=null, voted=feb16a71-ed08-43b3-b68b-8905cd82796b, raftlog=Memoized:712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:08,650 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:08,650 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: feb16a71-ed08-43b3-b68b-8905cd82796b<-51a90d96-5277-44ed-beb8-25e5b922217c#0:FAIL-t4
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: feb16a71-ed08-43b3-b68b-8905cd82796b<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t4
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112 ELECTION round 0: result REJECTED
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112
2023-02-08 21:34:08,650 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-LeaderElection112] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:08,651 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:08,651 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:09,129 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 6 from [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)] using NO_COMPRESSION
2023-02-08 21:34:09,129 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 3 from [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)] using NO_COMPRESSION
2023-02-08 21:34:09,132 [grpc-default-executor-11] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (3) to other datanode with compression NO_COMPRESSION
2023-02-08 21:34:09,139 [grpc-default-executor-14] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (6) to other datanode with compression NO_COMPRESSION
2023-02-08 21:34:09,174 [grpc-default-executor-14] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 11776 bytes for container 6
2023-02-08 21:34:09,174 [grpc-default-executor-12] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 6 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-0/data-0/containers/tmp/container-copy/container-6.tar
2023-02-08 21:34:09,175 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 6 is downloaded with size 11776, starting to import.
2023-02-08 21:34:09,185 [grpc-default-executor-11] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 12800 bytes for container 3
2023-02-08 21:34:09,186 [grpc-default-executor-14] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 3 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-0/data-0/containers/tmp/container-copy/container-3.tar
2023-02-08 21:34:09,186 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 3 is downloaded with size 12800, starting to import.
2023-02-08 21:34:09,214 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 3 is replicated successfully
2023-02-08 21:34:09,215 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 3, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL}, queued=2023-02-08T21:34:09.128Z}
2023-02-08 21:34:09,217 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 6 is replicated successfully
2023-02-08 21:34:09,218 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 6, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL}, queued=2023-02-08T21:34:09.128Z}
2023-02-08 21:34:09,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:09,230 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:09,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:09,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:09,360 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:09,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:09,392 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(73)) - Starting replication of container 1 from [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)] using NO_COMPRESSION
2023-02-08 21:34:09,400 [grpc-default-executor-11] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(61)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-02-08 21:34:09,416 [grpc-default-executor-11] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(102)) - Sent 12800 bytes for container 1
2023-02-08 21:34:09,417 [grpc-default-executor-14] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(202)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data-0/containers/tmp/container-copy/container-1.tar
2023-02-08 21:34:09,417 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(88)) - Container 1 is downloaded with size 12800, starting to import.
2023-02-08 21:34:09,438 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(95)) - Container 1 is replicated successfully
2023-02-08 21:34:09,439 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(217)) - Successful ReplicationTask{status=DONE, cmd={replicateContainerCommand: containerId: 1, replicaIndex: 0, sourceNodes: [51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)], priority: NORMAL}, queued=2023-02-08T21:34:09.391Z}
2023-02-08 21:34:09,480 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:09,480 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:09,481 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,225 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,230 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,238 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:10,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:10,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:10,481 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:10,481 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,239 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:11,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,369 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:11,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:11,481 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:11,481 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,173 [JvmPauseMonitor57] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-24a09729-c961-4f74-a8da-1db1f23bfb93: Detected pause in JVM or host machine (eg GC): pause of approximately 108452434ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,175 [JvmPauseMonitor58] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-79dbe8b6-7eb3-4f40-885c-9b270e3bff9d: Detected pause in JVM or host machine (eg GC): pause of approximately 205901725ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,175 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d483f22f-9e25-4e72-9070-8c514e67a945: Detected pause in JVM or host machine (eg GC): pause of approximately 286695908ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,175 [JvmPauseMonitor46] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-61e2ac77-ead7-4e07-97d9-f28a506a07a9: Detected pause in JVM or host machine (eg GC): pause of approximately 286796111ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,175 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-d7e32a70-9f0d-4f10-913d-abe3b834186e: Detected pause in JVM or host machine (eg GC): pause of approximately 303208314ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-87fc5ae4-06d7-4dd6-a957-d888d3372c6b: Detected pause in JVM or host machine (eg GC): pause of approximately 303437619ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor37] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-51a90d96-5277-44ed-beb8-25e5b922217c: Detected pause in JVM or host machine (eg GC): pause of approximately 303471119ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-57e34f8d-7b3e-4914-b42b-53a5fc13ebf8: Detected pause in JVM or host machine (eg GC): pause of approximately 303613324ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor34] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1ea3a110-dd3d-4689-8865-83ed09c3caaf: Detected pause in JVM or host machine (eg GC): pause of approximately 304007534ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-abab8a6e-4db0-471c-b862-cc66e458241d: Detected pause in JVM or host machine (eg GC): pause of approximately 305565971ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-675cd09c-5451-427a-be54-02ea82412c70: Detected pause in JVM or host machine (eg GC): pause of approximately 305622973ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-feb16a71-ed08-43b3-b68b-8905cd82796b: Detected pause in JVM or host machine (eg GC): pause of approximately 305719675ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,176 [JvmPauseMonitor40] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-712f2f09-531f-4a9c-a178-4f5e906f6733: Detected pause in JVM or host machine (eg GC): pause of approximately 305964981ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,177 [JvmPauseMonitor54] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-89a22697-0d01-4b31-a0d7-1bc78e753416: Detected pause in JVM or host machine (eg GC): pause of approximately 353980360ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,177 [JvmPauseMonitor35] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-5ef0eb67-7d25-4fae-babe-11dd56e72526: Detected pause in JVM or host machine (eg GC): pause of approximately 308736949ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,177 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 306679699ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,178 [JvmPauseMonitor51] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 391167172ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,177 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-f322f364-3549-40ba-952a-b6c14b6ec896: Detected pause in JVM or host machine (eg GC): pause of approximately 307353115ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,178 [JvmPauseMonitor55] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-8f2e834d-419f-4eeb-b382-a8e6a25122f3: Detected pause in JVM or host machine (eg GC): pause of approximately 382738165ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,177 [JvmPauseMonitor33] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 306468493ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,179 [09413839-b23a-4aca-94dd-890763e4f20d@group-8E5757024BCB-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5139ms but took extra 447258505ns (> threshold = 300ms)
2023-02-08 21:34:12,180 [JvmPauseMonitor56] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-9b379e2d-f792-462b-ba37-42e93604c872: Detected pause in JVM or host machine (eg GC): pause of approximately 468667175ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,180 [JvmPauseMonitor52] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-09413839-b23a-4aca-94dd-890763e4f20d: Detected pause in JVM or host machine (eg GC): pause of approximately 468784078ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,180 [JvmPauseMonitor53] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-ecb32549-f2ba-48dc-a0ed-8802c582cc24: Detected pause in JVM or host machine (eg GC): pause of approximately 468933881ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=485ms
GC pool 'PS Scavenge' had collection(s): count=1 time=91ms
2023-02-08 21:34:12,180 [89a22697-0d01-4b31-a0d7-1bc78e753416@group-8E5757024BCB-FollowerState] WARN  impl.FollowerState (FollowerState.java:run(130)) - Unexpected long sleep: sleep 5079ms but took extra 473710682ns (> threshold = 300ms)
2023-02-08 21:34:12,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:12,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:12,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:12,481 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:12,481 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,241 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:13,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:13,481 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:13,481 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,482 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:13,711 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065017513ns, electionTimeout:5064ms
2023-02-08 21:34:13,711 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState
2023-02-08 21:34:13,711 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2023-02-08 21:34:13,711 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-02-08 21:34:13,711 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113
2023-02-08 21:34:13,716 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113 ELECTION round 0: submit vote requests at term 5 for -1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,717 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:13,717 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:13,718 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: receive requestVote(ELECTION, 51a90d96-5277-44ed-beb8-25e5b922217c, group-F95237308131, 5, (t:0, i:0))
2023-02-08 21:34:13,718 [grpc-default-executor-14] INFO  impl.VoteContext (VoteContext.java:log(49)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FOLLOWER: accept ELECTION from 51a90d96-5277-44ed-beb8-25e5b922217c: our priority 0 <= candidate's priority 1
2023-02-08 21:34:13,718 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:13,718 [grpc-default-executor-14] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - feb16a71-ed08-43b3-b68b-8905cd82796b: shutdown feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:13,718 [grpc-default-executor-14] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - feb16a71-ed08-43b3-b68b-8905cd82796b: start feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState
2023-02-08 21:34:13,718 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:13,719 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:13,719 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:13,719 [grpc-default-executor-14] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131 replies to ELECTION vote request: 51a90d96-5277-44ed-beb8-25e5b922217c<-feb16a71-ed08-43b3-b68b-8905cd82796b#0:OK-t5. Peer's state: feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131:t5, leader=null, voted=51a90d96-5277-44ed-beb8-25e5b922217c, raftlog=Memoized:feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,719 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 712f2f09-531f-4a9c-a178-4f5e906f6733
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 51a90d96-5277-44ed-beb8-25e5b922217c<-feb16a71-ed08-43b3-b68b-8905cd82796b#0:OK-t5
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113 ELECTION round 0: result PASSED
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: changes role from CANDIDATE to LEADER at term 5 for changeToLeader
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-F95237308131 with new leaderId: 51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: change Leader from null to 51a90d96-5277-44ed-beb8-25e5b922217c at term 5 for becomeLeader, leader elected after 25353ms
2023-02-08 21:34:13,720 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-02-08 21:34:13,721 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:34:13,722 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-02-08 21:34:13,723 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-02-08 21:34:13,724 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 51a90d96-5277-44ed-beb8-25e5b922217c: start 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderStateImpl
2023-02-08 21:34:13,724 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:13,725 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: b6d535dc-4ea0-45d1-872d-f95237308131, Nodes: 51a90d96-5277-44ed-beb8-25e5b922217c(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)feb16a71-ed08-43b3-b68b-8905cd82796b(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108)712f2f09-531f-4a9c-a178-4f5e906f6733(fv-az214-81.1aolvm3ja0pufmfb1mjwo52tze.gx.internal.cloudapp.net/10.1.0.108), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:51a90d96-5277-44ed-beb8-25e5b922217c, CreationTimestamp2023-02-08T21:34:02.220Z[Etc/UTC]] moved to OPEN state
2023-02-08 21:34:13,725 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/current/log_inprogress_0
2023-02-08 21:34:13,737 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderElection113] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: set configuration 0: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,743 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: receive requestVote(ELECTION, 51a90d96-5277-44ed-beb8-25e5b922217c, group-F95237308131, 5, (t:0, i:0))
2023-02-08 21:34:13,743 [grpc-default-executor-11] INFO  impl.VoteContext (VoteContext.java:log(49)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FOLLOWER: accept ELECTION from 51a90d96-5277-44ed-beb8-25e5b922217c: our priority 0 <= candidate's priority 1
2023-02-08 21:34:13,743 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:13,743 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: shutdown 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:13,743 [grpc-default-executor-11] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: start 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState
2023-02-08 21:34:13,743 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState was interrupted
2023-02-08 21:34:13,745 [grpc-default-executor-11] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131 replies to ELECTION vote request: 51a90d96-5277-44ed-beb8-25e5b922217c<-712f2f09-531f-4a9c-a178-4f5e906f6733#0:OK-t5. Peer's state: 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131:t5, leader=null, voted=51a90d96-5277-44ed-beb8-25e5b922217c, raftlog=Memoized:712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,749 [feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread2] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-F95237308131 with new leaderId: 51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:13,749 [feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: change Leader from null to 51a90d96-5277-44ed-beb8-25e5b922217c at term 5 for appendEntries, leader elected after 25404ms
2023-02-08 21:34:13,755 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-02-08 21:34:13,755 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-02-08 21:34:13,757 [feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131: set configuration 0: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,759 [feb16a71-ed08-43b3-b68b-8905cd82796b-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:13,760 [712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(905)) - Leader change notification received for group: group-F95237308131 with new leaderId: 51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:13,760 [712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: change Leader from null to 51a90d96-5277-44ed-beb8-25e5b922217c at term 5 for appendEntries, leader elected after 25382ms
2023-02-08 21:34:13,769 [712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131: set configuration 0: peers:[51a90d96-5277-44ed-beb8-25e5b922217c|rpc:10.1.0.108:40693|dataStream:10.1.0.108:43653|priority:1|startupRole:FOLLOWER, feb16a71-ed08-43b3-b68b-8905cd82796b|rpc:10.1.0.108:33409|dataStream:10.1.0.108:44183|priority:0|startupRole:FOLLOWER, 712f2f09-531f-4a9c-a178-4f5e906f6733|rpc:10.1.0.108:42811|dataStream:10.1.0.108:40781|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-02-08 21:34:13,769 [712f2f09-531f-4a9c-a178-4f5e906f6733-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker: Starting segment from index:0
2023-02-08 21:34:13,771 [712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 712f2f09-531f-4a9c-a178-4f5e906f6733@group-F95237308131-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-6/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/current/log_inprogress_0
2023-02-08 21:34:13,771 [feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - feb16a71-ed08-43b3-b68b-8905cd82796b@group-F95237308131-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-5/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/current/log_inprogress_0
2023-02-08 21:34:14,226 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:14,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:14,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:14,360 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:14,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:14,372 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:14,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:14,482 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:14,482 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,227 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:15,361 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-08 21:34:15,482 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,482 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:15,482 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:16,227 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,231 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,242 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:16,361 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:16,482 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:16,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:17,227 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,232 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:17,361 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:17,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:17,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:18,227 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,232 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:18,361 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,361 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:18,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:18,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:19,227 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,232 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,243 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:19,361 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,362 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,373 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:19,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:19,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:20,228 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,232 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:20,362 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,362 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:20,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:20,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:21,228 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,232 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:21,362 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,362 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:21,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:21,483 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:22,228 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:22,362 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,362 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:22,483 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,483 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:22,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:23,228 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,244 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:23,362 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,362 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:23,484 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,484 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:23,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:24,228 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:24,362 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,363 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:24,484 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,484 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:24,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:25,229 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:25,363 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,363 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,374 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:25,484 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,484 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:25,484 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:26,229 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:26,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:26,245 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:26,363 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:26,363 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:26,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:26,484 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:26,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:26,484 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,229 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,233 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:27,363 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,363 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:27,485 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:27,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:27,485 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,234 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:28,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:28,485 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,485 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:28,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:29,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,234 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,246 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:29,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:29,485 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,485 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:29,485 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:30,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,234 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-02-08 21:34:30,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:30,485 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,485 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:30,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-02-08 21:34:31,230 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,234 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:31,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,375 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:31,486 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,486 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:31,486 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:32,231 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,234 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,247 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-02-08 21:34:32,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:32,486 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,486 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(105)) - Processed 0 containers with health state counts {},failed processing 0
2023-02-08 21:34:32,488 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(367)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-02-08 21:34:32,514 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(450)) - Shutting down the Mini Ozone Cluster
2023-02-08 21:34:32,514 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(465)) - Stopping the Mini Ozone Cluster
2023-02-08 21:34:32,514 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(547)) - Stopping the OzoneManager
2023-02-08 21:34:32,515 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2127)) - om1[localhost:0]: Stopping Ozone Manager
2023-02-08 21:34:32,524 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 42297
2023-02-08 21:34:32,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-02-08 21:34:32,530 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-02-08 21:34:32,538 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-02-08 21:34:32,538 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-02-08 21:34:32,538 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:34:32,541 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-02-08 21:34:32,547 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-02-08 21:34:32,548 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-02-08 21:34:32,548 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-02-08 21:34:32,558 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:88)
2023-02-08 21:34:32,559 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 88
2023-02-08 21:34:32,581 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 88
2023-02-08 21:34:32,581 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 88
2023-02-08 21:34:32,581 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-08 21:34:32,581 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(541)) - Stopping OMDoubleBuffer flush thread
2023-02-08 21:34:32,581 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:canFlush(626)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-02-08 21:34:32,582 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 88
2023-02-08 21:34:32,582 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:34:32,583 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-02-08 21:34:32,583 [JvmPauseMonitor33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-02-08 21:34:32,583 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-02-08 21:34:32,583 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stopDaemon(550)) - OMDoubleBuffer flush thread is not running.
2023-02-08 21:34:32,583 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-02-08 21:34:32,584 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-02-08 21:34:32,584 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-02-08 21:34:32,584 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SstFilteringService
2023-02-08 21:34:32,585 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@76b81824{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-02-08 21:34:32,586 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5e6ede3{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-02-08 21:34:32,586 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-02-08 21:34:32,586 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7113ca85{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-02-08 21:34:32,586 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2aa207eb{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-02-08 21:34:32,589 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(524)) - Stopping the HddsDatanodes
2023-02-08 21:34:32,596 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:34:32,597 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 51a90d96-5277-44ed-beb8-25e5b922217c: close
2023-02-08 21:34:32,597 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: shutdown
2023-02-08 21:34:32,597 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F95237308131,id=51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:32,597 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-LeaderStateImpl
2023-02-08 21:34:32,600 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Completed APPEND_ENTRIES, lastRequest: 51a90d96-5277-44ed-beb8-25e5b922217c->feb16a71-ed08-43b3-b68b-8905cd82796b#1-t5,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:5, i:0), CONFIGURATIONENTRY(current:id: "51a90d96-5277-44ed-beb8-25e5b922217c"
address: "10.1.0.108:40693"
priority: 1
dataStreamAddress: "10.1.0.108:43653"
clientAddress: "10.1.0.108:40693"
adminAddress: "10.1.0.108:40693"
startupRole: FOLLOWER
,id: "feb16a71-ed08-43b3-b68b-8905cd82796b"
address: "10.1.0.108:33409"
dataStreamAddress: "10.1.0.108:44183"
clientAddress: "10.1.0.108:33409"
adminAddress: "10.1.0.108:33409"
startupRole: FOLLOWER
,id: "712f2f09-531f-4a9c-a178-4f5e906f6733"
address: "10.1.0.108:42811"
dataStreamAddress: "10.1.0.108:40781"
clientAddress: "10.1.0.108:42811"
adminAddress: "10.1.0.108:42811"
startupRole: FOLLOWER
, old:)
2023-02-08 21:34:32,601 [grpc-default-executor-11] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - feb16a71-ed08-43b3-b68b-8905cd82796b: Completed APPEND_ENTRIES, lastRequest: null
2023-02-08 21:34:32,601 [grpc-default-executor-14] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:34:32,601 [grpc-default-executor-14] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 1 -> 0
2023-02-08 21:34:32,601 [grpc-default-executor-12] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->feb16a71-ed08-43b3-b68b-8905cd82796b-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:34:32,601 [grpc-default-executor-12] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->feb16a71-ed08-43b3-b68b-8905cd82796b: nextIndex: updateUnconditionally 0 -> 0
2023-02-08 21:34:32,604 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown server GrpcServerProtocolService now
2023-02-08 21:34:32,618 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-PendingRequests: sendNotLeaderResponses
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA: shutdown
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-4ED55B8471BA,id=51a90d96-5277-44ed-beb8-25e5b922217c
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-LeaderStateImpl
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-PendingRequests: sendNotLeaderResponses
2023-02-08 21:34:32,619 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:34:32,621 [51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-4ED55B8471BA: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/88f6dc45-8da9-44d8-88d6-4ed55b8471ba/sm/snapshot.1_0
2023-02-08 21:34:32,621 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-F95237308131: Taking a snapshot at:(t:5, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/sm/snapshot.5_0
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-4ED55B8471BA: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/88f6dc45-8da9-44d8-88d6-4ed55b8471ba/sm/snapshot.1_0 took: 1 ms
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-F95237308131: Finished taking a snapshot at:(t:5, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-3/data/ratis/b6d535dc-4ea0-45d1-872d-f95237308131/sm/snapshot.5_0 took: 0 ms
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:34:32,622 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:34:32,623 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131: closes. applyIndex: 0
2023-02-08 21:34:32,623 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA: closes. applyIndex: 0
2023-02-08 21:34:32,623 [51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:34:32,623 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-4ED55B8471BA-SegmentedRaftLogWorker close()
2023-02-08 21:34:32,624 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:34:32,624 [51a90d96-5277-44ed-beb8-25e5b922217c-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131-SegmentedRaftLogWorker close()
2023-02-08 21:34:32,624 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - cf311c28-b71f-4054-8501-4b3584e1b394 Close channels
2023-02-08 21:34:32,627 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - feb16a71-ed08-43b3-b68b-8905cd82796b Close channels
2023-02-08 21:34:32,628 [51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-02-08 21:34:32,629 [grpc-default-executor-14] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: Completed APPEND_ENTRIES, lastRequest: 51a90d96-5277-44ed-beb8-25e5b922217c->712f2f09-531f-4a9c-a178-4f5e906f6733#1-t5,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:5, i:0), CONFIGURATIONENTRY(current:id: "51a90d96-5277-44ed-beb8-25e5b922217c"
address: "10.1.0.108:40693"
priority: 1
dataStreamAddress: "10.1.0.108:43653"
clientAddress: "10.1.0.108:40693"
adminAddress: "10.1.0.108:40693"
startupRole: FOLLOWER
,id: "feb16a71-ed08-43b3-b68b-8905cd82796b"
address: "10.1.0.108:33409"
dataStreamAddress: "10.1.0.108:44183"
clientAddress: "10.1.0.108:33409"
adminAddress: "10.1.0.108:33409"
startupRole: FOLLOWER
,id: "712f2f09-531f-4a9c-a178-4f5e906f6733"
address: "10.1.0.108:42811"
dataStreamAddress: "10.1.0.108:40781"
clientAddress: "10.1.0.108:42811"
adminAddress: "10.1.0.108:42811"
startupRole: FOLLOWER
, old:)
2023-02-08 21:34:32,632 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 712f2f09-531f-4a9c-a178-4f5e906f6733 Close channels
2023-02-08 21:34:32,637 [grpc-default-executor-14] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 712f2f09-531f-4a9c-a178-4f5e906f6733: Completed APPEND_ENTRIES, lastRequest: null
2023-02-08 21:34:32,638 [grpc-default-executor-12] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:34:32,638 [grpc-default-executor-12] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-GrpcLogAppender: Failed to getClient for 712f2f09-531f-4a9c-a178-4f5e906f6733
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 51a90d96-5277-44ed-beb8-25e5b922217c is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:34:32,638 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(420)) - Attempting to stop container services.
2023-02-08 21:34:32,639 [grpc-default-executor-14] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-02-08 21:34:32,639 [grpc-default-executor-14] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - 51a90d96-5277-44ed-beb8-25e5b922217c@group-F95237308131->712f2f09-531f-4a9c-a178-4f5e906f6733-GrpcLogAppender: Failed to getClient for 712f2f09-531f-4a9c-a178-4f5e906f6733
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 51a90d96-5277-44ed-beb8-25e5b922217c is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-02-08 21:34:32,639 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 51a90d96-5277-44ed-beb8-25e5b922217c: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:34:32,639 [51a90d96-5277-44ed-beb8-25e5b922217c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x84986bfd, L:/0:0:0:0:0:0:0:0:43653] CLOSE
2023-02-08 21:34:32,640 [51a90d96-5277-44ed-beb8-25e5b922217c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x84986bfd, L:/0:0:0:0:0:0:0:0:43653] INACTIVE
2023-02-08 21:34:32,640 [51a90d96-5277-44ed-beb8-25e5b922217c-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x84986bfd, L:/0:0:0:0:0:0:0:0:43653] UNREGISTERED
2023-02-08 21:34:32,639 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: close
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B: shutdown
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-190A96312D4B,id=5ef0eb67-7d25-4fae-babe-11dd56e72526
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: shutdown 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-LeaderStateImpl
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-PendingRequests: sendNotLeaderResponses
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater: set stopIndex = 0
2023-02-08 21:34:32,642 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: shutdown server GrpcServerProtocolService now
2023-02-08 21:34:32,642 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-190A96312D4B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-1/data/ratis/c5279457-8c97-49d0-ad3a-190a96312d4b/sm/snapshot.1_0
2023-02-08 21:34:32,643 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE: shutdown
2023-02-08 21:34:32,643 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-48BDBC021DAE,id=5ef0eb67-7d25-4fae-babe-11dd56e72526
2023-02-08 21:34:32,643 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: shutdown 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-FollowerState
2023-02-08 21:34:32,643 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-190A96312D4B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-1/data/ratis/c5279457-8c97-49d0-ad3a-190a96312d4b/sm/snapshot.1_0 took: 1 ms
2023-02-08 21:34:32,643 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: shutdown server GrpcServerProtocolService successfully
2023-02-08 21:34:32,643 [grpc-default-executor-14] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:32,644 [5ef0eb67-7d25-4fae-babe-11dd56e72526-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x473fae8b, L:/0:0:0:0:0:0:0:0:36283] CLOSE
2023-02-08 21:34:32,644 [5ef0eb67-7d25-4fae-babe-11dd56e72526-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x473fae8b, L:/0:0:0:0:0:0:0:0:36283] INACTIVE
2023-02-08 21:34:32,644 [5ef0eb67-7d25-4fae-babe-11dd56e72526-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x473fae8b, L:/0:0:0:0:0:0:0:0:36283] UNREGISTERED
2023-02-08 21:34:32,643 [grpc-default-executor-11] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526: installSnapshot onError, lastRequest: 1ea3a110-dd3d-4689-8865-83ed09c3caaf->5ef0eb67-7d25-4fae-babe-11dd56e72526#339-t1,previous=(t:1, i:34),leaderCommit=34,initializing? true,entries: size=1, first=(t:1, i:35), METADATAENTRY(c:34): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-02-08 21:34:32,644 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater: Took a snapshot at index 0
2023-02-08 21:34:32,645 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-02-08 21:34:32,645 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B: closes. applyIndex: 0
2023-02-08 21:34:32,646 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater: set stopIndex = 35
2023-02-08 21:34:32,646 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-FollowerState was interrupted
2023-02-08 21:34:32,646 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-48BDBC021DAE: Taking a snapshot at:(t:1, i:35) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-1/data/ratis/b532d524-ffe1-4d4a-8932-48bdbc021dae/sm/snapshot.1_35
2023-02-08 21:34:32,655 [grpc-default-executor-11] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:34:32,655 [grpc-default-executor-14] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-02-08 21:34:32,656 [grpc-default-executor-11] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526: nextIndex: updateUnconditionally 36 -> 35
2023-02-08 21:34:32,656 [grpc-default-executor-14] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:34:32,657 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-48BDBC021DAE: Finished taking a snapshot at:(t:1, i:35) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3f1e3bc0-7fb2-42a1-9d9e-43d47b7a9b95/datanode-1/data/ratis/b532d524-ffe1-4d4a-8932-48bdbc021dae/sm/snapshot.1_35 took: 11 ms
2023-02-08 21:34:32,657 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater: Took a snapshot at index 35
2023-02-08 21:34:32,657 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 35
2023-02-08 21:34:32,658 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE: closes. applyIndex: 35
2023-02-08 21:34:32,658 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:34:32,659 [5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-02-08 21:34:32,660 [grpc-default-executor-11] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:34:32,660 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-190A96312D4B-SegmentedRaftLogWorker close()
2023-02-08 21:34:32,660 [grpc-default-executor-11] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526: nextIndex: updateUnconditionally 35 -> 34
2023-02-08 21:34:32,660 [5ef0eb67-7d25-4fae-babe-11dd56e72526-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5ef0eb67-7d25-4fae-babe-11dd56e72526@group-48BDBC021DAE-SegmentedRaftLogWorker close()
2023-02-08 21:34:32,660 [grpc-default-executor-14] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-02-08 21:34:32,660 [grpc-default-executor-14] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 1ea3a110-dd3d-4689-8865-83ed09c3caaf@group-48BDBC021DAE->5ef0eb67-7d25-4fae-babe-11dd56e72526: nextIndex: updateUnconditionally 34 -> 33
2023-02-08 21:34:32,663 [JvmPauseMonitor37] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-51a90d96-5277-44ed-beb8-25e5b922217c: Stopped
2023-02-08 21:34:32,664 [JvmPauseMonitor35] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-5ef0eb67-7d25-4fae-babe-11dd56e72526: Stopped
]]></system-out>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="13.989"/>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="31.848"/>
</testsuite>