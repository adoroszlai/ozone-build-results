No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-11-06 23:29:06,709 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm4.org/172.25.0.120
STARTUP_MSG:   args = [--bootstrap]
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/java-uuid-generator-4.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/890aed38d1b8ad57e2d1a798712c4a4b710969fa ; compiled by 'runner' on 2023-11-06T22:43Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=1ms, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.address.scmservice.scm4=scm4.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3,scm4, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-11-06 23:29:06,722 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-11-06 23:29:06,829 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-11-06 23:29:07,098 [main] INFO reflections.Reflections: Reflections took 196 ms to scan 3 urls, producing 134 keys and 290 values 
2023-11-06 23:29:07,487 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-11-06 23:29:07,489 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-11-06 23:29:07,639 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm4, RPC Address: scm4.org:9894 and Ratis port: 9894
2023-11-06 23:29:07,649 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm4: scm4.org
2023-11-06 23:29:08,696 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-11-06 23:29:08,697 [main] INFO server.StorageContainerManager: SCM login successful.
2023-11-06 23:29:08,844 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-11-06 23:29:09,490 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
2023-11-06 23:29:11,584 [main] INFO client.SCMCertificateClient: Certificate serial ID set to null
2023-11-06 23:29:11,587 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
2023-11-06 23:29:11,587 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
2023-11-06 23:29:11,593 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
2023-11-06 23:29:14,294 [main] INFO ha.HASecurityUtils: Init response: GETCERT
2023-11-06 23:29:14,309 [main] INFO client.SCMCertificateClient: Creating csr for SCM->hostName:scm4.org,scmId:1a30b843-dd19-4ea2-bff2-e54853fb8bbd,clusterId:CID-9874be73-7265-41b3-ade4-9de0136887b0,subject:scm-sub@scm4.org
2023-11-06 23:29:14,656 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.25.0.120,host:scm4.org
2023-11-06 23:29:14,656 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
2023-11-06 23:29:14,682 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm4.org,scmId:1a30b843-dd19-4ea2-bff2-e54853fb8bbd,clusterId:CID-9874be73-7265-41b3-ade4-9de0136887b0,subject:scm-sub@scm4.org
2023-11-06 23:29:15,452 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/CA-1.crt
2023-11-06 23:29:15,452 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQzMzFhMDkzOC1kNmYxLTQyYTktYTRhZS0xMDlm
NDU2YjRiMzMxMTAvBgNVBAoMKENJRC05ODc0YmU3My03MjY1LTQxYjMtYWRlNC05
ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEwHhcNMjMxMTA2MjMyNDQ1WhcNMjgxMjE0
MjMyNDQ1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQzMzFh
MDkzOC1kNmYxLTQyYTktYTRhZS0xMDlmNDU2YjRiMzMxMTAvBgNVBAoMKENJRC05
ODc0YmU3My03MjY1LTQxYjMtYWRlNC05ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCx6otT0bMW6KcCb5Itbv3A
7aVVnpXxPvd811+SO9tB8OfmZhrCW0qidTZZFkJZFOGy/7ZQubMgW1QbXqjAPj2R
N/pLV+5OgmAr9HqG1i0uc0ecPlgkYa5rf5d9zWinOu7I2O1IMo14+4zKcE1lZbKB
h9Q/qaw8bacxEmLPRfdWGAT9lberKEd1HKvmtQCU0/iijrpUelwHgfhAsDlbxRW5
W4SwZwg5yndRx+x46n1zIjNeSfr4yT0uZxTVqd/bPuFs28c6EVeGr5IN/udFfBr3
/DMnGGN/rtlaMuXLus3Z9xGc/7DcG/pHKXWrSj1ua+xOKfdIELVhGFk/kvhOeRVB
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBHpzXnlV8g
5Ys/MEuiDRN3LJhTKvjOXwcasHcNuBTB19mhmmKw3DVYwAbHD35K377Nl9O6q3fB
yn5RMSqrJMiIIDQdzEPUuKaGW1I1+2zXob8zZ8eN7BL4a57KaKSa5XXxRwNNmiez
HoiQhUIOk2b4elHySuhfiZNtzAGgt5DRaMQQU6l/39X0K6W9rBvYIT47wQ0p+ORP
tMbsmvRAtOP+LkztNjYusk+0Bc/qG5/ri6DQxeMVQLhNbYC0lA54qIZBFHO3c8Ax
2lvY9jEwxRR6Zgxn5ipyjFtTKlAmz0QqC+Zv+r3ztFcqOSwQvR09mNG20E4Du30U
JZov4vs9lh3P
-----END CERTIFICATE-----

2023-11-06 23:29:15,457 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/12.crt
2023-11-06 23:29:15,457 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyjCCArKgAwIBAgIBDDANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQzMzFhMDkzOC1kNmYxLTQyYTktYTRhZS0xMDlm
NDU2YjRiMzMxMTAvBgNVBAoMKENJRC05ODc0YmU3My03MjY1LTQxYjMtYWRlNC05
ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEwHhcNMjMxMTA2MjMyOTE1WhcNMjgxMjE0
MjMyOTE1WjCBijEZMBcGA1UEAwwQc2NtLXN1YkBzY200Lm9yZzEtMCsGA1UECwwk
MWEzMGI4NDMtZGQxOS00ZWEyLWJmZjItZTU0ODUzZmI4YmJkMTEwLwYDVQQKDChD
SUQtOTg3NGJlNzMtNzI2NS00MWIzLWFkZTQtOWRlMDEzNjg4N2IwMQswCQYDVQQF
EwIxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAJsTXXCahVlU3kZK
Es7VVdRCBU/Y6JbmzVWQ9EH/M2kDrwRsGJSqDziHcFqJN+ZqGs0bmc1je2XT+chV
x6EHkEkMnBuMWASijNAmAkRn8U6lUBNojOMOfwcBI3qe+LTb58cvcmFGYDjRUumQ
3b47EHTZHJLpywVC/tdRSoOTcradwqpvtu+AsQHwltDwoPnZmOcDpjPIARrLNXn9
R+JfFxJGLz5cVmRCnOjKKKwP5Tq33r6l2bB3lUXoWAOE48vBNpfITwGjttXa3H4P
v6wuEMzOZiecZG0PaUCRm+QcxfsVn9gjIa8R/HHQ4iZ78ahWPTheSElVDnY4Qen7
K4EijlcCAwEAAaM+MDwwGQYDVR0RBBIwEIcErBkAeIIIc2NtNC5vcmcwDwYDVR0T
AQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAb4wDQYJKoZIhvcNAQELBQADggEBAER8
mxWAPOBG0PiA4oZSVsXEN+pCVUhwcqO0nltzB18ZYAkVhD7+oj5vB7iA8Gw/vrFl
vDiCQ4PrYQZUMaiMyikv0wuoLp6KRHiFJQDqf//BPRtAuwRMJjdbuqJdZ3uamAcZ
dmPQIbr4w3zCYBezjW/A2/IanZi6FxXf0s6kKXffu+q67LBlhBacq97S9Dnjtbn6
S0IkNuQ0SzjXp5f/zVOoon4Q9FptwT6iHq4aSPYewfl1X8+5b0nsGB8vsEsP45Su
9x2YyQglBo8HbiKxpifFseD3yqeYFiE4BqevaEWDUGvD5ophI78YNJpER+2GMaIN
t6TUV2kBayGSYaNcWsQ=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQzMzFhMDkzOC1kNmYxLTQyYTktYTRhZS0xMDlm
NDU2YjRiMzMxMTAvBgNVBAoMKENJRC05ODc0YmU3My03MjY1LTQxYjMtYWRlNC05
ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEwHhcNMjMxMTA2MjMyNDQ1WhcNMjgxMjE0
MjMyNDQ1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQzMzFh
MDkzOC1kNmYxLTQyYTktYTRhZS0xMDlmNDU2YjRiMzMxMTAvBgNVBAoMKENJRC05
ODc0YmU3My03MjY1LTQxYjMtYWRlNC05ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCx6otT0bMW6KcCb5Itbv3A
7aVVnpXxPvd811+SO9tB8OfmZhrCW0qidTZZFkJZFOGy/7ZQubMgW1QbXqjAPj2R
N/pLV+5OgmAr9HqG1i0uc0ecPlgkYa5rf5d9zWinOu7I2O1IMo14+4zKcE1lZbKB
h9Q/qaw8bacxEmLPRfdWGAT9lberKEd1HKvmtQCU0/iijrpUelwHgfhAsDlbxRW5
W4SwZwg5yndRx+x46n1zIjNeSfr4yT0uZxTVqd/bPuFs28c6EVeGr5IN/udFfBr3
/DMnGGN/rtlaMuXLus3Z9xGc/7DcG/pHKXWrSj1ua+xOKfdIELVhGFk/kvhOeRVB
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBHpzXnlV8g
5Ys/MEuiDRN3LJhTKvjOXwcasHcNuBTB19mhmmKw3DVYwAbHD35K377Nl9O6q3fB
yn5RMSqrJMiIIDQdzEPUuKaGW1I1+2zXob8zZ8eN7BL4a57KaKSa5XXxRwNNmiez
HoiQhUIOk2b4elHySuhfiZNtzAGgt5DRaMQQU6l/39X0K6W9rBvYIT47wQ0p+ORP
tMbsmvRAtOP+LkztNjYusk+0Bc/qG5/ri6DQxeMVQLhNbYC0lA54qIZBFHO3c8Ax
2lvY9jEwxRR6Zgxn5ipyjFtTKlAmz0QqC+Zv+r3ztFcqOSwQvR09mNG20E4Du30U
JZov4vs9lh3P
-----END CERTIFICATE-----

2023-11-06 23:29:15,458 [main] INFO utils.CertificateCodec: Save certificate to /data/metadata/scm/sub-ca/certs/certificate.crt
2023-11-06 23:29:15,458 [main] INFO utils.CertificateCodec: Certificate -----BEGIN CERTIFICATE-----
MIIDyjCCArKgAwIBAgIBDDANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQzMzFhMDkzOC1kNmYxLTQyYTktYTRhZS0xMDlm
NDU2YjRiMzMxMTAvBgNVBAoMKENJRC05ODc0YmU3My03MjY1LTQxYjMtYWRlNC05
ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEwHhcNMjMxMTA2MjMyOTE1WhcNMjgxMjE0
MjMyOTE1WjCBijEZMBcGA1UEAwwQc2NtLXN1YkBzY200Lm9yZzEtMCsGA1UECwwk
MWEzMGI4NDMtZGQxOS00ZWEyLWJmZjItZTU0ODUzZmI4YmJkMTEwLwYDVQQKDChD
SUQtOTg3NGJlNzMtNzI2NS00MWIzLWFkZTQtOWRlMDEzNjg4N2IwMQswCQYDVQQF
EwIxMjCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAJsTXXCahVlU3kZK
Es7VVdRCBU/Y6JbmzVWQ9EH/M2kDrwRsGJSqDziHcFqJN+ZqGs0bmc1je2XT+chV
x6EHkEkMnBuMWASijNAmAkRn8U6lUBNojOMOfwcBI3qe+LTb58cvcmFGYDjRUumQ
3b47EHTZHJLpywVC/tdRSoOTcradwqpvtu+AsQHwltDwoPnZmOcDpjPIARrLNXn9
R+JfFxJGLz5cVmRCnOjKKKwP5Tq33r6l2bB3lUXoWAOE48vBNpfITwGjttXa3H4P
v6wuEMzOZiecZG0PaUCRm+QcxfsVn9gjIa8R/HHQ4iZ78ahWPTheSElVDnY4Qen7
K4EijlcCAwEAAaM+MDwwGQYDVR0RBBIwEIcErBkAeIIIc2NtNC5vcmcwDwYDVR0T
AQH/BAUwAwEB/zAOBgNVHQ8BAf8EBAMCAb4wDQYJKoZIhvcNAQELBQADggEBAER8
mxWAPOBG0PiA4oZSVsXEN+pCVUhwcqO0nltzB18ZYAkVhD7+oj5vB7iA8Gw/vrFl
vDiCQ4PrYQZUMaiMyikv0wuoLp6KRHiFJQDqf//BPRtAuwRMJjdbuqJdZ3uamAcZ
dmPQIbr4w3zCYBezjW/A2/IanZi6FxXf0s6kKXffu+q67LBlhBacq97S9Dnjtbn6
S0IkNuQ0SzjXp5f/zVOoon4Q9FptwT6iHq4aSPYewfl1X8+5b0nsGB8vsEsP45Su
9x2YyQglBo8HbiKxpifFseD3yqeYFiE4BqevaEWDUGvD5ophI78YNJpER+2GMaIN
t6TUV2kBayGSYaNcWsQ=
-----END CERTIFICATE-----

-----BEGIN CERTIFICATE-----
MIIDxTCCAq2gAwIBAgIBATANBgkqhkiG9w0BAQsFADCBhTEVMBMGA1UEAwwMc2Nt
QHNjbTEub3JnMS0wKwYDVQQLDCQzMzFhMDkzOC1kNmYxLTQyYTktYTRhZS0xMDlm
NDU2YjRiMzMxMTAvBgNVBAoMKENJRC05ODc0YmU3My03MjY1LTQxYjMtYWRlNC05
ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEwHhcNMjMxMTA2MjMyNDQ1WhcNMjgxMjE0
MjMyNDQ1WjCBhTEVMBMGA1UEAwwMc2NtQHNjbTEub3JnMS0wKwYDVQQLDCQzMzFh
MDkzOC1kNmYxLTQyYTktYTRhZS0xMDlmNDU2YjRiMzMxMTAvBgNVBAoMKENJRC05
ODc0YmU3My03MjY1LTQxYjMtYWRlNC05ZGUwMTM2ODg3YjAxCjAIBgNVBAUTATEw
ggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCx6otT0bMW6KcCb5Itbv3A
7aVVnpXxPvd811+SO9tB8OfmZhrCW0qidTZZFkJZFOGy/7ZQubMgW1QbXqjAPj2R
N/pLV+5OgmAr9HqG1i0uc0ecPlgkYa5rf5d9zWinOu7I2O1IMo14+4zKcE1lZbKB
h9Q/qaw8bacxEmLPRfdWGAT9lberKEd1HKvmtQCU0/iijrpUelwHgfhAsDlbxRW5
W4SwZwg5yndRx+x46n1zIjNeSfr4yT0uZxTVqd/bPuFs28c6EVeGr5IN/udFfBr3
/DMnGGN/rtlaMuXLus3Z9xGc/7DcG/pHKXWrSj1ua+xOKfdIELVhGFk/kvhOeRVB
AgMBAAGjPjA8MA8GA1UdEwEB/wQFMAMBAf8wDgYDVR0PAQH/BAQDAgEGMBkGA1Ud
EQQSMBCHBKwZAHSCCHNjbTEub3JnMA0GCSqGSIb3DQEBCwUAA4IBAQBHpzXnlV8g
5Ys/MEuiDRN3LJhTKvjOXwcasHcNuBTB19mhmmKw3DVYwAbHD35K377Nl9O6q3fB
yn5RMSqrJMiIIDQdzEPUuKaGW1I1+2zXob8zZ8eN7BL4a57KaKSa5XXxRwNNmiez
HoiQhUIOk2b4elHySuhfiZNtzAGgt5DRaMQQU6l/39X0K6W9rBvYIT47wQ0p+ORP
tMbsmvRAtOP+LkztNjYusk+0Bc/qG5/ri6DQxeMVQLhNbYC0lA54qIZBFHO3c8Ax
2lvY9jEwxRR6Zgxn5ipyjFtTKlAmz0QqC+Zv+r3ztFcqOSwQvR09mNG20E4Du30U
JZov4vs9lh3P
-----END CERTIFICATE-----

2023-11-06 23:29:15,459 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
2023-11-06 23:29:15,473 [main] INFO server.StorageContainerManager: SCM BootStrap  is successful for ClusterID CID-9874be73-7265-41b3-ade4-9de0136887b0, SCMID 1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:29:15,473 [main] INFO server.StorageContainerManager: Primary SCM Node ID 331a0938-d6f1-42a9-a4ae-109f456b4b33
2023-11-06 23:29:15,526 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm4.org/172.25.0.120
************************************************************/
No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
2023-11-06 23:29:20,850 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting StorageContainerManager
STARTUP_MSG:   host = scm4.org/172.25.0.120
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 1.4.0-SNAPSHOT
STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/hdds-rocks-native-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.6.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jgraphx-2.0.0.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/hdds-managed-rocksdb-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.6.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.6.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk8-1.8.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.5.1.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/commons-text-1.10.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-2.0.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hamcrest-2.1.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.5.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/java-uuid-generator-4.3.0.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.5.1.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.5.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.4.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/awaitility-4.2.0.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.33.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/rocksdb-checkpoint-differ-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.6.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/okio-3.4.0.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/guava-32.0.0-jre.jar:/opt/hadoop/share/ozone/lib/jgraph-5.13.0.0.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/antlr4-runtime-4.5.3.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.5.1.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.6.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.5.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-ext-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jgrapht-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.53.v20231009.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.100.Final.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-jdk7-1.8.0.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-2.8.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.5.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.5.1.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/okio-jvm-3.4.0.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/commons-fileupload-1.5.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
STARTUP_MSG:   build = https://github.com/apache/ozone/890aed38d1b8ad57e2d1a798712c4a4b710969fa ; compiled by 'runner' on 2023-11-06T22:43Z
STARTUP_MSG:   java = 11.0.19
STARTUP_MSG:   conf = {dfs.container.chunk.write.sync=false, dfs.container.ipc=9859, dfs.container.ipc.random.port=false, dfs.container.ratis.admin.port=9857, dfs.container.ratis.datastream.enabled=true, dfs.container.ratis.datastream.port=9855, dfs.container.ratis.datastream.random.port=false, dfs.container.ratis.enabled=false, dfs.container.ratis.ipc=9858, dfs.container.ratis.ipc.random.port=false, dfs.container.ratis.leader.pending.bytes.limit=1GB, dfs.container.ratis.log.appender.queue.byte-limit=32MB, dfs.container.ratis.log.appender.queue.num-elements=1, dfs.container.ratis.log.purge.gap=1000000, dfs.container.ratis.log.queue.byte-limit=4GB, dfs.container.ratis.log.queue.num-elements=1024, dfs.container.ratis.num.container.op.executors=10, dfs.container.ratis.num.write.chunk.threads.per.volume=10, dfs.container.ratis.replication.level=MAJORITY, dfs.container.ratis.rpc.type=GRPC, dfs.container.ratis.segment.preallocated.size=16KB, dfs.container.ratis.segment.size=1MB, dfs.container.ratis.server.port=9856, dfs.container.ratis.statemachine.max.pending.apply-transactions=10000, dfs.container.ratis.statemachinedata.sync.retries=-1, dfs.container.ratis.statemachinedata.sync.timeout=10s, dfs.ratis.leader.election.minimum.timeout.duration=5s, dfs.ratis.server.retry-cache.timeout.duration=600000ms, dfs.ratis.snapshot.threshold=10000, hadoop.hdds.db.rocksdb.WAL_size_limit_MB=0MB, hadoop.hdds.db.rocksdb.WAL_ttl_seconds=1200, hadoop.hdds.db.rocksdb.logging.enabled=false, hadoop.hdds.db.rocksdb.logging.level=INFO, hadoop.hdds.db.rocksdb.writeoption.sync=false, hdds.block.token.enabled=true, hdds.block.token.expiry.time=1d, hdds.command.status.report.interval=30s, hdds.container.action.max.limit=20, hdds.container.balancer.balancing.iteration.interval=70m, hdds.container.balancer.datanodes.involved.max.percentage.per.iteration=20, hdds.container.balancer.iterations=10, hdds.container.balancer.move.networkTopology.enable=false, hdds.container.balancer.move.replication.timeout=50m, hdds.container.balancer.move.timeout=65m, hdds.container.balancer.size.entering.target.max=26GB, hdds.container.balancer.size.leaving.source.max=26GB, hdds.container.balancer.size.moved.max.per.iteration=500GB, hdds.container.balancer.trigger.du.before.move.enable=false, hdds.container.balancer.utilization.threshold=10, hdds.container.checksum.verification.enabled=true, hdds.container.close.threshold=0.9f, hdds.container.replication.compression=NO_COMPRESSION, hdds.container.report.interval=60s, hdds.container.scrub.data.scan.interval=7d, hdds.container.scrub.dev.data.scan.enabled=true, hdds.container.scrub.dev.metadata.scan.enabled=true, hdds.container.scrub.enabled=false, hdds.container.scrub.metadata.scan.interval=3h, hdds.container.scrub.min.gap=15m, hdds.container.scrub.on.demand.volume.bytes.per.second=5242880, hdds.container.scrub.volume.bytes.per.second=5242880, hdds.container.token.enabled=true, hdds.crl.status.report.interval=60000ms, hdds.datanode.block.delete.max.lock.wait.timeout=100ms, hdds.datanode.block.delete.queue.limit=5, hdds.datanode.block.delete.threads.max=5, hdds.datanode.block.deleting.limit.per.interval=5000, hdds.datanode.block.deleting.max.lock.holding.time=1s, hdds.datanode.block.deleting.service.interval=60s, hdds.datanode.chunk.data.validation.check=false, hdds.datanode.client.bind.host=0.0.0.0, hdds.datanode.client.port=9864, hdds.datanode.command.queue.limit=5000, hdds.datanode.container.close.threads.max=3, hdds.datanode.container.delete.threads.max=2, hdds.datanode.container.schema.v3.enabled=true, hdds.datanode.container.schema.v3.key.separator=|, hdds.datanode.df.refresh.period=5m, hdds.datanode.dir=/data/hdds, hdds.datanode.disk.check.io.failures.tolerated=1, hdds.datanode.disk.check.io.file.size=100B, hdds.datanode.disk.check.io.test.count=3, hdds.datanode.disk.check.min.gap=10m, hdds.datanode.disk.check.timeout=10m, hdds.datanode.du.refresh.period=1h, hdds.datanode.failed.data.volumes.tolerated=-1, hdds.datanode.failed.db.volumes.tolerated=-1, hdds.datanode.failed.metadata.volumes.tolerated=-1, hdds.datanode.handler.count=1, hdds.datanode.hdds.datanode.check.empty.container.dir.on.delete=false, hdds.datanode.http-address=0.0.0.0:9882, hdds.datanode.http-bind-host=0.0.0.0, hdds.datanode.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.datanode.http.auth.kerberos.principal=HTTP/db@EXAMPLE.COM, hdds.datanode.http.auth.type=kerberos, hdds.datanode.http.enabled=true, hdds.datanode.https-address=0.0.0.0:9883, hdds.datanode.https-bind-host=0.0.0.0, hdds.datanode.metadata.rocksdb.cache.size=64MB, hdds.datanode.periodic.disk.check.interval.minutes=60, hdds.datanode.ratis.server.request.timeout=2m, hdds.datanode.read.chunk.threads.per.volume=10, hdds.datanode.recovering.container.scrubbing.service.interval=1m, hdds.datanode.replication.outofservice.limit.factor=2.0, hdds.datanode.replication.port=9886, hdds.datanode.replication.queue.limit=4096, hdds.datanode.replication.streams.limit=10, hdds.datanode.rocksdb.auto-compaction-small-sst-file=true, hdds.datanode.rocksdb.auto-compaction-small-sst-file-num-threshold=512, hdds.datanode.rocksdb.auto-compaction-small-sst-file-size-threshold=1MB, hdds.datanode.rocksdb.delete-obsolete-files-period=1h, hdds.datanode.rocksdb.log.level=INFO, hdds.datanode.rocksdb.log.max-file-num=64, hdds.datanode.rocksdb.log.max-file-size=32MB, hdds.datanode.rocksdb.max-open-files=1024, hdds.datanode.storage.utilization.critical.threshold=0.95, hdds.datanode.storage.utilization.warning.threshold=0.75, hdds.datanode.volume.min.free.space=100MB, hdds.datanode.wait.on.all.followers=false, hdds.db.profile=DISK, hdds.grpc.tls.enabled=true, hdds.grpc.tls.provider=OPENSSL, hdds.heartbeat.interval=30s, hdds.key.dir.name=keys, hdds.key.len=2048, hdds.node.report.interval=60000ms, hdds.pipeline.action.max.limit=20, hdds.pipeline.report.interval=60000ms, hdds.priv.key.file.name=private.pem, hdds.profiler.endpoint.enabled=false, hdds.prometheus.endpoint.enabled=true, hdds.public.key.file.name=public.pem, hdds.ratis.client.exponential.backoff.base.sleep=4s, hdds.ratis.client.exponential.backoff.max.sleep=40s, hdds.ratis.client.multilinear.random.retry.policy=5s, 5, 10s, 5, 15s, 5, 20s, 5, 25s, 5, 60s, 10, hdds.ratis.client.request.watch.timeout=3m, hdds.ratis.client.request.write.timeout=5m, hdds.ratis.client.retry.policy=org.apache.hadoop.hdds.ratis.retrypolicy.RequestTypeDependentRetryPolicyCreator, hdds.ratis.client.retrylimited.max.retries=180, hdds.ratis.client.retrylimited.retry.interval=1s, hdds.ratis.raft.client.async.outstanding-requests.max=32, hdds.ratis.raft.client.rpc.request.timeout=60s, hdds.ratis.raft.client.rpc.watch.request.timeout=180s, hdds.ratis.raft.grpc.flow.control.window=5MB, hdds.ratis.raft.grpc.message.size.max=32MB, hdds.ratis.raft.server.datastream.client.pool.size=10, hdds.ratis.raft.server.datastream.request.threads=20, hdds.ratis.raft.server.delete.ratis.log.directory=true, hdds.ratis.raft.server.leaderelection.pre-vote=true, hdds.ratis.raft.server.log.appender.wait-time.min=1ms, hdds.ratis.raft.server.notification.no-leader.timeout=300s, hdds.ratis.raft.server.rpc.request.timeout=60s, hdds.ratis.raft.server.rpc.slowness.timeout=300s, hdds.ratis.raft.server.watch.timeout=180s, hdds.ratis.raft.server.write.element-limit=1024, hdds.ratis.server.num.snapshots.retained=5, hdds.recon.heartbeat.interval=60s, hdds.rest.http-address=0.0.0.0:9880, hdds.rest.netty.high.watermark=65535, hdds.rest.netty.low.watermark=32768, hdds.rest.rest-csrf.enabled=false, hdds.scm.block.deleting.service.interval=60s, hdds.scm.block.deletion.per-interval.max=100000, hdds.scm.ec.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, hdds.scm.http.auth.kerberos.principal=HTTP/scm@EXAMPLE.COM, hdds.scm.http.auth.type=kerberos, hdds.scm.init.default.layout.version=-1, hdds.scm.kerberos.keytab.file=/etc/security/keytabs/scm.keytab, hdds.scm.kerberos.principal=scm/scm@EXAMPLE.COM, hdds.scm.pipeline.choose.policy.impl=org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy, hdds.scm.replication.container.inflight.deletion.limit=0, hdds.scm.replication.container.inflight.replication.limit=0, hdds.scm.replication.datanode.delete.container.limit=40, hdds.scm.replication.datanode.reconstruction.weight=3, hdds.scm.replication.datanode.replication.limit=20, hdds.scm.replication.enable.legacy=false, hdds.scm.replication.event.timeout=10m, hdds.scm.replication.event.timeout.datanode.offset=30s, hdds.scm.replication.inflight.limit.factor=0.75, hdds.scm.replication.maintenance.remaining.redundancy=1, hdds.scm.replication.maintenance.replica.minimum=2, hdds.scm.replication.over.replicated.interval=30s, hdds.scm.replication.push=true, hdds.scm.replication.thread.interval=300s, hdds.scm.replication.under.replicated.interval=30s, hdds.scm.safemode.atleast.one.node.reported.pipeline.pct=0.90, hdds.scm.safemode.enabled=true, hdds.scm.safemode.healthy.pipeline.pct=0.10, hdds.scm.safemode.min.datanode=1, hdds.scm.safemode.pipeline-availability.check=true, hdds.scm.safemode.pipeline.creation=true, hdds.scm.safemode.threshold.pct=0.99, hdds.scm.unknown-container.action=WARN, hdds.scm.wait.time.after.safemode.exit=5m, hdds.scmclient.failover.max.retry=15, hdds.scmclient.failover.retry.interval=2s, hdds.scmclient.max.retry.timeout=30s, hdds.scmclient.rpc.timeout=15m, hdds.secret.key.algorithm=HmacSHA256, hdds.secret.key.expiry.duration=1h, hdds.secret.key.file.name=secret_keys.json, hdds.secret.key.rotate.check.duration=1m, hdds.secret.key.rotate.duration=5m, hdds.security.client.datanode.container.protocol.acl=*, hdds.security.client.scm.block.protocol.acl=*, hdds.security.client.scm.certificate.protocol.acl=*, hdds.security.client.scm.container.protocol.acl=*, hdds.security.client.scm.secretkey.datanode.protocol.acl=*, hdds.security.client.scm.secretkey.om.protocol.acl=*, hdds.security.client.scm.secretkey.scm.protocol.acl=*, hdds.tracing.enabled=false, hdds.x509.ca.rotation.ack.timeout=PT15M, hdds.x509.ca.rotation.check.interval=P1D, hdds.x509.ca.rotation.enabled=false, hdds.x509.ca.rotation.time-of-day=02:00:00, hdds.x509.default.duration=P365D, hdds.x509.dir.name=certs, hdds.x509.expired.certificate.check.interval=P1D, hdds.x509.file.name=certificate.crt, hdds.x509.max.duration=P1865D, hdds.x509.renew.grace.duration=P28D, hdds.x509.rootca.certificate.polling.interval=PT2h, hdds.x509.signature.algorithm=SHA256withRSA, ozone.UnsafeByteOperations.enabled=true, ozone.acl.authorizer.class=org.apache.hadoop.ozone.security.acl.OzoneNativeAuthorizer, ozone.acl.enabled=true, ozone.administrators=testuser,recon,om, ozone.block.deleting.container.limit.per.interval=10, ozone.block.deleting.limit.per.task=1000, ozone.block.deleting.service.interval=1m, ozone.block.deleting.service.timeout=300000ms, ozone.block.deleting.service.workers=10, ozone.chunk.read.buffer.default.size=64KB, ozone.client.bucket.replication.config.refresh.time.ms=30000, ozone.client.bytes.per.checksum=1MB, ozone.client.checksum.combine.mode=COMPOSITE_CRC, ozone.client.checksum.type=CRC32, ozone.client.connection.timeout=5000ms, ozone.client.datastream.buffer.flush.size=16MB, ozone.client.datastream.min.packet.size=1MB, ozone.client.datastream.pipeline.mode=true, ozone.client.datastream.window.size=64MB, ozone.client.ec.grpc.retries.enabled=true, ozone.client.ec.grpc.retries.max=3, ozone.client.ec.grpc.write.timeout=30s, ozone.client.ec.reconstruct.stripe.read.pool.limit=30, ozone.client.ec.stripe.queue.size=2, ozone.client.exclude.nodes.expiry.time=600000, ozone.client.failover.max.attempts=500, ozone.client.fs.default.bucket.layout=FILE_SYSTEM_OPTIMIZED, ozone.client.key.latest.version.location=true, ozone.client.key.provider.cache.expiry=10d, ozone.client.list.cache=1000, ozone.client.list.trash.keys.max=1000, ozone.client.max.ec.stripe.write.retries=10, ozone.client.max.retries=5, ozone.client.read.timeout=30s, ozone.client.retry.interval=0, ozone.client.socket.timeout=5000ms, ozone.client.stream.buffer.flush.delay=true, ozone.client.stream.buffer.flush.size=16MB, ozone.client.stream.buffer.increment=0B, ozone.client.stream.buffer.max.size=32MB, ozone.client.stream.buffer.size=4MB, ozone.client.verify.checksum=true, ozone.client.wait.between.retries.millis=2000, ozone.container.cache.lock.stripes=1024, ozone.container.cache.size=1024, ozone.directory.deleting.service.interval=1m, ozone.filesystem.snapshot.enabled=true, ozone.freon.http-address=0.0.0.0:9884, ozone.freon.http-bind-host=0.0.0.0, ozone.freon.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.freon.http.auth.kerberos.principal=HTTP/_HOST@REALM, ozone.freon.http.auth.type=simple, ozone.freon.http.enabled=true, ozone.freon.https-address=0.0.0.0:9885, ozone.freon.https-bind-host=0.0.0.0, ozone.fs.datastream.auto.threshold=4MB, ozone.fs.datastream.enabled=false, ozone.fs.hsync.enabled=false, ozone.fs.iterate.batch-size=100, ozone.fs.listing.page.size=1024, ozone.fs.listing.page.size.max=5000, ozone.handler.type=distributed, ozone.http.filter.initializers=org.apache.hadoop.security.AuthenticationFilterInitializer, ozone.http.policy=HTTP_ONLY, ozone.httpfs.http.auth.kerberos.keytab=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.http.auth.kerberos.principal=HTTP/httpfs@EXAMPLE.COM, ozone.httpfs.http.auth.type=kerberos, ozone.httpfs.kerberos.keytab.file=/etc/security/keytabs/httpfs.keytab, ozone.httpfs.kerberos.principal=httpfs/httpfs@EXAMPLE.COM, ozone.https.client.keystore.resource=ssl-client.xml, ozone.https.client.need-auth=false, ozone.https.server.keystore.resource=ssl-server.xml, ozone.key.deleting.limit.per.task=20000, ozone.key.preallocation.max.blocks=64, ozone.manager.db.checkpoint.transfer.bandwidthPerSec=0, ozone.manager.delegation.remover.scan.interval=3600000, ozone.manager.delegation.token.max-lifetime=7d, ozone.manager.delegation.token.renew-interval=1d, ozone.metadata.dirs=/data/metadata, ozone.metadata.dirs.permissions=750, ozone.metastore.rocksdb.cf.write.buffer.size=128MB, ozone.metastore.rocksdb.statistics=OFF, ozone.network.flexible.fqdn.resolution.enabled=false, ozone.network.jvm.address.cache.enabled=true, ozone.network.topology.aware.read=true, ozone.om.address=0.0.0.0:9862, ozone.om.address.omservice.om1=om1, ozone.om.address.omservice.om2=om2, ozone.om.address.omservice.om3=om3, ozone.om.admin.protocol.max.retries=20, ozone.om.admin.protocol.wait.between.retries=1000, ozone.om.container.location.cache.size=100000, ozone.om.container.location.cache.ttl=360m, ozone.om.db.dirs.permissions=750, ozone.om.delta.update.data.size.max.limit=1024MB, ozone.om.enable.filesystem.paths=false, ozone.om.enable.ofs.shared.tmp.dir=false, ozone.om.fs.snapshot.max.limit=1000, ozone.om.grpc.bossgroup.size=8, ozone.om.grpc.maximum.response.length=134217728, ozone.om.grpc.read.thread.num=32, ozone.om.grpc.workergroup.size=32, ozone.om.handler.count.key=100, ozone.om.http-address=0.0.0.0:9874, ozone.om.http-address.omservice.om1=om1, ozone.om.http-address.omservice.om2=om2, ozone.om.http-address.omservice.om3=om3, ozone.om.http-bind-host=0.0.0.0, ozone.om.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.om.http.auth.kerberos.principal=HTTP/om@EXAMPLE.COM, ozone.om.http.auth.type=kerberos, ozone.om.http.enabled=true, ozone.om.https-address=0.0.0.0:9875, ozone.om.https-bind-host=0.0.0.0, ozone.om.internal.service.id=omservice, ozone.om.kerberos.keytab.file=/etc/security/keytabs/om.keytab, ozone.om.kerberos.principal=om/om@EXAMPLE.COM, ozone.om.key.path.lock.enabled=false, ozone.om.keyname.character.check.enabled=false, ozone.om.leader.election.minimum.timeout.duration=5s, ozone.om.lock.fair=false, ozone.om.multitenancy.enabled=false, ozone.om.multitenancy.ranger.sync.interval=10m, ozone.om.multitenancy.ranger.sync.timeout=10s, ozone.om.namespace.s3.strict=true, ozone.om.nodes.omservice=om1,om2,om3, ozone.om.open.key.cleanup.limit.per.task=1000, ozone.om.open.key.cleanup.service.interval=24h, ozone.om.open.key.cleanup.service.timeout=300s, ozone.om.open.key.expire.threshold=7d, ozone.om.open.mpu.cleanup.service.interval=24h, ozone.om.open.mpu.cleanup.service.timeout=300s, ozone.om.open.mpu.expire.threshold=30d, ozone.om.open.mpu.parts.cleanup.limit.per.task=1000, ozone.om.ratis.enable=true, ozone.om.ratis.log.appender.queue.byte-limit=32MB, ozone.om.ratis.log.appender.queue.num-elements=1024, ozone.om.ratis.log.purge.gap=1000000, ozone.om.ratis.log.purge.preservation.log.num=0, ozone.om.ratis.log.purge.upto.snapshot.index=true, ozone.om.ratis.minimum.timeout=5s, ozone.om.ratis.port=9872, ozone.om.ratis.rpc.type=GRPC, ozone.om.ratis.segment.preallocated.size=4MB, ozone.om.ratis.segment.size=4MB, ozone.om.ratis.server.failure.timeout.duration=120s, ozone.om.ratis.server.leaderelection.pre-vote=true, ozone.om.ratis.server.request.timeout=3s, ozone.om.ratis.server.retry.cache.timeout=600000ms, ozone.om.ratis.snapshot.max.total.sst.size=100000000, ozone.om.save.metrics.interval=5m, ozone.om.security.admin.protocol.acl=*, ozone.om.security.client.protocol.acl=*, ozone.om.service.ids=omservice, ozone.om.snapshot.cache.max.size=10, ozone.om.snapshot.checkpoint.dir.creation.poll.timeout=20s, ozone.om.snapshot.compaction.dag.max.time.allowed=30d, ozone.om.snapshot.compaction.dag.prune.daemon.run.interval=3600s, ozone.om.snapshot.db.max.open.files=100, ozone.om.snapshot.diff.cleanup.service.run.internal=1m, ozone.om.snapshot.diff.cleanup.service.timeout=5m, ozone.om.snapshot.diff.disable.native.libs=false, ozone.om.snapshot.diff.job.default.wait.time=1m, ozone.om.snapshot.diff.job.report.persistent.time=7d, ozone.om.snapshot.diff.max.allowed.keys.changed.per.job=10000000, ozone.om.snapshot.diff.max.jobs.purge.per.task=100, ozone.om.snapshot.diff.max.page.size=1000, ozone.om.snapshot.diff.thread.pool.size=10, ozone.om.snapshot.force.full.diff=false, ozone.om.snapshot.provider.connection.timeout=5000s, ozone.om.snapshot.provider.request.timeout=300000ms, ozone.om.snapshot.provider.socket.timeout=5000s, ozone.om.snapshot.sst_dumptool.buffer.size=8KB, ozone.om.snapshot.sst_dumptool.pool.size=1, ozone.om.transport.class=org.apache.hadoop.ozone.om.protocolPB.Hadoop3OmTransportFactory, ozone.om.unflushed.transaction.max.count=10000, ozone.om.upgrade.quota.recalculate.enabled=true, ozone.om.user.max.volume=1024, ozone.om.volume.listall.allowed=false, ozone.path.deleting.limit.per.task=6000, ozone.recon.address=recon:9891, ozone.recon.containerkey.flush.db.max.threshold=150000, ozone.recon.db.dir=/data/metadata/recon, ozone.recon.db.dirs.permissions=750, ozone.recon.heatmap.enable=false, ozone.recon.http-address=0.0.0.0:9888, ozone.recon.http-bind-host=0.0.0.0, ozone.recon.http.auth.kerberos.keytab=/etc/security/keytabs/recon.keytab, ozone.recon.http.auth.kerberos.principal=HTTP/recon@EXAMPLE.COM, ozone.recon.http.auth.type=kerberos, ozone.recon.http.enabled=true, ozone.recon.https-address=0.0.0.0:9889, ozone.recon.https-bind-host=0.0.0.0, ozone.recon.kerberos.keytab.file=/etc/security/keytabs/recon.keytab, ozone.recon.kerberos.principal=recon/recon@EXAMPLE.COM, ozone.recon.nssummary.flush.db.max.threshold=150000, ozone.recon.om.connection.request.timeout=5000, ozone.recon.om.connection.timeout=5s, ozone.recon.om.snapshot.task.flush.param=false, ozone.recon.om.snapshot.task.initial.delay=20s, ozone.recon.om.snapshot.task.interval.delay=1m, ozone.recon.om.socket.timeout=5s, ozone.recon.scm.connection.request.timeout=5s, ozone.recon.scm.connection.timeout=5s, ozone.recon.scm.container.threshold=100, ozone.recon.scm.snapshot.enabled=true, ozone.recon.scm.snapshot.task.initial.delay=1m, ozone.recon.scm.snapshot.task.interval.delay=24h, ozone.recon.security.client.datanode.container.protocol.acl=*, ozone.recon.task.thread.count=1, ozone.replication.allowed-configs=^((STANDALONE|RATIS)/(ONE|THREE))|(EC/(3-2|6-3|10-4)-(512|1024|2048|4096)k)$, ozone.rest.client.http.connection.max=100, ozone.rest.client.http.connection.per-route.max=20, ozone.s3.administrators=testuser,s3g, ozone.s3g.client.buffer.size=4KB, ozone.s3g.default.bucket.layout=OBJECT_STORE, ozone.s3g.http-address=0.0.0.0:9878, ozone.s3g.http-bind-host=0.0.0.0, ozone.s3g.http.auth.kerberos.keytab=/etc/security/keytabs/HTTP.keytab, ozone.s3g.http.auth.kerberos.principal=HTTP/s3g@EXAMPLE.COM, ozone.s3g.http.auth.type=kerberos, ozone.s3g.http.enabled=true, ozone.s3g.kerberos.keytab.file=/etc/security/keytabs/s3g.keytab, ozone.s3g.kerberos.principal=s3g/s3g@EXAMPLE.COM, ozone.s3g.list-keys.shallow.enabled=true, ozone.s3g.secret.http.auth.type=kerberos, ozone.s3g.secret.http.enabled=true, ozone.s3g.volume.name=s3v, ozone.scm.address.scmservice.scm1=scm1.org, ozone.scm.address.scmservice.scm2=scm2.org, ozone.scm.address.scmservice.scm3=scm3.org, ozone.scm.address.scmservice.scm4=scm4.org, ozone.scm.block.client.address=scm, ozone.scm.block.client.bind.host=0.0.0.0, ozone.scm.block.client.port=9863, ozone.scm.block.deletion.max.retry=4096, ozone.scm.block.size=256MB, ozone.scm.ca.list.retry.interval=10s, ozone.scm.chunk.size=4MB, ozone.scm.client.address=scm, ozone.scm.client.bind.host=0.0.0.0, ozone.scm.client.port=9860, ozone.scm.close.container.wait.duration=5s, ozone.scm.container.layout=FILE_PER_BLOCK, ozone.scm.container.lock.stripes=512, ozone.scm.container.placement.ec.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter, ozone.scm.container.placement.impl=org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware, ozone.scm.container.size=1GB, ozone.scm.datanode.admin.monitor.interval=30s, ozone.scm.datanode.disallow.same.peers=false, ozone.scm.datanode.id.dir=/data, ozone.scm.datanode.pipeline.limit=2, ozone.scm.datanode.port=9861, ozone.scm.datanode.ratis.volume.free-space.min=10MB, ozone.scm.db.dirs.permissions=750, ozone.scm.dead.node.interval=10m, ozone.scm.ec.pipeline.minimum=5, ozone.scm.ec.pipeline.per.volume.factor=1, ozone.scm.event.ContainerReport.thread.pool.size=10, ozone.scm.expired.container.replica.op.scrub.interval=5m, ozone.scm.grpc.port=9895, ozone.scm.ha.dbtransactionbuffer.flush.interval=600s, ozone.scm.ha.grpc.deadline.interval=30m, ozone.scm.ha.raft.server.log.appender.wait-time.min=0ms, ozone.scm.ha.ratis.leader.election.timeout=5s, ozone.scm.ha.ratis.leader.ready.check.interval=2s, ozone.scm.ha.ratis.leader.ready.wait.timeout=60s, ozone.scm.ha.ratis.log.appender.queue.byte-limit=32MB, ozone.scm.ha.ratis.log.appender.queue.num-elements=1024, ozone.scm.ha.ratis.log.purge.enabled=false, ozone.scm.ha.ratis.log.purge.gap=1000000, ozone.scm.ha.ratis.request.timeout=30s, ozone.scm.ha.ratis.rpc.type=GRPC, ozone.scm.ha.ratis.segment.preallocated.size=4MB, ozone.scm.ha.ratis.segment.size=4MB, ozone.scm.ha.ratis.server.failure.timeout.duration=120s, ozone.scm.ha.ratis.server.leaderelection.pre-vote=true, ozone.scm.ha.ratis.server.retry.cache.timeout=60s, ozone.scm.ha.ratis.server.snapshot.creation.gap=1024, ozone.scm.ha.ratis.snapshot.threshold=1000, ozone.scm.handler.count.key=100, ozone.scm.heartbeat.log.warn.interval.count=10, ozone.scm.heartbeat.rpc-retry-count=15, ozone.scm.heartbeat.rpc-retry-interval=1s, ozone.scm.heartbeat.rpc-timeout=5s, ozone.scm.heartbeat.thread.interval=3s, ozone.scm.http-address=0.0.0.0:9876, ozone.scm.http-bind-host=0.0.0.0, ozone.scm.http.enabled=true, ozone.scm.https-address=0.0.0.0:9877, ozone.scm.https-bind-host=0.0.0.0, ozone.scm.info.wait.duration=10m, ozone.scm.keyvalue.container.deletion-choosing.policy=org.apache.hadoop.ozone.container.common.impl.TopNOrderedContainerDeletionChoosingPolicy, ozone.scm.network.topology.schema.file=network-topology-default.xml, ozone.scm.nodes.scmservice=scm1,scm2,scm3,scm4, ozone.scm.pipeline.allocated.timeout=5m, ozone.scm.pipeline.creation.auto.factor.one=true, ozone.scm.pipeline.creation.interval=30s, ozone.scm.pipeline.destroy.timeout=66s, ozone.scm.pipeline.leader-choose.policy=org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy, ozone.scm.pipeline.owner.container.count=1, ozone.scm.pipeline.per.metadata.disk=2, ozone.scm.pipeline.scrub.interval=5m, ozone.scm.ratis.enable=true, ozone.scm.ratis.pipeline.limit=0, ozone.scm.ratis.port=9894, ozone.scm.security.handler.count.key=2, ozone.scm.security.service.bind.host=0.0.0.0, ozone.scm.security.service.port=9961, ozone.scm.sequence.id.batch.size=1000, ozone.scm.service.ids=scmservice, ozone.scm.skip.bootstrap.validation=false, ozone.scm.stale.node.interval=5m, ozone.scm.update.client.crl.check.interval=600s, ozone.scm.update.service.port=9893, ozone.security.enabled=true, ozone.security.http.kerberos.enabled=true, ozone.server.default.replication=3, ozone.server.default.replication.type=RATIS, ozone.service.shutdown.timeout=60s, ozone.snapshot.deleting.limit.per.task=10, ozone.snapshot.deleting.service.interval=30s, ozone.snapshot.deleting.service.timeout=300s, ozone.snapshot.filtering.limit.per.task=2, ozone.snapshot.filtering.service.interval=1m, ozone.snapshot.key.deleting.limit.per.task=20000, ozone.sst.filtering.service.timeout=300000ms, ozone.trace.enabled=false, recon.om.delta.update.limit=2000, recon.om.delta.update.loop.limit=10, scm.container.client.idle.threshold=10s, scm.container.client.max.size=256}
************************************************************/
2023-11-06 23:29:20,864 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
2023-11-06 23:29:20,958 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-11-06 23:29:21,317 [main] INFO reflections.Reflections: Reflections took 291 ms to scan 3 urls, producing 134 keys and 290 values 
2023-11-06 23:29:21,463 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
2023-11-06 23:29:21,479 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-11-06 23:29:21,515 [main] INFO ha.SCMHANodeDetails: Found matching SCM address with SCMServiceId: scmservice, SCMNodeId: scm4, RPC Address: scm4.org:9894 and Ratis port: 9894
2023-11-06 23:29:21,516 [main] INFO ha.SCMHANodeDetails: Setting configuration key ozone.scm.address with value of key ozone.scm.address.scmservice.scm4: scm4.org
2023-11-06 23:29:22,340 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
2023-11-06 23:29:22,341 [main] INFO server.StorageContainerManager: SCM login successful.
2023-11-06 23:29:24,475 [main] INFO client.SCMCertificateClient: Certificate serial ID set to 12
2023-11-06 23:29:25,227 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 12
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:29:15 UTC 2023
           Final Date: Thu Dec 14 23:29:15 UTC 2028
            SubjectDN: CN=scm-sub@scm4.org,OU=1a30b843-dd19-4ea2-bff2-e54853fb8bbd,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=12
           Public Key: RSA Public Key [d5:57:4a:86:3f:99:df:bc:af:25:d5:12:29:53:60:c1:db:92:70:5b],[56:66:d1:a4]
        modulus: 9b135d709a855954de464a12ced555d442054fd8e896e6cd5590f441ff336903af046c1894aa0f3887705a8937e66a1acd1b99cd637b65d3f9c855c7a10790490c9c1b8c5804a28cd026024467f14ea55013688ce30e7f0701237a9ef8b4dbe7c72f7261466038d152e990ddbe3b1074d91c92e9cb0542fed7514a839372b69dc2aa6fb6ef80b101f096d0f0a0f9d998e703a633c8011acb3579fd47e25f1712462f3e5c5664429ce8ca28ac0fe53ab7debea5d9b0779545e8580384e3cbc13697c84f01a3b6d5dadc7e0fbfac2e10ccce66279c646d0f6940919be41cc5fb159fd82321af11fc71d0e2267bf1a8563d385e4849550e763841e9fb2b81228e57
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 447c9b15803ce046d0f880e2865256c5c437ea42
                       55487072a3b49e5b73075f19600915843efea23e
                       6f07b880f06c3fbeb165bc38824383eb61065431
                       a88cca292fd30ba82e9e8a4478852500ea7fffc1
                       3d1b40bb044c26375bbaa25d677b9a9807197663
                       d021baf8c37cc26017b38d6fc0dbf21a9d98ba17
                       15dfd2cea42977dfbbeabaecb06584169cabded2
                       f439e3b5b9fa4b422436e4344b38d7a797ffcd53
                       a8a27e10f45a6dc13ea21eae1a48f61ec1f9755f
                       cfb96f49ec181f2fb04b0fe394aef71d98c90825
                       068f076e22b1a627c5b1e0f7caa79816213806a7
                       af684583506bc3e68a6123bf18349a4447ed8631
                       a20db7a4d45769016b219261a35c5ac4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/12.crt.
2023-11-06 23:29:25,290 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 12
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:29:15 UTC 2023
           Final Date: Thu Dec 14 23:29:15 UTC 2028
            SubjectDN: CN=scm-sub@scm4.org,OU=1a30b843-dd19-4ea2-bff2-e54853fb8bbd,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=12
           Public Key: RSA Public Key [d5:57:4a:86:3f:99:df:bc:af:25:d5:12:29:53:60:c1:db:92:70:5b],[56:66:d1:a4]
        modulus: 9b135d709a855954de464a12ced555d442054fd8e896e6cd5590f441ff336903af046c1894aa0f3887705a8937e66a1acd1b99cd637b65d3f9c855c7a10790490c9c1b8c5804a28cd026024467f14ea55013688ce30e7f0701237a9ef8b4dbe7c72f7261466038d152e990ddbe3b1074d91c92e9cb0542fed7514a839372b69dc2aa6fb6ef80b101f096d0f0a0f9d998e703a633c8011acb3579fd47e25f1712462f3e5c5664429ce8ca28ac0fe53ab7debea5d9b0779545e8580384e3cbc13697c84f01a3b6d5dadc7e0fbfac2e10ccce66279c646d0f6940919be41cc5fb159fd82321af11fc71d0e2267bf1a8563d385e4849550e763841e9fb2b81228e57
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 447c9b15803ce046d0f880e2865256c5c437ea42
                       55487072a3b49e5b73075f19600915843efea23e
                       6f07b880f06c3fbeb165bc38824383eb61065431
                       a88cca292fd30ba82e9e8a4478852500ea7fffc1
                       3d1b40bb044c26375bbaa25d677b9a9807197663
                       d021baf8c37cc26017b38d6fc0dbf21a9d98ba17
                       15dfd2cea42977dfbbeabaecb06584169cabded2
                       f439e3b5b9fa4b422436e4344b38d7a797ffcd53
                       a8a27e10f45a6dc13ea21eae1a48f61ec1f9755f
                       cfb96f49ec181f2fb04b0fe394aef71d98c90825
                       068f076e22b1a627c5b1e0f7caa79816213806a7
                       af684583506bc3e68a6123bf18349a4447ed8631
                       a20db7a4d45769016b219261a35c5ac4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe
 from file: /data/metadata/scm/sub-ca/certs/certificate.crt.
2023-11-06 23:29:25,351 [main] INFO client.SCMCertificateClient: Added certificate   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:24:45 UTC 2023
           Final Date: Thu Dec 14 23:24:45 UTC 2028
            SubjectDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Public Key: RSA Public Key [9e:57:88:e6:0e:e5:7a:de:33:77:fb:70:1a:08:4c:c1:b3:20:87:18],[56:66:d1:a4]
        modulus: b1ea8b53d1b316e8a7026f922d6efdc0eda5559e95f13ef77cd75f923bdb41f0e7e6661ac25b4aa275365916425914e1b2ffb650b9b3205b541b5ea8c03e3d9137fa4b57ee4e82602bf47a86d62d2e73479c3e582461ae6b7f977dcd68a73aeec8d8ed48328d78fb8cca704d6565b28187d43fa9ac3c6da7311262cf45f7561804fd95b7ab2847751cabe6b50094d3f8a28eba547a5c0781f840b0395bc515b95b84b0670839ca7751c7ec78ea7d7322335e49faf8c93d2e6714d5a9dfdb3ee16cdbc73a115786af920dfee7457c1af7fc332718637faed95a32e5cbbacdd9f7119cffb0dc1bfa472975ab4a3d6e6bec4e29f74810b56118593f92f84e791541
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 47a735e7955f20e58b3f304ba20d13772c98532a
                       f8ce5f071ab0770db814c1d7d9a19a62b0dc3558
                       c006c70f7e4adfbecd97d3baab77c1ca7e51312a
                       ab24c88820341dcc43d4b8a6865b5235fb6cd7a1
                       bf3367c78dec12f86b9eca68a49ae575f147034d
                       9a27b31e889085420e9366f87a51f24ae85f8993
                       6dcc01a0b790d168c41053a97fdfd5f42ba5bdac
                       1bd8213e3bc10d29f8e44fb4c6ec9af440b4e3fe
                       2e4ced36362eb24fb405cfea1b9feb8ba0d0c5e3
                       1540b84d6d80b4940e78a886411473b773c031da
                       5bd8f63130c5147a660c67e62a728c5b532a5026
                       cf442a0be66ffabdf3b4572a392c10bd1d3d98d1
                       b6d04e03bb7d14259a2fe2fb3d961dcf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

 from file: /data/metadata/scm/sub-ca/certs/CA-1.crt.
2023-11-06 23:29:25,355 [main] INFO client.SCMCertificateClient: CertificateRenewerService and root ca rotation polling is disabled for scm/sub-ca
2023-11-06 23:29:25,895 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-11-06 23:29:26,376 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-11-06 23:29:26,777 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-11-06 23:29:26,780 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
2023-11-06 23:29:26,929 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
2023-11-06 23:29:27,414 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:29:27,546 [main] INFO ssl.ReloadingX509KeyManager: Key manager is loaded with certificate chain
2023-11-06 23:29:27,552 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 12
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:29:15 UTC 2023
           Final Date: Thu Dec 14 23:29:15 UTC 2028
            SubjectDN: CN=scm-sub@scm4.org,OU=1a30b843-dd19-4ea2-bff2-e54853fb8bbd,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=12
           Public Key: RSA Public Key [d5:57:4a:86:3f:99:df:bc:af:25:d5:12:29:53:60:c1:db:92:70:5b],[56:66:d1:a4]
        modulus: 9b135d709a855954de464a12ced555d442054fd8e896e6cd5590f441ff336903af046c1894aa0f3887705a8937e66a1acd1b99cd637b65d3f9c855c7a10790490c9c1b8c5804a28cd026024467f14ea55013688ce30e7f0701237a9ef8b4dbe7c72f7261466038d152e990ddbe3b1074d91c92e9cb0542fed7514a839372b69dc2aa6fb6ef80b101f096d0f0a0f9d998e703a633c8011acb3579fd47e25f1712462f3e5c5664429ce8ca28ac0fe53ab7debea5d9b0779545e8580384e3cbc13697c84f01a3b6d5dadc7e0fbfac2e10ccce66279c646d0f6940919be41cc5fb159fd82321af11fc71d0e2267bf1a8563d385e4849550e763841e9fb2b81228e57
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 447c9b15803ce046d0f880e2865256c5c437ea42
                       55487072a3b49e5b73075f19600915843efea23e
                       6f07b880f06c3fbeb165bc38824383eb61065431
                       a88cca292fd30ba82e9e8a4478852500ea7fffc1
                       3d1b40bb044c26375bbaa25d677b9a9807197663
                       d021baf8c37cc26017b38d6fc0dbf21a9d98ba17
                       15dfd2cea42977dfbbeabaecb06584169cabded2
                       f439e3b5b9fa4b422436e4344b38d7a797ffcd53
                       a8a27e10f45a6dc13ea21eae1a48f61ec1f9755f
                       cfb96f49ec181f2fb04b0fe394aef71d98c90825
                       068f076e22b1a627c5b1e0f7caa79816213806a7
                       af684583506bc3e68a6123bf18349a4447ed8631
                       a20db7a4d45769016b219261a35c5ac4
       Extensions: 
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 

                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0xbe

2023-11-06 23:29:27,559 [main] INFO ssl.ReloadingX509KeyManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:24:45 UTC 2023
           Final Date: Thu Dec 14 23:24:45 UTC 2028
            SubjectDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Public Key: RSA Public Key [9e:57:88:e6:0e:e5:7a:de:33:77:fb:70:1a:08:4c:c1:b3:20:87:18],[56:66:d1:a4]
        modulus: b1ea8b53d1b316e8a7026f922d6efdc0eda5559e95f13ef77cd75f923bdb41f0e7e6661ac25b4aa275365916425914e1b2ffb650b9b3205b541b5ea8c03e3d9137fa4b57ee4e82602bf47a86d62d2e73479c3e582461ae6b7f977dcd68a73aeec8d8ed48328d78fb8cca704d6565b28187d43fa9ac3c6da7311262cf45f7561804fd95b7ab2847751cabe6b50094d3f8a28eba547a5c0781f840b0395bc515b95b84b0670839ca7751c7ec78ea7d7322335e49faf8c93d2e6714d5a9dfdb3ee16cdbc73a115786af920dfee7457c1af7fc332718637faed95a32e5cbbacdd9f7119cffb0dc1bfa472975ab4a3d6e6bec4e29f74810b56118593f92f84e791541
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 47a735e7955f20e58b3f304ba20d13772c98532a
                       f8ce5f071ab0770db814c1d7d9a19a62b0dc3558
                       c006c70f7e4adfbecd97d3baab77c1ca7e51312a
                       ab24c88820341dcc43d4b8a6865b5235fb6cd7a1
                       bf3367c78dec12f86b9eca68a49ae575f147034d
                       9a27b31e889085420e9366f87a51f24ae85f8993
                       6dcc01a0b790d168c41053a97fdfd5f42ba5bdac
                       1bd8213e3bc10d29f8e44fb4c6ec9af440b4e3fe
                       2e4ced36362eb24fb405cfea1b9feb8ba0d0c5e3
                       1540b84d6d80b4940e78a886411473b773c031da
                       5bd8f63130c5147a660c67e62a728c5b532a5026
                       cf442a0be66ffabdf3b4572a392c10bd1d3d98d1
                       b6d04e03bb7d14259a2fe2fb3d961dcf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-11-06 23:29:27,579 [main] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-11-06 23:29:27,580 [main] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-11-06 23:29:27,581 [main] INFO ssl.ReloadingX509TrustManager: Trust manager is loaded with certificates
2023-11-06 23:29:27,586 [main] INFO ssl.ReloadingX509TrustManager:   [0]         Version: 3
         SerialNumber: 1
             IssuerDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Start Date: Mon Nov 06 23:24:45 UTC 2023
           Final Date: Thu Dec 14 23:24:45 UTC 2028
            SubjectDN: CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1
           Public Key: RSA Public Key [9e:57:88:e6:0e:e5:7a:de:33:77:fb:70:1a:08:4c:c1:b3:20:87:18],[56:66:d1:a4]
        modulus: b1ea8b53d1b316e8a7026f922d6efdc0eda5559e95f13ef77cd75f923bdb41f0e7e6661ac25b4aa275365916425914e1b2ffb650b9b3205b541b5ea8c03e3d9137fa4b57ee4e82602bf47a86d62d2e73479c3e582461ae6b7f977dcd68a73aeec8d8ed48328d78fb8cca704d6565b28187d43fa9ac3c6da7311262cf45f7561804fd95b7ab2847751cabe6b50094d3f8a28eba547a5c0781f840b0395bc515b95b84b0670839ca7751c7ec78ea7d7322335e49faf8c93d2e6714d5a9dfdb3ee16cdbc73a115786af920dfee7457c1af7fc332718637faed95a32e5cbbacdd9f7119cffb0dc1bfa472975ab4a3d6e6bec4e29f74810b56118593f92f84e791541
public exponent: 10001

  Signature Algorithm: SHA256WITHRSA
            Signature: 47a735e7955f20e58b3f304ba20d13772c98532a
                       f8ce5f071ab0770db814c1d7d9a19a62b0dc3558
                       c006c70f7e4adfbecd97d3baab77c1ca7e51312a
                       ab24c88820341dcc43d4b8a6865b5235fb6cd7a1
                       bf3367c78dec12f86b9eca68a49ae575f147034d
                       9a27b31e889085420e9366f87a51f24ae85f8993
                       6dcc01a0b790d168c41053a97fdfd5f42ba5bdac
                       1bd8213e3bc10d29f8e44fb4c6ec9af440b4e3fe
                       2e4ced36362eb24fb405cfea1b9feb8ba0d0c5e3
                       1540b84d6d80b4940e78a886411473b773c031da
                       5bd8f63130c5147a660c67e62a728c5b532a5026
                       cf442a0be66ffabdf3b4572a392c10bd1d3d98d1
                       b6d04e03bb7d14259a2fe2fb3d961dcf
       Extensions: 
                       critical(true) BasicConstraints: isCa(true)
                       critical(true) KeyUsage: 0x6
                       critical(false) 2.5.29.17 value = Sequence
    Tagged [7] IMPLICIT 
        DER Octet String[4] 
    Tagged [2] IMPLICIT 
        DER Octet String[8] 


2023-11-06 23:29:27,690 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-11-06 23:29:27,707 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-11-06 23:29:27,960 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
2023-11-06 23:29:28,017 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-11-06 23:29:28,041 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
2023-11-06 23:29:28,045 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-11-06 23:29:28,051 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
2023-11-06 23:29:28,052 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
2023-11-06 23:29:28,052 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
2023-11-06 23:29:28,060 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
2023-11-06 23:29:28,068 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:29:28,070 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-11-06 23:29:28,073 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-11-06 23:29:28,121 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-11-06 23:29:28,152 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-11-06 23:29:28,156 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-11-06 23:29:29,371 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = DISABLED (default)
2023-11-06 23:29:29,376 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
2023-11-06 23:29:29,377 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
2023-11-06 23:29:29,378 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-11-06 23:29:29,378 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-11-06 23:29:29,383 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-11-06 23:29:29,419 [main] INFO server.RaftServer: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: addNew group-9DE0136887B0:[] returns group-9DE0136887B0:java.util.concurrent.CompletableFuture@2b82018[Not completed]
2023-11-06 23:29:29,481 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: new RaftServerImpl for group-9DE0136887B0:[] with SCMStateMachine:uninitialized
2023-11-06 23:29:29,496 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
2023-11-06 23:29:29,496 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
2023-11-06 23:29:29,498 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
2023-11-06 23:29:29,498 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
2023-11-06 23:29:29,498 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-11-06 23:29:29,501 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
2023-11-06 23:29:29,557 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-11-06 23:29:29,564 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
2023-11-06 23:29:29,613 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
2023-11-06 23:29:29,615 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
2023-11-06 23:29:29,677 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
2023-11-06 23:29:29,689 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.timeout = 10s (default)
2023-11-06 23:29:29,707 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
2023-11-06 23:29:29,709 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
2023-11-06 23:29:29,747 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.read.option = DEFAULT (default)
2023-11-06 23:29:29,910 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-11-06 23:29:29,913 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-11-06 23:29:29,914 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
2023-11-06 23:29:29,914 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
2023-11-06 23:29:29,915 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
2023-11-06 23:29:29,915 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-groupManagement] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
2023-11-06 23:29:29,919 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
2023-11-06 23:29:29,919 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-11-06 23:29:29,919 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
2023-11-06 23:29:29,973 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7), software layout = HADOOP_PRC_PORTS_IN_DATANODEDETAILS (version = 7)
2023-11-06 23:29:30,038 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
2023-11-06 23:29:30,040 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
2023-11-06 23:29:30,050 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
2023-11-06 23:29:30,053 [main] INFO ha.SequenceIdGenerator: upgrade CertificateId to 2
2023-11-06 23:29:30,056 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
2023-11-06 23:29:30,226 [main] INFO node.SCMNodeManager: Entering startup safe mode.
2023-11-06 23:29:30,347 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackAware
2023-11-06 23:29:30,362 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-11-06 23:29:30,426 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
2023-11-06 23:29:30,521 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-11-06 23:29:30,523 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-11-06 23:29:30,567 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
2023-11-06 23:29:30,569 [main] INFO pipeline.BackgroundPipelineCreator: Starting scm4-RatisPipelineUtilsThread.
2023-11-06 23:29:30,585 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
2023-11-06 23:29:30,591 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
2023-11-06 23:29:30,625 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
2023-11-06 23:29:30,632 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
2023-11-06 23:29:30,803 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-11-06 23:29:30,806 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-11-06 23:29:30,948 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
2023-11-06 23:29:31,975 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
2023-11-06 23:29:31,994 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
2023-11-06 23:29:31,998 [scm4-ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
2023-11-06 23:29:32,036 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
2023-11-06 23:29:32,057 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 0
2023-11-06 23:29:32,071 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-11-06 23:29:32,543 [main] INFO security.SecretKeyManagerService: Scheduling rotation checker with interval PT1M
2023-11-06 23:29:32,544 [main] INFO ha.SCMServiceManager: Registering service SecretKeyManagerService.
2023-11-06 23:29:32,595 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
2023-11-06 23:29:32,640 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-11-06 23:29:32,699 [main] INFO ipc.Server: Listener at 0.0.0.0:9961
2023-11-06 23:29:32,703 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
2023-11-06 23:29:32,781 [main] INFO server.StorageContainerManager: SCM start with adminUsers: [testuser, recon, om, scm]
2023-11-06 23:29:35,532 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-11-06 23:29:35,570 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-11-06 23:29:35,571 [main] INFO ipc.Server: Listener at 0.0.0.0:9861
2023-11-06 23:29:35,572 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
2023-11-06 23:29:35,665 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-11-06 23:29:35,678 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-11-06 23:29:35,678 [main] INFO ipc.Server: Listener at 0.0.0.0:9863
2023-11-06 23:29:35,679 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
2023-11-06 23:29:35,741 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
2023-11-06 23:29:35,761 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-11-06 23:29:35,762 [main] INFO ipc.Server: Listener at 0.0.0.0:9860
2023-11-06 23:29:35,763 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
2023-11-06 23:29:36,106 [main] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
2023-11-06 23:29:36,112 [main] INFO server.StorageContainerManager: 
Container Balancer status:
Key                            Value
Running                        false
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB
Number of Iterations                               10
Time Limit for Single Container's Movement         65min
Time Limit for Single Container's Replication      50min
Interval between each Iteration                    70min
Whether to Enable Network Topology                 false
Whether to Trigger Refresh Datanode Usage Info     false
Container IDs to Exclude from Balancing            None
Datanodes Specified to be Balanced                 None
Datanodes Excluded from Balancing                  None

2023-11-06 23:29:36,114 [main] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-11-06 23:29:36,128 [main] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
2023-11-06 23:29:36,156 [main] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
2023-11-06 23:29:36,163 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0 does not exist. Creating ...
2023-11-06 23:29:36,203 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/in_use.lock acquired by nodename 6@scm4.org
2023-11-06 23:29:36,231 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0 has been successfully formatted.
2023-11-06 23:29:36,265 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
2023-11-06 23:29:36,412 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
2023-11-06 23:29:36,414 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:29:36,436 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-11-06 23:29:36,447 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
2023-11-06 23:29:36,481 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-11-06 23:29:36,538 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
2023-11-06 23:29:36,542 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-11-06 23:29:36,544 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:29:36,599 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0
2023-11-06 23:29:36,602 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-11-06 23:29:36,604 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
2023-11-06 23:29:36,612 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
2023-11-06 23:29:36,620 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
2023-11-06 23:29:36,622 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
2023-11-06 23:29:36,630 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
2023-11-06 23:29:36,630 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-11-06 23:29:36,637 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-11-06 23:29:36,727 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-11-06 23:29:36,730 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:29:36,922 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
2023-11-06 23:29:36,924 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
2023-11-06 23:29:36,925 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
2023-11-06 23:29:36,947 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-11-06 23:29:36,948 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-11-06 23:29:36,958 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: start with initializing state, conf=-1: peers:[]|listeners:[], old=null
2023-11-06 23:29:36,963 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: changes role from      null to FOLLOWER at term 0 for startInitializing
2023-11-06 23:29:36,967 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9DE0136887B0,id=1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:29:36,973 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-11-06 23:29:36,974 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
2023-11-06 23:29:36,974 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
2023-11-06 23:29:36,977 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
2023-11-06 23:29:37,011 [main] INFO server.RaftServer: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: start RPC server
2023-11-06 23:29:37,252 [main] INFO server.GrpcService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: GrpcService started, listening on 9894
2023-11-06 23:29:37,273 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Started
2023-11-06 23:29:37,343 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 3 nodes: [nodeId=scm2,nodeAddress=scm2.org/172.25.0.117:9863, nodeId=scm1,nodeAddress=scm1.org/172.25.0.116:9863, nodeId=scm3,nodeAddress=scm3.org/172.25.0.118:9863]
2023-11-06 23:29:40,436 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: receive installSnapshot: 331a0938-d6f1-42a9-a4ae-109f456b4b33->1a30b843-dd19-4ea2-bff2-e54853fb8bbd#0-t2,notify:(t:1, i:0)
2023-11-06 23:29:40,458 [grpc-default-executor-0] INFO ha.SCMStateMachine: leader changed, yet current SCM is still follower.
2023-11-06 23:29:40,459 [grpc-default-executor-0] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: change Leader from null to 331a0938-d6f1-42a9-a4ae-109f456b4b33 at term 2 for installSnapshot, leader elected after 10781ms
2023-11-06 23:29:40,482 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: Received notification to install snapshot at index 0
2023-11-06 23:29:40,492 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: InstallSnapshot notification result: ALREADY_INSTALLED, current snapshot index: -1
2023-11-06 23:29:41,207 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set new configuration index: 25
configurationEntry {
  peers {
    id: "06b07224-3166-4961-ae74-6b03fdaa51d3"
    address: "scm3.org:9894"
    startupRole: FOLLOWER
  }
  peers {
    id: "331a0938-d6f1-42a9-a4ae-109f456b4b33"
    address: "scm1.org:9894"
    startupRole: FOLLOWER
  }
  peers {
    id: "1be38a04-9c47-40de-8329-a7f0281e7ddf"
    address: "scm2.org:9894"
    startupRole: FOLLOWER
  }
}
 from snapshot
2023-11-06 23:29:41,218 [grpc-default-executor-0] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 25: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,262 [grpc-default-executor-0] INFO impl.SnapshotInstallationHandler: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: reply installSnapshot: 331a0938-d6f1-42a9-a4ae-109f456b4b33<-1a30b843-dd19-4ea2-bff2-e54853fb8bbd#0:OK-t0,ALREADY_INSTALLED
2023-11-06 23:29:41,329 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed INSTALL_SNAPSHOT, lastRequest: 331a0938-d6f1-42a9-a4ae-109f456b4b33->1a30b843-dd19-4ea2-bff2-e54853fb8bbd#0-t2,notify:(t:1, i:0)
2023-11-06 23:29:41,329 [grpc-default-executor-0] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed INSTALL_SNAPSHOT, lastReply: null
2023-11-06 23:29:41,684 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread2] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: start 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState
2023-11-06 23:29:41,715 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread2] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-11-06 23:29:41,720 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:29:41,721 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:29:41,728 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread2] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: inconsistency entries. Reply:331a0938-d6f1-42a9-a4ae-109f456b4b33<-1a30b843-dd19-4ea2-bff2-e54853fb8bbd#0:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-11-06 23:29:41,730 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: Failed appendEntries as previous log entry ((t:1, i:0)) is not found
2023-11-06 23:29:41,730 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: inconsistency entries. Reply:331a0938-d6f1-42a9-a4ae-109f456b4b33<-1a30b843-dd19-4ea2-bff2-e54853fb8bbd#1:FAIL-t2,INCONSISTENCY,nextIndex=0,followerCommit=-1,matchIndex=-1
2023-11-06 23:29:41,804 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 0: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,805 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 1: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,810 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 15: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:29:41,812 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 17: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,815 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 23: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:29:41,816 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 25: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,830 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: Starting segment from index:0
2023-11-06 23:29:41,897 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
2023-11-06 23:29:41,961 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 0: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,962 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 1: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,962 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 15: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:29:41,963 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 17: peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:41,969 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 23: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:29:41,969 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 25: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:42,136 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_inprogress_0
2023-11-06 23:29:42,152 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_inprogress_0 to /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_0-0
2023-11-06 23:29:42,184 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_inprogress_1
2023-11-06 23:29:42,272 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 0
2023-11-06 23:29:42,278 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 75: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:29:42,276 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
2023-11-06 23:29:42,283 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-11-06 23:29:42,287 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
2023-11-06 23:29:42,302 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 77: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:29:42,335 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
2023-11-06 23:29:42,352 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-11-06 23:29:42,557 [main] INFO ha.SCMHAManagerImpl: Successfully added SCM scm4 to group group-9DE0136887B0:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
2023-11-06 23:29:42,561 [main] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
2023-11-06 23:29:42,704 [main] INFO SCMHATransactionMonitor: Starting SCMHATransactionMonitor Service.
2023-11-06 23:29:42,734 [main] INFO ha.SCMServiceManager: Registering service SCMHATransactionMonitor.
2023-11-06 23:29:42,735 [main] INFO SCMHATransactionMonitor: SCMHATransactionMonitor Service is already running, skip start.
2023-11-06 23:29:42,925 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = a75f675f-83d2-44ab-add6-95bf5771b537, creation at: 2023-11-06T23:25:14.972Z, expire at: 2023-11-07T00:25:14.972Z)]
2023-11-06 23:29:42,935 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = a75f675f-83d2-44ab-add6-95bf5771b537, creation at: 2023-11-06T23:25:14.972Z, expire at: 2023-11-07T00:25:14.972Z)
2023-11-06 23:29:43,106 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2023-11-06 23:29:43,229 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-11-06 23:29:43,230 [main] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
2023-11-06 23:29:43,322 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = a75f675f-83d2-44ab-add6-95bf5771b537, creation at: 2023-11-06T23:25:14.972Z, expire at: 2023-11-07T00:25:14.972Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-11-06 23:29:43,332 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
2023-11-06 23:29:43,333 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
2023-11-06 23:29:43,333 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
2023-11-06 23:29:43,402 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 2.
2023-11-06 23:29:43,661 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 4 for CN=scm-sub@scm2.org,OU=1be38a04-9c47-40de-8329-a7f0281e7ddf,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=4 is stored
2023-11-06 23:29:43,710 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 5 for CN=scm-sub@scm3.org,OU=06b07224-3166-4961-ae74-6b03fdaa51d3,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=5 is stored
2023-11-06 23:29:43,731 [main] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
2023-11-06 23:29:43,735 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-11-06 23:29:43,765 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
2023-11-06 23:29:44,237 [main] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
2023-11-06 23:29:44,237 [main] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
2023-11-06 23:29:44,280 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.SCMCertStore: Scm certificate 12 for CN=scm-sub@scm4.org,OU=1a30b843-dd19-4ea2-bff2-e54853fb8bbd,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=12 is stored
2023-11-06 23:29:44,280 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-11-06 23:29:44,303 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
2023-11-06 23:29:44,767 [main] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
2023-11-06 23:29:44,782 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
2023-11-06 23:29:44,784 [main] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
2023-11-06 23:29:44,785 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
2023-11-06 23:29:45,744 [main] INFO server.StorageContainerManager: Persist certificate serialId 1 on Scm Bootstrap Node 1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:29:45,792 [main] INFO server.SCMCertStore: Scm certificate 1 for CN=scm@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=1 is stored
2023-11-06 23:29:45,814 [main] INFO server.StorageContainerManager: Persist certificate serialId 2 on Scm Bootstrap Node 1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:29:45,837 [main] INFO server.SCMCertStore: Scm certificate 2 for CN=scm-sub@scm1.org,OU=331a0938-d6f1-42a9-a4ae-109f456b4b33,O=CID-9874be73-7265-41b3-ade4-9de0136887b0,SERIALNUMBER=2 is stored
2023-11-06 23:29:46,087 [main] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
2023-11-06 23:29:46,087 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
2023-11-06 23:29:46,096 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
2023-11-06 23:29:46,473 [main] INFO util.log: Logging initialized @30051ms to org.eclipse.jetty.util.log.Slf4jLog
2023-11-06 23:29:46,751 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:29:46,752 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:29:47,246 [main] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
2023-11-06 23:29:47,313 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-11-06 23:29:47,332 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
2023-11-06 23:29:47,333 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
2023-11-06 23:29:47,336 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
2023-11-06 23:29:47,369 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
2023-11-06 23:29:47,771 [main] INFO http.BaseHttpServer: HTTP server of scm uses base directory /data/metadata/webserver
2023-11-06 23:29:47,779 [main] INFO http.HttpServer2: Jetty bound to port 9876
2023-11-06 23:29:47,785 [main] INFO server.Server: jetty-9.4.53.v20231009; built: 2023-10-09T12:29:09.265Z; git: 27bde00a0b95a1d5bbee0eae7984f891d2d0f8c9; jvm 11.0.19+7-LTS
2023-11-06 23:29:47,871 [main] INFO server.session: DefaultSessionIdManager workerName=node0
2023-11-06 23:29:47,873 [main] INFO server.session: No SessionScavenger set, using defaults
2023-11-06 23:29:47,876 [main] INFO server.session: node0 Scavenging every 660000ms
2023-11-06 23:29:47,923 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-11-06 23:29:47,926 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@19cf111c{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
2023-11-06 23:29:47,928 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4d390a0c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-11-06 23:29:48,137 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/HTTP.keytab, for principal HTTP/scm@EXAMPLE.COM
2023-11-06 23:29:48,157 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@162304e3{scm,/,file:///data/metadata/webserver/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-8814771631973803185/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-11-06 23:29:48,180 [main] INFO server.AbstractConnector: Started ServerConnector@634a3a2{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-11-06 23:29:48,181 [main] INFO server.Server: Started @31758ms
2023-11-06 23:29:48,192 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
2023-11-06 23:29:48,193 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
2023-11-06 23:29:48,196 [main] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
2023-11-06 23:29:48,225 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-11-06 23:29:48,228 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-11-06 23:29:48,229 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-scm/sub-ca-refreshCACertificates] INFO client.SCMCertificateClient: CA certificates are not changed.
2023-11-06 23:29:51,867 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:29:51,868 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:29:56,885 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:29:56,886 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:01,895 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:01,895 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:06,923 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:06,923 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:12,117 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:12,118 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:17,300 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:17,301 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:22,317 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:22,319 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:27,360 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:27,360 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:32,562 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:32,562 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:33,906 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 79: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:2|startupRole:FOLLOWER]|listeners:[], old=peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[]
2023-11-06 23:30:33,962 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-server-thread1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 81: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:2|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:30:34,242 [grpc-default-executor-1] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: shutdown 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState
2023-11-06 23:30:34,245 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState] INFO impl.FollowerState: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-FollowerState was interrupted
2023-11-06 23:30:34,246 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-11-06 23:30:34,259 [grpc-default-executor-1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: change Leader from 331a0938-d6f1-42a9-a4ae-109f456b4b33 to null at term 2 for ELECTION
2023-11-06 23:30:34,265 [grpc-default-executor-1] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: start 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1
2023-11-06 23:30:34,289 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.LeaderElection: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1 ELECTION round 0: submit vote requests at term 3 for 81: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:2|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:30:34,317 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
2023-11-06 23:30:34,318 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-11-06 23:30:34,347 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 331a0938-d6f1-42a9-a4ae-109f456b4b33
2023-11-06 23:30:34,348 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for 06b07224-3166-4961-ae74-6b03fdaa51d3
2023-11-06 23:30:34,347 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1-3] INFO server.GrpcServerProtocolClient: Build channel for 1be38a04-9c47-40de-8329-a7f0281e7ddf
2023-11-06 23:30:35,306 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed APPEND_ENTRIES, lastRequest: 331a0938-d6f1-42a9-a4ae-109f456b4b33->1a30b843-dd19-4ea2-bff2-e54853fb8bbd#39-t2,previous=(t:2, i:81),leaderCommit=81,initializing? true,entries: size=1, first=(t:2, i:82), METADATAENTRY(c:81)
2023-11-06 23:30:35,345 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed APPEND_ENTRIES, lastReply: null
2023-11-06 23:30:35,421 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed APPEND_ENTRIES, lastRequest: null
2023-11-06 23:30:35,476 [grpc-default-executor-2] INFO server.GrpcServerProtocolService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: Completed APPEND_ENTRIES, lastReply: serverReply {
  requestorId: "331a0938-d6f1-42a9-a4ae-109f456b4b33"
  replyId: "1a30b843-dd19-4ea2-bff2-e54853fb8bbd"
  raftGroupId {
    id: "\230t\276sreA\263\255\344\235\340\023h\207\260"
  }
  callId: 34
  success: true
}
term: 2
nextIndex: 79
followerCommit: 78
matchIndex: 18446744073709551615
isHearbeat: true

2023-11-06 23:30:35,516 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.LeaderElection: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1: ELECTION PASSED received 2 response(s) and 0 exception(s):
2023-11-06 23:30:35,516 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.LeaderElection:   Response 0: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd<-06b07224-3166-4961-ae74-6b03fdaa51d3#0:OK-t3
2023-11-06 23:30:35,518 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.LeaderElection:   Response 1: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd<-331a0938-d6f1-42a9-a4ae-109f456b4b33#0:OK-t3
2023-11-06 23:30:35,519 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.LeaderElection: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1 ELECTION round 0: result PASSED
2023-11-06 23:30:35,522 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: shutdown 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1
2023-11-06 23:30:35,525 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
2023-11-06 23:30:35,526 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 3.
2023-11-06 23:30:35,527 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,3>
2023-11-06 23:30:35,558 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: change Leader from null to 1a30b843-dd19-4ea2-bff2-e54853fb8bbd at term 3 for becomeLeader, leader elected after 1267ms
2023-11-06 23:30:35,567 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
2023-11-06 23:30:35,598 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-11-06 23:30:35,610 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-11-06 23:30:35,623 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
2023-11-06 23:30:35,623 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
2023-11-06 23:30:35,625 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
2023-11-06 23:30:35,637 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
2023-11-06 23:30:35,639 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-11-06 23:30:35,659 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-11-06 23:30:35,659 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:30:35,660 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-11-06 23:30:35,663 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-11-06 23:30:35,664 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-11-06 23:30:35,666 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-11-06 23:30:35,666 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-11-06 23:30:35,667 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-11-06 23:30:35,667 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-11-06 23:30:35,667 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-11-06 23:30:35,673 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-11-06 23:30:35,673 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:30:35,673 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-11-06 23:30:35,675 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-11-06 23:30:35,675 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-11-06 23:30:35,676 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-11-06 23:30:35,676 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-11-06 23:30:35,677 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-11-06 23:30:35,678 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-11-06 23:30:35,678 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-11-06 23:30:35,679 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-11-06 23:30:35,679 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-11-06 23:30:35,680 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1024 (custom)
2023-11-06 23:30:35,680 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 0ms (custom)
2023-11-06 23:30:35,681 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-11-06 23:30:35,681 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
2023-11-06 23:30:35,681 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.element-limit = 8 (default)
2023-11-06 23:30:35,681 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.install_snapshot.request.timeout = 3000ms (default)
2023-11-06 23:30:35,682 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-11-06 23:30:35,682 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
2023-11-06 23:30:35,687 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: start 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderStateImpl
2023-11-06 23:30:35,690 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: Rolling segment log-1_82 to index:82
2023-11-06 23:30:35,691 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_inprogress_1 to /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_1-82
2023-11-06 23:30:35,710 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/9874be73-7265-41b3-ade4-9de0136887b0/current/log_inprogress_83
2023-11-06 23:30:35,722 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderElection1] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: set configuration 83: peers:[06b07224-3166-4961-ae74-6b03fdaa51d3|rpc:scm3.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 331a0938-d6f1-42a9-a4ae-109f456b4b33|rpc:scm1.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1be38a04-9c47-40de-8329-a7f0281e7ddf|rpc:scm2.org:9894|admin:|client:|dataStream:|priority:1|startupRole:FOLLOWER, 1a30b843-dd19-4ea2-bff2-e54853fb8bbd|rpc:scm4.org:9894|admin:|client:|dataStream:|priority:2|startupRole:FOLLOWER]|listeners:[], old=null
2023-11-06 23:30:35,905 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
2023-11-06 23:30:35,935 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
2023-11-06 23:30:47,537 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm4.org:52004 / 172.25.0.120:52004
2023-11-06 23:30:47,595 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-11-06 23:30:59,125 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm4.org:46612 / 172.25.0.120:46612
2023-11-06 23:30:59,131 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-11-06 23:31:28,434 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net:55262 / 172.25.0.121:55262
2023-11-06 23:31:28,443 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-11-06 23:31:28,446 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 534df7e5e210, UUID: 061317fc-307b-4b1d-b68f-ea277657752c
2023-11-06 23:31:28,689 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for CertificateId, expected lastId is 0, actual lastId is 12.
2023-11-06 23:31:28,750 [IPC Server handler 1 on default port 9961] INFO ha.SequenceIdGenerator: Allocate a batch for CertificateId, change lastId from 12 to 13.
2023-11-06 23:31:28,911 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions in CSR: 2.5.29.15, 2.5.29.17
2023-11-06 23:31:28,922 [IPC Server handler 1 on default port 9961] INFO authority.DefaultApprover: Extensions to add to the certificate if they present in CSR: 2.5.29.17, 2.5.29.19, 1.3.6.1.5.5.7.1.12, 2.5.29.35, 2.5.29.15, 2.5.29.37
2023-11-06 23:31:29,046 [IPC Server handler 1 on default port 9961] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
2023-11-06 23:31:29,556 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 0 Root CA certificates
2023-11-06 23:31:29,556 [IPC Server handler 0 on default port 9961] INFO client.SCMCertificateClient: scm/sub-ca has 1 CA certificates
2023-11-06 23:31:32,546 [scm4-SecretKeyManagerService] INFO symmetric.SecretKeyManager: SecretKey rotation is happening, new key generated SecretKey(id = 3dddbdc8-d2c8-4290-89d6-c4b20142b23b, creation at: 2023-11-06T23:31:32.545075Z, expire at: 2023-11-07T00:31:32.545075Z)
2023-11-06 23:31:32,587 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Updating keys with [SecretKey(id = a75f675f-83d2-44ab-add6-95bf5771b537, creation at: 2023-11-06T23:25:14.972Z, expire at: 2023-11-07T00:25:14.972Z), SecretKey(id = 3dddbdc8-d2c8-4290-89d6-c4b20142b23b, creation at: 2023-11-06T23:31:32.545Z, expire at: 2023-11-07T00:31:32.545Z)]
2023-11-06 23:31:32,588 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.SecretKeyStateImpl: Current key updated SecretKey(id = 3dddbdc8-d2c8-4290-89d6-c4b20142b23b, creation at: 2023-11-06T23:31:32.545Z, expire at: 2023-11-07T00:31:32.545Z)
2023-11-06 23:31:32,590 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO symmetric.LocalSecretKeyStore: Saved [SecretKey(id = 3dddbdc8-d2c8-4290-89d6-c4b20142b23b, creation at: 2023-11-06T23:31:32.545Z, expire at: 2023-11-07T00:31:32.545Z), SecretKey(id = a75f675f-83d2-44ab-add6-95bf5771b537, creation at: 2023-11-06T23:25:14.972Z, expire at: 2023-11-07T00:25:14.972Z)] to file /data/metadata/scm/keys/secret_keys.json
2023-11-06 23:31:33,689 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net:55276 / 172.25.0.121:55276
2023-11-06 23:31:33,751 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SecretKeyProtocolDatanode
2023-11-06 23:31:43,241 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net:43014 / 172.25.0.121:43014
2023-11-06 23:31:43,285 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
2023-11-06 23:31:49,090 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net:59716 / 172.25.0.121:59716
2023-11-06 23:31:49,189 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-11-06 23:31:50,714 [IPC Server handler 5 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/061317fc-307b-4b1d-b68f-ea277657752c
2023-11-06 23:31:50,764 [IPC Server handler 5 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 061317fc-307b-4b1d-b68f-ea277657752c{ip: 172.25.0.121, host: ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net, ports: [HTTP=9882, CLIENT_RPC=9864, REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 13, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-11-06 23:31:50,802 [scm4-EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm4-RatisPipelineUtilsThread.
2023-11-06 23:31:50,838 [scm4-RatisPipelineUtilsThread-0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=07a71bbd-cf08-47d8-be47-090a222b3540 to datanode:061317fc-307b-4b1d-b68f-ea277657752c
2023-11-06 23:31:50,875 [scm4-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 1 required.
2023-11-06 23:31:50,910 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on scm4-RatisPipelineUtilsThread.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-11-06 23:31:50,930 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
2023-11-06 23:31:50,996 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-11-06 23:31:50,997 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to RUNNING.
2023-11-06 23:31:50,998 [scm4-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-11-06 23:31:50,998 [scm4-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-11-06 23:31:50,998 [scm4-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-11-06 23:31:51,004 [scm4-EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-11-06 23:31:51,007 [scm4-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-11-06 23:31:51,007 [scm4-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-11-06 23:31:51,007 [scm4-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-11-06 23:31:51,009 [scm4-EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-11-06 23:31:51,009 [scm4-EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
2023-11-06 23:31:51,010 [scm4-EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
2023-11-06 23:31:51,010 [scm4-EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=false, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-11-06 23:31:51,010 [scm4-EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-11-06 23:31:51,020 [scm4-RatisPipelineUtilsThread-0] INFO pipeline.BackgroundPipelineCreator: Created new pipeline Pipeline[ Id: 07a71bbd-cf08-47d8-be47-090a222b3540, Nodes: 061317fc-307b-4b1d-b68f-ea277657752c(ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net/172.25.0.121), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-11-06T23:31:50.825844Z[UTC]]
2023-11-06 23:32:05,594 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm4.org:46226 / 172.25.0.120:46226
2023-11-06 23:32:05,598 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-11-06 23:32:20,518 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from scm4.org:46912 / 172.25.0.120:46912
2023-11-06 23:32:20,537 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
2023-11-06 23:32:22,773 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from ozonesecure-ha_datanode4_1.ozonesecure-ha_ozone_net:34696 / 172.25.0.121:34696
2023-11-06 23:32:22,937 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
2023-11-06 23:32:23,317 [SIGTERM handler] ERROR server.StorageContainerManagerStarter: RECEIVED SIGNAL 15: SIGTERM
2023-11-06 23:32:23,348 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down StorageContainerManager at scm4.org/172.25.0.120
************************************************************/
2023-11-06 23:32:23,520 [shutdown-hook-0] INFO server.StorageContainerManager: Container Balancer is not running.
2023-11-06 23:32:23,520 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping Replication Manager Service.
2023-11-06 23:32:23,520 [shutdown-hook-0] INFO replication.ReplicationManager: Stopping Replication Monitor Thread.
2023-11-06 23:32:23,521 [scm4-UnderReplicatedProcessor] WARN replication.UnhealthyReplicationProcessor: scm4-UnderReplicatedProcessor interrupted. Exiting...
2023-11-06 23:32:23,521 [scm4-OverReplicatedProcessor] WARN replication.UnhealthyReplicationProcessor: scm4-OverReplicatedProcessor interrupted. Exiting...
2023-11-06 23:32:23,525 [scm4-ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread is stopped
2023-11-06 23:32:23,526 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping the Datanode Admin Monitor.
2023-11-06 23:32:23,527 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping datanode service RPC server
2023-11-06 23:32:23,527 [shutdown-hook-0] INFO server.SCMDatanodeProtocolServer: Stopping the RPC server for DataNodes
2023-11-06 23:32:23,527 [shutdown-hook-0] INFO ipc.Server: Stopping server on 9861
2023-11-06 23:32:23,573 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-11-06 23:32:23,574 [IPC Server listener on 9861] INFO ipc.Server: Stopping IPC Server listener on 9861
2023-11-06 23:32:24,269 [scm4-SCMHeartbeatProcessor-0] WARN node.NodeStateManager: Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-11-06 23:32:24,271 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping block service RPC server
2023-11-06 23:32:24,272 [shutdown-hook-0] INFO server.SCMBlockProtocolServer: Stopping the RPC server for Block Protocol
2023-11-06 23:32:24,273 [shutdown-hook-0] INFO ipc.Server: Stopping server on 9863
2023-11-06 23:32:24,290 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-11-06 23:32:24,290 [IPC Server listener on 9863] INFO ipc.Server: Stopping IPC Server listener on 9863
2023-11-06 23:32:24,312 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping the StorageContainerLocationProtocol RPC server
2023-11-06 23:32:24,319 [shutdown-hook-0] INFO server.SCMClientProtocolServer: Stopping the RPC server for Client Protocol
2023-11-06 23:32:24,320 [shutdown-hook-0] INFO ipc.Server: Stopping server on 9860
2023-11-06 23:32:24,327 [IPC Server listener on 9860] INFO ipc.Server: Stopping IPC Server listener on 9860
2023-11-06 23:32:24,357 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-11-06 23:32:24,369 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping Storage Container Manager HTTP server.
2023-11-06 23:32:24,399 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.w.WebAppContext@162304e3{scm,/,null,STOPPED}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
2023-11-06 23:32:24,409 [shutdown-hook-0] INFO server.AbstractConnector: Stopped ServerConnector@634a3a2{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
2023-11-06 23:32:24,409 [shutdown-hook-0] INFO server.session: node0 Stopped scavenging
2023-11-06 23:32:24,410 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@4d390a0c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-11-06 23:32:24,411 [shutdown-hook-0] INFO handler.ContextHandler: Stopped o.e.j.s.ServletContextHandler@19cf111c{logs,/logs,file:///var/log/hadoop/,STOPPED}
2023-11-06 23:32:24,417 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping SCM LayoutVersionManager Service.
2023-11-06 23:32:24,418 [shutdown-hook-0] INFO server.SCMSecurityProtocolServer: Stopping the SCMSecurityProtocolServer.
2023-11-06 23:32:24,420 [shutdown-hook-0] INFO ipc.Server: Stopping server on 9961
2023-11-06 23:32:24,425 [IPC Server Responder] INFO ipc.Server: Stopping IPC Server Responder
2023-11-06 23:32:24,425 [IPC Server listener on 9961] INFO ipc.Server: Stopping IPC Server listener on 9961
2023-11-06 23:32:24,427 [shutdown-hook-0] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService stopping
2023-11-06 23:32:24,434 [shutdown-hook-0] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService stopped!
2023-11-06 23:32:24,434 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping Block Manager Service.
2023-11-06 23:32:24,434 [shutdown-hook-0] INFO utils.BackgroundService: Shutting down service SCMBlockDeletingService
2023-11-06 23:32:24,436 [shutdown-hook-0] INFO utils.BackgroundService: Shutting down service SCMBlockDeletingService
2023-11-06 23:32:24,439 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping SCM Event Queue.
2023-11-06 23:32:24,443 [shutdown-hook-0] INFO server.StorageContainerManager: Stopping SCM HA services.
2023-11-06 23:32:24,444 [shutdown-hook-0] INFO ha.SCMRatisServerImpl: stopping ratis server 0.0.0.0:9894
2023-11-06 23:32:24,445 [shutdown-hook-0] INFO server.RaftServer: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: close
2023-11-06 23:32:24,449 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO server.RaftServer$Division: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0: shutdown
2023-11-06 23:32:24,450 [shutdown-hook-0] INFO server.GrpcService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: shutdown server GrpcServerProtocolService now
2023-11-06 23:32:24,459 [Thread-377] INFO server.GrpcServerProtocolClient: 06b07224-3166-4961-ae74-6b03fdaa51d3 Close channels
2023-11-06 23:32:24,459 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9DE0136887B0,id=1a30b843-dd19-4ea2-bff2-e54853fb8bbd
2023-11-06 23:32:24,459 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO impl.RoleInfo: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: shutdown 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-LeaderStateImpl
2023-11-06 23:32:24,461 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO impl.PendingRequests: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-PendingRequests: sendNotLeaderResponses
2023-11-06 23:32:24,462 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-11-06 23:32:24,468 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-11-06 23:32:24,470 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-GrpcLogAppender-LogAppenderDaemon] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-11-06 23:32:24,494 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO ha.SCMStateMachine: current leader SCM steps down.
2023-11-06 23:32:24,494 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO ha.SCMContext: update <isLeader,term> from <true,3> to <false,0>
2023-11-06 23:32:24,494 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO ha.SCMContext: update <isLeaderReady> from <false> to <false>
2023-11-06 23:32:24,505 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,518 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-GrpcLogAppender: Failed to getClient for 06b07224-3166-4961-ae74-6b03fdaa51d3
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,519 [Thread-379] INFO server.GrpcServerProtocolClient: 1be38a04-9c47-40de-8329-a7f0281e7ddf Close channels
2023-11-06 23:32:24,519 [Thread-378] INFO server.GrpcServerProtocolClient: 331a0938-d6f1-42a9-a4ae-109f456b4b33 Close channels
2023-11-06 23:32:24,495 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to PAUSING.
2023-11-06 23:32:24,524 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to PAUSING.
2023-11-06 23:32:24,527 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO SCMHATransactionMonitor: Service SCMHATransactionMonitor transitions to PAUSING.
2023-11-06 23:32:24,531 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd-impl-thread2] INFO impl.StateMachineUpdater: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater: set stopIndex = 94
2023-11-06 23:32:24,540 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO ha.SCMStateMachine: Current Snapshot Index 94, takeSnapshot took 9 ms
2023-11-06 23:32:24,542 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO impl.StateMachineUpdater: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater: Took a snapshot at index 94
2023-11-06 23:32:24,542 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO impl.StateMachineUpdater: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 94
2023-11-06 23:32:24,545 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,546 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-GrpcLogAppender: Failed to getClient for 331a0938-d6f1-42a9-a4ae-109f456b4b33
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,547 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,548 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-GrpcLogAppender: Failed to getClient for 1be38a04-9c47-40de-8329-a7f0281e7ddf
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,559 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,559 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->06b07224-3166-4961-ae74-6b03fdaa51d3-GrpcLogAppender: Failed to getClient for 06b07224-3166-4961-ae74-6b03fdaa51d3
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,549 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.StorageContainerManager: Storage Container Manager is not running.
2023-11-06 23:32:24,566 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.StorageContainerManager: Stopping Replication Manager Service.
2023-11-06 23:32:24,566 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO replication.ReplicationManager: Replication Monitor Thread is not running.
2023-11-06 23:32:24,578 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,580 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->1be38a04-9c47-40de-8329-a7f0281e7ddf-GrpcLogAppender: Failed to getClient for 1be38a04-9c47-40de-8329-a7f0281e7ddf
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener$3.run(DelayedClientCall.java:471)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.delayOrExecute(DelayedClientCall.java:435)
	at org.apache.ratis.thirdparty.io.grpc.internal.DelayedClientCall$DelayedListener.onClose(DelayedClientCall.java:468)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,586 [1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0-StateMachineUpdater] INFO server.StorageContainerManager: Terminating with exit status 0: scm statemachine is closed by ratis, terminate SCM
2023-11-06 23:32:24,787 [grpc-default-executor-3] INFO server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-11-06 23:32:24,787 [grpc-default-executor-3] WARN server.GrpcLogAppender: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd@group-9DE0136887B0->331a0938-d6f1-42a9-a4ae-109f456b4b33-GrpcLogAppender: Failed to getClient for 331a0938-d6f1-42a9-a4ae-109f456b4b33
org.apache.ratis.protocol.exceptions.AlreadyClosedException: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:112)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:117)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:56)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:429)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:563)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:744)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:723)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
2023-11-06 23:32:24,792 [shutdown-hook-0] INFO server.GrpcService: 1a30b843-dd19-4ea2-bff2-e54853fb8bbd: shutdown server GrpcServerProtocolService successfully
