<?xml version="1.0" encoding="UTF-8"?>
<testsuite xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="https://maven.apache.org/surefire/maven-surefire-plugin/xsd/surefire-test-report-3.0.xsd" version="3.0" name="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="271.935" tests="7" errors="1" skipped="0" failures="0">
  <properties>
    <property name="awt.toolkit" value="sun.awt.X11.XToolkit"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="sun.cpu.isalist" value=""/>
    <property name="sun.jnu.encoding" value="UTF-8"/>
    <property name="java.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.48.1/grpc-netty-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.48.1/grpc-core-1.48.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.77.Final/netty-codec-http2-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.77.Final/netty-common-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.77.Final/netty-buffer-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.77.Final/netty-codec-http-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.77.Final/netty-handler-proxy-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.77.Final/netty-codec-socks-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.52.Final/netty-tcnative-classes-2.0.52.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.4.10/kotlin-stdlib-common-1.4.10.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.31.v20200723/jetty-client-9.4.31.v20200723.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.48.1/grpc-protobuf-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.48.1/grpc-api-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.48.1/grpc-context-1.48.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.48.1/grpc-protobuf-lite-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.48.1/grpc-stub-1.48.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.77.Final/netty-transport-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.77.Final/netty-resolver-4.1.77.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.77.Final/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.77.Final/netty-transport-classes-epoll-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.77.Final/netty-transport-native-unix-common-4.1.77.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.77.Final/netty-codec-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.77.Final/netty-handler-4.1.77.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:"/>
    <property name="java.vm.vendor" value="Temurin"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="test.build.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="test.cache.data" value=""/>
    <property name="java.vendor.url" value="https://adoptium.net/"/>
    <property name="user.timezone" value="Etc/UTC"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="os.name" value="Linux"/>
    <property name="test.build.data" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.boot.library.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/amd64"/>
    <property name="sun.java.command" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter6064191024080482680.jar /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire 2023-01-03T14-03-18_669-jvmRun1 surefire1398065283591973548tmp surefire_02017820019775463813tmp"/>
    <property name="surefire.test.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/classes:/home/runner/.m2/repository/org/apache/ozone/ozone-common/1.4.0-SNAPSHOT/ozone-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/grpc/grpc-netty/1.48.1/grpc-netty-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-core/1.48.1/grpc-core-1.48.1.jar:/home/runner/.m2/repository/com/google/android/annotations/4.1.1.4/annotations-4.1.1.4.jar:/home/runner/.m2/repository/org/codehaus/mojo/animal-sniffer-annotations/1.21/animal-sniffer-annotations-1.21.jar:/home/runner/.m2/repository/com/google/errorprone/error_prone_annotations/2.2.0/error_prone_annotations-2.2.0.jar:/home/runner/.m2/repository/io/perfmark/perfmark-api/0.25.0/perfmark-api-0.25.0.jar:/home/runner/.m2/repository/io/netty/netty-codec-http2/4.1.77.Final/netty-codec-http2-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-common/4.1.77.Final/netty-common-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-buffer/4.1.77.Final/netty-buffer-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-http/4.1.77.Final/netty-codec-http-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler-proxy/4.1.77.Final/netty-handler-proxy-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-codec-socks/4.1.77.Final/netty-codec-socks-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-classes/2.0.52.Final/netty-tcnative-classes-2.0.52.Final.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-linux-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-osx-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-osx-aarch_64.jar:/home/runner/.m2/repository/io/netty/netty-tcnative-boringssl-static/2.0.52.Final/netty-tcnative-boringssl-static-2.0.52.Final-windows-x86_64.jar:/home/runner/.m2/repository/org/apache/commons/commons-compress/1.21/commons-compress-1.21.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-client/1.4.0-SNAPSHOT/hdds-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-client/1.4.0-SNAPSHOT/ozone-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-test-utils/1.4.0-SNAPSHOT/hdds-test-utils-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/guava/guava/31.1-jre/guava-31.1-jre.jar:/home/runner/.m2/repository/com/google/guava/failureaccess/1.0.1/failureaccess-1.0.1.jar:/home/runner/.m2/repository/com/google/guava/listenablefuture/9999.0-empty-to-avoid-conflict-with-guava/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/home/runner/.m2/repository/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.jar:/home/runner/.m2/repository/org/checkerframework/checker-qual/3.12.0/checker-qual-3.12.0.jar:/home/runner/.m2/repository/com/google/j2objc/j2objc-annotations/1.3/j2objc-annotations-1.3.jar:/home/runner/.m2/repository/commons-io/commons-io/2.11.0/commons-io-2.11.0.jar:/home/runner/.m2/repository/commons-logging/commons-logging/1.2/commons-logging-1.2.jar:/home/runner/.m2/repository/ch/qos/reload4j/reload4j/1.2.22/reload4j-1.2.22.jar:/home/runner/.m2/repository/org/slf4j/slf4j-api/1.7.36/slf4j-api-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-server/1.4.0-SNAPSHOT/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util-ajax/9.4.49.v20220914/jetty-util-ajax-9.4.49.v20220914.jar:/home/runner/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-framework/1.4.0-SNAPSHOT/hdds-server-framework-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-server/1.4.0-SNAPSHOT/hdds-interface-server-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/commons/commons-configuration2/2.1.1/commons-configuration2-2.1.1.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-core/2.17.1/log4j-core-2.17.1.jar:/home/runner/.m2/repository/com/lmax/disruptor/3.4.2/disruptor-3.4.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-servlet/9.4.49.v20220914/jetty-servlet-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-security/9.4.49.v20220914/jetty-security-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/rocksdb/rocksdbjni/7.7.3/rocksdbjni-7.7.3.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_dropwizard/0.7.0/simpleclient_dropwizard-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient/0.7.0/simpleclient-0.7.0.jar:/home/runner/.m2/repository/io/prometheus/simpleclient_common/0.7.0/simpleclient_common-0.7.0.jar:/home/runner/.m2/repository/com/github/spotbugs/spotbugs-annotations/3.1.12/spotbugs-annotations-3.1.12.jar:/home/runner/.m2/repository/io/dropwizard/metrics/metrics-core/3.2.4/metrics-core-3.2.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs-client/3.3.4/hadoop-hdfs-client-3.3.4.jar:/home/runner/.m2/repository/com/squareup/okhttp3/okhttp/4.9.3/okhttp-4.9.3.jar:/home/runner/.m2/repository/com/squareup/okio/okio/2.8.0/okio-2.8.0.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib-common/1.4.10/kotlin-stdlib-common-1.4.10.jar:/home/runner/.m2/repository/org/bouncycastle/bcprov-jdk15on/1.67/bcprov-jdk15on-1.67.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/aspectj/aspectjrt/1.9.7/aspectjrt-1.9.7.jar:/home/runner/.m2/repository/org/aspectj/aspectjweaver/1.9.7/aspectjweaver-1.9.7.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-client/1.4.0-SNAPSHOT/hdds-interface-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-protobuf_3_7/1.1.1/hadoop-shaded-protobuf_3_7-1.1.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-interface-storage/1.4.0-SNAPSHOT/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/reflections/reflections/0.9.11/reflections-0.9.11.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-client/1.19/jersey-client-1.19.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-intg/2.3.0/ranger-intg-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-common/2.3.0/ranger-plugins-common-2.3.0.jar:/home/runner/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-cred/2.3.0/ranger-plugins-cred-2.3.0.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugins-audit/2.3.0/ranger-plugins-audit-2.3.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-client/9.4.31.v20200723/jetty-client-9.4.31.v20200723.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpmime/4.5.6/httpmime-4.5.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore-nio/4.4.6/httpcore-nio-4.4.6.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpasyncclient/4.1.3/httpasyncclient-4.1.3.jar:/home/runner/.m2/repository/com/carrotsearch/hppc/0.8.0/hppc-0.8.0.jar:/home/runner/.m2/repository/org/apache/orc/orc-core/1.5.8/orc-core-1.5.8.jar:/home/runner/.m2/repository/net/java/dev/jna/jna/5.2.0/jna-5.2.0.jar:/home/runner/.m2/repository/net/java/dev/jna/jna-platform/5.2.0/jna-platform-5.2.0.jar:/home/runner/.m2/repository/com/kstruct/gethostname4j/0.0.2/gethostname4j-0.0.2.jar:/home/runner/.m2/repository/org/apache/ranger/ranger-plugin-classloader/2.3.0/ranger-plugin-classloader-2.3.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-minikdc/3.3.4/hadoop-minikdc-3.3.4.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-simplekdc/1.0.1/kerb-simplekdc-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-client/1.0.1/kerb-client-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-config/1.0.1/kerby-config-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-common/1.0.1/kerb-common-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-crypto/1.0.1/kerb-crypto-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-util/1.0.1/kerb-util-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/token-provider/1.0.1/token-provider-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-admin/1.0.1/kerb-admin-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-server/1.0.1/kerb-server-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-identity/1.0.1/kerb-identity-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-xdr/1.0.1/kerby-xdr-1.0.1.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-s3gateway/1.4.0-SNAPSHOT/ozone-s3gateway-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar:/home/runner/.m2/repository/org/jboss/weld/servlet/weld-servlet/2.4.7.Final/weld-servlet-2.4.7.Final.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet-core/2.34/jersey-container-servlet-core-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/jakarta.inject/2.6.1/jakarta.inject-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-common/2.34/jersey-common-2.34.jar:/home/runner/.m2/repository/jakarta/ws/rs/jakarta.ws.rs-api/2.1.6/jakarta.ws.rs-api-2.1.6.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/cdi/jersey-cdi1x/2.34/jersey-cdi1x-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/inject/jersey-hk2/2.34/jersey-hk2-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-locator/2.6.1/hk2-locator-2.6.1.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-jaxb/2.34/jersey-media-jaxb-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/osgi-resource-locator/1.0.3/osgi-resource-locator-1.0.3.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-api/2.5.0/hk2-api-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/hk2-utils/2.5.0/hk2-utils-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/hk2/external/aopalliance-repackaged/2.5.0/aopalliance-repackaged-2.5.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-xml/2.13.4/jackson-dataformat-xml-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.13.4/jackson-core-2.13.4.jar:/home/runner/.m2/repository/org/codehaus/woodstox/stax2-api/4.2.1/stax2-api-4.2.1.jar:/home/runner/.m2/repository/com/fasterxml/woodstox/woodstox-core/5.4.0/woodstox-core-5.4.0.jar:/home/runner/.m2/repository/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.13.4/jackson-module-jaxb-annotations-2.13.4.jar:/home/runner/.m2/repository/jakarta/xml/bind/jakarta.xml.bind-api/2.3.3/jakarta.xml.bind-api-2.3.3.jar:/home/runner/.m2/repository/jakarta/activation/jakarta.activation-api/1.2.1/jakarta.activation-api-1.2.1.jar:/home/runner/.m2/repository/javax/enterprise/cdi-api/1.2/cdi-api-1.2.jar:/home/runner/.m2/repository/javax/el/javax.el-api/3.0.0/javax.el-api-3.0.0.jar:/home/runner/.m2/repository/javax/interceptor/javax.interceptor-api/1.2/javax.interceptor-api-1.2.jar:/home/runner/.m2/repository/javax/inject/javax.inject/1/javax.inject-1.jar:/home/runner/.m2/repository/javax/xml/bind/jaxb-api/2.3.0/jaxb-api-2.3.0.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-runtime/2.3.0.1/jaxb-runtime-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/jaxb-core/2.3.0.1/jaxb-core-2.3.0.1.jar:/home/runner/.m2/repository/org/glassfish/jaxb/txw2/2.3.0.1/txw2-2.3.0.1.jar:/home/runner/.m2/repository/com/sun/istack/istack-commons-runtime/3.0.5/istack-commons-runtime-3.0.5.jar:/home/runner/.m2/repository/org/jvnet/staxex/stax-ex/1.7.8/stax-ex-1.7.8.jar:/home/runner/.m2/repository/com/sun/xml/fastinfoset/FastInfoset/1.2.13/FastInfoset-1.2.13.jar:/home/runner/.m2/repository/javax/activation/activation/1.1.1/activation-1.1.1.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf/1.48.1/grpc-protobuf-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-api/1.48.1/grpc-api-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-context/1.48.1/grpc-context-1.48.1.jar:/home/runner/.m2/repository/com/google/api/grpc/proto-google-common-protos/2.9.0/proto-google-common-protos-2.9.0.jar:/home/runner/.m2/repository/io/grpc/grpc-protobuf-lite/1.48.1/grpc-protobuf-lite-1.48.1.jar:/home/runner/.m2/repository/io/grpc/grpc-stub/1.48.1/grpc-stub-1.48.1.jar:/home/runner/.m2/repository/io/netty/netty-transport/4.1.77.Final/netty-transport-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-resolver/4.1.77.Final/netty-resolver-4.1.77.Final.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-csi/1.4.0-SNAPSHOT/ozone-csi-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/protobuf/protobuf-java-util/3.19.6/protobuf-java-util-3.19.6.jar:/home/runner/.m2/repository/com/google/code/gson/gson/2.9.0/gson-2.9.0.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-config/1.4.0-SNAPSHOT/hdds-config-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-epoll/4.1.77.Final/netty-transport-native-epoll-4.1.77.Final-linux-x86_64.jar:/home/runner/.m2/repository/io/netty/netty-transport-classes-epoll/4.1.77.Final/netty-transport-classes-epoll-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-transport-native-unix-common/4.1.77.Final/netty-transport-native-unix-common-4.1.77.Final.jar:/home/runner/.m2/repository/org/slf4j/slf4j-reload4j/1.7.36/slf4j-reload4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-recon/1.4.0-SNAPSHOT/ozone-recon-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-reconcodegen/1.4.0-SNAPSHOT/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-multibindings/4.0/guice-multibindings-4.0.jar:/home/runner/.m2/repository/com/google/inject/guice/4.0/guice-4.0.jar:/home/runner/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-assistedinject/4.0/guice-assistedinject-4.0.jar:/home/runner/.m2/repository/com/google/inject/extensions/guice-servlet/4.0/guice-servlet-4.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/containers/jersey-container-servlet/2.34/jersey-container-servlet-2.34.jar:/home/runner/.m2/repository/org/glassfish/hk2/guice-bridge/2.5.0/guice-bridge-2.5.0.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-server/2.34/jersey-server-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/core/jersey-client/2.34/jersey-client-2.34.jar:/home/runner/.m2/repository/jakarta/annotation/jakarta.annotation-api/1.3.5/jakarta.annotation-api-1.3.5.jar:/home/runner/.m2/repository/jakarta/validation/jakarta.validation-api/2.0.2/jakarta.validation-api-2.0.2.jar:/home/runner/.m2/repository/org/glassfish/jersey/media/jersey-media-json-jackson/2.34/jersey-media-json-jackson-2.34.jar:/home/runner/.m2/repository/org/glassfish/jersey/ext/jersey-entity-filtering/2.34/jersey-entity-filtering-2.34.jar:/home/runner/.m2/repository/org/jooq/jooq/3.11.10/jooq-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-meta/3.11.10/jooq-meta-3.11.10.jar:/home/runner/.m2/repository/org/jooq/jooq-codegen/3.11.10/jooq-codegen-3.11.10.jar:/home/runner/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/home/runner/.m2/repository/org/apache/derby/derby/10.14.2.0/derby-10.14.2.0.jar:/home/runner/.m2/repository/org/xerial/sqlite-jdbc/3.25.2/sqlite-jdbc-3.25.2.jar:/home/runner/.m2/repository/org/springframework/spring-jdbc/5.3.23/spring-jdbc-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-beans/5.3.23/spring-beans-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-core/5.3.23/spring-core-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-jcl/5.3.23/spring-jcl-5.3.23.jar:/home/runner/.m2/repository/org/springframework/spring-tx/5.3.23/spring-tx-5.3.23.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-client/1.4.0-SNAPSHOT/ozone-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-erasurecode/1.4.0-SNAPSHOT/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem/1.4.0-SNAPSHOT/ozone-filesystem-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-filesystem-common/1.4.0-SNAPSHOT/ozone-filesystem-common-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-tools/1.4.0-SNAPSHOT/ozone-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-tools/2.4.2-8b8bdda-SNAPSHOT/ratis-tools-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-core/1.12.261/aws-java-sdk-core-1.12.261.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpclient/4.5.13/httpclient-4.5.13.jar:/home/runner/.m2/repository/org/apache/httpcomponents/httpcore/4.4.13/httpcore-4.4.13.jar:/home/runner/.m2/repository/software/amazon/ion/ion-java/1.0.2/ion-java-1.0.2.jar:/home/runner/.m2/repository/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.13.4/jackson-dataformat-cbor-2.13.4.jar:/home/runner/.m2/repository/joda-time/joda-time/2.8.1/joda-time-2.8.1.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-s3/1.12.261/aws-java-sdk-s3-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/aws-java-sdk-kms/1.12.261/aws-java-sdk-kms-1.12.261.jar:/home/runner/.m2/repository/com/amazonaws/jmespath-java/1.12.261/jmespath-java-1.12.261.jar:/home/runner/.m2/repository/org/kohsuke/metainf-services/metainf-services/1.8/metainf-services-1.8.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-tools/1.4.0-SNAPSHOT/hdds-tools-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/home/runner/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar:/home/runner/.m2/repository/org/apache/ozone/ozone-manager/1.4.0-SNAPSHOT/ozone-manager-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-client/1.4.0-SNAPSHOT/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/info/picocli/picocli/4.6.1/picocli-4.6.1.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.13.4/jackson-annotations-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.13.4/jackson-datatype-jsr310-2.13.4.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-annotation-processing/1.4.0-SNAPSHOT/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server/2.4.2-8b8bdda-SNAPSHOT/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-client/2.4.2-8b8bdda-SNAPSHOT/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-server-api/2.4.2-8b8bdda-SNAPSHOT/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-metrics/2.4.2-8b8bdda-SNAPSHOT/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-netty/2.4.2-8b8bdda-SNAPSHOT/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-grpc/2.4.2-8b8bdda-SNAPSHOT/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/logging/log4j/log4j-api/2.17.1/log4j-api-2.17.1.jar:/home/runner/.m2/repository/org/apache/commons/commons-pool2/2.6.0/commons-pool2-2.6.0.jar:/home/runner/.m2/repository/org/bouncycastle/bcpkix-jdk15on/1.67/bcpkix-jdk15on-1.67.jar:/home/runner/.m2/repository/commons-validator/commons-validator/1.6/commons-validator-1.6.jar:/home/runner/.m2/repository/commons-beanutils/commons-beanutils/1.9.4/commons-beanutils-1.9.4.jar:/home/runner/.m2/repository/commons-digester/commons-digester/1.8.1/commons-digester-1.8.1.jar:/home/runner/.m2/repository/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-client/1.6.0/jaeger-client-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-thrift/1.6.0/jaeger-thrift-1.6.0.jar:/home/runner/.m2/repository/org/apache/thrift/libthrift/0.14.1/libthrift-0.14.1.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-core/1.6.0/jaeger-core-1.6.0.jar:/home/runner/.m2/repository/io/jaegertracing/jaeger-tracerresolver/1.6.0/jaeger-tracerresolver-1.6.0.jar:/home/runner/.m2/repository/io/opentracing/contrib/opentracing-tracerresolver/0.1.8/opentracing-tracerresolver-0.1.8.jar:/home/runner/.m2/repository/org/jetbrains/kotlin/kotlin-stdlib/1.6.21/kotlin-stdlib-1.6.21.jar:/home/runner/.m2/repository/org/jetbrains/annotations/13.0/annotations-13.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-util/0.33.0/opentracing-util-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-api/0.33.0/opentracing-api-0.33.0.jar:/home/runner/.m2/repository/io/opentracing/opentracing-noop/0.33.0/opentracing-noop-0.33.0.jar:/home/runner/.m2/repository/org/yaml/snakeyaml/1.33/snakeyaml-1.33.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-interface-admin/1.4.0-SNAPSHOT/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/junit/junit/4.13.1/junit-4.13.1.jar:/home/runner/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-api/5.8.2/junit-jupiter-api-5.8.2.jar:/home/runner/.m2/repository/org/opentest4j/opentest4j/1.2.0/opentest4j-1.2.0.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-commons/1.8.2/junit-platform-commons-1.8.2.jar:/home/runner/.m2/repository/org/apiguardian/apiguardian-api/1.1.2/apiguardian-api-1.1.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-params/5.8.2/junit-jupiter-params-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-migrationsupport/5.8.2/junit-jupiter-migrationsupport-5.8.2.jar:/home/runner/.m2/repository/org/junit/jupiter/junit-jupiter-engine/5.8.2/junit-jupiter-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-engine/1.8.2/junit-platform-engine-1.8.2.jar:/home/runner/.m2/repository/org/junit/vintage/junit-vintage-engine/5.8.2/junit-vintage-engine-5.8.2.jar:/home/runner/.m2/repository/org/junit/platform/junit-platform-launcher/1.8.2/junit-platform-launcher-1.8.2.jar:/home/runner/.m2/repository/org/mockito/mockito-core/2.28.2/mockito-core-2.28.2.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy/1.9.10/byte-buddy-1.9.10.jar:/home/runner/.m2/repository/net/bytebuddy/byte-buddy-agent/1.9.10/byte-buddy-agent-1.9.10.jar:/home/runner/.m2/repository/org/objenesis/objenesis/1.0/objenesis-1.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-auth/3.3.4/hadoop-auth-3.3.4.jar:/home/runner/.m2/repository/com/nimbusds/nimbus-jose-jwt/9.8.1/nimbus-jose-jwt-9.8.1.jar:/home/runner/.m2/repository/com/github/stephenc/jcip/jcip-annotations/1.0-1/jcip-annotations-1.0-1.jar:/home/runner/.m2/repository/net/minidev/json-smart/2.4.7/json-smart-2.4.7.jar:/home/runner/.m2/repository/net/minidev/accessors-smart/2.4.7/accessors-smart-2.4.7.jar:/home/runner/.m2/repository/org/ow2/asm/asm/5.0.4/asm-5.0.4.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar:/home/runner/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar:/home/runner/.m2/repository/org/apache/yetus/audience-annotations/0.5.0/audience-annotations-0.5.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar:/home/runner/.m2/repository/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-core/1.19/jersey-core-1.19.jar:/home/runner/.m2/repository/javax/ws/rs/jsr311-api/1.1.1/jsr311-api-1.1.1.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-server/1.19/jersey-server-1.19.jar:/home/runner/.m2/repository/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-server/9.4.49.v20220914/jetty-server-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-http/9.4.49.v20220914/jetty-http-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-io/9.4.49.v20220914/jetty-io-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-webapp/9.4.49.v20220914/jetty-webapp-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-xml/9.4.49.v20220914/jetty-xml-9.4.49.v20220914.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/home/runner/.m2/repository/commons-net/commons-net/3.9.0/commons-net-3.9.0.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-servlet/1.19/jersey-servlet-1.19.jar:/home/runner/.m2/repository/com/sun/jersey/jersey-json/1.19/jersey-json-1.19.jar:/home/runner/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/home/runner/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-xc/1.9.2/jackson-xc-1.9.2.jar:/home/runner/.m2/repository/com/google/re2j/re2j/1.1/re2j-1.1.jar:/home/runner/.m2/repository/com/jcraft/jsch/0.1.54/jsch-0.1.54.jar:/home/runner/.m2/repository/org/apache/curator/curator-client/4.2.0/curator-client-4.2.0.jar:/home/runner/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar:/home/runner/.m2/repository/org/apache/kerby/kerb-core/1.0.1/kerb-core-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-pkix/1.0.1/kerby-pkix-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-asn1/1.0.1/kerby-asn1-1.0.1.jar:/home/runner/.m2/repository/org/apache/kerby/kerby-util/1.0.1/kerby-util-1.0.1.jar:/home/runner/.m2/repository/dnsjava/dnsjava/2.1.7/dnsjava-2.1.7.jar:/home/runner/.m2/repository/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar:/home/runner/.m2/repository/org/eclipse/jetty/jetty-util/9.4.49.v20220914/jetty-util-9.4.49.v20220914.jar:/home/runner/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.13.4.2/jackson-databind-2.13.4.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-kms/3.3.4/hadoop-kms-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-server-scm/1.4.0-SNAPSHOT/hdds-server-scm-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT-tests.jar:/home/runner/.m2/repository/com/github/luben/zstd-jni/1.5.2-5/zstd-jni-1.5.2-5.jar:/home/runner/.m2/repository/commons-codec/commons-codec/1.15/commons-codec-1.15.jar:/home/runner/.m2/repository/io/netty/netty-codec/4.1.77.Final/netty-codec-4.1.77.Final.jar:/home/runner/.m2/repository/io/netty/netty-handler/4.1.77.Final/netty-handler-4.1.77.Final.jar:/home/runner/.m2/repository/org/apache/ozone/hdds-hadoop-dependency-test/1.4.0-SNAPSHOT/hdds-hadoop-dependency-test-1.4.0-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-common/3.3.4/hadoop-common-3.3.4-tests.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-hdfs/3.3.4/hadoop-hdfs-3.3.4-tests.jar:/home/runner/.m2/repository/org/assertj/assertj-core/3.12.2/assertj-core-3.12.2.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/3.3.4/hadoop-mapreduce-client-jobclient-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/3.3.4/hadoop-mapreduce-client-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-common/3.3.4/hadoop-yarn-common-3.3.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-api/3.3.4/hadoop-yarn-api-3.3.4.jar:/home/runner/.m2/repository/com/sun/jersey/contribs/jersey-guice/1.19/jersey-guice-1.19.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.13.4/jackson-jaxrs-json-provider-2.13.4.jar:/home/runner/.m2/repository/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.13.4/jackson-jaxrs-base-2.13.4.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-yarn-client/3.3.4/hadoop-yarn-client-3.3.4.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-client/9.4.43.v20210629/websocket-client-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-common/9.4.43.v20210629/websocket-common-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/eclipse/jetty/websocket/websocket-api/9.4.43.v20210629/websocket-api-9.4.43.v20210629.jar:/home/runner/.m2/repository/org/jline/jline/3.9.0/jline-3.9.0.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/3.3.4/hadoop-mapreduce-client-core-3.3.4.jar:/home/runner/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar:/home/runner/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar:/home/runner/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-annotations/3.3.4/hadoop-annotations-3.3.4.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/../lib/tools.jar:/home/runner/.m2/repository/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar:/home/runner/.m2/repository/org/apache/hadoop/hadoop-distcp/3.3.4/hadoop-distcp-3.3.4-tests.jar:/home/runner/.m2/repository/org/slf4j/jul-to-slf4j/1.7.36/jul-to-slf4j-1.7.36.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-common/2.4.2-8b8bdda-SNAPSHOT/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-thirdparty-misc/1.0.3/ratis-thirdparty-misc-1.0.3.jar:/home/runner/.m2/repository/org/apache/ratis/ratis-proto/2.4.2-8b8bdda-SNAPSHOT/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="user.home" value="/home/runner"/>
    <property name="user.language" value="en"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="java.home" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre"/>
    <property name="java.security.krb5.conf" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/krb5.conf"/>
    <property name="file.separator" value="/"/>
    <property name="basedir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="line.separator" value="&#10;"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="skip.installnpx" value="true"/>
    <property name="java.awt.graphicsenv" value="sun.awt.X11GraphicsEnvironment"/>
    <property name="surefire.fork.timeout" value="3600"/>
    <property name="surefire.real.class.path" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/surefire/surefirebooter6064191024080482680.jar:/home/runner/.m2/repository/org/jacoco/org.jacoco.agent/0.8.5/org.jacoco.agent-0.8.5-runtime.jar"/>
    <property name="sun.boot.class.path" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/temurin-8-jdk-amd64/jre/classes"/>
    <property name="hadoop.log.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="java.runtime.version" value="1.8.0_352-b08"/>
    <property name="skip.npx" value="true"/>
    <property name="user.name" value="runner"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="path.separator" value=":"/>
    <property name="java.security.egd" value="file:///dev/urandom"/>
    <property name="os.version" value="5.15.0-1023-azure"/>
    <property name="java.endorsed.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/endorsed"/>
    <property name="java.runtime.name" value="OpenJDK Runtime Environment"/>
    <property name="file.encoding" value="UTF-8"/>
    <property name="java.vm.name" value="OpenJDK 64-Bit Server VM"/>
    <property name="test.build.webapps" value=""/>
    <property name="localRepository" value="/home/runner/.m2/repository"/>
    <property name="jetty.git.hash" value="4231a3b2e4cb8548a412a789936d640a97b1aa0a"/>
    <property name="java.vendor.url.bug" value="https://github.com/adoptium/adoptium-support/issues"/>
    <property name="require.test.libhadoop" value=""/>
    <property name="java.io.tmpdir" value="/tmp"/>
    <property name="java.version" value="1.8.0_352"/>
    <property name="surefire.rerunFailingTestsCount" value="5"/>
    <property name="user.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test"/>
    <property name="os.arch" value="amd64"/>
    <property name="test.build.classes" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="java.awt.printerjob" value="sun.print.PSPrinterJob"/>
    <property name="sun.os.patch.level" value="unknown"/>
    <property name="org.apache.ratis.thirdparty.io.netty.allocator.useCacheForAllThreads" value="false"/>
    <property name="hadoop.tmp.dir" value="/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/tmp"/>
    <property name="java.library.path" value="/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib"/>
    <property name="java.vendor" value="Temurin"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.vm.version" value="25.352-b08"/>
    <property name="java.specification.maintenance.version" value="4"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="java.ext.dirs" value="/usr/lib/jvm/temurin-8-jdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext"/>
    <property name="java.class.version" value="52.0"/>
  </properties>
  <testcase name="testNodeWithOpenPipelineCanBeDecommissionedAndRecommissioned" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="54.077"/>
  <testcase name="testContainerIsReplicatedWhenAllNodesGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="44.828"/>
  <testcase name="testMaintenanceEndsAutomaticallyAtTimeout" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="37.55"/>
  <testcase name="testSingleNodeWithOpenPipelineCanGotoMaintenance" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="39.152"/>
  <testcase name="testSCMHandlesRestartForMaintenanceNode" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="43.154">
    <error type="java.util.concurrent.TimeoutException"><![CDATA[java.util.concurrent.TimeoutException: 
Timed out waiting for condition. Thread diagnostics:
Timestamp: 2023-01-03 02:07:00,988

"ChunkWriter-3-0" daemon prio=5 tid=4457 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 35427" daemon prio=5 tid=4042 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4621 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5040 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2801-thread-1"  prio=5 tid=5987 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 35747" daemon prio=5 tid=4165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 34621" daemon prio=5 tid=5953 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1964746733-5467" daemon prio=5 tid=5467 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=3995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-3" daemon prio=5 tid=541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"19aec3d0-bc58-440a-899b-3969d29112cc-impl-thread1"  prio=5 tid=5518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5305 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"qtp1337264528-4421-acceptor-0@660bb8a5-ServerConnector@13e2fa49{HTTP/1.1, (http/1.1)}{0.0.0.0:36497}" daemon prio=3 tid=4421 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 36679" daemon prio=5 tid=4082 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor56" daemon prio=5 tid=5761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 33121" daemon prio=5 tid=5150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5420 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker"  prio=5 tid=5828 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2528-thread-1"  prio=5 tid=5355 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-6de4f0cb-1"  prio=5 tid=3547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4287" daemon prio=5 tid=4287 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3862 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5578 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 36679" daemon prio=5 tid=4086 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=4726 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3484" daemon prio=5 tid=3484 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor47" daemon prio=5 tid=4734 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3552 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 34645" daemon prio=5 tid=3421 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Parameter Sending Thread #0" daemon prio=5 tid=124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5508 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-59462052D018-StateMachineUpdater" daemon prio=5 tid=4763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=5313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4269 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 35747" daemon prio=5 tid=4166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1715-thread-1" daemon prio=5 tid=3615 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-6D7CE5058BEF-StateMachineUpdater" daemon prio=5 tid=4782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-5D5576319555-FollowerState" daemon prio=5 tid=3858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3494 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 42211" daemon prio=5 tid=5170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5534 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState" daemon prio=5 tid=6097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"JvmPauseMonitor46" daemon prio=5 tid=4711 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-8" daemon prio=5 tid=1970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3677 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2678-thread-1"  prio=5 tid=5887 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1942-thread-1" daemon prio=5 tid=4249 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 42211" daemon prio=5 tid=5185 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=4513 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 40427" daemon prio=5 tid=5936 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5650 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-D9296D6C4CE8->25c9036e-1b5b-4734-abbe-c826b10abe90-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"a89e0418-9005-4742-9592-8c0c855df8ce-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4280 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5dc3356e-1"  prio=5 tid=3490 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4144" daemon prio=5 tid=4144 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3483-acceptor-0@d78928c-ServerConnector@4c6482ba{HTTP/1.1, (http/1.1)}{0.0.0.0:33483}" daemon prio=3 tid=3483 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6076 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4606 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 42125" daemon prio=5 tid=5190 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp856589424-4145" daemon prio=5 tid=4145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker"  prio=5 tid=5606 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5566 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5908 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 15 on default port 33881" daemon prio=5 tid=5339 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806->af27b707-902e-436a-b36c-df002345c922-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6039 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4390 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4334" daemon prio=5 tid=4334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4241 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4518 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4006 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"pool-2543-thread-1"  prio=5 tid=5834 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5437" daemon prio=5 tid=5437 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5429 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4331" daemon prio=5 tid=4331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=1971 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5524" daemon prio=5 tid=5524 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@26247244" daemon prio=5 tid=3432 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 34645" daemon prio=5 tid=3403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-5D5576319555-SegmentedRaftLogWorker"  prio=5 tid=3792 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLogWorker"  prio=5 tid=5872 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4484 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@30963874" daemon prio=5 tid=3555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5531 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5745 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor57" daemon prio=5 tid=5773 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4712 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"pool-1704-thread-1"  prio=5 tid=3593 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4261" daemon prio=5 tid=4261 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-0" daemon prio=5 tid=472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2512-thread-1" daemon prio=5 tid=5350 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=5311 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 40427" daemon prio=5 tid=5935 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=4510 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=5312 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=5827 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ff063fb" daemon prio=5 tid=5456 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1876163108-5210-acceptor-0@22e0718f-ServerConnector@1906bf93{HTTP/1.1, (http/1.1)}{0.0.0.0:37391}" daemon prio=3 tid=5210 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5123 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"OMDoubleBufferFlushThread" daemon prio=5 tid=4123 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:538)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:268)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$537/1370311703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5361" daemon prio=5 tid=5361 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 32791" daemon prio=5 tid=5965 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=6078 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4111" daemon prio=5 tid=4111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 42211" daemon prio=5 tid=5182 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 9 on default port 33881" daemon prio=5 tid=5333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1892971966-3396" daemon prio=5 tid=3396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderStateImpl" daemon prio=5 tid=6027 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5568 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater" daemon prio=5 tid=3809 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Under Replicated Processor" daemon prio=5 tid=5898 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"612e7161-302d-4bcf-a524-ec09f4414ff1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4533 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3158 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 33881" daemon prio=5 tid=5329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=3634 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5396" daemon prio=5 tid=5396 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5452 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 35427" daemon prio=5 tid=4050 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5768 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5118 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Command processor thread" daemon prio=5 tid=3609 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3489" daemon prio=5 tid=3489 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 32791" daemon prio=5 tid=5979 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5507 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 33121" daemon prio=5 tid=5161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 36679" daemon prio=5 tid=4093 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1750886181-4230" daemon prio=5 tid=4230 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@30acf1a6" daemon prio=5 tid=3619 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6077 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp937486555-3598" daemon prio=5 tid=3598 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5497" daemon prio=5 tid=5497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 46401" daemon prio=5 tid=4080 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-44513b2-1"  prio=5 tid=4292 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4106" daemon prio=5 tid=4106 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 40427" daemon prio=5 tid=5932 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-server-thread1" daemon prio=5 tid=3866 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-6"  prio=5 tid=5310 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1395010122-4107-acceptor-0@6e787954-ServerConnector@4a8fee2c{HTTP/1.1, (http/1.1)}{0.0.0.0:40953}" daemon prio=3 tid=4107 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5476 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=5782 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4456 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5377 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5579 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 33881" daemon prio=5 tid=5327 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp899869274-5994" daemon prio=5 tid=5994 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3488" daemon prio=5 tid=3488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5498" daemon prio=5 tid=5498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3985 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderStateImpl" daemon prio=5 tid=6013 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 6 on default port 34621" daemon prio=5 tid=5951 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1634-thread-1" daemon prio=5 tid=3533 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=5783 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4218 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3024 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4608 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3513" daemon prio=5 tid=3513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor53" daemon prio=5 tid=5620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 33121" daemon prio=5 tid=5152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1641-thread-1"  prio=5 tid=3806 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4548" daemon prio=5 tid=4548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=696 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5748 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5047 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4130 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5457 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 34621" daemon prio=5 tid=5952 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"51ba1163-8388-41ac-b784-1dd4f62d306b-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4251 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 0.0.0.0/40427"  prio=5 tid=1 runnable
java.lang.Thread.State: RUNNABLE
        at java.lang.Thread.dumpThreads(Native Method)
        at java.lang.Thread.getAllStackTraces(Thread.java:1615)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:93)
        at org.apache.ozone.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:79)
        at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
        at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
        at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
        at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
        at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$164/40075281.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall$$Lambda$165/1418620248.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
        at org.junit.jupiter.engine.execution.ExecutableInvoker$$Lambda$322/914942811.apply(Unknown Source)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
        at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
        at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor$$Lambda$1221/945683299.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
        at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1583353301.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/319558327.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1514476350.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/1876682596.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1583353301.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/319558327.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1514476350.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService$$Lambda$268/1876682596.accept(Unknown Source)
        at java.util.ArrayList.forEach(ArrayList.java:1259)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$264/1583353301.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$263/319558327.invoke(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask$$Lambda$262/1514476350.execute(Unknown Source)
        at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
        at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
        at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
        at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator$$Lambda$220/245765246.accept(Unknown Source)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
        at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
        at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
        at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
        at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
        at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
        at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
        at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
        at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6059 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6073 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5427 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-5"  prio=5 tid=5260 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4629 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1627-thread-1"  prio=5 tid=3509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=1976 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5471" daemon prio=5 tid=5471 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4571 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 34621" daemon prio=5 tid=5948 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2578-thread-1"  prio=5 tid=5839 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4493 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-FB7BC2B45922-SegmentedRaftLogWorker"  prio=5 tid=3780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5106 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor54" daemon prio=5 tid=5665 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5122 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 7 on default port 42211" daemon prio=5 tid=5173 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4624 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5552" daemon prio=5 tid=5552 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5536 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5479 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-D9296D6C4CE8->a89e0418-9005-4742-9592-8c0c855df8ce-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3522 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor39" daemon prio=5 tid=3738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4615 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3742 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3633 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3622-acceptor-0@4cb1074b-ServerConnector@7473a835{HTTP/1.1, (http/1.1)}{0.0.0.0:37329}" daemon prio=3 tid=3622 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-2" daemon prio=5 tid=540 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 33121" daemon prio=5 tid=5159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3521 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-8EF27F6AF45A-SegmentedRaftLogWorker"  prio=5 tid=4812 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5769 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp950981263-4207" daemon prio=5 tid=4207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 35427" daemon prio=5 tid=4057 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 1 on default port 33881" daemon prio=5 tid=5325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5575 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4213 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2-server-thread1" daemon prio=5 tid=3864 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1650-thread-1"  prio=5 tid=3538 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 40427" daemon prio=5 tid=5944 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-222f7586-1"  prio=5 tid=4336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 42125" daemon prio=5 tid=5116 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1337264528-4420" daemon prio=5 tid=4420 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=5823 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-EEEF55C80313-SegmentedRaftLogWorker"  prio=5 tid=4764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp899869274-5990" daemon prio=5 tid=5990 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 34645" daemon prio=5 tid=3405 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=4760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 34645" daemon prio=5 tid=3412 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp899869274-5989-acceptor-0@23beb04c-ServerConnector@73839f22{HTTP/1.1, (http/1.1)}{0.0.0.0:42719}" daemon prio=3 tid=5989 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor41" daemon prio=5 tid=4136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"19aec3d0-bc58-440a-899b-3969d29112cc-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5517 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3684 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6060 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5472" daemon prio=5 tid=5472 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4224 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker"  prio=5 tid=5881 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-StateMachineUpdater" daemon prio=5 tid=5856 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4744 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922-server-thread2" daemon prio=5 tid=6043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4730 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1337264528-4426" daemon prio=5 tid=4426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5904 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-EEEF55C80313-StateMachineUpdater" daemon prio=5 tid=4775 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3437" daemon prio=5 tid=3437 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 34621" daemon prio=5 tid=5964 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 18 on default port 34621" daemon prio=5 tid=5963 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 33881" daemon prio=5 tid=5343 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Client (1986131162) connection to 0.0.0.0/0.0.0.0:36679 from runner" daemon prio=5 tid=4450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3741 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 33121" daemon prio=5 tid=5164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3701 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5026 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4234" daemon prio=5 tid=4234 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-10" daemon prio=5 tid=3457 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 35427" daemon prio=5 tid=4058 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker"  prio=5 tid=5840 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2664-thread-1"  prio=5 tid=5520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3487" daemon prio=5 tid=3487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-B93932A5F6FE-LeaderStateImpl" daemon prio=5 tid=4845 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-3"  prio=5 tid=5232 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 34621" daemon prio=5 tid=5958 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp937486555-3596" daemon prio=5 tid=3596 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=4016 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 35747" daemon prio=5 tid=4160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5921 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806->56e9ebea-1da6-4510-b9da-2a36b64eada2-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=6040 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Signal Dispatcher" daemon prio=9 tid=4 runnable
java.lang.Thread.State: RUNNABLE
"IPC Server handler 11 on default port 32791" daemon prio=5 tid=5976 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-DatanodeCommandForSCMNodeManager"  prio=5 tid=5784 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-935EE45E604E-LeaderStateImpl" daemon prio=5 tid=4861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-2-0" daemon prio=5 tid=4709 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 42125" daemon prio=5 tid=5204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=3502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1192749-1"  prio=5 tid=3401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922-server-thread1" daemon prio=5 tid=6041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 33121" daemon prio=5 tid=5146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState" daemon prio=5 tid=5848 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"qtp702233778-3482" daemon prio=5 tid=3482 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=6014 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5317" daemon prio=5 tid=5317 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3023 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-AE8A92DE7426-SegmentedRaftLogWorker"  prio=5 tid=3842 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"612e7161-302d-4bcf-a524-ec09f4414ff1@group-92921429485D-StateMachineUpdater" daemon prio=5 tid=4829 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"612e7161-302d-4bcf-a524-ec09f4414ff1@group-92921429485D-SegmentedRaftLogWorker"  prio=5 tid=4827 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3679 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 34621" daemon prio=5 tid=5946 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5087 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4752 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1926-thread-1"  prio=5 tid=4767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-AE8A92DE7426-StateMachineUpdater" daemon prio=5 tid=3844 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3516" daemon prio=5 tid=3516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@484206d3" daemon prio=5 tid=4418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 35427" daemon prio=5 tid=4047 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5460 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4745 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-9"  prio=5 tid=5276 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 42125" daemon prio=5 tid=5189 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 42125" daemon prio=5 tid=5194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4239 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2507-thread-1"  prio=5 tid=5314 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 42211" daemon prio=5 tid=5177 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5376 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2018-thread-1"  prio=5 tid=4325 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@10c41b6c" daemon prio=5 tid=5492 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 33881" daemon prio=5 tid=5324 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5132 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-0" daemon prio=5 tid=6046 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4132 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3706 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5474" daemon prio=5 tid=5474 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-6D7CE5058BEF-LeaderStateImpl" daemon prio=5 tid=4843 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-0-0" daemon prio=5 tid=4707 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4260" daemon prio=5 tid=4260 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3506 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34645" daemon prio=5 tid=3382 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5610 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4295 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=3520 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#0" daemon prio=5 tid=5667 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3441" daemon prio=5 tid=3441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5473" daemon prio=5 tid=5473 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4147" daemon prio=5 tid=4147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@224a7c98" daemon prio=5 tid=5519 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"timer4" daemon prio=5 tid=562 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5433 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5561 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5500" daemon prio=5 tid=5500 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-8EF27F6AF45A-LeaderStateImpl" daemon prio=5 tid=4863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#1" daemon prio=5 tid=4738 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp950981263-4201" daemon prio=5 tid=4201 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp899869274-5991" daemon prio=5 tid=5991 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 33881" daemon prio=5 tid=5342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=4754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 46401" daemon prio=5 tid=4066 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5371 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=1977 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5322" daemon prio=5 tid=5322 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 32791" daemon prio=5 tid=5981 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"null-request--thread1" daemon prio=5 tid=5218 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4489 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4237 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1337264528-4427" daemon prio=5 tid=4427 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 36679" daemon prio=5 tid=4099 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5451 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-80A041299B2B-LeaderStateImpl" daemon prio=5 tid=3874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#1" daemon prio=5 tid=5582 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4293 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4978 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4332" daemon prio=5 tid=4332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4387 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 32791" daemon prio=5 tid=5984 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4753 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 36679" daemon prio=5 tid=4096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-D9296D6C4CE8-StateMachineUpdater" daemon prio=5 tid=4793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3495 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6068 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5356" daemon prio=5 tid=5356 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5372 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4561 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Over Replicated Processor" daemon prio=5 tid=5112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"DatanodeAdminManager-0" daemon prio=5 tid=5113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3545" daemon prio=5 tid=3545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3447 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2632-thread-1"  prio=5 tid=5871 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-19ff3e35-1"  prio=5 tid=5323 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 42211" daemon prio=5 tid=5172 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 35427" daemon prio=5 tid=4056 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=4022 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5760 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5771 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4008 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3674 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35427" daemon prio=5 tid=4044 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5919 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4317 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb-impl-thread1"  prio=5 tid=5491 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5134 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1337264528-4422" daemon prio=5 tid=4422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2587-thread-1"  prio=5 tid=5436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4462 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5391" daemon prio=5 tid=5391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1876163108-5209" daemon prio=5 tid=5209 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4545" daemon prio=5 tid=4545 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-935EE45E604E-SegmentedRaftLogWorker"  prio=5 tid=4800 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3739 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5444" daemon prio=5 tid=5444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1919-thread-1" daemon prio=5 tid=4222 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 34645" daemon prio=5 tid=3409 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 42125" daemon prio=5 tid=5201 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor37" daemon prio=5 tid=3702 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Finalizer" daemon prio=8 tid=3 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6080 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread1" daemon prio=5 tid=5857 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 42211" daemon prio=5 tid=5183 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5785 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4551" daemon prio=5 tid=4551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5669 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5527" daemon prio=5 tid=5527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6070 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 34621" daemon prio=5 tid=5962 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=4247 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3397" daemon prio=5 tid=3397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-6" daemon prio=5 tid=1968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=4570 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5580 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 35747" daemon prio=5 tid=4159 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 33881" daemon prio=5 tid=5336 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1560-thread-1"  prio=5 tid=3392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 36679" daemon prio=5 tid=4083 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1876163108-5211" daemon prio=5 tid=5211 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5439" daemon prio=5 tid=5439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-4"  prio=5 tid=5259 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 33121" daemon prio=5 tid=5163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=5912 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"ChunkWriter-0-0" daemon prio=5 tid=4454 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=4265 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-9"  prio=5 tid=5275 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5624 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3689 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=4133 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-StateMachineUpdater" daemon prio=5 tid=5863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=3863 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1722-thread-1"  prio=5 tid=3841 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1889-thread-1"  prio=5 tid=4126 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 33121" daemon prio=5 tid=5151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5424 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5553-acceptor-0@98df4cb-ServerConnector@7f07d3fd{HTTP/1.1, (http/1.1)}{0.0.0.0:46403}" daemon prio=3 tid=5553 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 42211" daemon prio=5 tid=5167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4632 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 42125" daemon prio=5 tid=5198 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=3694 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-5" daemon prio=5 tid=568 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 33881" daemon prio=5 tid=5341 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 2 on default port 34621" daemon prio=5 tid=5947 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3137 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6079 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3393" daemon prio=5 tid=3393 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4010 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"BlockDeletingService#0" daemon prio=5 tid=3740 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLogWorker"  prio=5 tid=5877 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6057 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderStateImpl" daemon prio=5 tid=6025 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BlockDeletingService#2" daemon prio=5 tid=4953 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5767 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5618 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4461 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4258" daemon prio=5 tid=4258 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 40427" daemon prio=5 tid=5927 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@76e44b53" daemon prio=5 tid=4282 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"pool-2618-thread-1"  prio=5 tid=5466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4577 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=3998 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5443" daemon prio=5 tid=5443 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1691-thread-1"  prio=5 tid=3818 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5754 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 42211" daemon prio=5 tid=5176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Timer-5"  prio=5 tid=4137 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp950981263-4203" daemon prio=5 tid=4203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5501" daemon prio=5 tid=5501 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 33121" daemon prio=5 tid=5157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=4617 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 42125" daemon prio=5 tid=5187 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3737 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5581 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5463 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState" daemon prio=5 tid=6036 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"BlockDeletingService#1" daemon prio=5 tid=4527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 34645" daemon prio=5 tid=3420 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@74d19661" daemon prio=5 tid=5426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 46401" daemon prio=5 tid=4068 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=5751 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3499 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4245 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-5"  prio=5 tid=5262 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5535 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1876163108-5212" daemon prio=5 tid=5212 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35747" daemon prio=5 tid=4169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #4" daemon prio=5 tid=4902 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3492 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 33121" daemon prio=5 tid=5158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=3497 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-2"  prio=5 tid=5230 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3705 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5494" daemon prio=5 tid=5494 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 46401" daemon prio=5 tid=4065 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5914 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5555" daemon prio=5 tid=5555 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 35427" daemon prio=5 tid=4046 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3535 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=4722 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5440" daemon prio=5 tid=5440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4486 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 33121" daemon prio=5 tid=5124 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Under Replicated Processor" daemon prio=5 tid=5111 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-worker-ELG-3-1" daemon prio=5 tid=471 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 32791" daemon prio=5 tid=5975 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1964746733-5470" daemon prio=5 tid=5470 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 42125" daemon prio=5 tid=5202 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 32791" daemon prio=5 tid=5901 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 13 on default port 32791" daemon prio=5 tid=5978 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=6015 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-2"  prio=5 tid=5229 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 33121" daemon prio=5 tid=5162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4716 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3621" daemon prio=5 tid=3621 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"pool-2602-thread-1" daemon prio=5 tid=5461 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1965-thread-1" daemon prio=5 tid=4278 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=3999 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:662)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$415/661867450.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=5308 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-2150-thread-1"  prio=5 tid=4542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4715 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5756 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor36" daemon prio=5 tid=3690 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState" daemon prio=5 tid=5850 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"pool-1891-thread-1"  prio=5 tid=4141 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 33881" daemon prio=5 tid=5337 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2536-thread-1" daemon prio=5 tid=5383 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1731-thread-1"  prio=5 tid=3620 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 34621" daemon prio=5 tid=5950 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@45f96c54" daemon prio=5 tid=3450 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f-impl-thread1"  prio=5 tid=5434 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5107 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$405/1726477667.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5042 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5297 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-e21d73-1"  prio=5 tid=5996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4385 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3697 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35747" daemon prio=5 tid=4162 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2641-thread-1"  prio=5 tid=5493 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4266 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 35747" daemon prio=5 tid=4163 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c36dba4c-5c72-465b-8876-3f5e456990a2-server-thread2" daemon prio=5 tid=3867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3605 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4729 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Listener at 127.0.0.1/33881"  prio=5 tid=14 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:353)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$createClusters$1(MiniOzoneClusterProvider.java:237)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$340/852190062.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4240 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=3997 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5523" daemon prio=5 tid=5523 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4512 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4148" daemon prio=5 tid=4148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"612e7161-302d-4bcf-a524-ec09f4414ff1@group-92921429485D-LeaderStateImpl" daemon prio=5 tid=4892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 40427" daemon prio=5 tid=5909 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-StateMachineUpdater" daemon prio=5 tid=5879 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-9EC58D582F46-LeaderStateImpl" daemon prio=5 tid=3898 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3444 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=4723 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 35427" daemon prio=5 tid=4059 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=3531 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5770 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-1512fd3d-1"  prio=5 tid=3442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp899869274-5993" daemon prio=5 tid=5993 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5554" daemon prio=5 tid=5554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=5922 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4702 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 42211" daemon prio=5 tid=5181 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#1" daemon prio=5 tid=3682 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread2" daemon prio=5 tid=6044 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3649 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1618-thread-1"  prio=5 tid=3791 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4142" daemon prio=5 tid=4142 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4290" daemon prio=5 tid=4290 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4112" daemon prio=5 tid=4112 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3693 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=3755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 34645" daemon prio=5 tid=3408 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4238 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5496" daemon prio=5 tid=5496 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922-impl-thread1"  prio=5 tid=5353 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 40427" daemon prio=5 tid=5934 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 42211" daemon prio=5 tid=5178 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-D9296D6C4CE8-FollowerState" daemon prio=5 tid=4850 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@5ba3abd7" daemon prio=5 tid=4319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@99bf4" daemon prio=5 tid=4273 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4291" daemon prio=5 tid=4291 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3675 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3699 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5744 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-8"  prio=5 tid=5274 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3440" daemon prio=5 tid=3440 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2655-thread-1"  prio=5 tid=5876 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4329" daemon prio=5 tid=4329 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3544" daemon prio=5 tid=3544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4483 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4459 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5545 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4550" daemon prio=5 tid=4550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4449 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3640 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3541" daemon prio=5 tid=3541 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3438" daemon prio=5 tid=3438 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5395" daemon prio=5 tid=5395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 46401" daemon prio=5 tid=4072 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp723834011-5442" daemon prio=5 tid=5442 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor55" daemon prio=5 tid=5749 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-1"  prio=5 tid=5226 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-6D7CE5058BEF-SegmentedRaftLogWorker"  prio=5 tid=4780 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker"  prio=5 tid=5835 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5792 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=4015 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3510" daemon prio=5 tid=3510 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-2a59281c-1"  prio=5 tid=5475 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-CommandQueueReportForCommandQueueReportHandler" daemon prio=5 tid=4755 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 42125" daemon prio=5 tid=5193 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=3752 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1588-thread-1" daemon prio=5 tid=3469 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5119 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=5306 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp899869274-5995" daemon prio=5 tid=5995 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3526 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35427" daemon prio=5 tid=4060 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 40427" daemon prio=5 tid=5911 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp723834011-5441" daemon prio=5 tid=5441 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ReplicationMonitor" daemon prio=5 tid=5110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:662)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$415/661867450.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 34621" daemon prio=5 tid=5905 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"om1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4124 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 34645" daemon prio=5 tid=3410 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2147043764-3543" daemon prio=5 tid=3543 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-SegmentedRaftLogWorker"  prio=5 tid=5868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5505 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5777 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5360" daemon prio=5 tid=5360 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp937486555-3597" daemon prio=5 tid=3597 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=4938 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4416 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 33881" daemon prio=5 tid=5330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=5619 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 40427" daemon prio=5 tid=5926 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=5138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 42211" daemon prio=5 tid=5166 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"OpenKeyCleanupService#0" daemon prio=5 tid=3391 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3735 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 35427" daemon prio=5 tid=4055 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-OpenPipelineForHealthyPipelineSafeModeRule" daemon prio=5 tid=6003 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 36679" daemon prio=5 tid=4081 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-6701e216-1"  prio=5 tid=4209 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4751 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 46401" daemon prio=5 tid=4076 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5046 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-1-0" daemon prio=5 tid=5131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker"  prio=5 tid=5888 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1958-thread-1"  prio=5 tid=4254 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1572-thread-1"  prio=5 tid=3778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3426 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5506 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4717 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4601 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 35427" daemon prio=5 tid=4054 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-2a64e839-1"  prio=5 tid=4150 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5073 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 46401" daemon prio=5 tid=4062 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@2ebe4b7f" daemon prio=5 tid=3422 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3512" daemon prio=5 tid=3512 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 40427" daemon prio=5 tid=5929 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 15 on default port 40427" daemon prio=5 tid=5940 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-D9296D6C4CE8-StateMachineUpdater" daemon prio=5 tid=4789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 33881" daemon prio=5 tid=5304 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"ChunkWriter-2-0" daemon prio=5 tid=5759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3704 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 36679" daemon prio=5 tid=4084 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp397445177-4549" daemon prio=5 tid=4549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3514" daemon prio=5 tid=3514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b-server-thread2" daemon prio=5 tid=4917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4728 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=6000 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3551 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3caf31c8" daemon prio=5 tid=5483 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3517" daemon prio=5 tid=3517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 40427" daemon prio=5 tid=5931 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread3" daemon prio=5 tid=5859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3676 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5357-acceptor-0@33cc45db-ServerConnector@72bdf00a{HTTP/1.1, (http/1.1)}{0.0.0.0:34259}" daemon prio=3 tid=5357 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3623" daemon prio=5 tid=3623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"OpenKeyCleanupService#0" daemon prio=5 tid=4140 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3641 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater" daemon prio=5 tid=5614 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"pool-1896-thread-1" daemon prio=5 tid=4186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-3"  prio=5 tid=5231 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4108" daemon prio=5 tid=4108 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-B93932A5F6FE-SegmentedRaftLogWorker"  prio=5 tid=4784 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5430 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4401 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5574 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3648 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=6058 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3672 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4109" daemon prio=5 tid=4109 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@33b75d80" daemon prio=5 tid=3592 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 40427" daemon prio=5 tid=5933 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server idle connection scanner for port 32791" daemon prio=5 tid=5903 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp1876163108-5216" daemon prio=5 tid=5216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3734 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 34621" daemon prio=5 tid=5907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-EEEF55C80313-StateMachineUpdater" daemon prio=5 tid=4770 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=5894 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$405/1726477667.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-45508c27-1"  prio=5 tid=5397 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5352 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-B4D0CDD0329B-LeaderStateImpl" daemon prio=5 tid=4841 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=700 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5393" daemon prio=5 tid=5393 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4176 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4941 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3400" daemon prio=5 tid=3400 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3548 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4257" daemon prio=5 tid=4257 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-AE8A92DE7426-LeaderStateImpl" daemon prio=5 tid=3900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 14 on default port 33881" daemon prio=5 tid=5338 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 36679" daemon prio=5 tid=4095 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp990000395-3435-acceptor-0@3866f97b-ServerConnector@35fff60e{HTTP/1.1, (http/1.1)}{0.0.0.0:43059}" daemon prio=3 tid=3435 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=3380 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"pool-1549-thread-1"  prio=5 tid=3349 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4739 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 32791" daemon prio=5 tid=5971 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-0-0" daemon prio=5 tid=5616 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5362" daemon prio=5 tid=5362 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor52" daemon prio=5 tid=5577 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=4937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-7"  prio=5 tid=5269 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3629" daemon prio=5 tid=3629 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-2064-thread-1"  prio=5 tid=4795 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@7ba6d42c" daemon prio=5 tid=3480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"bc03f53a-8f38-42c1-b7a4-94894081fc1e-impl-thread1"  prio=5 tid=5549 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 32791" daemon prio=5 tid=5972 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Over Replicated Processor" daemon prio=5 tid=5899 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker"  prio=5 tid=5861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2135-thread-1"  prio=5 tid=4826 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4272 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5027 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4255" daemon prio=5 tid=4255 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4242 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3515" daemon prio=5 tid=3515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Mini-Cluster-Provider-Reap"  prio=5 tid=15 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider.lambda$reapClusters$0(MiniOzoneClusterProvider.java:199)
        at org.apache.hadoop.ozone.MiniOzoneClusterProvider$$Lambda$341/1674403916.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=2002 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 32791" daemon prio=5 tid=5970 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=4516 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5621 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=4977 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2453-thread-1"  prio=5 tid=5208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4578 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5385 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3703 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5666 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4708 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-EEEF55C80313->51ba1163-8388-41ac-b784-1dd4f62d306b-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4912 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 35427" daemon prio=5 tid=4043 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1595-thread-1"  prio=5 tid=3786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 33121" daemon prio=5 tid=5149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1395010122-4113" daemon prio=5 tid=4113 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 46401" daemon prio=5 tid=4074 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5514 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 33881" daemon prio=5 tid=5335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp688901239-3627" daemon prio=5 tid=3627 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker"  prio=5 tid=5849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-StateMachineUpdater" daemon prio=5 tid=5890 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5511 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=4020 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-5D5576319555-SegmentedRaftLogWorker"  prio=5 tid=3783 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4460 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3394-acceptor-0@2841531b-ServerConnector@3a389618{HTTP/1.1, (http/1.1)}{0.0.0.0:36675}" daemon prio=3 tid=3394 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-boss-ELG-1-1" daemon prio=5 tid=140 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@561af69e" daemon prio=5 tid=4300 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-DatanodeCommandForSCMNodeManager" daemon prio=5 tid=6032 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4011 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5565 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5481 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1581-thread-1"  prio=5 tid=3433 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-1"  prio=5 tid=5227 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4d7208b6-1"  prio=5 tid=4428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2625-thread-1" daemon prio=5 tid=5488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4380 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=3383 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"BlockDeletingService#0" daemon prio=5 tid=3758 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=4725 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 32791" daemon prio=5 tid=5969 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"DatanodeAdminManager-0" daemon prio=5 tid=5900 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderStateImpl" daemon prio=5 tid=6029 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"DatanodeAdminManager-0" daemon prio=5 tid=4002 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-LeaderStateImpl" daemon prio=5 tid=3861 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp950981263-4206" daemon prio=5 tid=4206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5852 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5526" daemon prio=5 tid=5526 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 36679" daemon prio=5 tid=4091 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1613786745-5557" daemon prio=5 tid=5557 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3404a332-1"  prio=5 tid=5364 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp937486555-3599" daemon prio=5 tid=3599 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-StateMachineUpdater" daemon prio=5 tid=5837 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=5115 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"ChunkReader-ELG-0" daemon prio=5 tid=4611 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4ed383b6-1"  prio=5 tid=5217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3685 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2519-thread-1"  prio=5 tid=5825 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3607 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3683 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5998 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=4190 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4546-acceptor-0@5959edbd-ServerConnector@29e8c4dc{HTTP/1.1, (http/1.1)}{0.0.0.0:41587}" daemon prio=3 tid=4546 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=4014 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Socket Reader #1 for port 0"  prio=5 tid=5303 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 3 on default port 32791" daemon prio=5 tid=5968 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 19 on default port 36679" daemon prio=5 tid=4100 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-3-0" daemon prio=5 tid=3636 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 36679" daemon prio=5 tid=4094 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5747 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=5774 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=5662 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3617 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3524 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3651 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6074 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35427" daemon prio=5 tid=4051 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5781 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3929 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34645" daemon prio=5 tid=3402 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4735 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3653 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2057-thread-1" daemon prio=5 tid=4403 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5503 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4301 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5763 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-49836264-1"  prio=5 tid=4263 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3981 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5315" daemon prio=5 tid=5315 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=5916 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5532 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Timer-4"  prio=5 tid=3388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Socket Reader #1 for port 34621"  prio=5 tid=5906 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"IPC Server handler 13 on default port 40427" daemon prio=5 tid=5938 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5478 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 34645" daemon prio=5 tid=3414 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-59462052D018-LeaderStateImpl" daemon prio=5 tid=4833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker"  prio=5 tid=5884 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@75aadd51" daemon prio=5 tid=5378 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 33881" daemon prio=5 tid=5340 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderStateImpl" daemon prio=5 tid=6038 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"IPC Server handler 2 on default port 35747" daemon prio=5 tid=4153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp268746859-5321" daemon prio=5 tid=5321 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4256-acceptor-0@55853157-ServerConnector@56358d43{HTTP/1.1, (http/1.1)}{0.0.0.0:38485}" daemon prio=3 tid=4256 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5567 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 32791" daemon prio=5 tid=5980 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1836965867-4284" daemon prio=5 tid=4284 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 32791" daemon prio=5 tid=5982 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server Responder" daemon prio=5 tid=5117 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3681 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3540-acceptor-0@4b455a1d-ServerConnector@3fff5da4{HTTP/1.1, (http/1.1)}{0.0.0.0:46199}" daemon prio=3 tid=3540 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5316-acceptor-0@5ed4d14c-ServerConnector@1f06192c{HTTP/1.1, (http/1.1)}{0.0.0.0:41811}" daemon prio=3 tid=5316 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"RatisPipelineUtilsThread - 0"  prio=5 tid=3996 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator.run(BackgroundPipelineCreator.java:176)
        at org.apache.hadoop.hdds.scm.pipeline.BackgroundPipelineCreator$$Lambda$405/1726477667.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 34645" daemon prio=5 tid=3415 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Periodic HDDS volume checker" daemon prio=5 tid=3586 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=3525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-80A041299B2B-SegmentedRaftLogWorker"  prio=5 tid=3801 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4235" daemon prio=5 tid=4235 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"a89e0418-9005-4742-9592-8c0c855df8ce-server-thread3" daemon prio=5 tid=4858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-impl-thread1"  prio=5 tid=5298 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5394" daemon prio=5 tid=5394 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4573 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5359" daemon prio=5 tid=5359 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Reference Handler" daemon prio=10 tid=2 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=5917 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-server-thread2" daemon prio=5 tid=3868 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1604-thread-1"  prio=5 tid=3481 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5556" daemon prio=5 tid=5556 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 34645" daemon prio=5 tid=3413 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5482 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5128 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"IPC Server handler 0 on default port 35747" daemon prio=5 tid=4151 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-StateMachineUpdater" daemon prio=5 tid=5867 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeReportForNodeReportHandler" daemon prio=5 tid=5822 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5997 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-StateMachineUpdater" daemon prio=5 tid=5883 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3430 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4939 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3931 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 42125" daemon prio=5 tid=5188 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 46401" daemon prio=5 tid=4069 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Over Replicated Processor" daemon prio=5 tid=4001 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 40427" daemon prio=5 tid=5928 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@64745270" daemon prio=5 tid=5986 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-2648-thread-1" daemon prio=5 tid=5515 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp925872880-4262" daemon prio=5 tid=4262 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5114 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@5de4c7e2" daemon prio=5 tid=4226 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3628 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4485 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 34645" daemon prio=5 tid=3418 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 4 on default port 34645" daemon prio=5 tid=3406 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"om1@group-C5BA1605619E-SegmentedRaftLogWorker"  prio=5 tid=3384 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f91ab00" daemon prio=5 tid=5510 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"qtp397445177-4552" daemon prio=5 tid=4552 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-7"  prio=5 tid=5270 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4286" daemon prio=5 tid=4286 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=4959 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3399" daemon prio=5 tid=3399 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 40427" daemon prio=5 tid=5930 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5422 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5030 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3686 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 32791" daemon prio=5 tid=5973 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@1f9b93b3" daemon prio=5 tid=5465 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3466 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 34645" daemon prio=5 tid=3404 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState" daemon prio=5 tid=6037 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"qtp899869274-5992" daemon prio=5 tid=5992 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5318" daemon prio=5 tid=5318 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor40" daemon prio=5 tid=3756 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6067 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3774 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5766 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5576 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 35747" daemon prio=5 tid=4157 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@31c24b50" daemon prio=5 tid=4217 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=4021 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3554 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"surefire-forkedjvm-command-thread" daemon prio=5 tid=10 runnable
java.lang.Thread.State: RUNNABLE
        at java.io.FileInputStream.readBytes(Native Method)
        at java.io.FileInputStream.read(FileInputStream.java:255)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:284)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
        at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
        at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
        at org.apache.maven.surefire.api.util.internal.Channels$3.readImpl(Channels.java:214)
        at org.apache.maven.surefire.api.util.internal.AbstractNoninterruptibleReadableChannel.read(AbstractNoninterruptibleReadableChannel.java:54)
        at org.apache.maven.surefire.booter.spi.LegacyMasterProcessChannelDecoder.decode(LegacyMasterProcessChannelDecoder.java:80)
        at org.apache.maven.surefire.booter.CommandReader$CommandRunnable.run(CommandReader.java:343)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@4a41524a" daemon prio=5 tid=5435 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3025 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=6072 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 46401" daemon prio=5 tid=4064 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor43" daemon prio=5 tid=4517 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=3449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker"  prio=5 tid=5831 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5459 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp950981263-4205" daemon prio=5 tid=4205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"56e9ebea-1da6-4510-b9da-2a36b64eada2-impl-thread1"  prio=5 tid=5386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4276 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-EEEF55C80313-FollowerState" daemon prio=5 tid=4907 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"qtp925872880-4259" daemon prio=5 tid=4259 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 35747" daemon prio=5 tid=4164 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5533 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"bc03f53a-8f38-42c1-b7a4-94894081fc1e-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5548 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp268746859-5320" daemon prio=5 tid=5320 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 34621" daemon prio=5 tid=5955 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2063334643-5390-acceptor-0@3b1683db-ServerConnector@bb07957{HTTP/1.1, (http/1.1)}{0.0.0.0:43929}" daemon prio=3 tid=5390 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForPipelineReportHandler" daemon prio=5 tid=4724 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3760 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=3613 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4732 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-5"  prio=5 tid=5263 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 35427" daemon prio=5 tid=4049 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=6075 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4327" daemon prio=5 tid=4327 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 36679" daemon prio=5 tid=4089 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ReplicationMonitor" daemon prio=5 tid=5897 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:662)
        at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager$$Lambda$415/661867450.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 36679" daemon prio=5 tid=4090 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp702233778-3486" daemon prio=5 tid=3486 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 46401" daemon prio=5 tid=4063 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp937486555-3600" daemon prio=5 tid=3600 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3390b8ab-1"  prio=5 tid=5445 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-1"  prio=5 tid=5048 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=3635 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4216 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5559" daemon prio=5 tid=5559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5499" daemon prio=5 tid=5499 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-EEEF55C80313-LeaderStateImpl" daemon prio=5 tid=4908 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"JvmPauseMonitor45" daemon prio=5 tid=4610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-3bdba2d7-1"  prio=5 tid=5502 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 35747" daemon prio=5 tid=4161 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-1"  prio=5 tid=5224 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 35747" daemon prio=5 tid=4158 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=4974 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 42125" daemon prio=5 tid=5186 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 5 on default port 35747" daemon prio=5 tid=4156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=5490 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-59462052D018-SegmentedRaftLogWorker"  prio=5 tid=4761 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1395010122-4110" daemon prio=5 tid=4110 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 42125" daemon prio=5 tid=5197 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4129 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-StateMachineUpdater" daemon prio=5 tid=5870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule" daemon prio=5 tid=5780 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 32791"  prio=5 tid=5902 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"ChunkReader-ELG-0" daemon prio=5 tid=5762 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4228" daemon prio=5 tid=4228 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"om1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3346 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-StateMachineUpdater" daemon prio=5 tid=5830 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5421 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3984 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 42211" daemon prio=5 tid=5175 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#0" daemon prio=5 tid=4736 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3673 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=1967 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-7"  prio=5 tid=5268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@51806019" daemon prio=5 tid=4631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4463 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-8-0" daemon prio=5 tid=4023 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5796 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 10 on default port 42125" daemon prio=5 tid=5196 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c3f2673" daemon prio=5 tid=4102 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4267 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=3342 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:538)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:268)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$537/1370311703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=4210 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"BackgroundPipelineScrubberThread" daemon prio=5 tid=5895 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 33121" daemon prio=5 tid=5165 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-2571-thread-1" daemon prio=5 tid=5431 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5765 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp937486555-3595-acceptor-0@5fab117-ServerConnector@54dd6307{HTTP/1.1, (http/1.1)}{0.0.0.0:40613}" daemon prio=3 tid=3595 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b-server-thread1" daemon prio=5 tid=4915 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-4"  prio=5 tid=5257 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-B4D0CDD0329B-StateMachineUpdater" daemon prio=5 tid=4779 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@74d0ff71" daemon prio=5 tid=4253 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3606 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:32791 - 0 "  prio=5 tid=3733 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"prometheus" daemon prio=5 tid=5924 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.hadoop.metrics2.impl.SinkQueue.waitForData(SinkQueue.java:114)
        at org.apache.hadoop.metrics2.impl.SinkQueue.consumeAll(SinkQueue.java:83)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter.publishMetricsFromQueue(MetricsSinkAdapter.java:135)
        at org.apache.hadoop.metrics2.impl.MetricsSinkAdapter$1.run(MetricsSinkAdapter.java:89)
"IPC Server handler 5 on default port 42211" daemon prio=5 tid=5171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 0"  prio=5 tid=4004 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp899869274-5988" daemon prio=5 tid=5988 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 40427" daemon prio=5 tid=5943 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-EEEF55C80313->06e981fa-2395-4d42-a053-e3b5197e7f77-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=4911 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4718 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-StateMachineUpdater" daemon prio=5 tid=5842 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=4955 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer3" daemon prio=5 tid=561 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3647 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3556 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 33881" daemon prio=5 tid=5326 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp990000395-3439" daemon prio=5 tid=3439 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5509 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5778 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 42125" daemon prio=5 tid=5192 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3608 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5349 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-B4D0CDD0329B-SegmentedRaftLogWorker"  prio=5 tid=4777 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1862-thread-1"  prio=5 tid=4103 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4521 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4335" daemon prio=5 tid=4335 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4146" daemon prio=5 tid=4146 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 46401" daemon prio=5 tid=4070 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Under Replicated Processor" daemon prio=5 tid=4000 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.container.replication.UnhealthyReplicationProcessor.run(UnhealthyReplicationProcessor.java:135)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3638 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f-client-thread1" daemon prio=5 tid=5145 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server Responder" daemon prio=5 tid=5121 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at org.apache.hadoop.ipc.Server$Responder.doRunLoop(Server.java:1532)
        at org.apache.hadoop.ipc.Server$Responder.run(Server.java:1515)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 33881" daemon prio=5 tid=5328 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 12 on default port 46401" daemon prio=5 tid=4073 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@53d6a620" daemon prio=5 tid=5550 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 13 on default port 42125" daemon prio=5 tid=5199 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"25c9036e-1b5b-4734-abbe-c826b10abe90-server-thread3" daemon prio=5 tid=4859 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5469-acceptor-0@6a6eddfd-ServerConnector@1412dbbe{HTTP/1.1, (http/1.1)}{0.0.0.0:38399}" daemon prio=3 tid=5469 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"SCM Heartbeat Processing Thread - 0" daemon prio=5 tid=5893 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5776 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4731 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor42" daemon prio=5 tid=4458 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Client (1986131162) connection to 0.0.0.0/0.0.0.0:42125 from runner" daemon prio=5 tid=5563 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"IPC Server handler 10 on default port 33121" daemon prio=5 tid=5156 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5562 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5450 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 35427" daemon prio=5 tid=4048 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp2147043764-3542" daemon prio=5 tid=3542 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 34621" daemon prio=5 tid=5959 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-FB7BC2B45922-LeaderStateImpl" daemon prio=5 tid=3853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1836965867-4285-acceptor-0@23243089-ServerConnector@5d710ef3{HTTP/1.1, (http/1.1)}{0.0.0.0:45869}" daemon prio=3 tid=4285 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=4511 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer2" daemon prio=5 tid=560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker"  prio=5 tid=5612 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5544 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1972-thread-1"  prio=5 tid=4783 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5573 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5480 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 35747" daemon prio=5 tid=4168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1981-thread-1"  prio=5 tid=4283 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5522-acceptor-0@45ae402c-ServerConnector@7888ed54{HTTP/1.1, (http/1.1)}{0.0.0.0:45949}" daemon prio=3 tid=5522 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3451 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5538 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2063334643-5392" daemon prio=5 tid=5392 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 42211" daemon prio=5 tid=5184 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-LeaderStateImpl" daemon prio=5 tid=3882 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState" daemon prio=5 tid=6096 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@3674a55" daemon prio=5 tid=3528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=4274 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5572 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1912-thread-1"  prio=5 tid=4200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3529 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=5374 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-0"  prio=5 tid=5221 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4328-acceptor-0@2c93e0e9-ServerConnector@28bbcbc3{HTTP/1.1, (http/1.1)}{0.0.0.0:38197}" daemon prio=3 tid=4328 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-GrpcLogAppender-LogAppenderDaemon" daemon prio=5 tid=5853 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.grpc.server.GrpcLogAppender.mayWait(GrpcLogAppender.java:198)
        at org.apache.ratis.grpc.server.GrpcLogAppender.run(GrpcLogAppender.java:148)
        at org.apache.ratis.server.leader.LogAppenderDaemon.run(LogAppenderDaemon.java:78)
        at org.apache.ratis.server.leader.LogAppenderDaemon$$Lambda$1106/1145105885.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3930 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"OM StateMachine ApplyTransaction Thread - 0" daemon prio=5 tid=6056 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5786 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@40d926b9" daemon prio=5 tid=5207 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-9-0" daemon prio=5 tid=4024 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3152 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=4101 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=6071 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 35427" daemon prio=5 tid=4013 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"BlockDeletingService#0" daemon prio=5 tid=4614 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1935-thread-1"  prio=5 tid=4227 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4743 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=5302 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"grpc-default-worker-ELG-3-2" daemon prio=5 tid=473 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait0(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:182)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWait(EpollEventLoop.java:290)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:354)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5521" daemon prio=5 tid=5521 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 36679" daemon prio=5 tid=4097 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1903-thread-1"  prio=5 tid=4759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4270 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=4017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=4522 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35427" daemon prio=5 tid=4045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule" daemon prio=5 tid=5999 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=5670 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-5756e07-1"  prio=5 tid=5529 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread1" daemon prio=5 tid=5855 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4973 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1964746733-5468" daemon prio=5 tid=5468 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4288" daemon prio=5 tid=4288 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 32791" daemon prio=5 tid=5977 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"JvmPauseMonitor44" daemon prio=5 tid=4574 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4958 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1337264528-4423" daemon prio=5 tid=4423 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3436" daemon prio=5 tid=3436 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5668 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 34621" daemon prio=5 tid=5949 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-2-0" daemon prio=5 tid=5789 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 35427" daemon prio=5 tid=4041 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp950981263-4208" daemon prio=5 tid=4208 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3743 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 33121" daemon prio=5 tid=5155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c82fe81" daemon prio=5 tid=4244 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5206 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 46401" daemon prio=5 tid=4067 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=3982 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor34" daemon prio=5 tid=3637 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer7" daemon prio=5 tid=705 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-2505-thread-1"  prio=5 tid=5299 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4618 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=4138 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 8 on default port 42211" daemon prio=5 tid=5174 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp856589424-4149" daemon prio=5 tid=4149 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-0"  prio=5 tid=5223 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp723834011-5438-acceptor-0@323771e3-ServerConnector@71ee89e5{HTTP/1.1, (http/1.1)}{0.0.0.0:38147}" daemon prio=3 tid=5438 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-8"  prio=5 tid=5272 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4742 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3639 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5348 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4942 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1-client-thread1" daemon prio=5 tid=6055 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 46401" daemon prio=5 tid=4079 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=5661 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77@group-EEEF55C80313-SegmentedRaftLogWorker"  prio=5 tid=4768 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5764 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-3"  prio=5 tid=5233 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-46ccfda9-1"  prio=5 tid=3631 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule" daemon prio=5 tid=6001 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-SegmentedRaftLogWorker"  prio=5 tid=3807 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer0" daemon prio=5 tid=707 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Server handler 16 on default port 35747" daemon prio=5 tid=4167 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a89e0418-9005-4742-9592-8c0c855df8ce-server-thread2" daemon prio=5 tid=4857 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 40427" daemon prio=5 tid=5942 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread2" daemon prio=5 tid=5858 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-StateMachineUpdater" daemon prio=5 tid=5608 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor33" daemon prio=5 tid=3387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1da69f9" daemon prio=5 tid=4488 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=3611 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 46401" daemon prio=5 tid=4009 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp688901239-3625" daemon prio=5 tid=3625 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5487 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4211 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 34645" daemon prio=5 tid=3419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=3695 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-0"  prio=5 tid=5222 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3691 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=5086 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=4012 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"qtp2063334643-5389" daemon prio=5 tid=5389 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-D9296D6C4CE8-LeaderStateImpl" daemon prio=5 tid=4851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1337264528-4425" daemon prio=5 tid=4425 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4232" daemon prio=5 tid=4232 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4243 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 35747" daemon prio=5 tid=4154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 46401" daemon prio=5 tid=4071 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 10 on default port 33881" daemon prio=5 tid=5334 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=4940 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=5625 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2073-thread-1"  prio=5 tid=4419 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-D9296D6C4CE8-StateMachineUpdater" daemon prio=5 tid=4798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=5477 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3928 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 34621" daemon prio=5 tid=5961 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-EEEF55C80313-FollowerState" daemon prio=5 tid=4916 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"IPC Server handler 13 on default port 42211" daemon prio=5 tid=5179 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-6"  prio=5 tid=5265 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2687-thread-1"  prio=5 tid=5551 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-7aaa8694-1"  prio=5 tid=4114 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 46401" daemon prio=5 tid=4061 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-4-0" daemon prio=5 tid=4019 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderStateImpl" daemon prio=5 tid=6011 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=5779 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-4"  prio=5 tid=5258 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 40427" daemon prio=5 tid=5937 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5375 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"SCMBlockDeletingService#0" daemon prio=5 tid=5985 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-StateMachineUpdater" daemon prio=5 tid=5605 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1876163108-5213" daemon prio=5 tid=5213 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-6-0" daemon prio=5 tid=5136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor48" daemon prio=5 tid=4748 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 42125" daemon prio=5 tid=5200 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1750886181-4233" daemon prio=5 tid=4233 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3448 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2128-thread-1" daemon prio=5 tid=4525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"KeyDeletingService#0" daemon prio=5 tid=3389 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@388586f3" daemon prio=5 tid=3652 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4384 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1337264528-4424" daemon prio=5 tid=4424 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 33881" daemon prio=5 tid=5331 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4294 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4572 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=5623 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-3-0" daemon prio=5 tid=4018 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"process reaper" daemon prio=10 tid=12 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5622 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 42125" daemon prio=5 tid=5203 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=5373 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@f7f2b52" daemon prio=5 tid=4194 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-2-0" daemon prio=5 tid=5915 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5530 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@553ec1da" daemon prio=5 tid=4171 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5484 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77-server-thread3" daemon prio=5 tid=4918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5788 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3159 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 33121" daemon prio=5 tid=5153 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp268746859-5319" daemon prio=5 tid=5319 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 35747" daemon prio=5 tid=4131 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"qtp585757798-5363" daemon prio=5 tid=5363 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3624 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 34621" daemon prio=5 tid=5954 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7c948c4b-a779-4597-819f-06099ef104a1@group-9EC58D582F46-StateMachineUpdater" daemon prio=5 tid=3838 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3630" daemon prio=5 tid=3630 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=4710 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2671-thread-1" daemon prio=5 tid=5546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4954 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3493 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4386 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-SegmentedRaftLogWorker"  prio=5 tid=3796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5564 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-80A041299B2B-StateMachineUpdater" daemon prio=5 tid=3803 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"DirectoryDeletingService#0" daemon prio=5 tid=4139 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1507316155-5528" daemon prio=5 tid=5528 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4220 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2609-thread-1"  prio=5 tid=5864 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-47637046-1"  prio=5 tid=4236 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-8EF27F6AF45A-StateMachineUpdater" daemon prio=5 tid=4814 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp950981263-4204" daemon prio=5 tid=4204 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 17 on default port 36679" daemon prio=5 tid=4098 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkWriter-1-0" daemon prio=5 tid=4455 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4229-acceptor-0@32f6b913-ServerConnector@1d08eaf7{HTTP/1.1, (http/1.1)}{0.0.0.0:43939}" daemon prio=3 tid=4229 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 34621" daemon prio=5 tid=5945 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ChunkReader-ELG-0" daemon prio=5 tid=4575 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp1081963187-4333" daemon prio=5 tid=4333 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Socket Reader #1 for port 0"  prio=5 tid=3381 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread1" daemon prio=5 tid=6042 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3478 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"qtp664417615-5495-acceptor-0@7cc48620-ServerConnector@1d5eed52{HTTP/1.1, (http/1.1)}{0.0.0.0:42089}" daemon prio=3 tid=5495 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 40427" daemon prio=5 tid=5939 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Socket Reader #1 for port 40427"  prio=5 tid=5910 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:1296)
        at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:1275)
"ChunkReader-ELG-0" daemon prio=5 tid=5750 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-4e991b83-1"  prio=5 tid=5560 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 35427" daemon prio=5 tid=4052 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@571c3b32" daemon prio=5 tid=5344 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 18 on default port 32791" daemon prio=5 tid=5983 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState" daemon prio=5 tid=6098 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-StateMachineUpdater" daemon prio=5 tid=5833 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@28f88471" daemon prio=5 tid=5537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-6"  prio=5 tid=5267 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 42125" daemon prio=5 tid=5191 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp937486555-3601" daemon prio=5 tid=3601 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-3-0" daemon prio=5 tid=5663 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-0-0" daemon prio=5 tid=5130 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 32791" daemon prio=5 tid=5966 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp397445177-4547" daemon prio=5 tid=4547 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"DataNode DiskChecker thread 0" daemon prio=5 tid=5382 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"51ba1163-8388-41ac-b784-1dd4f62d306b@group-EEEF55C80313-SegmentedRaftLogWorker"  prio=5 tid=4773 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 34621" daemon prio=5 tid=5957 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 33881" daemon prio=5 tid=5332 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-B93932A5F6FE-StateMachineUpdater" daemon prio=5 tid=4786 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3539" daemon prio=5 tid=3539 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 0"  prio=5 tid=5379 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-1993-thread-1" daemon prio=5 tid=4315 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread2" daemon prio=5 tid=5860 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=3698 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=5617 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Session-HouseKeeper-bcc751e-1"  prio=5 tid=4553 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater" daemon prio=5 tid=3798 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 36679" daemon prio=5 tid=4085 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"a89e0418-9005-4742-9592-8c0c855df8ce@group-D9296D6C4CE8-SegmentedRaftLogWorker"  prio=5 tid=4787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"timer5" daemon prio=5 tid=701 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"JvmPauseMonitor51" daemon prio=5 tid=5309 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3604 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp950981263-4202-acceptor-0@59a92daa-ServerConnector@7640ea34{HTTP/1.1, (http/1.1)}{0.0.0.0:40897}" daemon prio=3 tid=4202 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4497 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=4582 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp856589424-4143-acceptor-0@5cc0be50-ServerConnector@76059b86{HTTP/1.1, (http/1.1)}{0.0.0.0:40777}" daemon prio=3 tid=4143 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"qtp688901239-3626" daemon prio=5 tid=3626 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97-impl-thread1"  prio=5 tid=5464 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerReplicationThread-1" daemon prio=5 tid=6054 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 5 on default port 34645" daemon prio=5 tid=3407 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3646 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=3549 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderStateImpl" daemon prio=5 tid=6017 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ChunkWriter-2-0" daemon prio=5 tid=3688 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 42211" daemon prio=5 tid=5120 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@53fbc5e9" daemon prio=5 tid=3610 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:42125 - 0 "  prio=5 tid=5611 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-9EC58D582F46-SegmentedRaftLogWorker"  prio=5 tid=3836 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3445 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-8"  prio=5 tid=5273 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=4625 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1892971966-3398" daemon prio=5 tid=3398 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"qtp1836965867-4289" daemon prio=5 tid=4289 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=4268 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@554db480" daemon prio=5 tid=3537 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server idle connection scanner for port 36679" daemon prio=5 tid=4005 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"StaleRecoveringContainerScrubbingService#1" daemon prio=5 tid=4581 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3753 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4956 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 7 on default port 36679" daemon prio=5 tid=4088 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-6799c9b1-1"  prio=5 tid=3518 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"302a8c77-15cc-4d7d-baad-75f44faccb3e@group-D9296D6C4CE8-SegmentedRaftLogWorker"  prio=5 tid=4796 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp702233778-3485" daemon prio=5 tid=3485 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"1f39c4a2-123f-4ca0-aca4-b650c3c85ddf@group-5D5576319555-StateMachineUpdater" daemon prio=5 tid=3794 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4298 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=5381 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@54180e51" daemon prio=5 tid=3498 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-LeaderStateImpl" daemon prio=5 tid=3870 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1892971966-3395" daemon prio=5 tid=3395 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=4299 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"grpc-default-executor-9" daemon prio=5 tid=3136 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp1613786745-5558" daemon prio=5 tid=5558 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 0 on default port 40427" daemon prio=5 tid=5925 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderStateImpl" daemon prio=5 tid=5851 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"qtp1507316155-5525" daemon prio=5 tid=5525 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"timer6" daemon prio=5 tid=704 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"pool-1611-thread-1" daemon prio=5 tid=3504 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=5449 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"EndpointStateMachine task thread for /0.0.0.0:36679 - 0 "  prio=5 tid=4562 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server listener on 0" daemon prio=5 tid=4007 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"IPC Server handler 9 on default port 42125" daemon prio=5 tid=5195 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@15dfd9d4" daemon prio=5 tid=5354 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-5D5576319555-FollowerState" daemon prio=5 tid=3865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4214 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=5793 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 42125" daemon prio=5 tid=5205 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 16 on default port 40427" daemon prio=5 tid=5941 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"BlockDeletingService#2" daemon prio=5 tid=6069 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp2147043764-3546" daemon prio=5 tid=3546 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"pool-1949-thread-1"  prio=5 tid=4772 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-5D5576319555-StateMachineUpdater" daemon prio=5 tid=3785 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 33121" daemon prio=5 tid=5160 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"EventQueue-NewNodeForNewNodeHandler" daemon prio=5 tid=4721 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 19 on default port 35747" daemon prio=5 tid=4170 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FixedThreadPoolWithAffinityExecutor-5-0" daemon prio=5 tid=5918 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=3696 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Daemon Thread" daemon prio=5 tid=3645 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:324)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$807/2030930921.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 34645" daemon prio=5 tid=3411 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-D9296D6C4CE8-SegmentedRaftLogWorker"  prio=5 tid=4791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"PartialTableCache Cleanup Thread - 0" daemon prio=5 tid=3773 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4599 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 35747" daemon prio=5 tid=4152 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Session-HouseKeeper-1685a0f7-1"  prio=5 tid=3602 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp937486555-3594" daemon prio=5 tid=3594 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5454 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4271 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 42211" daemon prio=5 tid=5168 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-StateMachineUpdater" daemon prio=5 tid=5874 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp1876163108-5214" daemon prio=5 tid=5214 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderStateImpl" daemon prio=5 tid=6031 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-6"  prio=5 tid=5266 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"06e981fa-2395-4d42-a053-e3b5197e7f77-server-thread1" daemon prio=5 tid=4913 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 14 on default port 34645" daemon prio=5 tid=3416 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3553 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-935EE45E604E-StateMachineUpdater" daemon prio=5 tid=4802 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-SegmentedRaftLogWorker"  prio=5 tid=3787 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"pool-1680-thread-1" daemon prio=5 tid=3588 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=4749 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5660 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ExpiredContainerReplicaOpScrubberThread" daemon prio=5 tid=5896 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService.run(BackgroundSCMService.java:110)
        at org.apache.hadoop.hdds.scm.ha.BackgroundSCMService$$Lambda$408/1600120622.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@6563902c" daemon prio=5 tid=4539 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 36679" daemon prio=5 tid=4092 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=4215 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-2"  prio=5 tid=5228 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"c36dba4c-5c72-465b-8876-3f5e456990a2@group-FB7BC2B45922-StateMachineUpdater" daemon prio=5 tid=3782 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 34621" daemon prio=5 tid=5960 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@63735ab2" daemon prio=5 tid=4389 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"pool-2004-thread-1"  prio=5 tid=4790 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=4750 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 32791" daemon prio=5 tid=5967 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server listener on 0" daemon prio=5 tid=4003 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.hadoop.ipc.Server$Listener.run(Server.java:1358)
"Periodic HDDS volume checker" daemon prio=5 tid=5513 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=5649 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-LeaderStateImpl" daemon prio=5 tid=5447 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:418)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventQueue.poll(LeaderStateImpl.java:159)
        at org.apache.ratis.server.impl.LeaderStateImpl$EventProcessor.run(LeaderStateImpl.java:630)
"Timer for 'StorageContainerManager' metrics system" daemon prio=5 tid=5923 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"DirectoryDeletingService#0" daemon prio=5 tid=3390 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=4297 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 2 on default port 33121" daemon prio=5 tid=5148 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ec-reconstruct-reader-TID-0"  prio=5 tid=5041 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker"  prio=5 tid=5865 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 15 on default port 34645" daemon prio=5 tid=3417 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=5570 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1-NettyServerStreamRpc-bossGroup--thread1"  prio=5 tid=3590 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:813)
        at org.apache.ratis.thirdparty.io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:460)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5053 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Periodic HDDS volume checker" daemon prio=5 tid=4313 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"qtp585757798-5358" daemon prio=5 tid=5358 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"64899d46-4b28-46dc-a6e3-98f7c12bf9be@group-EEEF55C80313-StateMachineUpdater" daemon prio=5 tid=4766 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3692 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5787 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3ce87859" daemon prio=5 tid=3508 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-1-0" daemon prio=5 tid=3687 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"timer1" daemon prio=5 tid=559 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)
"IPC Client (1986131162) connection to /0.0.0.0:32791 from runner" daemon prio=5 tid=5892 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ipc.Client$Connection.waitForWork(Client.java:1086)
        at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1133)
"19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-StateMachineUpdater" daemon prio=5 tid=5886 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ec-reconstruct-reader-TID-2"  prio=5 tid=5051 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:458)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.take(SynchronousQueue.java:924)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater" daemon prio=5 tid=3789 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-0-0" daemon prio=5 tid=5757 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#0" daemon prio=5 tid=3680 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkWriter-2-0" daemon prio=5 tid=4746 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingDeque.takeFirst(LinkedBlockingDeque.java:492)
        at java.util.concurrent.LinkedBlockingDeque.take(LinkedBlockingDeque.java:680)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b974528" daemon prio=5 tid=5571 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.util.JvmPauseMonitor$Monitor.run(JvmPauseMonitor.java:192)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=4135 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 2" daemon prio=5 tid=3446 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Parameter Sending Thread #1" daemon prio=5 tid=1330 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 16 on default port 46401" daemon prio=5 tid=4077 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"ContainerOp-9ab3fecf-8e2d-490d-9db2-5d5576319555-9"  prio=5 tid=5278 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"ChunkReader-ELG-0" daemon prio=5 tid=3757 runnable
java.lang.Thread.State: RUNNABLE
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native Method)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:209)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.Native.epollWait(Native.java:202)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.epollWaitNoTimerChange(EpollEventLoop.java:294)
        at org.apache.ratis.thirdparty.io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:351)
        at org.apache.ratis.thirdparty.io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:995)
        at org.apache.ratis.thirdparty.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
        at java.lang.Thread.run(Thread.java:750)
"af27b707-902e-436a-b36c-df002345c922-server-thread3" daemon prio=5 tid=6045 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=5076 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 6 on default port 36679" daemon prio=5 tid=4087 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 17 on default port 46401" daemon prio=5 tid=4078 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"FullTableCache Cleanup Thread - 0" daemon prio=5 tid=697 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 11 on default port 34621" daemon prio=5 tid=5956 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Command processor thread" daemon prio=5 tid=3527 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 9 on default port 32791" daemon prio=5 tid=5974 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 8 on default port 33121" daemon prio=5 tid=5154 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 42211" daemon prio=5 tid=5180 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"pool-1565-thread-1" daemon prio=5 tid=3428 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 3 on default port 42211" daemon prio=5 tid=5169 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"qtp1876163108-5215" daemon prio=5 tid=5215 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90@group-D9296D6C4CE8-FollowerState" daemon prio=5 tid=4849 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.server.impl.FollowerState.run(FollowerState.java:128)
"StaleRecoveringContainerScrubbingService#2" daemon prio=5 tid=4980 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#1" daemon prio=5 tid=3642 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"om1@group-C5BA1605619E-StateMachineUpdater" daemon prio=5 tid=3386 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2163)
        at org.apache.ratis.util.AwaitForSignal.await(AwaitForSignal.java:62)
        at org.apache.ratis.server.impl.StateMachineUpdater.waitForCommit(StateMachineUpdater.java:207)
        at org.apache.ratis.server.impl.StateMachineUpdater.run(StateMachineUpdater.java:176)
        at java.lang.Thread.run(Thread.java:750)
"qtp990000395-3434" daemon prio=5 tid=3434 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101)
        at org.eclipse.jetty.io.ManagedSelector.nioSelect(ManagedSelector.java:183)
        at org.eclipse.jetty.io.ManagedSelector.select(ManagedSelector.java:190)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.select(ManagedSelector.java:606)
        at org.eclipse.jetty.io.ManagedSelector$SelectorProducer.produce(ManagedSelector.java:543)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produceTask(EatWhatYouKill.java:362)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:186)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)
        at org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.produce(EatWhatYouKill.java:137)
        at org.eclipse.jetty.io.ManagedSelector$$Lambda$478/873213136.run(Unknown Source)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 3" daemon prio=5 tid=5453 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 12 on default port 35427" daemon prio=5 tid=4053 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=5569 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker@3f5eb1d3" daemon prio=5 tid=5387 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.commandhandler.DeleteBlocksCommandHandler$DeleteCmdWorker.run(DeleteBlocksCommandHandler.java:184)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 4 on default port 35747" daemon prio=5 tid=4155 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"IPC Server handler 14 on default port 46401" daemon prio=5 tid=4075 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"StaleRecoveringContainerScrubbingService#0" daemon prio=5 tid=3759 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor58" daemon prio=5 tid=5791 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp108688461-3511-acceptor-0@6fc486ba-ServerConnector@d747d92{HTTP/1.1, (http/1.1)}{0.0.0.0:33691}" daemon prio=3 tid=3511 runnable
java.lang.Thread.State: RUNNABLE
        at sun.nio.ch.ServerSocketChannelImpl.accept0(Native Method)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:421)
        at sun.nio.ch.ServerSocketChannelImpl.accept(ServerSocketChannelImpl.java:249)
        at org.eclipse.jetty.server.ServerConnector.accept(ServerConnector.java:388)
        at org.eclipse.jetty.server.AbstractConnector$Acceptor.run(AbstractConnector.java:704)
        at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)
        at java.lang.Thread.run(Thread.java:750)
"7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker"  prio=5 tid=5603 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.apache.ratis.util.DataBlockingQueue.poll(DataBlockingQueue.java:148)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker.run(SegmentedRaftLogWorker.java:312)
        at org.apache.ratis.server.raftlog.segmented.SegmentedRaftLogWorker$$Lambda$718/856878070.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"OMDoubleBufferFlushThread" daemon prio=5 tid=5296 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Object.wait(Native Method)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.canFlush(OzoneManagerDoubleBuffer.java:538)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer.flushTransactions(OzoneManagerDoubleBuffer.java:268)
        at org.apache.hadoop.ozone.om.ratis.OzoneManagerDoubleBuffer$$Lambda$537/1370311703.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"FixedThreadPoolWithAffinityExecutor-7-0" daemon prio=5 tid=5920 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:266)
        at org.apache.hadoop.hdds.scm.server.ContainerReportQueue.poll(ContainerReportQueue.java:42)
        at org.apache.hadoop.hdds.server.events.FixedThreadPoolWithAffinityExecutor$ContainerReportProcessTask.run(FixedThreadPoolWithAffinityExecutor.java:247)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
        at java.util.concurrent.FutureTask.run(FutureTask.java:266)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Command processor thread" daemon prio=5 tid=5455 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$initCommandHandlerThread$3(DatanodeStateMachine.java:644)
        at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine$$Lambda$809/168931503.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"qtp1750886181-4231" daemon prio=5 tid=4231 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at org.eclipse.jetty.util.BlockingArrayQueue.poll(BlockingArrayQueue.java:382)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.idleJobPoll(QueuedThreadPool.java:974)
        at org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1018)
        at java.lang.Thread.run(Thread.java:750)
"25c9036e-1b5b-4734-abbe-c826b10abe90-server-thread1" daemon prio=5 tid=4854 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.SynchronousQueue$TransferStack.awaitFulfill(SynchronousQueue.java:460)
        at java.util.concurrent.SynchronousQueue$TransferStack.transfer(SynchronousQueue.java:362)
        at java.util.concurrent.SynchronousQueue.poll(SynchronousQueue.java:941)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode State Machine Task Thread - 1"  prio=5 tid=4448 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"BlockDeletingService#2" daemon prio=5 tid=4979 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"JvmPauseMonitor35" daemon prio=5 tid=3678 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at java.lang.Thread.sleep(Native Method)
        at java.lang.Thread.sleep(Thread.java:342)
        at java.util.concurrent.TimeUnit.sleep(TimeUnit.java:386)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:325)
        at org.apache.ratis.util.TimeDuration.sleep(TimeDuration.java:310)
        at org.apache.ratis.util.JvmPauseMonitor.detectPause(JvmPauseMonitor.java:119)
        at org.apache.ratis.util.JvmPauseMonitor.run(JvmPauseMonitor.java:108)
        at org.apache.ratis.util.JvmPauseMonitor$$Lambda$759/703659254.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:750)
"IPC Server handler 1 on default port 33121" daemon prio=5 tid=5147 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at org.apache.hadoop.ipc.CallQueueManager.take(CallQueueManager.java:317)
        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)
"Datanode ReportManager Thread - 0" daemon prio=5 tid=4383 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 4" daemon prio=5 tid=3650 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"pool-2552-thread-1"  prio=5 tid=5388 timed_waiting
java.lang.Thread.State: TIMED_WAITING
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)
"Datanode ReportManager Thread - 1" daemon prio=5 tid=3523 in Object.wait()
java.lang.Thread.State: WAITING (on object monitor)
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1088)
        at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)


	at org.apache.ozone.test.GenericTestUtils.waitFor(GenericTestUtils.java:231)
	at org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance.testSCMHandlesRestartForMaintenanceNode(TestDecommissionAndMaintenance.java:585)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:725)
	at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140)
	at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:84)
	at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104)
	at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:214)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:210)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:135)
	at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:66)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.util.ArrayList.forEach(ArrayList.java:1259)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.execute(JUnitPlatformProvider.java:188)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invokeAllTests(JUnitPlatformProvider.java:154)
	at org.apache.maven.surefire.junitplatform.JUnitPlatformProvider.invoke(JUnitPlatformProvider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:428)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:162)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:562)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:548)
]]></error>
    <system-out><![CDATA[2023-01-03 14:06:17,907 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 46005
2023-01-03 14:06:17,911 [Listener at 127.0.0.1/35747] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:17,928 [Listener at 127.0.0.1/35747] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:17,928 [Listener at 127.0.0.1/35747] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-01-03 14:06:17,928 [Listener at 127.0.0.1/35747] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-01-03 14:06:17,929 [Listener at 127.0.0.1/35747] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:17,929 [Listener at 127.0.0.1/35747] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(144)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:17,937 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:17,938 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:17,941 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-01-03 14:06:17,943 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:17,943 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:17,944 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0a0177c4, L:/0:0:0:0:0:0:0:0:45707] CLOSE
2023-01-03 14:06:17,944 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0a0177c4, L:/0:0:0:0:0:0:0:0:45707] INACTIVE
2023-01-03 14:06:17,944 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x0a0177c4, L:/0:0:0:0:0:0:0:0:45707] UNREGISTERED
2023-01-03 14:06:17,946 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-01-03 14:06:17,946 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-01-03 14:06:17,946 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-01-03 14:06:17,946 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:17,954 [main] INFO  rpc.RpcClient (RpcClient.java:createVolume(474)) - Creating Volume: vol1, with user83057 as owner and space quota set to -1 bytes, counts quota set to -1
2023-01-03 14:06:17,963 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 166
2023-01-03 14:06:17,963 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:166)
2023-01-03 14:06:17,963 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 166
2023-01-03 14:06:17,963 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 166
2023-01-03 14:06:17,963 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-01-03 14:06:17,963 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(466)) - Stopping OMDoubleBuffer flush thread
2023-01-03 14:06:17,964 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(385)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-01-03 14:06:17,965 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 166
2023-01-03 14:06:17,965 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:17,966 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-01-03 14:06:17,968 [JvmPauseMonitor25] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-01-03 14:06:17,968 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-01-03 14:06:17,969 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(478)) - OMDoubleBuffer flush thread is not running.
2023-01-03 14:06:17,969 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-01-03 14:06:17,969 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-01-03 14:06:17,969 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-01-03 14:06:17,975 [OM StateMachine ApplyTransaction Thread - 0] INFO  volume.OMVolumeCreateRequest (OMVolumeCreateRequest.java:validateAndUpdateCache(195)) - created volume:vol1 for user:user83057
2023-01-03 14:06:17,979 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4d7fabe7{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-01-03 14:06:17,979 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@201ea755{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:17,979 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:17,981 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7b28667{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-01-03 14:06:17,983 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1578bce8{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:17,993 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(523)) - Stopping the HddsDatanodes
2023-01-03 14:06:17,997 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:18,002 [main] INFO  rpc.RpcClient (RpcClient.java:createBucket(693)) - Creating Bucket: vol1/bucket1, with bucket layout LEGACY, runner as owner, Versioning false, Storage Type set to DISK and Encryption set to false 
2023-01-03 14:06:18,003 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003: close
2023-01-03 14:06:18,004 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE: shutdown
2023-01-03 14:06:18,004 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-9F35241392CE,id=5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:18,004 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003: shutdown 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-LeaderStateImpl
2023-01-03 14:06:18,004 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:18,005 [OM StateMachine ApplyTransaction Thread - 0] INFO  bucket.OMBucketCreateRequest (OMBucketCreateRequest.java:validateAndUpdateCache(260)) - created bucket: bucket1 of layout LEGACY in volume: vol1
2023-01-03 14:06:18,006 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:18,006 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-9F35241392CE: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-4/data/ratis/c3b14682-4c72-4669-86f1-9f35241392ce/sm/snapshot.1_0
2023-01-03 14:06:18,009 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:18,009 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-9F35241392CE: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-4/data/ratis/c3b14682-4c72-4669-86f1-9f35241392ce/sm/snapshot.1_0 took: 3 ms
2023-01-03 14:06:18,010 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:18,010 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:18,010 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE: closes. applyIndex: 0
2023-01-03 14:06:18,012 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:18,012 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A: shutdown
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-9F35241392CE-SegmentedRaftLogWorker close()
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B9661FB30C0A,id=5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003: shutdown 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-LeaderStateImpl
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:18,013 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:18,014 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-B9661FB30C0A: Taking a snapshot at:(t:3, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-4/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0
2023-01-03 14:06:18,014 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08 Close channels
2023-01-03 14:06:18,015 [grpc-default-executor-10] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:18,015 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-B9661FB30C0A: Finished taking a snapshot at:(t:3, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-4/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0 took: 2 ms
2023-01-03 14:06:18,015 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:18,015 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:18,016 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A: closes. applyIndex: 0
2023-01-03 14:06:18,016 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:06:18,016 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 89282906-b815-4a6d-bda0-404bb113e200: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:06:18,017 [grpc-default-executor-9] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 89282906-b815-4a6d-bda0-404bb113e200: Completed APPEND_ENTRIES, lastRequest: 5573e85b-a1ef-42aa-8f1f-8db9238bd003->89282906-b815-4a6d-bda0-404bb113e200#1-t3,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:3, i:0), CONFIGURATIONENTRY(current:id: "89282906-b815-4a6d-bda0-404bb113e200"
address: "10.1.0.35:46873"
dataStreamAddress: "10.1.0.35:46133"
clientAddress: "10.1.0.35:46873"
adminAddress: "10.1.0.35:46873"
startupRole: FOLLOWER
,id: "4db05c90-fb2b-44c1-a5c3-62f45e9c05ff"
address: "10.1.0.35:34451"
dataStreamAddress: "10.1.0.35:44223"
clientAddress: "10.1.0.35:34451"
adminAddress: "10.1.0.35:34451"
startupRole: FOLLOWER
,id: "5573e85b-a1ef-42aa-8f1f-8db9238bd003"
address: "10.1.0.35:44365"
priority: 1
dataStreamAddress: "10.1.0.35:42425"
clientAddress: "10.1.0.35:44365"
adminAddress: "10.1.0.35:44365"
startupRole: FOLLOWER
, old:)
2023-01-03 14:06:18,017 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: Completed APPEND_ENTRIES, lastRequest: 5573e85b-a1ef-42aa-8f1f-8db9238bd003->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff#1-t3,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:3, i:0), CONFIGURATIONENTRY(current:id: "89282906-b815-4a6d-bda0-404bb113e200"
address: "10.1.0.35:46873"
dataStreamAddress: "10.1.0.35:46133"
clientAddress: "10.1.0.35:46873"
adminAddress: "10.1.0.35:46873"
startupRole: FOLLOWER
,id: "4db05c90-fb2b-44c1-a5c3-62f45e9c05ff"
address: "10.1.0.35:34451"
dataStreamAddress: "10.1.0.35:44223"
clientAddress: "10.1.0.35:34451"
adminAddress: "10.1.0.35:34451"
startupRole: FOLLOWER
,id: "5573e85b-a1ef-42aa-8f1f-8db9238bd003"
address: "10.1.0.35:44365"
priority: 1
dataStreamAddress: "10.1.0.35:42425"
clientAddress: "10.1.0.35:44365"
adminAddress: "10.1.0.35:44365"
startupRole: FOLLOWER
, old:)
2023-01-03 14:06:18,018 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:18,018 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:18,018 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:18,018 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: nextIndex: updateUnconditionally 1 -> 0
2023-01-03 14:06:18,018 [grpc-default-executor-9] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:18,018 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200: nextIndex: updateUnconditionally 1 -> 0
2023-01-03 14:06:18,019 [grpc-default-executor-9] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: nextIndex: updateUnconditionally 0 -> 0
2023-01-03 14:06:18,019 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A->89282906-b815-4a6d-bda0-404bb113e200: nextIndex: updateUnconditionally 0 -> 0
2023-01-03 14:06:18,035 [5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:18,035 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff Close channels
2023-01-03 14:06:18,037 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003@group-B9661FB30C0A-SegmentedRaftLogWorker close()
2023-01-03 14:06:18,038 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 89282906-b815-4a6d-bda0-404bb113e200 Close channels
2023-01-03 14:06:18,039 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:18,042 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc487862b, L:/0:0:0:0:0:0:0:0:42425] CLOSE
2023-01-03 14:06:18,042 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc487862b, L:/0:0:0:0:0:0:0:0:42425] INACTIVE
2023-01-03 14:06:18,042 [5573e85b-a1ef-42aa-8f1f-8db9238bd003-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc487862b, L:/0:0:0:0:0:0:0:0:42425] UNREGISTERED
2023-01-03 14:06:18,065 [JvmPauseMonitor30] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-5573e85b-a1ef-42aa-8f1f-8db9238bd003: Stopped
2023-01-03 14:06:18,066 [IPC Server handler 9 on default port 34621] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for containerId, change lastId from 0 to 1000.
2023-01-03 14:06:18,066 [IPC Server handler 9 on default port 34621] WARN  ha.SequenceIdGenerator (SequenceIdGenerator.java:allocateBatch(237)) - Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
2023-01-03 14:06:18,066 [IPC Server handler 9 on default port 34621] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:getNextId(128)) - Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
2023-01-03 14:06:18,072 [Listener at 127.0.0.1/35747] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-01-03 14:06:18,072 [Listener at 127.0.0.1/35747] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-01-03 14:06:18,099 [Listener at 127.0.0.1/35747] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:18,100 [Listener at 127.0.0.1/35747] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:18,100 [Listener at 127.0.0.1/35747] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:18,102 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:18,102 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: close
2023-01-03 14:06:18,109 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C: shutdown
2023-01-03 14:06:18,109 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23C37724191C,id=b3a67b98-d7e4-49a8-83c5-9d813aec1f6d
2023-01-03 14:06:18,109 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: shutdown b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-FollowerState
2023-01-03 14:06:18,111 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:18,118 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8: shutdown
2023-01-03 14:06:18,122 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-23C37724191C: Taking a snapshot at:(t:1, i:27) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-1/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27
2023-01-03 14:06:18,123 [grpc-default-executor-6] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:18,121 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater: set stopIndex = 27
2023-01-03 14:06:18,121 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-FollowerState was interrupted
2023-01-03 14:06:18,124 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:18,125 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x728b6e92, L:/0:0:0:0:0:0:0:0:43161] CLOSE
2023-01-03 14:06:18,125 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x728b6e92, L:/0:0:0:0:0:0:0:0:43161] INACTIVE
2023-01-03 14:06:18,125 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x728b6e92, L:/0:0:0:0:0:0:0:0:43161] UNREGISTERED
2023-01-03 14:06:18,124 [grpc-default-executor-8] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-01-03 14:06:18,126 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: nextIndex: updateUnconditionally 28 -> 27
2023-01-03 14:06:18,124 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-01-03 14:06:18,126 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: nextIndex: updateUnconditionally 27 -> 26
2023-01-03 14:06:18,123 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: installSnapshot onError, lastRequest: edb1aef9-02a8-4817-80a7-afb47d970b52->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d#371-t1,previous=(t:1, i:26),leaderCommit=25,initializing? true,entries: size=1, first=(t:1, i:27), METADATAENTRY(c:25): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:18,125 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-23C37724191C: Finished taking a snapshot at:(t:1, i:27) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-1/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27 took: 3 ms
2023-01-03 14:06:18,127 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater: Took a snapshot at index 27
2023-01-03 14:06:18,127 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 27
2023-01-03 14:06:18,128 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,125 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-01C13A1042D8,id=b3a67b98-d7e4-49a8-83c5-9d813aec1f6d
2023-01-03 14:06:18,141 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:18,143 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: nextIndex: updateUnconditionally 27 -> 26
2023-01-03 14:06:18,138 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C: closes. applyIndex: 27
2023-01-03 14:06:18,143 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: shutdown b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-LeaderStateImpl
2023-01-03 14:06:18,143 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:18,144 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-23C37724191C-SegmentedRaftLogWorker close()
2023-01-03 14:06:18,143 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:18,145 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:18,145 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-01C13A1042D8: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-1/data/ratis/34852c1e-c153-4809-8357-01c13a1042d8/sm/snapshot.1_0
2023-01-03 14:06:18,145 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,146 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-01C13A1042D8: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-1/data/ratis/34852c1e-c153-4809-8357-01c13a1042d8/sm/snapshot.1_0 took: 1 ms
2023-01-03 14:06:18,146 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:18,146 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:18,146 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,148 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:18,148 [grpc-default-executor-0] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: nextIndex: updateUnconditionally 26 -> 25
2023-01-03 14:06:18,148 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8: closes. applyIndex: 0
2023-01-03 14:06:18,149 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:18,149 [b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d@group-01C13A1042D8-SegmentedRaftLogWorker close()
2023-01-03 14:06:18,164 [JvmPauseMonitor27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-b3a67b98-d7e4-49a8-83c5-9d813aec1f6d: Stopped
2023-01-03 14:06:18,180 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,195 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,198 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,199 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,201 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,201 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,201 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 1 containers.
2023-01-03 14:06:18,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,205 [Listener at 127.0.0.1/35747] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 105 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:18,206 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,207 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1253)) - Container #1 is over replicated. Expected replica count is 3, but found 4.
2023-01-03 14:06:18,207 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1588)) - Sending delete container command for container #1 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:18,207 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1253)) - Container #2 is over replicated. Expected replica count is 3, but found 4.
2023-01-03 14:06:18,208 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1588)) - Sending delete container command for container #2 to datanode 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:18,208 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1253)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2023-01-03 14:06:18,208 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1588)) - Sending delete container command for container #3 to datanode 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:18,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 5 milliseconds for processing 11 containers.
2023-01-03 14:06:18,213 [Listener at 127.0.0.1/35747] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(349)) - upgrade localId to 111677748019200000
2023-01-03 14:06:18,213 [Listener at 127.0.0.1/35747] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(359)) - upgrade delTxnId to 0
2023-01-03 14:06:18,214 [Listener at 127.0.0.1/35747] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:upgradeToSequenceId(376)) - upgrade containerId to 0
2023-01-03 14:06:18,214 [Listener at 127.0.0.1/35747] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-01-03 14:06:18,232 [Listener at 127.0.0.1/35747] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:initialize(78)) - No pipeline exists in current db
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-01-03 14:06:18,239 [Listener at 127.0.0.1/35747] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-01-03 14:06:18,239 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,241 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:18,245 [Listener at 127.0.0.1/35747] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-01-03 14:06:18,245 [Listener at 127.0.0.1/35747] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-01-03 14:06:18,245 [Listener at 127.0.0.1/35747] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:18,245 [Listener at 127.0.0.1/35747] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-01-03 14:06:18,246 [Listener at 127.0.0.1/35747] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-01-03 14:06:18,246 [Listener at 127.0.0.1/35747] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-01-03 14:06:18,246 [Listener at 127.0.0.1/35747] INFO  replication.ReplicationManager (ReplicationManager.java:start(261)) - Starting Replication Monitor Thread.
2023-01-03 14:06:18,247 [Listener at 127.0.0.1/35747] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-01-03 14:06:18,248 [Listener at 127.0.0.1/35747] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 0
2023-01-03 14:06:18,248 [Listener at 127.0.0.1/35747] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 0, healthy pipeline threshold count is 1
2023-01-03 14:06:18,248 [Listener at 127.0.0.1/35747] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
2023-01-03 14:06:18,248 [Listener at 127.0.0.1/35747] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:18,249 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,250 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-01-03 14:06:18,250 [Listener at 0.0.0.0/42125] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:18,251 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-01-03 14:06:18,252 [Listener at 0.0.0.0/42211] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:18,252 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-01-03 14:06:18,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:18,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:18,275 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,284 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,291 [Listener at 0.0.0.0/33121] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-01-03 14:06:18,291 [Listener at 0.0.0.0/33121] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-01-03 14:06:18,291 [Listener at 0.0.0.0/33121] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-01-03 14:06:18,291 [Listener at 0.0.0.0/33121] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1423)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:33121
2023-01-03 14:06:18,291 [Listener at 0.0.0.0/33121] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - StorageContainerManager metrics system started (again)
2023-01-03 14:06:18,328 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,331 [Listener at 0.0.0.0/33121] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:33121
2023-01-03 14:06:18,336 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:18,338 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-01-03 14:06:18,356 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,365 [Listener at 0.0.0.0/33121] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42211
2023-01-03 14:06:18,365 [Listener at 0.0.0.0/33121] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:42211
2023-01-03 14:06:18,365 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:18,366 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-01-03 14:06:18,367 [Listener at 0.0.0.0/33121] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:42125
2023-01-03 14:06:18,367 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:18,367 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-01-03 14:06:18,370 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40d926b9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:18,370 [Listener at 0.0.0.0/33121] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:0
2023-01-03 14:06:18,370 [Listener at 0.0.0.0/33121] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:18,376 [Listener at 0.0.0.0/33121] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:18,380 [Listener at 0.0.0.0/33121] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 37391
2023-01-03 14:06:18,381 [Listener at 0.0.0.0/33121] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:18,382 [Listener at 0.0.0.0/33121] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:18,382 [Listener at 0.0.0.0/33121] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:18,382 [Listener at 0.0.0.0/33121] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:18,383 [Listener at 0.0.0.0/33121] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@14342f6b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:18,383 [Listener at 0.0.0.0/33121] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@268f06a1{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-01-03 14:06:18,385 [Listener at 0.0.0.0/33121] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@6a48bfb8{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:18,387 [Listener at 0.0.0.0/33121] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1906bf93{HTTP/1.1, (http/1.1)}{0.0.0.0:37391}
2023-01-03 14:06:18,387 [Listener at 0.0.0.0/33121] INFO  server.Server (Server.java:doStart(415)) - Started @177512ms
2023-01-03 14:06:18,388 [Listener at 0.0.0.0/33121] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:18,388 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,389 [Listener at 0.0.0.0/33121] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:37391
2023-01-03 14:06:18,389 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(115)) - ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:loadOMHAConfig(226)) - Configuration does not have ozone.om.address set. Falling back to the default OM address /127.0.0.1:0
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(254)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] INFO  ha.OMHANodeDetails (OMHANodeDetails.java:getOMNodeDetailsForNonHA(261)) - OM Node ID is not set. Setting it to the default ID: om1
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:18,394 [Listener at 0.0.0.0/33121] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
2023-01-03 14:06:18,411 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,412 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,413 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,502 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,510 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,516 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,592 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,602 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,611 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,646 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,657 [Listener at 0.0.0.0/33121] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 262 ms to scan 2 urls, producing 154 keys and 428 values [using 2 cores]
2023-01-03 14:06:18,658 [Listener at 0.0.0.0/33121] INFO  upgrade.OMLayoutVersionManager (OMLayoutVersionManager.java:lambda$0(115)) - Skipping Upgrade Action MockOmUpgradeAction since it has been finalized.
2023-01-03 14:06:18,658 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:18,658 [Listener at 0.0.0.0/33121] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:42211]
2023-01-03 14:06:18,659 [Listener at 0.0.0.0/33121] INFO  proxy.SCMBlockLocationFailoverProxyProvider (SCMBlockLocationFailoverProxyProvider.java:<init>(114)) - Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=/0.0.0.0:42211]
2023-01-03 14:06:18,674 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDBPath(225)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:18,674 [Listener at 0.0.0.0/33121] INFO  codec.OmKeyInfoCodec (OmKeyInfoCodec.java:<init>(49)) - OmKeyInfoCodec ignorePipeline = true
2023-01-03 14:06:18,674 [Listener at 0.0.0.0/33121] INFO  codec.RepeatedOmKeyInfoCodec (RepeatedOmKeyInfoCodec.java:<init>(41)) - RepeatedOmKeyInfoCodec ignorePipeline = true
2023-01-03 14:06:18,720 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,728 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,735 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:18,735 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,067 [Listener at 0.0.0.0/33121] INFO  om.OzoneManager (OzoneManager.java:instantiateServices(717)) - S3 Multi-Tenancy is disabled
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] INFO  om.OzoneManager (OzoneManager.java:addS3GVolumeToDB(4402)) - Created Volume s3v With Owner runner required for S3Gateway operations.
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] WARN  utils.OzoneManagerRatisUtils (OzoneManagerRatisUtils.java:getOMRatisSnapshotDirectory(434)) - ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,068 [Listener at 0.0.0.0/33121] WARN  server.ServerUtils (ServerUtils.java:getDefaultRatisDirectory(237)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2023-01-03 14:06:19,069 [Listener at 0.0.0.0/33121] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:<init>(160)) - Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: localhost:42527
2023-01-03 14:06:19,069 [Listener at 0.0.0.0/33121] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:loadSnapshotInfoFromDB(636)) - LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
2023-01-03 14:06:19,069 [IPC Server handler 10 on default port 40427] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:startMaintenance(366)) - Starting Maintenance for node 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,069 [Listener at 0.0.0.0/33121] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.port = 42527 (fallback to raft.grpc.server.port)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.port = 42527 (fallback to raft.grpc.server.port)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 42527 (custom)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 33554432 (custom)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 3000ms (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:19,070 [Listener at 0.0.0.0/33121] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:19,071 [Listener at 0.0.0.0/33121] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:19,071 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:19,071 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:19,072 [Listener at 0.0.0.0/33121] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:19,074 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2023-01-03 14:06:19,074 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:19,075 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-01-03 14:06:19,077 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:19,077 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:19,077 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-01-03 14:06:19,077 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:19,077 [Listener at 0.0.0.0/33121] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis] (custom)
2023-01-03 14:06:19,078 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87ce99fd] REGISTERED
2023-01-03 14:06:19,078 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87ce99fd] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:19,078 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x87ce99fd, L:/0:0:0:0:0:0:0:0:34367] ACTIVE
2023-01-03 14:06:19,081 [Listener at 0.0.0.0/33121] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - om1: addNew group-C5BA1605619E:[om1|rpc:localhost:42527|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@60db0874[Not completed]
2023-01-03 14:06:19,081 [Listener at 0.0.0.0/33121] INFO  om.OzoneManager (OzoneManager.java:initializeRatisServer(1979)) - OzoneManager Ratis server initialized at port 42527
2023-01-03 14:06:19,082 [pool-2505-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:localhost:42527|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
2023-01-03 14:06:19,082 [Listener at 0.0.0.0/33121] INFO  om.OzoneManager (OzoneManager.java:getRpcServer(1106)) - Creating RPC Server
2023-01-03 14:06:19,082 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 1s (custom)
2023-01-03 14:06:19,082 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 1200ms (custom)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 120s (custom)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:localhost:42527|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis] (custom)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 120s (custom)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 300s (custom)
2023-01-03 14:06:19,083 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:19,085 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:19,085 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:19,086 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:19,087 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:19,087 [pool-2505-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:19,181 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,194 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,199 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:19,199 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,201 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(426)) - Sending command of type deleteContainerCommand for container ContainerInfo{id=#7, state=CLOSED, pipelineID=PipelineID=f7989919-f3c6-4c21-b9ff-586f23243835, stateEnterTime=2023-01-03T14:05:42.981Z, owner=om1} to 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,201 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(426)) - Sending command of type deleteContainerCommand for container ContainerInfo{id=#8, state=CLOSED, pipelineID=PipelineID=64398470-874b-482c-b675-b57ef8659ca2, stateEnterTime=2023-01-03T14:05:43.413Z, owner=om1} to 773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,202 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(426)) - Sending command of type deleteContainerCommand for container ContainerInfo{id=#9, state=CLOSED, pipelineID=PipelineID=00409626-6e09-4821-98a6-be1b464cfa48, stateEnterTime=2023-01-03T14:05:43.586Z, owner=om1} to b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,202 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(426)) - Sending command of type deleteContainerCommand for container ContainerInfo{id=#10, state=CLOSED, pipelineID=PipelineID=6004d107-9210-450f-b66b-299616578970, stateEnterTime=2023-01-03T14:05:43.790Z, owner=om1} to 773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,202 [Over Replicated Processor] INFO  replication.ReplicationManager (ReplicationManager.java:sendDatanodeCommand(426)) - Sending command of type deleteContainerCommand for container ContainerInfo{id=#11, state=CLOSED, pipelineID=PipelineID=8538d93a-b62c-49e6-81c3-d5f147804e17, stateEnterTime=2023-01-03T14:05:43.906Z, owner=om1} to 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:19,202 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 5 containers with health state counts {OVER_REPLICATED=5},failed processing 0
2023-01-03 14:06:19,202 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:19,202 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:19,204 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,206 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:19,212 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-01-03 14:06:19,239 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:19,241 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:19,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:19,266 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:19,357 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,403 [Listener at 0.0.0.0/33121] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 320 ms to scan 19 urls, producing 67 keys and 4516 values [using 2 cores]
2023-01-03 14:06:19,404 [Listener at 0.0.0.0/33121] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:19,404 [Socket Reader #1 for port 0] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 0
2023-01-03 14:06:19,424 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2023-01-03 14:06:19,433 [Listener at 127.0.0.1/33881] INFO  om.OzoneManager (OzoneManager.java:start(1486)) - OzoneManager RPC server is listening at localhost/127.0.0.1:33881
2023-01-03 14:06:19,433 [Listener at 127.0.0.1/33881] INFO  ratis.OzoneManagerRatisServer (OzoneManagerRatisServer.java:start(555)) - Starting OzoneManagerRatisServer om1 at port 42527
2023-01-03 14:06:19,433 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
2023-01-03 14:06:19,435 [om1-impl-thread1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:19,436 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 4096 (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 4194304 (custom)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 4194304 (custom)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:19,437 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:19,438 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,439 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 64KB (=65536) (default)
2023-01-03 14:06:19,439 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,439 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = false (default)
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:localhost:42527|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-FollowerState
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
2023-01-03 14:06:19,445 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 1s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:19,445 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:19,445 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 1200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:19,446 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 400000 (default)
2023-01-03 14:06:19,446 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = -1 (default)
2023-01-03 14:06:19,446 [om1-impl-thread1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = true (custom)
2023-01-03 14:06:19,446 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - om1: start RPC server
2023-01-03 14:06:19,447 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - om1: GrpcService started, listening on 42527
2023-01-03 14:06:19,447 [Listener at 127.0.0.1/33881] INFO  om.OzoneManager (OzoneManager.java:start(1502)) - Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
2023-01-03 14:06:19,448 [JvmPauseMonitor51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-om1: Started
2023-01-03 14:06:19,449 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2023-01-03 14:06:19,449 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:19,450 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:19,450 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:19,451 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:19,452 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2023-01-03 14:06:19,452 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:19,452 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:19,452 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 41811
2023-01-03 14:06:19,452 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:19,462 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:19,462 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:19,462 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:19,463 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@630500b5{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:19,463 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@5fd0a9d3{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-01-03 14:06:19,465 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@28be4b37{ozoneManager,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-01-03 14:06:19,468 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1f06192c{HTTP/1.1, (http/1.1)}{0.0.0.0:41811}
2023-01-03 14:06:19,469 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @178593ms
2023-01-03 14:06:19,469 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:19,469 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of ozoneManager listening at http://0.0.0.0:41811
2023-01-03 14:06:19,471 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:19,471 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 0: starting
2023-01-03 14:06:19,477 [Listener at 127.0.0.1/33881] INFO  om.OzoneManager (OzoneManager.java:startTrashEmptier(1923)) - Trash Interval set to 0. Files deleted won't move to trash
2023-01-03 14:06:19,479 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@571c3b32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:19,487 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,487 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,487 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:19,498 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:19,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkPipelinesClosedOnNode(325)) - Waiting for pipelines to close for 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. There are 2 pipelines
2023-01-03 14:06:19,511 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}. Finalizing its pipelines [PipelineID=1bf27372-4842-4c40-9fd6-2537f1aeb008, PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4]
2023-01-03 14:06:19,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:19,512 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 1bf27372-4842-4c40-9fd6-2537f1aeb008, Nodes: 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:8161063e-a6c1-4ab4-9440-f30963410d31, CreationTimestamp2023-01-03T14:05:08.951Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:19,512 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=1bf27372-4842-4c40-9fd6-2537f1aeb008 close command to datanode 8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:19,515 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 1bf27372-4842-4c40-9fd6-2537f1aeb008, Nodes: 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:8161063e-a6c1-4ab4-9440-f30963410d31, CreationTimestamp2023-01-03T14:05:08.951Z[Etc/UTC]] removed.
2023-01-03 14:06:19,519 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #1 closed for pipeline=PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:19,519 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #2 closed for pipeline=PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:19,519 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #5 closed for pipeline=PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:19,520 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 3184f6cc-9864-43cd-8e09-0f561755d9b4, Nodes: 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:8161063e-a6c1-4ab4-9440-f30963410d31, CreationTimestamp2023-01-03T14:05:09.336Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:19,520 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 close command to datanode 8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:19,520 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 close command to datanode 7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:19,520 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 close command to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:19,520 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 3184f6cc-9864-43cd-8e09-0f561755d9b4, Nodes: 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:8161063e-a6c1-4ab4-9440-f30963410d31, CreationTimestamp2023-01-03T14:05:09.336Z[Etc/UTC]] removed.
2023-01-03 14:06:19,520 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #1, current state: CLOSING
2023-01-03 14:06:19,520 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #2, current state: CLOSING
2023-01-03 14:06:19,520 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #5, current state: CLOSING
2023-01-03 14:06:19,526 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:19,570 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 43 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:19,571 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:19,572 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:19,572 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:19,572 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds
2023-01-03 14:06:19,582 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds
2023-01-03 14:06:19,586 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,594 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis to VolumeSet
2023-01-03 14:06:19,594 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis
2023-01-03 14:06:19,595 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis
2023-01-03 14:06:19,602 [IPC Server handler 15 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:19,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,603 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=1bf27372-4842-4c40-9fd6-2537f1aeb008 is not found
2023-01-03 14:06:19,603 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 is not found
2023-01-03 14:06:19,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,610 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,614 [Thread-2971] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds
2023-01-03 14:06:19,614 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:19,619 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:19,619 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:19,619 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:19,619 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:19,620 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:19,621 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:19,622 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:19,623 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:19,623 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:19,623 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:19,626 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:19,626 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:19,626 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:19,626 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:19,626 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis] (custom)
2023-01-03 14:06:19,627 [af27b707-902e-436a-b36c-df002345c922-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x49376042] REGISTERED
2023-01-03 14:06:19,627 [af27b707-902e-436a-b36c-df002345c922-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x49376042] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:19,627 [af27b707-902e-436a-b36c-df002345c922-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x49376042, L:/0:0:0:0:0:0:0:0:42839] ACTIVE
2023-01-03 14:06:19,631 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:19,639 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:19,639 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:19,644 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:19,646 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,652 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:19,653 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:19,653 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:19,653 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:19,653 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:19,654 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 34259
2023-01-03 14:06:19,654 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:19,667 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:19,667 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:19,667 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-03 14:06:19,667 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6feb559b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:19,667 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4caed28d{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:19,720 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,722 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: addNew group-E75C438DA29B:[773b8dbf-6336-4037-abee-6d5bd5e00f08|rpc:10.1.0.35:43245|dataStream:10.1.0.35:46643|priority:1|startupRole:FOLLOWER] returns group-E75C438DA29B:java.util.concurrent.CompletableFuture@14f0ba96[Not completed]
2023-01-03 14:06:19,723 [pool-2355-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: new RaftServerImpl for group-E75C438DA29B:[773b8dbf-6336-4037-abee-6d5bd5e00f08|rpc:10.1.0.35:43245|dataStream:10.1.0.35:46643|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:19,723 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:19,723 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:19,723 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:19,723 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B: ConfigurationManager, init=-1: peers:[773b8dbf-6336-4037-abee-6d5bd5e00f08|rpc:10.1.0.35:43245|dataStream:10.1.0.35:46643|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data/ratis] (custom)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:19,724 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:19,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,729 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,729 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,729 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:19,729 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:19,729 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:19,730 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:19,730 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:19,730 [pool-2355-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data/ratis/102fa275-103f-4187-b404-e75c438da29b does not exist. Creating ...
2023-01-03 14:06:19,734 [pool-2355-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data/ratis/102fa275-103f-4187-b404-e75c438da29b/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:19,735 [pool-2355-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data/ratis/102fa275-103f-4187-b404-e75c438da29b has been successfully formatted.
2023-01-03 14:06:19,736 [pool-2355-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-E75C438DA29B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:19,736 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 102fa275-103f-4187-b404-e75c438da29b, Nodes: 773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:773b8dbf-6336-4037-abee-6d5bd5e00f08, CreationTimestamp2023-01-03T14:06:16.832Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:19,736 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,736 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data/ratis/102fa275-103f-4187-b404-e75c438da29b
2023-01-03 14:06:19,737 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:19,738 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:19,739 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:19,740 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:19,797 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B: start as a follower, conf=-1: peers:[773b8dbf-6336-4037-abee-6d5bd5e00f08|rpc:10.1.0.35:43245|dataStream:10.1.0.35:46643|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:19,798 [pool-2355-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: start 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState
2023-01-03 14:06:19,799 [pool-2355-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E75C438DA29B,id=773b8dbf-6336-4037-abee-6d5bd5e00f08
2023-01-03 14:06:19,799 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:19,799 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:19,799 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:19,799 [pool-2355-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:19,800 [773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:19,800 [773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:19,800 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=102fa275-103f-4187-b404-e75c438da29b
2023-01-03 14:06:19,800 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=102fa275-103f-4187-b404-e75c438da29b.
2023-01-03 14:06:19,804 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,808 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:19,927 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@19bc36d3{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-34259-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-3157747243821730449/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:19,931 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@72bdf00a{HTTP/1.1, (http/1.1)}{0.0.0.0:34259}
2023-01-03 14:06:19,932 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @179056ms
2023-01-03 14:06:19,932 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:19,932 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:34259
2023-01-03 14:06:19,933 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:19,933 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,933 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:19,933 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:19,944 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:19,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@75aadd51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:19,957 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/meta/datanode.id
2023-01-03 14:06:19,968 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:20,017 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 48 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:20,018 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:20,026 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:20,027 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:20,027 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds
2023-01-03 14:06:20,032 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds
2023-01-03 14:06:20,044 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis to VolumeSet
2023-01-03 14:06:20,044 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis
2023-01-03 14:06:20,044 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis
2023-01-03 14:06:20,055 [Thread-2987] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds
2023-01-03 14:06:20,055 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:20,056 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:20,057 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:20,058 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:20,059 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:20,060 [56e9ebea-1da6-4510-b9da-2a36b64eada2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc7987b6f] REGISTERED
2023-01-03 14:06:20,060 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis] (custom)
2023-01-03 14:06:20,060 [56e9ebea-1da6-4510-b9da-2a36b64eada2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc7987b6f] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:20,060 [56e9ebea-1da6-4510-b9da-2a36b64eada2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc7987b6f, L:/0:0:0:0:0:0:0:0:35533] ACTIVE
2023-01-03 14:06:20,061 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:20,064 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:20,064 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:20,064 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:20,065 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:20,065 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:20,066 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:20,066 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:20,066 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:20,066 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 43929
2023-01-03 14:06:20,066 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:20,067 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:20,067 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:20,067 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-03 14:06:20,068 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@1644fa1f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:20,068 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6336bbdf{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:20,103 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-4/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-0ff2e894-9c2b-4c9b-82d7-92cf94274506/container.db for volume DS-0ff2e894-9c2b-4c9b-82d7-92cf94274506
2023-01-03 14:06:20,103 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:20,104 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:20,105 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:20,116 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@631246b3{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:20,122 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5af5119f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:20,122 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:20,125 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@6b3a0c2e{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:20,127 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 8161063e-a6c1-4ab4-9440-f30963410d31: remove    LEADER 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008:t1, leader=8161063e-a6c1-4ab4-9440-f30963410d31, voted=8161063e-a6c1-4ab4-9440-f30963410d31, raftlog=Memoized:8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-SegmentedRaftLog:OPENED:c0, conf=0: peers:[8161063e-a6c1-4ab4-9440-f30963410d31|rpc:10.1.0.35:38537|dataStream:10.1.0.35:36601|priority:1|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-01-03 14:06:20,127 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008: shutdown
2023-01-03 14:06:20,127 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-2537F1AEB008,id=8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:20,127 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 8161063e-a6c1-4ab4-9440-f30963410d31: shutdown 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-LeaderStateImpl
2023-01-03 14:06:20,127 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:20,128 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:20,128 [8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-2537F1AEB008: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/1bf27372-4842-4c40-9fd6-2537f1aeb008/sm/snapshot.1_0
2023-01-03 14:06:20,128 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@732d6e6{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:20,131 [8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-2537F1AEB008: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/1bf27372-4842-4c40-9fd6-2537f1aeb008/sm/snapshot.1_0 took: 3 ms
2023-01-03 14:06:20,131 [8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:20,131 [8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:20,131 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008: closes. applyIndex: 0
2023-01-03 14:06:20,131 [8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,132 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,132 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-2537F1AEB008: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/1bf27372-4842-4c40-9fd6-2537f1aeb008
2023-01-03 14:06:20,132 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=1bf27372-4842-4c40-9fd6-2537f1aeb008 command on datanode 8161063e-a6c1-4ab4-9440-f30963410d31.
2023-01-03 14:06:20,132 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 8161063e-a6c1-4ab4-9440-f30963410d31: remove    LEADER 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4:t2, leader=8161063e-a6c1-4ab4-9440-f30963410d31, voted=8161063e-a6c1-4ab4-9440-f30963410d31, raftlog=Memoized:8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-SegmentedRaftLog:OPENED:c39, conf=0: peers:[8161063e-a6c1-4ab4-9440-f30963410d31|rpc:10.1.0.35:38537|dataStream:10.1.0.35:36601|priority:1|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:0|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-01-03 14:06:20,133 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4: shutdown
2023-01-03 14:06:20,133 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F561755D9B4,id=8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:20,133 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 8161063e-a6c1-4ab4-9440-f30963410d31: shutdown 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-LeaderStateImpl
2023-01-03 14:06:20,133 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:20,134 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:20,134 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7c948c4b-a779-4597-819f-06099ef104a1: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:06:20,134 [grpc-default-executor-8] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: Completed APPEND_ENTRIES, lastRequest: 8161063e-a6c1-4ab4-9440-f30963410d31->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2#172-t2,previous=(t:2, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:2, i:39), METADATAENTRY(c:38)
2023-01-03 14:06:20,134 [grpc-default-executor-10] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:06:20,134 [grpc-default-executor-0] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 7c948c4b-a779-4597-819f-06099ef104a1: Completed APPEND_ENTRIES, lastRequest: 8161063e-a6c1-4ab4-9440-f30963410d31->7c948c4b-a779-4597-819f-06099ef104a1#167-t2,previous=(t:2, i:38),leaderCommit=38,initializing? true,entries: size=1, first=(t:2, i:39), METADATAENTRY(c:38)
2023-01-03 14:06:20,135 [grpc-default-executor-3] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,135 [grpc-default-executor-3] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1: nextIndex: updateUnconditionally 40 -> 39
2023-01-03 14:06:20,135 [grpc-default-executor-10] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,135 [grpc-default-executor-10] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: nextIndex: updateUnconditionally 40 -> 39
2023-01-03 14:06:20,136 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,136 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->7c948c4b-a779-4597-819f-06099ef104a1: nextIndex: updateUnconditionally 39 -> 38
2023-01-03 14:06:20,137 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,137 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: nextIndex: updateUnconditionally 39 -> 38
2023-01-03 14:06:20,137 [Command processor thread] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:20,148 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater: set stopIndex = 39
2023-01-03 14:06:20,148 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-0F561755D9B4: Taking a snapshot at:(t:2, i:39) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_39
2023-01-03 14:06:20,157 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-0F561755D9B4: Finished taking a snapshot at:(t:2, i:39) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_39 took: 8 ms
2023-01-03 14:06:20,163 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater: Took a snapshot at index 39
2023-01-03 14:06:20,163 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 39
2023-01-03 14:06:20,164 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4: closes. applyIndex: 39
2023-01-03 14:06:20,164 [8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,164 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,165 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:20,169 [IPC Server handler 18 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,169 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,169 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=1bf27372-4842-4c40-9fd6-2537f1aeb008 is not found
2023-01-03 14:06:20,169 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 is not found
2023-01-03 14:06:20,170 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 89282906-b815-4a6d-bda0-404bb113e200: close
2023-01-03 14:06:20,170 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3: shutdown
2023-01-03 14:06:20,171 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-CC0A89235CA3,id=89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:20,171 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 89282906-b815-4a6d-bda0-404bb113e200: shutdown 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-LeaderStateImpl
2023-01-03 14:06:20,171 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:20,171 [89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-CC0A89235CA3: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-3/data/ratis/7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3/sm/snapshot.1_0
2023-01-03 14:06:20,172 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:20,172 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 89282906-b815-4a6d-bda0-404bb113e200: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:20,172 [89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-CC0A89235CA3: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-3/data/ratis/7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3/sm/snapshot.1_0 took: 0 ms
2023-01-03 14:06:20,172 [89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:20,172 [89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:20,173 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08 Close channels
2023-01-03 14:06:20,173 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3: closes. applyIndex: 0
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 89282906-b815-4a6d-bda0-404bb113e200@group-CC0A89235CA3-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A: shutdown
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B9661FB30C0A,id=89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 89282906-b815-4a6d-bda0-404bb113e200: shutdown 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-FollowerState
2023-01-03 14:06:20,174 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-FollowerState was interrupted
2023-01-03 14:06:20,175 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-B9661FB30C0A: Taking a snapshot at:(t:3, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-3/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0
2023-01-03 14:06:20,175 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:20,178 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff Close channels
2023-01-03 14:06:20,178 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003 Close channels
2023-01-03 14:06:20,178 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 89282906-b815-4a6d-bda0-404bb113e200: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x77fe58f4, L:/0:0:0:0:0:0:0:0:46133] CLOSE
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-B9661FB30C0A: Finished taking a snapshot at:(t:3, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-3/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0 took: 4 ms
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x77fe58f4, L:/0:0:0:0:0:0:0:0:46133] INACTIVE
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x77fe58f4, L:/0:0:0:0:0:0:0:0:46133] UNREGISTERED
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:20,179 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:20,180 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,181 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A: closes. applyIndex: 0
2023-01-03 14:06:20,182 [89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,182 [89282906-b815-4a6d-bda0-404bb113e200-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 89282906-b815-4a6d-bda0-404bb113e200@group-B9661FB30C0A-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,187 [JvmPauseMonitor29] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-89282906-b815-4a6d-bda0-404bb113e200: Stopped
2023-01-03 14:06:20,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,194 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,197 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-1/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-c650bc73-cc47-4bce-b304-702d026ca78e/container.db for volume DS-c650bc73-cc47-4bce-b304-702d026ca78e
2023-01-03 14:06:20,198 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:20,198 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:20,199 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,199 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:20,200 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,203 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,203 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:20,203 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:20,206 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,213 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:20,217 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,217 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,219 [IPC Server handler 6 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,219 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,220 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #1 to QUASI_CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2023-01-03 14:06:20,220 [IPC Server handler 9 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,221 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,221 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,221 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,223 [IPC Server handler 12 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,223 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #2 to QUASI_CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2023-01-03 14:06:20,223 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,224 [IPC Server handler 8 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,225 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,225 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,225 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,225 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@cbcfa78{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:20,226 [IPC Server handler 10 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (ENTERING_MAINTENANCE, 0)
2023-01-03 14:06:20,227 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(285)) - Moving container #5 to QUASI_CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} reported QUASI_CLOSED replica.
2023-01-03 14:06:20,227 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,227 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 8161063e-a6c1-4ab4-9440-f30963410d31@group-0F561755D9B4: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:20,227 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 command on datanode 8161063e-a6c1-4ab4-9440-f30963410d31.
2023-01-03 14:06:20,229 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@53a63711{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:20,230 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:20,233 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@349f58b0{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:20,236 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@bdf7933{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:20,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,241 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:20,252 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - 7c948c4b-a779-4597-819f-06099ef104a1: remove  FOLLOWER 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4:t2, leader=8161063e-a6c1-4ab4-9440-f30963410d31, voted=8161063e-a6c1-4ab4-9440-f30963410d31, raftlog=Memoized:7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-SegmentedRaftLog:OPENED:c38, conf=0: peers:[8161063e-a6c1-4ab4-9440-f30963410d31|rpc:10.1.0.35:38537|dataStream:10.1.0.35:36601|priority:1|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:0|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-01-03 14:06:20,252 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4: shutdown
2023-01-03 14:06:20,253 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F561755D9B4,id=7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:20,253 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7c948c4b-a779-4597-819f-06099ef104a1: shutdown 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-FollowerState
2023-01-03 14:06:20,253 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater: set stopIndex = 38
2023-01-03 14:06:20,253 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-FollowerState was interrupted
2023-01-03 14:06:20,253 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-0F561755D9B4: Taking a snapshot at:(t:2, i:38) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_38
2023-01-03 14:06:20,260 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:20,261 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - edb1aef9-02a8-4817-80a7-afb47d970b52: close
2023-01-03 14:06:20,261 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C: shutdown
2023-01-03 14:06:20,261 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23C37724191C,id=edb1aef9-02a8-4817-80a7-afb47d970b52
2023-01-03 14:06:20,261 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - edb1aef9-02a8-4817-80a7-afb47d970b52: shutdown edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-LeaderStateImpl
2023-01-03 14:06:20,261 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - edb1aef9-02a8-4817-80a7-afb47d970b52: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:20,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:20,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:20,269 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d Close channels
2023-01-03 14:06:20,270 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - e9b53549-c119-47d5-a583-bc601a9ace80 Close channels
2023-01-03 14:06:20,269 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6: shutdown
2023-01-03 14:06:20,270 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-023DDA6062A6,id=edb1aef9-02a8-4817-80a7-afb47d970b52
2023-01-03 14:06:20,270 [grpc-default-executor-8] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:20,270 [grpc-default-executor-3] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:20,273 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:20,273 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->b3a67b98-d7e4-49a8-83c5-9d813aec1f6d-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:20,276 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-0F561755D9B4: Finished taking a snapshot at:(t:2, i:38) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_38 took: 23 ms
2023-01-03 14:06:20,276 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater: Took a snapshot at index 38
2023-01-03 14:06:20,276 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 38
2023-01-03 14:06:20,276 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater: set stopIndex = 27
2023-01-03 14:06:20,276 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-23C37724191C: Taking a snapshot at:(t:1, i:27) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-2/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27
2023-01-03 14:06:20,277 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4: closes. applyIndex: 38
2023-01-03 14:06:20,277 [7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,277 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:06:20,278 [grpc-default-executor-3] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - e9b53549-c119-47d5-a583-bc601a9ace80: Completed APPEND_ENTRIES, lastRequest: edb1aef9-02a8-4817-80a7-afb47d970b52->e9b53549-c119-47d5-a583-bc601a9ace80#373-t1,previous=(t:1, i:26),leaderCommit=25,initializing? true,entries: size=1, first=(t:1, i:27), METADATAENTRY(c:25)
2023-01-03 14:06:20,278 [grpc-default-executor-10] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,278 [grpc-default-executor-2] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - e9b53549-c119-47d5-a583-bc601a9ace80: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:06:20,278 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-23C37724191C: Finished taking a snapshot at:(t:1, i:27) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-2/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27 took: 3 ms
2023-01-03 14:06:20,278 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,279 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:06:20,280 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - edb1aef9-02a8-4817-80a7-afb47d970b52: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:20,280 [edb1aef9-02a8-4817-80a7-afb47d970b52-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9899450f, L:/0:0:0:0:0:0:0:0:43563] CLOSE
2023-01-03 14:06:20,280 [edb1aef9-02a8-4817-80a7-afb47d970b52-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9899450f, L:/0:0:0:0:0:0:0:0:43563] INACTIVE
2023-01-03 14:06:20,280 [edb1aef9-02a8-4817-80a7-afb47d970b52-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9899450f, L:/0:0:0:0:0:0:0:0:43563] UNREGISTERED
2023-01-03 14:06:20,280 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater: Took a snapshot at index 27
2023-01-03 14:06:20,280 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 27
2023-01-03 14:06:20,285 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,285 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 is not found
2023-01-03 14:06:20,290 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - edb1aef9-02a8-4817-80a7-afb47d970b52: shutdown edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-LeaderStateImpl
2023-01-03 14:06:20,290 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:20,291 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:20,291 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-023DDA6062A6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-2/data/ratis/e5c39811-52ae-4ced-85ba-023dda6062a6/sm/snapshot.1_0
2023-01-03 14:06:20,292 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C: closes. applyIndex: 27
2023-01-03 14:06:20,292 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,292 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,293 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-023DDA6062A6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-2/data/ratis/e5c39811-52ae-4ced-85ba-023dda6062a6/sm/snapshot.1_0 took: 1 ms
2023-01-03 14:06:20,293 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:20,293 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:20,294 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6: closes. applyIndex: 0
2023-01-03 14:06:20,298 [grpc-default-executor-10] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-GrpcLogAppender: Failed to getClient for e9b53549-c119-47d5-a583-bc601a9ace80
org.apache.ratis.protocol.exceptions.AlreadyClosedException: edb1aef9-02a8-4817-80a7-afb47d970b52 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:20,298 [edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,298 [grpc-default-executor-2] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(137)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-23C37724191C->e9b53549-c119-47d5-a583-bc601a9ace80-GrpcLogAppender: Failed to getClient for e9b53549-c119-47d5-a583-bc601a9ace80
org.apache.ratis.protocol.exceptions.AlreadyClosedException: edb1aef9-02a8-4817-80a7-afb47d970b52 is already CLOSED
	at org.apache.ratis.util.PeerProxyMap$PeerAndProxy.getProxy(PeerProxyMap.java:61)
	at org.apache.ratis.util.PeerProxyMap.getProxy(PeerProxyMap.java:115)
	at org.apache.ratis.grpc.server.GrpcLogAppender.getClient(GrpcLogAppender.java:116)
	at org.apache.ratis.grpc.server.GrpcLogAppender.resetClient(GrpcLogAppender.java:121)
	at org.apache.ratis.grpc.server.GrpcLogAppender.access$500(GrpcLogAppender.java:58)
	at org.apache.ratis.grpc.server.GrpcLogAppender$AppendLogResponseHandler.onCompleted(GrpcLogAppender.java:416)
	at org.apache.ratis.thirdparty.io.grpc.stub.ClientCalls$StreamObserverToCallListenerAdapter.onClose(ClientCalls.java:485)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.closeObserver(ClientCallImpl.java:562)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl.access$300(ClientCallImpl.java:70)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInternal(ClientCallImpl.java:743)
	at org.apache.ratis.thirdparty.io.grpc.internal.ClientCallImpl$ClientStreamListenerImpl$1StreamClosed.runInContext(ClientCallImpl.java:722)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:20,302 [edb1aef9-02a8-4817-80a7-afb47d970b52-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - edb1aef9-02a8-4817-80a7-afb47d970b52@group-023DDA6062A6-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,306 [JvmPauseMonitor28] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-edb1aef9-02a8-4817-80a7-afb47d970b52: Stopped
2023-01-03 14:06:20,310 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,310 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,315 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,316 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,316 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,316 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,318 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,319 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,319 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,319 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,322 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,322 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-0F561755D9B4: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:20,322 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 command on datanode 7c948c4b-a779-4597-819f-06099ef104a1.
2023-01-03 14:06:20,357 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,398 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=c3b14682-4c72-4669-86f1-9f35241392ce, PipelineID=a19e8429-6698-4bdc-8bbb-b9661fb30c0a]
2023-01-03 14:06:20,398 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: c3b14682-4c72-4669-86f1-9f35241392ce, Nodes: 5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:5573e85b-a1ef-42aa-8f1f-8db9238bd003, CreationTimestamp2023-01-03T14:04:33.374Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:20,398 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: a19e8429-6698-4bdc-8bbb-b9661fb30c0a, Nodes: 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:5573e85b-a1ef-42aa-8f1f-8db9238bd003, CreationTimestamp2023-01-03T14:05:49.674Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:20,418 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,446 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@440cc3eb{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-43929-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-128288394738061684/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:20,451 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@bb07957{HTTP/1.1, (http/1.1)}{0.0.0.0:43929}
2023-01-03 14:06:20,451 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @179575ms
2023-01-03 14:06:20,451 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:20,451 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:43929
2023-01-03 14:06:20,452 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:20,452 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:20,462 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:20,463 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@74d19661] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:20,466 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/meta/datanode.id
2023-01-03 14:06:20,479 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:20,498 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c, PipelineID=34852c1e-c153-4809-8357-01c13a1042d8]
2023-01-03 14:06:20,498 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #4 closed for pipeline=PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c
2023-01-03 14:06:20,498 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #5 closed for pipeline=PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c
2023-01-03 14:06:20,498 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closeContainersForPipeline(421)) - Container #6 closed for pipeline=PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c
2023-01-03 14:06:20,499 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 28ccbd3d-0f91-40a0-af2b-23c37724191c, Nodes: edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:OPEN, leaderId:edb1aef9-02a8-4817-80a7-afb47d970b52, CreationTimestamp2023-01-03T14:04:32.743Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:20,499 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 34852c1e-c153-4809-8357-01c13a1042d8, Nodes: b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:b3a67b98-d7e4-49a8-83c5-9d813aec1f6d, CreationTimestamp2023-01-03T14:04:32.342Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:20,499 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #4, current state: CLOSING
2023-01-03 14:06:20,499 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #5, current state: CLOSING
2023-01-03 14:06:20,499 [EventQueue-CloseContainerForCloseContainerEventHandler] INFO  container.CloseContainerEventHandler (CloseContainerEventHandler.java:onMessage(73)) - Close container Event triggered for container : #6, current state: CLOSING
2023-01-03 14:06:20,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:20,525 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 42 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:20,526 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:20,527 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:20,527 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:20,527 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds
2023-01-03 14:06:20,527 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds
2023-01-03 14:06:20,538 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis to VolumeSet
2023-01-03 14:06:20,538 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis
2023-01-03 14:06:20,538 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis
2023-01-03 14:06:20,549 [Thread-3019] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds
2023-01-03 14:06:20,549 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:20,551 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:20,552 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:20,552 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:20,553 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:20,554 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis] (custom)
2023-01-03 14:06:20,555 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:20,557 [3a3da11c-e5c3-43e0-8561-5c3126dc697f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9c112abf] REGISTERED
2023-01-03 14:06:20,557 [3a3da11c-e5c3-43e0-8561-5c3126dc697f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9c112abf] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:20,557 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:20,557 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:20,558 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:20,558 [3a3da11c-e5c3-43e0-8561-5c3126dc697f-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x9c112abf, L:/0:0:0:0:0:0:0:0:43551] ACTIVE
2023-01-03 14:06:20,558 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:20,559 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:20,559 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:20,559 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:20,559 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:20,560 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38147
2023-01-03 14:06:20,560 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:20,561 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:20,561 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:20,561 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-03 14:06:20,561 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@45d4faae{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:20,562 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@c1e9a60{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:20,579 [om1@group-C5BA1605619E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:1133481291ns, electionTimeout:1133ms
2023-01-03 14:06:20,579 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - om1: shutdown om1@group-C5BA1605619E-FollowerState
2023-01-03 14:06:20,579 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:20,579 [om1@group-C5BA1605619E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:20,579 [om1@group-C5BA1605619E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderElection101
2023-01-03 14:06:20,581 [om1@group-C5BA1605619E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - om1@group-C5BA1605619E-LeaderElection101 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:localhost:42527|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:20,581 [om1@group-C5BA1605619E-LeaderElection101] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - om1@group-C5BA1605619E-LeaderElection101 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:20,581 [om1@group-C5BA1605619E-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - om1: shutdown om1@group-C5BA1605619E-LeaderElection101
2023-01-03 14:06:20,581 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:20,582 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 1498ms
2023-01-03 14:06:20,582 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:20,582 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-01-03 14:06:20,583 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 64MB (=67108864) (default)
2023-01-03 14:06:20,583 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 10s (default)
2023-01-03 14:06:20,583 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:20,584 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:20,584 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 4096 (default)
2023-01-03 14:06:20,584 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:20,584 [om1@group-C5BA1605619E-LeaderElection101] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - om1: start om1@group-C5BA1605619E-LeaderStateImpl
2023-01-03 14:06:20,584 [om1@group-C5BA1605619E-LeaderElection101] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:20,589 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,603 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/ozone-meta/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
2023-01-03 14:06:20,603 [om1@group-C5BA1605619E-LeaderElection101] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:localhost:42527|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:20,603 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:remove(107)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: remove  FOLLOWER f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4:t2, leader=8161063e-a6c1-4ab4-9440-f30963410d31, voted=8161063e-a6c1-4ab4-9440-f30963410d31, raftlog=Memoized:f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-SegmentedRaftLog:OPENED:c38, conf=0: peers:[8161063e-a6c1-4ab4-9440-f30963410d31|rpc:10.1.0.35:38537|dataStream:10.1.0.35:36601|priority:1|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:0|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null RUNNING
2023-01-03 14:06:20,604 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4: shutdown
2023-01-03 14:06:20,604 [Command processor thread] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0F561755D9B4,id=f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:20,604 [Command processor thread] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-FollowerState
2023-01-03 14:06:20,604 [Command processor thread] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater: set stopIndex = 38
2023-01-03 14:06:20,604 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-FollowerState was interrupted
2023-01-03 14:06:20,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,605 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineReportHandler (PipelineReportHandler.java:processPipelineReport(115)) - Reported pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 is not found
2023-01-03 14:06:20,605 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-0F561755D9B4: Taking a snapshot at:(t:2, i:38) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_38
2023-01-03 14:06:20,606 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:notifyConfigurationChanged(192)) - Received Configuration change notification from Ratis. New Peer list:
[id: "om1"
address: "localhost:42527"
startupRole: FOLLOWER
]
2023-01-03 14:06:20,607 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-0F561755D9B4: Finished taking a snapshot at:(t:2, i:38) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4/sm/snapshot.2_38 took: 2 ms
2023-01-03 14:06:20,607 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater: Took a snapshot at index 38
2023-01-03 14:06:20,607 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 38
2023-01-03 14:06:20,608 [Command processor thread] INFO  server.RaftServer$Division (ServerState.java:close(466)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4: closes. applyIndex: 38
2023-01-03 14:06:20,608 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:20,608 [Command processor thread] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4-SegmentedRaftLogWorker close()
2023-01-03 14:06:20,610 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,612 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,646 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,650 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,682 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,683 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:20,684 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,686 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,686 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:20,686 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,687 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,689 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,689 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:20,691 [Command processor thread] INFO  server.RaftServer$Division (RaftServerImpl.java:groupRemove(428)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-0F561755D9B4: Succeed to remove RaftStorageDirectory Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/3184f6cc-9864-43cd-8e09-0f561755d9b4
2023-01-03 14:06:20,692 [Command processor thread] INFO  commandhandler.ClosePipelineCommandHandler (ClosePipelineCommandHandler.java:handle(78)) - Close Pipeline PipelineID=3184f6cc-9864-43cd-8e09-0f561755d9b4 command on datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2.
2023-01-03 14:06:20,692 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,692 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,729 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,729 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,784 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@194c71ea{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38147-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-666432346589658781/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:20,788 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@71ee89e5{HTTP/1.1, (http/1.1)}{0.0.0.0:38147}
2023-01-03 14:06:20,788 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @179912ms
2023-01-03 14:06:20,788 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:20,788 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38147
2023-01-03 14:06:20,789 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:20,789 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:20,789 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:20,789 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:20,799 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:20,803 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ff063fb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:20,804 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/meta/datanode.id
2023-01-03 14:06:20,808 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:20,815 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:20,858 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 43 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:20,859 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:20,860 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:20,860 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:20,860 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds
2023-01-03 14:06:20,860 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds
2023-01-03 14:06:20,870 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis to VolumeSet
2023-01-03 14:06:20,870 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis
2023-01-03 14:06:20,870 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis
2023-01-03 14:06:20,880 [Thread-3035] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds
2023-01-03 14:06:20,880 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:20,881 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:20,882 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:20,882 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:20,882 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:20,882 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:20,886 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:20,886 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:20,887 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:20,888 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:20,888 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:20,888 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:20,888 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xffbab6b5] REGISTERED
2023-01-03 14:06:20,888 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:20,888 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xffbab6b5] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:20,888 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis] (custom)
2023-01-03 14:06:20,888 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xffbab6b5, L:/0:0:0:0:0:0:0:0:32925] ACTIVE
2023-01-03 14:06:20,889 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:20,891 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:20,891 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:20,892 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:20,892 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 38399
2023-01-03 14:06:20,893 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:20,894 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:20,894 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:20,894 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:20,895 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@163cd8e9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:20,895 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@566e7cf5{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:21,061 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@8b100be{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-38399-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-7978206102148036016/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:21,065 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1412dbbe{HTTP/1.1, (http/1.1)}{0.0.0.0:38399}
2023-01-03 14:06:21,066 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @180190ms
2023-01-03 14:06:21,066 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:21,066 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:38399
2023-01-03 14:06:21,066 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:21,066 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,067 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,067 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:21,077 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:21,086 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3caf31c8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:21,088 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/meta/datanode.id
2023-01-03 14:06:21,100 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:21,141 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 41 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:21,142 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:21,143 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:21,143 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:21,143 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds
2023-01-03 14:06:21,143 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds
2023-01-03 14:06:21,153 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis to VolumeSet
2023-01-03 14:06:21,153 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis
2023-01-03 14:06:21,153 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis
2023-01-03 14:06:21,166 [Thread-3049] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds
2023-01-03 14:06:21,166 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:21,168 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:21,169 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:21,169 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:21,169 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:21,169 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:21,169 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:21,170 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:21,171 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:21,171 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:21,171 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x29746398] REGISTERED
2023-01-03 14:06:21,171 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis] (custom)
2023-01-03 14:06:21,171 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x29746398] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:21,175 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:21,175 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x29746398, L:/0:0:0:0:0:0:0:0:36099] ACTIVE
2023-01-03 14:06:21,177 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:21,177 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:21,177 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:21,178 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:21,178 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:21,179 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:21,179 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:21,179 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:21,179 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42089
2023-01-03 14:06:21,179 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:21,182 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:21,182 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:21,183 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-03 14:06:21,183 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@19be4f2d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:21,183 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@aff457a{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:21,184 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,198 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,199 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,200 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,203 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,203 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #1 with BCSID 38, which is in QUASI_CLOSED state.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #2 with BCSID 30, which is in QUASI_CLOSED state.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #5 with BCSID 33, which is in QUASI_CLOSED state.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,204 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:21,205 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,206 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,213 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:21,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:21,226 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,241 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:21,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:21,269 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:21,323 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,357 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,357 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@3a04e472{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-42089-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6098015667002213531/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:21,361 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@1d5eed52{HTTP/1.1, (http/1.1)}{0.0.0.0:42089}
2023-01-03 14:06:21,361 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @180485ms
2023-01-03 14:06:21,361 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:21,362 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:42089
2023-01-03 14:06:21,363 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:21,363 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,363 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,363 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:21,374 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:21,375 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7f91ab00] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:21,378 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/meta/datanode.id
2023-01-03 14:06:21,390 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:21,417 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,435 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 44 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:21,436 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:21,437 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:21,437 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:21,437 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds
2023-01-03 14:06:21,438 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds
2023-01-03 14:06:21,449 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis to VolumeSet
2023-01-03 14:06:21,449 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis
2023-01-03 14:06:21,449 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis
2023-01-03 14:06:21,459 [Thread-3063] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds
2023-01-03 14:06:21,459 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:21,460 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:21,461 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:21,462 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:21,463 [19aec3d0-bc58-440a-899b-3969d29112cc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x064b8470] REGISTERED
2023-01-03 14:06:21,463 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis] (custom)
2023-01-03 14:06:21,464 [19aec3d0-bc58-440a-899b-3969d29112cc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x064b8470] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:21,464 [19aec3d0-bc58-440a-899b-3969d29112cc-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x064b8470, L:/0:0:0:0:0:0:0:0:39215] ACTIVE
2023-01-03 14:06:21,465 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:21,466 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:21,466 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:21,467 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:21,468 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:21,468 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:21,468 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:21,469 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:21,469 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:21,469 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 45949
2023-01-03 14:06:21,469 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:21,470 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:21,470 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:21,470 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:21,471 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@790ec75b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:21,471 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@cd70a83{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:21,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:checkContainersReplicatedOnNode(377)) - 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has 3 sufficientlyReplicated, 0 underReplicated and 0 unhealthy containers
2023-01-03 14:06:21,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:putIntoMaintenance(421)) - Datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} has entered maintenance
2023-01-03 14:06:21,511 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:21,512 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  node.ReadOnlyHealthyToHealthyNodeHandler (ReadOnlyHealthyToHealthyNodeHandler.java:onMessage(51)) - Datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} moved to HEALTHY state.
2023-01-03 14:06:21,512 [EventQueue-HealthyReadonlyToHealthyNodeForReadOnlyHealthyToHealthyNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:21,512 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 to datanode:a13c81fc-644c-4ecf-91c3-6e9a75ed36aa
2023-01-03 14:06:21,512 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 to datanode:7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:21,512 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 to datanode:f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:21,513 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6, Nodes: a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:21.512Z[Etc/UTC]].
2023-01-03 14:06:21,513 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:21,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,647 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,650 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,651 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@4ce2988a{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-45949-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6109262014643113267/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:21,655 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7888ed54{HTTP/1.1, (http/1.1)}{0.0.0.0:45949}
2023-01-03 14:06:21,655 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @180779ms
2023-01-03 14:06:21,655 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:21,655 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:45949
2023-01-03 14:06:21,656 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,656 [Listener at 127.0.0.1/33881] WARN  impl.MetricRegistriesImpl (MetricRegistriesImpl.java:addReporterRegistration(111)) - New reporters are added after registries were created. Some metrics will be missing from the reporter. Please add reporter before adding any new registry.
2023-01-03 14:06:21,656 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:21,656 [Listener at 127.0.0.1/33881] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2023-01-03 14:06:21,659 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5266978316ns, electionTimeout:5082ms
2023-01-03 14:06:21,659 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState
2023-01-03 14:06:21,659 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2023-01-03 14:06:21,668 [Listener at 127.0.0.1/33881] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(235)) - HddsDatanodeService host:fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net ip:10.1.0.35
2023-01-03 14:06:21,670 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:21,670 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: start 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102
2023-01-03 14:06:21,671 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28f88471] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:21,672 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A: change Leader from 5573e85b-a1ef-42aa-8f1f-8db9238bd003 to null at term 3 for ELECTION
2023-01-03 14:06:21,672 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/meta/datanode.id
2023-01-03 14:06:21,673 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102 ELECTION round 0: submit vote requests at term 4 for 0: peers:[89282906-b815-4a6d-bda0-404bb113e200|rpc:10.1.0.35:46873|dataStream:10.1.0.35:46133|priority:0|startupRole:FOLLOWER, 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff|rpc:10.1.0.35:34451|dataStream:10.1.0.35:44223|priority:0|startupRole:FOLLOWER, 5573e85b-a1ef-42aa-8f1f-8db9238bd003|rpc:10.1.0.35:44365|dataStream:10.1.0.35:42425|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:21,674 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:21,674 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:21,684 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102 got exception when requesting votes: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102: ELECTION REJECTED received 0 response(s) and 2 exception(s):
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 0: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LogUtils.java:infoOrTrace(137)) -   Exception 1: java.util.concurrent.ExecutionException: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102 ELECTION round 0: result REJECTED
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102
2023-01-03 14:06:21,688 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-LeaderElection102] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: start 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState
2023-01-03 14:06:21,692 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,695 [Listener at 127.0.0.1/33881] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:21,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,728 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,729 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,748 [Listener at 127.0.0.1/33881] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 52 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:21,749 [Listener at 127.0.0.1/33881] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:getEndPointTaskThreadPoolSize(248)) - Datanode State Machine Task Thread Pool size 2
2023-01-03 14:06:21,750 [Listener at 127.0.0.1/33881] INFO  volume.HddsVolume (HddsVolume.java:<init>(117)) - Creating HddsVolume: /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds of storage type : DISK capacity : 9223372036854775807
2023-01-03 14:06:21,750 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds to VolumeSet
2023-01-03 14:06:21,750 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds
2023-01-03 14:06:21,751 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds
2023-01-03 14:06:21,765 [Listener at 127.0.0.1/33881] INFO  volume.MutableVolumeSet (MutableVolumeSet.java:initializeVolumeSet(174)) - Added Volume : /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis to VolumeSet
2023-01-03 14:06:21,765 [Listener at 127.0.0.1/33881] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(141)) - Scheduling a check for /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis
2023-01-03 14:06:21,766 [Listener at 127.0.0.1/33881] INFO  volume.StorageVolumeChecker (StorageVolumeChecker.java:checkAllVolumes(202)) - Scheduled health check for volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis
2023-01-03 14:06:21,776 [Thread-3081] INFO  ozoneimpl.ContainerReader (ContainerReader.java:readVolume(175)) - Finish verifying containers on volume /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds
2023-01-03 14:06:21,777 [Listener at 127.0.0.1/33881] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:buildContainerSet(301)) - Build ContainerSet costs 0s
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  server.RaftServer (ConfUtils.java:logGet(46)) - raft.rpc.type = GRPC (default)
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.admin.port = 0 (custom)
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logFallback(53)) - raft.grpc.client.host = null (fallback to raft.grpc.server.host)
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.client.port = 0 (custom)
2023-01-03 14:06:21,778 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.host = null (default)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.port = 0 (default)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.message.size.max = 32MB (=33554432) (custom)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  server.GrpcService (ConfUtils.java:logGet(46)) - raft.grpc.flow.control.window = 5MB (=5242880) (custom)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.cached = true (default)
2023-01-03 14:06:21,779 [Listener at 127.0.0.1/33881] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.async.request.thread.pool.size = 32 (default)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  impl.DataStreamServerImpl (ConfUtils.java:logGet(46)) - raft.datastream.type = NETTY (custom)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.cached = false (default)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.async.write.thread.pool.size = 16 (default)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.data-stream.client.pool.size = 10 (default)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.use-epoll = false (default)
2023-01-03 14:06:21,780 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.boss-group.size = 0 (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.worker-group.size = 0 (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.server.tls.conf = null (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.host = null (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  netty.NettyConfigKeys$DataStream (ConfUtils.java:logGet(46)) - raft.netty.dataStream.port = 0 (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.cached = true (default)
2023-01-03 14:06:21,781 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.proxy.size = 0 (default)
2023-01-03 14:06:21,782 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:21,782 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:21,782 [bc03f53a-8f38-42c1-b7a4-94894081fc1e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x073334d2] REGISTERED
2023-01-03 14:06:21,782 [Listener at 127.0.0.1/33881] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis] (custom)
2023-01-03 14:06:21,782 [bc03f53a-8f38-42c1-b7a4-94894081fc1e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x073334d2] BIND: 0.0.0.0/0.0.0.0:0
2023-01-03 14:06:21,782 [bc03f53a-8f38-42c1-b7a4-94894081fc1e-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x073334d2, L:/0:0:0:0:0:0:0:0:33549] ACTIVE
2023-01-03 14:06:21,784 [Listener at 127.0.0.1/33881] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(132)) - GrpcServer channel type EpollServerSocketChannel
2023-01-03 14:06:21,787 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2023-01-03 14:06:21,787 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:21,787 [Listener at 127.0.0.1/33881] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:21,788 [Listener at 127.0.0.1/33881] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:21,790 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:21,790 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2023-01-03 14:06:21,790 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:21,791 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:21,791 [Listener at 127.0.0.1/33881] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 46403
2023-01-03 14:06:21,791 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:21,793 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:21,794 [Listener at 127.0.0.1/33881] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:21,794 [Listener at 127.0.0.1/33881] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:21,794 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@646124c3{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:21,794 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@4dc06b28{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
2023-01-03 14:06:21,809 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:21,980 [Listener at 127.0.0.1/33881] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@7a607bce{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-46403-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-6470680727495021364/webapp/,AVAILABLE}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:21,986 [Listener at 127.0.0.1/33881] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@7f07d3fd{HTTP/1.1, (http/1.1)}{0.0.0.0:46403}
2023-01-03 14:06:21,986 [Listener at 127.0.0.1/33881] INFO  server.Server (Server.java:doStart(415)) - Started @181110ms
2023-01-03 14:06:21,986 [Listener at 127.0.0.1/33881] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:21,987 [Listener at 127.0.0.1/33881] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of hddsDatanode listening at http://0.0.0.0:46403
2023-01-03 14:06:21,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-01-03 14:06:21,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:21,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:21,988 [Datanode State Machine Daemon Thread] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(508)) - Ozone container server started.
2023-01-03 14:06:22,015 [Datanode State Machine Task Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(138)) - DatanodeDetails is persisted to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/meta/datanode.id
2023-01-03 14:06:22,018 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b974528] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:22,022 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-0bae22d9-b183-4712-9517-78aacb6c1d71/container.db to cache
2023-01-03 14:06:22,022 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-0bae22d9-b183-4712-9517-78aacb6c1d71/container.db for volume DS-0bae22d9-b183-4712-9517-78aacb6c1d71
2023-01-03 14:06:22,024 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:22,024 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:22,025 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 38645
2023-01-03 14:06:22,028 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:22,036 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - af27b707-902e-436a-b36c-df002345c922: start RPC server
2023-01-03 14:06:22,036 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - af27b707-902e-436a-b36c-df002345c922: GrpcService started, listening on 40275
2023-01-03 14:06:22,038 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis af27b707-902e-436a-b36c-df002345c922 is started using port 40275 for RATIS
2023-01-03 14:06:22,038 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis af27b707-902e-436a-b36c-df002345c922 is started using port 40275 for RATIS_ADMIN
2023-01-03 14:06:22,038 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis af27b707-902e-436a-b36c-df002345c922 is started using port 40275 for RATIS_SERVER
2023-01-03 14:06:22,038 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis af27b707-902e-436a-b36c-df002345c922 is started using port 42839 for RATIS_DATASTREAM
2023-01-03 14:06:22,038 [JvmPauseMonitor52] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-af27b707-902e-436a-b36c-df002345c922: Started
2023-01-03 14:06:22,042 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc af27b707-902e-436a-b36c-df002345c922 is started using port 40537
2023-01-03 14:06:22,183 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,198 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,199 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,199 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,203 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,203 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,204 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #1 with BCSID 38, which is in QUASI_CLOSED state.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #1 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #2 with BCSID 30, which is in QUASI_CLOSED state.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #2 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:forceCloseContainer(1109)) - Force closing container #5 with BCSID 33, which is in QUASI_CLOSED state.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,205 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,210 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 6 milliseconds for processing 6 containers.
2023-01-03 14:06:22,210 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:22,214 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 11 containers.
2023-01-03 14:06:22,215 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-3/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-8287d56b-61b6-464b-aa63-253855824b62/container.db for volume DS-8287d56b-61b6-464b-aa63-253855824b62
2023-01-03 14:06:22,215 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:22,216 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:22,217 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:22,227 [IPC Server handler 2 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-01-03 14:06:22,227 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,233 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2057c90a{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:22,236 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@33edf73f{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:22,237 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:22,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,241 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:22,242 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@21db7367{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:22,245 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@59f00130{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:22,279 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,279 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,279 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:22,280 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: close
2023-01-03 14:06:22,280 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:22,281 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A: shutdown
2023-01-03 14:06:22,281 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-B9661FB30C0A,id=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff
2023-01-03 14:06:22,281 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState
2023-01-03 14:06:22,281 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-FollowerState was interrupted
2023-01-03 14:06:22,281 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:22,281 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 1 is closed with bcsId 38.
2023-01-03 14:06:22,281 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,281 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,283 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 2 is closed with bcsId 30.
2023-01-03 14:06:22,283 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,283 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:22,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:22,286 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 89282906-b815-4a6d-bda0-404bb113e200 Close channels
2023-01-03 14:06:22,288 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 5573e85b-a1ef-42aa-8f1f-8db9238bd003 Close channels
2023-01-03 14:06:22,288 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:22,289 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc54c755f, L:/0:0:0:0:0:0:0:0:44223] CLOSE
2023-01-03 14:06:22,289 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc54c755f, L:/0:0:0:0:0:0:0:0:44223] INACTIVE
2023-01-03 14:06:22,289 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xc54c755f, L:/0:0:0:0:0:0:0:0:44223] UNREGISTERED
2023-01-03 14:06:22,290 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 5 is closed with bcsId 33.
2023-01-03 14:06:22,290 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-B9661FB30C0A: Taking a snapshot at:(t:3, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-6/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191: shutdown
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-46C5B9CBA191,id=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: shutdown 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-LeaderStateImpl
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:22,291 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-46C5B9CBA191: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-6/data/ratis/63169f10-7458-4b53-8652-46c5b9cba191/sm/snapshot.1_0
2023-01-03 14:06:22,292 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-46C5B9CBA191: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-6/data/ratis/63169f10-7458-4b53-8652-46c5b9cba191/sm/snapshot.1_0 took: 0 ms
2023-01-03 14:06:22,292 [IPC Server handler 0 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-01-03 14:06:22,292 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:22,292 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:22,292 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,292 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #1 to CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2023-01-03 14:06:22,293 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #2 to CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2023-01-03 14:06:22,293 [FixedThreadPoolWithAffinityExecutor-0-0] INFO  container.IncrementalContainerReportHandler (AbstractContainerReportHandler.java:updateContainerState(318)) - Moving container #5 to CLOSED state, datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} reported CLOSED replica.
2023-01-03 14:06:22,294 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-B9661FB30C0A: Finished taking a snapshot at:(t:3, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-6/data/ratis/a19e8429-6698-4bdc-8bbb-b9661fb30c0a/sm/snapshot.3_0 took: 4 ms
2023-01-03 14:06:22,294 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:22,294 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:22,295 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A: closes. applyIndex: 0
2023-01-03 14:06:22,295 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191: closes. applyIndex: 0
2023-01-03 14:06:22,295 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:22,295 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-46C5B9CBA191-SegmentedRaftLogWorker close()
2023-01-03 14:06:22,297 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:22,297 [4db05c90-fb2b-44c1-a5c3-62f45e9c05ff-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff@group-B9661FB30C0A-SegmentedRaftLogWorker close()
2023-01-03 14:06:22,298 [IPC Server handler 13 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:updateDatanodeOpState(545)) - Scheduling a command to update the operationalState persisted on 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: ENTERING_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} as the reported value does not match the value stored in SCM (IN_MAINTENANCE, 0)
2023-01-03 14:06:22,298 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,299 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,299 [JvmPauseMonitor32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-4db05c90-fb2b-44c1-a5c3-62f45e9c05ff: Stopped
2023-01-03 14:06:22,314 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-2/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-ec7f3ac8-44af-4f43-a1ef-75c96bdb772f/container.db for volume DS-ec7f3ac8-44af-4f43-a1ef-75c96bdb772f
2023-01-03 14:06:22,314 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:22,315 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:22,316 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:22,325 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,329 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@1f6091da{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:22,329 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@257e51f6{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:22,330 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:22,333 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@456020a8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:22,335 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@400282c9{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:22,339 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:22,340 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - e9b53549-c119-47d5-a583-bc601a9ace80: close
2023-01-03 14:06:22,340 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - e9b53549-c119-47d5-a583-bc601a9ace80: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:22,340 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B: shutdown
2023-01-03 14:06:22,340 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - edb1aef9-02a8-4817-80a7-afb47d970b52 Close channels
2023-01-03 14:06:22,341 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - b3a67b98-d7e4-49a8-83c5-9d813aec1f6d Close channels
2023-01-03 14:06:22,342 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - e9b53549-c119-47d5-a583-bc601a9ace80: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:22,342 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-57BB3B5ECA4B,id=e9b53549-c119-47d5-a583-bc601a9ace80
2023-01-03 14:06:22,342 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - e9b53549-c119-47d5-a583-bc601a9ace80: shutdown e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-LeaderStateImpl
2023-01-03 14:06:22,342 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-PendingRequests: sendNotLeaderResponses
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:06:22,341 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C: shutdown
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-23C37724191C,id=e9b53549-c119-47d5-a583-bc601a9ace80
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - e9b53549-c119-47d5-a583-bc601a9ace80: shutdown e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-FollowerState
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x208570f3, L:/0:0:0:0:0:0:0:0:35775] CLOSE
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x208570f3, L:/0:0:0:0:0:0:0:0:35775] INACTIVE
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x208570f3, L:/0:0:0:0:0:0:0:0:35775] UNREGISTERED
2023-01-03 14:06:22,343 [e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-57BB3B5ECA4B: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-0/data/ratis/1509e613-77e1-4ee2-81e9-57bb3b5eca4b/sm/snapshot.1_0
2023-01-03 14:06:22,344 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-FollowerState was interrupted
2023-01-03 14:06:22,344 [e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-57BB3B5ECA4B: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-0/data/ratis/1509e613-77e1-4ee2-81e9-57bb3b5eca4b/sm/snapshot.1_0 took: 1 ms
2023-01-03 14:06:22,344 [e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:06:22,344 [e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:06:22,346 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater: set stopIndex = 27
2023-01-03 14:06:22,346 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B: closes. applyIndex: 0
2023-01-03 14:06:22,346 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-23C37724191C: Taking a snapshot at:(t:1, i:27) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-0/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27
2023-01-03 14:06:22,347 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-23C37724191C: Finished taking a snapshot at:(t:1, i:27) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-0/data/ratis/28ccbd3d-0f91-40a0-af2b-23c37724191c/sm/snapshot.1_27 took: 1 ms
2023-01-03 14:06:22,347 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,347 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,347 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater: Took a snapshot at index 27
2023-01-03 14:06:22,348 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 27
2023-01-03 14:06:22,348 [e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:22,348 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 1 is closed with bcsId 38.
2023-01-03 14:06:22,349 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-57BB3B5ECA4B-SegmentedRaftLogWorker close()
2023-01-03 14:06:22,349 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,349 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,350 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,351 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C: closes. applyIndex: 27
2023-01-03 14:06:22,351 [e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:22,351 [e9b53549-c119-47d5-a583-bc601a9ace80-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - e9b53549-c119-47d5-a583-bc601a9ace80@group-23C37724191C-SegmentedRaftLogWorker close()
2023-01-03 14:06:22,351 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 2 is closed with bcsId 30.
2023-01-03 14:06:22,351 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,351 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,352 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,352 [JvmPauseMonitor26] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-e9b53549-c119-47d5-a583-bc601a9ace80: Stopped
2023-01-03 14:06:22,356 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 5 is closed with bcsId 33.
2023-01-03 14:06:22,357 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 7c948c4b-a779-4597-819f-06099ef104a1: addNew group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] returns group-03ABF1FB5BF6:java.util.concurrent.CompletableFuture@1bf2b4e7[Not completed]
2023-01-03 14:06:22,357 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 7c948c4b-a779-4597-819f-06099ef104a1: new RaftServerImpl for group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:22,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:22,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:22,357 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:22,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:22,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:22,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:22,358 [pool-1691-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: ConfigurationManager, init=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:22,358 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis] (custom)
2023-01-03 14:06:22,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,359 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:22,359 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:22,359 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:22,359 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:22,359 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:22,361 [pool-1691-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 does not exist. Creating ...
2023-01-03 14:06:22,362 [pool-1691-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:22,363 [pool-1691-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 has been successfully formatted.
2023-01-03 14:06:22,363 [pool-1691-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-03ABF1FB5BF6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:22,364 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:22,364 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:22,365 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:22,366 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:22,367 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,414 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:22,415 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:22,415 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:22,430 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,430 [pool-1691-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,430 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: start as a follower, conf=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:22,431 [pool-1691-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7c948c4b-a779-4597-819f-06099ef104a1: start 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-03ABF1FB5BF6,id=7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:22,432 [pool-1691-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:22,433 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6
2023-01-03 14:06:22,433 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:22,433 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:22,437 [grpc-default-executor-8] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: addNew group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] returns group-03ABF1FB5BF6:java.util.concurrent.CompletableFuture@69d9a1d3[Not completed]
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: new RaftServerImpl for group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:22,438 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: ConfigurationManager, init=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis] (custom)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:22,439 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:22,440 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:22,440 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:22,440 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:22,440 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:22,440 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:22,441 [pool-1722-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 does not exist. Creating ...
2023-01-03 14:06:22,442 [pool-1722-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:22,442 [pool-1722-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 has been successfully formatted.
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-03ABF1FB5BF6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:22,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:22,443 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:22,444 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:22,446 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:22,446 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: start as a follower, conf=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:22,451 [pool-1722-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:22,452 [pool-1722-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: start a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:22,452 [pool-1722-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-03ABF1FB5BF6,id=a13c81fc-644c-4ecf-91c3-6e9a75ed36aa
2023-01-03 14:06:22,453 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:22,453 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:22,453 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:22,453 [pool-1722-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:22,452 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:22,454 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:22,461 [grpc-default-executor-8] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: addNew group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] returns group-03ABF1FB5BF6:java.util.concurrent.CompletableFuture@5beabeb2[Not completed]
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: new RaftServerImpl for group-03ABF1FB5BF6:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: ConfigurationManager, init=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:22,462 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis] (custom)
2023-01-03 14:06:22,463 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:22,463 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:22,463 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:22,463 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:22,463 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:22,464 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:22,464 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:22,464 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:22,465 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:22,465 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:22,465 [pool-1641-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 does not exist. Creating ...
2023-01-03 14:06:22,466 [pool-1641-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6 has been successfully formatted.
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-03ABF1FB5BF6: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:22,467 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:22,468 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:22,470 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,471 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:22,471 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: start as a follower, conf=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:22,477 [pool-1641-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: start f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-03ABF1FB5BF6,id=f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:22,478 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:22,478 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:22,478 [pool-1641-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:22,481 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6.
2023-01-03 14:06:22,492 [main] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(350)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-01-03 14:06:22,493 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1518)) - Container Balancer is not running.
2023-01-03 14:06:22,493 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1525)) - Stopping Replication Manager Service.
2023-01-03 14:06:22,493 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(296)) - Stopping Replication Monitor Thread.
2023-01-03 14:06:22,496 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Stopping the Datanode Admin Monitor.
2023-01-03 14:06:22,496 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping datanode service RPC server
2023-01-03 14:06:22,497 [main] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-01-03 14:06:22,496 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(666)) - Replication Monitor Thread is stopped
2023-01-03 14:06:22,499 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Under Replicated Processor interrupted. Exiting...
2023-01-03 14:06:22,499 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Over Replicated Processor interrupted. Exiting...
2023-01-03 14:06:22,499 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 32791
2023-01-03 14:06:22,508 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:22,511 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-d2d7a056-d7a3-4757-8837-a8ed8824418d/container.db to cache
2023-01-03 14:06:22,511 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-d2d7a056-d7a3-4757-8837-a8ed8824418d/container.db for volume DS-d2d7a056-d7a3-4757-8837-a8ed8824418d
2023-01-03 14:06:22,513 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:22,513 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:22,514 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:22,515 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=e5c39811-52ae-4ced-85ba-023dda6062a6, PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c]
2023-01-03 14:06:22,515 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: e5c39811-52ae-4ced-85ba-023dda6062a6, Nodes: edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:edb1aef9-02a8-4817-80a7-afb47d970b52, CreationTimestamp2023-01-03T14:04:32.742Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:22,515 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3, PipelineID=a19e8429-6698-4bdc-8bbb-b9661fb30c0a]
2023-01-03 14:06:22,515 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3, Nodes: 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:89282906-b815-4a6d-bda0-404bb113e200, CreationTimestamp2023-01-03T14:04:33.065Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:22,515 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 35233
2023-01-03 14:06:22,517 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:22,519 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start RPC server
2023-01-03 14:06:22,519 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: GrpcService started, listening on 39427
2023-01-03 14:06:22,519 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 56e9ebea-1da6-4510-b9da-2a36b64eada2 is started using port 39427 for RATIS
2023-01-03 14:06:22,520 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 56e9ebea-1da6-4510-b9da-2a36b64eada2 is started using port 39427 for RATIS_ADMIN
2023-01-03 14:06:22,520 [JvmPauseMonitor53] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-56e9ebea-1da6-4510-b9da-2a36b64eada2: Started
2023-01-03 14:06:22,520 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 56e9ebea-1da6-4510-b9da-2a36b64eada2 is started using port 39427 for RATIS_SERVER
2023-01-03 14:06:22,520 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 56e9ebea-1da6-4510-b9da-2a36b64eada2 is started using port 35533 for RATIS_DATASTREAM
2023-01-03 14:06:22,520 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 56e9ebea-1da6-4510-b9da-2a36b64eada2 is started using port 33637
2023-01-03 14:06:22,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,609 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-01-03 14:06:22,610 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1547)) - Stopping block service RPC server
2023-01-03 14:06:22,610 [main] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-01-03 14:06:22,612 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 34621
2023-01-03 14:06:22,615 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:22,618 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:22,618 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1554)) - Stopping the StorageContainerLocationProtocol RPC server
2023-01-03 14:06:22,618 [main] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-01-03 14:06:22,620 [main] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 40427
2023-01-03 14:06:22,623 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:22,625 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping Storage Container Manager HTTP server.
2023-01-03 14:06:22,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:22,627 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@14aaca3b{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:22,628 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@46859bd8{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:22,628 [main] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:22,636 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@64dd0a77{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-01-03 14:06:22,636 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@27024081{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:22,639 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1567)) - Stopping SCM LayoutVersionManager Service.
2023-01-03 14:06:22,639 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Block Manager Service.
2023-01-03 14:06:22,639 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:22,641 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:22,641 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1597)) - Stopping SCM Event Queue.
2023-01-03 14:06:22,645 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1608)) - Stopping SCM HA services.
2023-01-03 14:06:22,645 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-01-03 14:06:22,646 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-01-03 14:06:22,646 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-01-03 14:06:22,646 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-01-03 14:06:22,646 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping HddsDatanode metrics system...
2023-01-03 14:06:22,654 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,656 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-01-03 14:06:22,656 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - HddsDatanode metrics system stopped.
2023-01-03 14:06:22,657 [main] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-01-03 14:06:22,657 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-01-03 14:06:22,657 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:22,657 [main] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:22,657 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-01-03 14:06:22,657 [main] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Replication Monitor Thread is not running.
2023-01-03 14:06:22,657 [main] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-01-03 14:06:22,658 [main] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1626)) - Stopping SCM MetadataStore.
2023-01-03 14:06:22,659 [main] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:22,659 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-01-03 14:06:22,659 [main] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-01-03 14:06:22,659 [main] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:22,660 [main] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(144)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:22,685 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-01-03 14:06:22,685 [main] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-01-03 14:06:22,691 [main] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:22,726 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,726 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 1 is synced with bcsId 38.
2023-01-03 14:06:22,728 [EndpointStateMachine task thread for /0.0.0.0:32791 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:32791 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az47-978/10.1.0.35"; destination host is: "0.0.0.0":32791; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy54.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-01-03 14:06:22,738 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 1 is closed with bcsId 38.
2023-01-03 14:06:22,738 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,738 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 2 is synced with bcsId 30.
2023-01-03 14:06:22,740 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 2 is closed with bcsId 30.
2023-01-03 14:06:22,740 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,740 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:flushAndSyncDB(437)) - Container 5 is synced with bcsId 33.
2023-01-03 14:06:22,742 [Command processor thread] INFO  keyvalue.KeyValueContainer (KeyValueContainer.java:close(352)) - Container 5 is closed with bcsId 33.
2023-01-03 14:06:22,755 [main] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 62 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:22,758 [main] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-01-03 14:06:22,762 [main] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-01-03 14:06:22,762 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-01-03 14:06:22,762 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:22,763 [main] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-01-03 14:06:22,764 [main] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:22,764 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-01-03 14:06:22,764 [main] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-01-03 14:06:22,769 [main] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-01-03 14:06:22,770 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-01-03 14:06:22,770 [main] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:22,770 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-01-03 14:06:22,774 [main] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-01-03 14:06:22,775 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-01-03 14:06:22,776 [main] INFO  replication.ReplicationManager (ReplicationManager.java:start(261)) - Starting Replication Monitor Thread.
2023-01-03 14:06:22,777 [main] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-01-03 14:06:22,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:22,782 [main] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-01-03 14:06:22,782 [main] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 1, healthy pipeline threshold count is 1
2023-01-03 14:06:22,782 [main] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 1, pipeline's with at least one datanode reported threshold count is 1
2023-01-03 14:06:22,783 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:22,783 [Socket Reader #1 for port 32791] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 32791
2023-01-03 14:06:22,787 [Listener at 0.0.0.0/32791] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:22,788 [Socket Reader #1 for port 34621] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 34621
2023-01-03 14:06:22,789 [Listener at 0.0.0.0/34621] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:22,794 [Socket Reader #1 for port 40427] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 40427
2023-01-03 14:06:22,807 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-01-03 14:06:22,807 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-01-03 14:06:22,807 [Listener at 0.0.0.0/40427] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-01-03 14:06:22,808 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1423)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40427
2023-01-03 14:06:22,813 [Listener at 0.0.0.0/40427] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-01-03 14:06:22,813 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-01-03 14:06:22,813 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-01-03 14:06:22,820 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:22,863 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-67ff9235-f490-44f9-866c-3e30db591b0e/container.db to cache
2023-01-03 14:06:22,863 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-67ff9235-f490-44f9-866c-3e30db591b0e/container.db for volume DS-67ff9235-f490-44f9-866c-3e30db591b0e
2023-01-03 14:06:22,863 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:22,863 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:22,864 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 42411
2023-01-03 14:06:22,868 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:22,869 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-01-03 14:06:22,876 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-01-03 14:06:22,876 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start RPC server
2023-01-03 14:06:22,877 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: GrpcService started, listening on 45127
2023-01-03 14:06:22,877 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3a3da11c-e5c3-43e0-8561-5c3126dc697f is started using port 45127 for RATIS
2023-01-03 14:06:22,877 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3a3da11c-e5c3-43e0-8561-5c3126dc697f is started using port 45127 for RATIS_ADMIN
2023-01-03 14:06:22,877 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3a3da11c-e5c3-43e0-8561-5c3126dc697f is started using port 45127 for RATIS_SERVER
2023-01-03 14:06:22,877 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 3a3da11c-e5c3-43e0-8561-5c3126dc697f is started using port 43551 for RATIS_DATASTREAM
2023-01-03 14:06:22,877 [JvmPauseMonitor54] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-3a3da11c-e5c3-43e0-8561-5c3126dc697f: Started
2023-01-03 14:06:22,878 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 3a3da11c-e5c3-43e0-8561-5c3126dc697f is started using port 37815
2023-01-03 14:06:22,904 [Listener at 0.0.0.0/40427] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:40427
2023-01-03 14:06:22,905 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:22,907 [IPC Server listener on 40427] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 40427: starting
2023-01-03 14:06:22,914 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34621
2023-01-03 14:06:22,914 [Listener at 0.0.0.0/40427] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:34621
2023-01-03 14:06:22,915 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:22,915 [IPC Server listener on 34621] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 34621: starting
2023-01-03 14:06:22,916 [Listener at 0.0.0.0/40427] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:32791
2023-01-03 14:06:22,920 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:22,921 [IPC Server listener on 32791] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 32791: starting
2023-01-03 14:06:22,923 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7010c9e4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:22,927 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:42719
2023-01-03 14:06:22,927 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:22,928 [Listener at 0.0.0.0/40427] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:22,928 [Listener at 0.0.0.0/40427] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:22,929 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:22,930 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-01-03 14:06:22,930 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:22,930 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:22,931 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42719
2023-01-03 14:06:22,931 [Listener at 0.0.0.0/40427] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:22,934 [Listener at 0.0.0.0/40427] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:22,934 [Listener at 0.0.0.0/40427] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:22,934 [Listener at 0.0.0.0/40427] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 660000ms
2023-01-03 14:06:22,935 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@218e186b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:22,935 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@612531a3{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-01-03 14:06:22,942 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@11ad327f{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:22,945 [Listener at 0.0.0.0/40427] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@5ace6611{HTTP/1.1, (http/1.1)}{0.0.0.0:42719}
2023-01-03 14:06:22,945 [Listener at 0.0.0.0/40427] INFO  server.Server (Server.java:doStart(415)) - Started @182069ms
2023-01-03 14:06:22,945 [Listener at 0.0.0.0/40427] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:22,946 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:42719
2023-01-03 14:06:22,946 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-01-03 14:06:22,946 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:22,946 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:22,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-01-03 14:06:22,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:22,987 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:23,113 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-fc2971e9-2581-423a-a3b4-a99879786c88/container.db to cache
2023-01-03 14:06:23,113 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-fc2971e9-2581-423a-a3b4-a99879786c88/container.db for volume DS-fc2971e9-2581-423a-a3b4-a99879786c88
2023-01-03 14:06:23,114 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:23,114 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:23,114 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 41099
2023-01-03 14:06:23,117 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:23,118 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start RPC server
2023-01-03 14:06:23,118 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: GrpcService started, listening on 35277
2023-01-03 14:06:23,119 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 is started using port 35277 for RATIS
2023-01-03 14:06:23,119 [JvmPauseMonitor55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: Started
2023-01-03 14:06:23,119 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 is started using port 35277 for RATIS_ADMIN
2023-01-03 14:06:23,119 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 is started using port 35277 for RATIS_SERVER
2023-01-03 14:06:23,119 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 is started using port 32925 for RATIS_DATASTREAM
2023-01-03 14:06:23,120 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 is started using port 44421
2023-01-03 14:06:23,183 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,199 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,204 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:23,213 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1253)) - Container #2 is over replicated. Expected replica count is 3, but found 4.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1588)) - Sending delete container command for container #2 to datanode 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleOverReplicatedContainer(1253)) - Container #3 is over replicated. Expected replica count is 3, but found 4.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendDeleteCommand(1588)) - Sending delete container command for container #3 to datanode 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,215 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:23,216 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:23,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:23,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:23,285 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:23,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:23,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,403 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-1d3a7760-f5b5-4957-bef2-ddc42251d91e/container.db to cache
2023-01-03 14:06:23,403 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-1d3a7760-f5b5-4957-bef2-ddc42251d91e/container.db for volume DS-1d3a7760-f5b5-4957-bef2-ddc42251d91e
2023-01-03 14:06:23,403 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:23,403 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:23,404 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 34583
2023-01-03 14:06:23,407 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:23,416 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start RPC server
2023-01-03 14:06:23,417 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: GrpcService started, listening on 39571
2023-01-03 14:06:23,417 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 7aee5cb6-4ed9-41f9-a897-fb72e55180cb is started using port 39571 for RATIS
2023-01-03 14:06:23,417 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 7aee5cb6-4ed9-41f9-a897-fb72e55180cb is started using port 39571 for RATIS_ADMIN
2023-01-03 14:06:23,417 [JvmPauseMonitor56] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-7aee5cb6-4ed9-41f9-a897-fb72e55180cb: Started
2023-01-03 14:06:23,417 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 7aee5cb6-4ed9-41f9-a897-fb72e55180cb is started using port 39571 for RATIS_SERVER
2023-01-03 14:06:23,417 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 7aee5cb6-4ed9-41f9-a897-fb72e55180cb is started using port 36099 for RATIS_DATASTREAM
2023-01-03 14:06:23,418 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 7aee5cb6-4ed9-41f9-a897-fb72e55180cb is started using port 34845
2023-01-03 14:06:23,425 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:23,425 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=c3b14682-4c72-4669-86f1-9f35241392ce close command to datanode 5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:23,425 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: c3b14682-4c72-4669-86f1-9f35241392ce, Nodes: 5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:5573e85b-a1ef-42aa-8f1f-8db9238bd003, CreationTimestamp2023-01-03T14:04:33.374Z[Etc/UTC]] removed.
2023-01-03 14:06:23,426 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=a19e8429-6698-4bdc-8bbb-b9661fb30c0a close command to datanode 89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:23,426 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=a19e8429-6698-4bdc-8bbb-b9661fb30c0a close command to datanode 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff
2023-01-03 14:06:23,426 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=a19e8429-6698-4bdc-8bbb-b9661fb30c0a close command to datanode 5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:23,426 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: a19e8429-6698-4bdc-8bbb-b9661fb30c0a, Nodes: 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}5573e85b-a1ef-42aa-8f1f-8db9238bd003{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35741, RATIS=44365, RATIS_ADMIN=44365, RATIS_SERVER=44365, RATIS_DATASTREAM=42425, STANDALONE=44757], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:5573e85b-a1ef-42aa-8f1f-8db9238bd003, CreationTimestamp2023-01-03T14:05:49.674Z[Etc/UTC]] removed.
2023-01-03 14:06:23,426 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/5573e85b-a1ef-42aa-8f1f-8db9238bd003
2023-01-03 14:06:23,525 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:23,525 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c close command to datanode edb1aef9-02a8-4817-80a7-afb47d970b52
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c close command to datanode e9b53549-c119-47d5-a583-bc601a9ace80
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=28ccbd3d-0f91-40a0-af2b-23c37724191c close command to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 28ccbd3d-0f91-40a0-af2b-23c37724191c, Nodes: edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:CLOSED, leaderId:edb1aef9-02a8-4817-80a7-afb47d970b52, CreationTimestamp2023-01-03T14:04:32.743Z[Etc/UTC]] removed.
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=34852c1e-c153-4809-8357-01c13a1042d8 close command to datanode b3a67b98-d7e4-49a8-83c5-9d813aec1f6d
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 34852c1e-c153-4809-8357-01c13a1042d8, Nodes: b3a67b98-d7e4-49a8-83c5-9d813aec1f6d{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34491, RATIS=34135, RATIS_ADMIN=34135, RATIS_SERVER=34135, RATIS_DATASTREAM=43161, STANDALONE=44873], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:b3a67b98-d7e4-49a8-83c5-9d813aec1f6d, CreationTimestamp2023-01-03T14:04:32.342Z[Etc/UTC]] removed.
2023-01-03 14:06:23,526 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/b3a67b98-d7e4-49a8-83c5-9d813aec1f6d
2023-01-03 14:06:23,591 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,655 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,696 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-3e86adcf-731f-4709-a48b-a7ccccee856d/container.db to cache
2023-01-03 14:06:23,696 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-3e86adcf-731f-4709-a48b-a7ccccee856d/container.db for volume DS-3e86adcf-731f-4709-a48b-a7ccccee856d
2023-01-03 14:06:23,696 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:23,696 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:23,697 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 45245
2023-01-03 14:06:23,700 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis 19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:23,704 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start RPC server
2023-01-03 14:06:23,704 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - 19aec3d0-bc58-440a-899b-3969d29112cc: GrpcService started, listening on 43677
2023-01-03 14:06:23,704 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 19aec3d0-bc58-440a-899b-3969d29112cc is started using port 43677 for RATIS
2023-01-03 14:06:23,704 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 19aec3d0-bc58-440a-899b-3969d29112cc is started using port 43677 for RATIS_ADMIN
2023-01-03 14:06:23,705 [JvmPauseMonitor57] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-19aec3d0-bc58-440a-899b-3969d29112cc: Started
2023-01-03 14:06:23,705 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 19aec3d0-bc58-440a-899b-3969d29112cc is started using port 43677 for RATIS_SERVER
2023-01-03 14:06:23,705 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis 19aec3d0-bc58-440a-899b-3969d29112cc is started using port 39215 for RATIS_DATASTREAM
2023-01-03 14:06:23,705 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc 19aec3d0-bc58-440a-899b-3969d29112cc is started using port 44805
2023-01-03 14:06:23,736 [EndpointStateMachine task thread for /0.0.0.0:32791 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:32791. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-01-03 14:06:23,747 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState (RunningDatanodeState.java:computeNextContainerState(207)) - Error in executing end point task.
java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.report(FutureTask.java:122)
	at java.util.concurrent.FutureTask.get(FutureTask.java:192)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:309)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:509)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	... 1 more
2023-01-03 14:06:23,749 [IPC Server handler 0 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode e673a28b-a4f0-4b9b-b939-463b757d484f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=39651, RATIS=32789, RATIS_ADMIN=32789, RATIS_SERVER=32789, RATIS_DATASTREAM=33659, STANDALONE=35199], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,749 [IPC Server handler 1 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,750 [IPC Server handler 2 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,758 [IPC Server handler 3 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,758 [IPC Server handler 4 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,758 [IPC Server handler 5 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode c36dba4c-5c72-465b-8876-3f5e456990a2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34999, RATIS=37333, RATIS_ADMIN=37333, RATIS_SERVER=37333, RATIS_DATASTREAM=37189, STANDALONE=37423], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,760 [IPC Server handler 6 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,760 [IPC Server handler 7 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode e673a28b-a4f0-4b9b-b939-463b757d484f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=39651, RATIS=32789, RATIS_ADMIN=32789, RATIS_SERVER=32789, RATIS_DATASTREAM=33659, STANDALONE=35199], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,761 [IPC Server handler 8 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,761 [IPC Server handler 9 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,762 [IPC Server handler 10 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:23,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:23,808 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:23,946 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 0 of 7 DN Heartbeats.
2023-01-03 14:06:23,947 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:23,947 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:23,961 [IPC Server handler 18 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:23,961 [IPC Server handler 18 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : af27b707-902e-436a-b36c-df002345c922{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=38645, RATIS=40275, RATIS_ADMIN=40275, RATIS_SERVER=40275, RATIS_DATASTREAM=42839, STANDALONE=40537], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:23,968 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-01-03 14:06:23,968 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-01-03 14:06:23,970 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-01-03 14:06:23,973 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:23,973 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=7a992f2c-1f6d-4807-9430-911a592a5de1 to datanode:af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:23,974 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 7a992f2c-1f6d-4807-9430-911a592a5de1, Nodes: af27b707-902e-436a-b36c-df002345c922{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=38645, RATIS=40275, RATIS_ADMIN=40275, RATIS_SERVER=40275, RATIS_DATASTREAM=42839, STANDALONE=40537], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:23.973Z[Etc/UTC]].
2023-01-03 14:06:23,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 1 of 7 DN Heartbeats.
2023-01-03 14:06:23,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:23,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:24,043 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  utils.DatanodeStoreCache (DatanodeStoreCache.java:addDB(58)) - Added db /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-5b72625d-1455-46c0-b2e8-36bc790e9519/container.db to cache
2023-01-03 14:06:24,043 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  volume.HddsVolume (HddsVolume.java:createDbStore(307)) - SchemaV3 db is created and loaded at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data-0/containers/hdds/ea0dd9a4-adf3-421a-94f9-55ec37df1381/DS-5b72625d-1455-46c0-b2e8-36bc790e9519/container.db for volume DS-5b72625d-1455-46c0-b2e8-36bc790e9519
2023-01-03 14:06:24,044 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(395)) - Attempting to start container services.
2023-01-03 14:06:24,044 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(312)) - Scheduled background container scanners and the on-demand container scanner have been disabled.
2023-01-03 14:06:24,046 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  replication.ReplicationServer (ReplicationServer.java:start(106)) - ReplicationServer is started using port 44929
2023-01-03 14:06:24,048 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(517)) - Starting XceiverServerRatis bc03f53a-8f38-42c1-b7a4-94894081fc1e
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.RaftServer (RaftServerProxy.java:startImpl(393)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: start RPC server
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.GrpcService (GrpcService.java:startImpl(262)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: GrpcService started, listening on 33781
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis bc03f53a-8f38-42c1-b7a4-94894081fc1e is started using port 33781 for RATIS
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis bc03f53a-8f38-42c1-b7a4-94894081fc1e is started using port 33781 for RATIS_ADMIN
2023-01-03 14:06:24,052 [JvmPauseMonitor58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(105)) - JvmPauseMonitor-bc03f53a-8f38-42c1-b7a4-94894081fc1e: Started
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis bc03f53a-8f38-42c1-b7a4-94894081fc1e is started using port 33781 for RATIS_SERVER
2023-01-03 14:06:24,052 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:getRealPort(543)) - XceiverServerRatis bc03f53a-8f38-42c1-b7a4-94894081fc1e is started using port 33549 for RATIS_DATASTREAM
2023-01-03 14:06:24,053 [EndpointStateMachine task thread for /0.0.0.0:42125 - 0 ] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:start(180)) - XceiverServerGrpc bc03f53a-8f38-42c1-b7a4-94894081fc1e is started using port 38729
2023-01-03 14:06:24,183 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,204 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:24,213 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1196)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1560)) - Sending replicate container command for container #1 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,216 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:24,217 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:24,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:24,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:24,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:24,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:24,298 [IPC Server handler 0 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:24,298 [IPC Server handler 0 on default port 32791] INFO  node.NodeStateManager (NodeStateManager.java:newNodeStatus(338)) - Updating nodeOperationalState on registration as the datanode has a persisted state of IN_MAINTENANCE and expiry of 0
2023-01-03 14:06:24,298 [IPC Server handler 0 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,323 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-01-03 14:06:24,324 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-01-03 14:06:24,342 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-01-03 14:06:24,342 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-01-03 14:06:24,346 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,346 [EventQueue-NewNodeForNewNodeHandler] INFO  node.NodeDecommissionManager (NodeDecommissionManager.java:continueAdminForNode(267)) - Continue admin for datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,347 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-6/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-4f6ec218-6348-465c-b2e0-b0f922ce0be5/container.db for volume DS-4f6ec218-6348-465c-b2e0-b0f922ce0be5
2023-01-03 14:06:24,348 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:24,348 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:24,349 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:24,358 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@2ba2529c{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:24,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,359 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@6a918bff{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:24,359 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:24,360 [ForkJoinPool.commonPool-worker-0] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-0/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-0d462afc-1ed9-4dae-a477-a00d6f7b0368/container.db for volume DS-0d462afc-1ed9-4dae-a477-a00d6f7b0368
2023-01-03 14:06:24,360 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:24,360 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@40f0586{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:24,360 [ForkJoinPool.commonPool-worker-0] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:24,363 [ForkJoinPool.commonPool-worker-0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:24,367 [IPC Server handler 1 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:24,367 [IPC Server handler 1 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,367 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,367 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-01-03 14:06:24,368 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-01-03 14:06:24,361 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4e3c256f{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:24,377 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@4de41d1{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:24,378 [ForkJoinPool.commonPool-worker-0] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@63c2417b{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:24,378 [ForkJoinPool.commonPool-worker-0] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:24,380 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,381 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:24,382 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@14769ef8{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:24,382 [ForkJoinPool.commonPool-worker-0] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@24a0ff5d{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:24,384 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: close
2023-01-03 14:06:24,384 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:24,384 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B: shutdown
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-E75C438DA29B,id=773b8dbf-6336-4037-abee-6d5bd5e00f08
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: shutdown 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-StateMachineUpdater: set stopIndex = -1
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-FollowerState was interrupted
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  server.RaftServer$Division (ServerState.java:close(466)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B: closes. applyIndex: -1
2023-01-03 14:06:24,385 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:06:24,385 [773b8dbf-6336-4037-abee-6d5bd5e00f08-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdbadd10f, L:/0:0:0:0:0:0:0:0:43165] CLOSE
2023-01-03 14:06:24,386 [773b8dbf-6336-4037-abee-6d5bd5e00f08-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdbadd10f, L:/0:0:0:0:0:0:0:0:43165] INACTIVE
2023-01-03 14:06:24,386 [773b8dbf-6336-4037-abee-6d5bd5e00f08-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xdbadd10f, L:/0:0:0:0:0:0:0:0:43165] UNREGISTERED
2023-01-03 14:06:24,386 [773b8dbf-6336-4037-abee-6d5bd5e00f08-impl-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - 773b8dbf-6336-4037-abee-6d5bd5e00f08@group-E75C438DA29B-SegmentedRaftLogWorker close()
2023-01-03 14:06:24,393 [JvmPauseMonitor50] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-773b8dbf-6336-4037-abee-6d5bd5e00f08: Stopped
2023-01-03 14:06:24,426 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=1509e613-77e1-4ee2-81e9-57bb3b5eca4b]
2023-01-03 14:06:24,426 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 1509e613-77e1-4ee2-81e9-57bb3b5eca4b, Nodes: e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:e9b53549-c119-47d5-a583-bc601a9ace80, CreationTimestamp2023-01-03T14:04:32.048Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:24,443 [IPC Server handler 2 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a13c81fc-644c-4ecf-91c3-6e9a75ed36aa
2023-01-03 14:06:24,444 [IPC Server handler 2 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,444 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,446 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,446 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 0, required at least one datanode reported per pipeline count is 1
2023-01-03 14:06:24,446 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-01-03 14:06:24,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-01-03 14:06:24,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-01-03 14:06:24,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-01-03 14:06:24,449 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,464 [IPC Server handler 0 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:24,464 [IPC Server handler 0 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 56e9ebea-1da6-4510-b9da-2a36b64eada2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35233, RATIS=39427, RATIS_ADMIN=39427, RATIS_SERVER=39427, RATIS_DATASTREAM=35533, STANDALONE=33637], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,464 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,466 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-01-03 14:06:24,467 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=fde9ffad-ff0c-4976-a307-3fc619618735 to datanode:56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:24,467 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: fde9ffad-ff0c-4976-a307-3fc619618735, Nodes: 56e9ebea-1da6-4510-b9da-2a36b64eada2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35233, RATIS=39427, RATIS_ADMIN=39427, RATIS_SERVER=39427, RATIS_DATASTREAM=35533, STANDALONE=33637], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:24.467Z[Etc/UTC]].
2023-01-03 14:06:24,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,655 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:24,726 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines [PipelineID=63169f10-7458-4b53-8652-46c5b9cba191]
2023-01-03 14:06:24,727 [IPC Server handler 3 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c36dba4c-5c72-465b-8876-3f5e456990a2
2023-01-03 14:06:24,727 [EventQueue-StaleNodeForStaleNodeHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:closePipeline(442)) - Pipeline Pipeline[ Id: 63169f10-7458-4b53-8652-46c5b9cba191, Nodes: 4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:OPEN, leaderId:4db05c90-fb2b-44c1-a5c3-62f45e9c05ff, CreationTimestamp2023-01-03T14:04:33.985Z[Etc/UTC]] moved to CLOSED state
2023-01-03 14:06:24,727 [IPC Server handler 3 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : c36dba4c-5c72-465b-8876-3f5e456990a2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34999, RATIS=37333, RATIS_ADMIN=37333, RATIS_SERVER=37333, RATIS_DATASTREAM=37189, STANDALONE=37423], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,727 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,731 [IPC Server handler 4 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e673a28b-a4f0-4b9b-b939-463b757d484f
2023-01-03 14:06:24,730 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,730 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 1
2023-01-03 14:06:24,732 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-01-03 14:06:24,731 [IPC Server handler 4 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : e673a28b-a4f0-4b9b-b939-463b757d484f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=39651, RATIS=32789, RATIS_ADMIN=32789, RATIS_SERVER=32789, RATIS_DATASTREAM=33659, STANDALONE=35199], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,732 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,732 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,745 [IPC Server handler 5 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:24,745 [IPC Server handler 5 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,745 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,747 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,749 [IPC Server handler 6 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1f39c4a2-123f-4ca0-aca4-b650c3c85ddf
2023-01-03 14:06:24,749 [IPC Server handler 6 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,749 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-01-03 14:06:24,749 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-01-03 14:06:24,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-01-03 14:06:24,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-01-03 14:06:24,750 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:24,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-01-03 14:06:24,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(918)) - Service ReplicationManager transitions to RUNNING.
2023-01-03 14:06:24,750 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-01-03 14:06:24,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:24,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:24,783 [EventQueue-StartAdminOnNodeForStartDatanodeAdminHandler] INFO  node.StartDatanodeAdminHandler (StartDatanodeAdminHandler.java:onMessage(57)) - Admin start on datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}. Finalizing its pipelines []
2023-01-03 14:06:24,806 [IPC Server handler 18 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:24,806 [IPC Server handler 18 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 3a3da11c-e5c3-43e0-8561-5c3126dc697f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42411, RATIS=45127, RATIS_ADMIN=45127, RATIS_SERVER=45127, RATIS_DATASTREAM=43551, STANDALONE=37815], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:24,806 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-01-03 14:06:24,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-01-03 14:06:24,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-01-03 14:06:24,809 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-01-03 14:06:24,810 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:24,810 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=1d686bf7-d384-4098-b977-8ee01340381c to datanode:3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:24,810 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 1d686bf7-d384-4098-b977-8ee01340381c, Nodes: 3a3da11c-e5c3-43e0-8561-5c3126dc697f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42411, RATIS=45127, RATIS_ADMIN=45127, RATIS_SERVER=45127, RATIS_DATASTREAM=43551, STANDALONE=37815], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:24.810Z[Etc/UTC]].
2023-01-03 14:06:24,810 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=80270caf-3929-4273-963a-b90486f78806 to datanode:56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:24,810 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=80270caf-3929-4273-963a-b90486f78806 to datanode:af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:24,810 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=80270caf-3929-4273-963a-b90486f78806 to datanode:3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:24,811 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 80270caf-3929-4273-963a-b90486f78806, Nodes: 56e9ebea-1da6-4510-b9da-2a36b64eada2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35233, RATIS=39427, RATIS_ADMIN=39427, RATIS_SERVER=39427, RATIS_DATASTREAM=35533, STANDALONE=33637], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}af27b707-902e-436a-b36c-df002345c922{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=38645, RATIS=40275, RATIS_ADMIN=40275, RATIS_SERVER=40275, RATIS_DATASTREAM=42839, STANDALONE=40537], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3a3da11c-e5c3-43e0-8561-5c3126dc697f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42411, RATIS=45127, RATIS_ADMIN=45127, RATIS_SERVER=45127, RATIS_DATASTREAM=43551, STANDALONE=37815], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:24.810Z[Etc/UTC]].
2023-01-03 14:06:24,811 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:24,811 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:24,947 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:24,947 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Cluster exits safe mode
2023-01-03 14:06:24,947 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:24,953 [Listener at 0.0.0.0/40427] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:06:24,953 [Listener at 0.0.0.0/40427] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - 8161063e-a6c1-4ab4-9440-f30963410d31: close
2023-01-03 14:06:24,954 [Listener at 0.0.0.0/40427] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - 8161063e-a6c1-4ab4-9440-f30963410d31: shutdown server GrpcServerProtocolService now
2023-01-03 14:06:24,958 [Listener at 0.0.0.0/40427] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7c948c4b-a779-4597-819f-06099ef104a1 Close channels
2023-01-03 14:06:24,959 [grpc-default-executor-2] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:06:24,962 [Listener at 0.0.0.0/40427] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2 Close channels
2023-01-03 14:06:24,963 [Listener at 0.0.0.0/40427] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - 8161063e-a6c1-4ab4-9440-f30963410d31: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:06:24,963 [8161063e-a6c1-4ab4-9440-f30963410d31-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xff0619e8, L:/0:0:0:0:0:0:0:0:36601] CLOSE
2023-01-03 14:06:24,963 [8161063e-a6c1-4ab4-9440-f30963410d31-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xff0619e8, L:/0:0:0:0:0:0:0:0:36601] INACTIVE
2023-01-03 14:06:24,964 [8161063e-a6c1-4ab4-9440-f30963410d31-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xff0619e8, L:/0:0:0:0:0:0:0:0:36601] UNREGISTERED
2023-01-03 14:06:24,965 [JvmPauseMonitor38] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-8161063e-a6c1-4ab4-9440-f30963410d31: Stopped
2023-01-03 14:06:24,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 3 of 7 DN Heartbeats.
2023-01-03 14:06:24,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:24,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:25,088 [IPC Server handler 16 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:25,089 [IPC Server handler 16 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41099, RATIS=35277, RATIS_ADMIN=35277, RATIS_SERVER=35277, RATIS_DATASTREAM=32925, STANDALONE=44421], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:25,089 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:25,089 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=eae543f6-77ba-41c0-8e28-5795c9144dab to datanode:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:25,089 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: eae543f6-77ba-41c0-8e28-5795c9144dab, Nodes: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41099, RATIS=35277, RATIS_ADMIN=35277, RATIS_SERVER=35277, RATIS_DATASTREAM=32925, STANDALONE=44421], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:25.089Z[Etc/UTC]].
2023-01-03 14:06:25,090 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-01-03 14:06:25,183 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,204 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:25,204 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,213 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #8, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-01-03 14:06:25,213 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(225)) - Container #8 is under replicated, but no commands were created to correct it
2023-01-03 14:06:25,213 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #11, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {4=(ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=773b8dbf-6336-4037-abee-6d5bd5e00f08, sequenceId=0, keyCount=2, bytesUsed=38,replicaIndex=4},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-01-03 14:06:25,213 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(225)) - Container #11 is under replicated, but no commands were created to correct it
2023-01-03 14:06:25,213 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #10, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 0. Available sources are: {}
2023-01-03 14:06:25,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(225)) - Container #10 is under replicated, but no commands were created to correct it
2023-01-03 14:06:25,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {5=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=773b8dbf-6336-4037-abee-6d5bd5e00f08, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-01-03 14:06:25,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(225)) - Container #7 is under replicated, but no commands were created to correct it
2023-01-03 14:06:25,214 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 4 containers with health state counts {UNDER_REPLICATED=4},failed processing 0
2023-01-03 14:06:25,217 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(213)) - No healthy node found to allocate container.
2023-01-03 14:06:25,217 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1229)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:214)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:180)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:122)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1193)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:540)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:345)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:661)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:25,217 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,217 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,218 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,218 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,218 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,218 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:25,218 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:25,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:25,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:25,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:25,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:25,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,367 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,377 [IPC Server handler 15 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:25,377 [IPC Server handler 15 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 7aee5cb6-4ed9-41f9-a897-fb72e55180cb{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34583, RATIS=39571, RATIS_ADMIN=39571, RATIS_SERVER=39571, RATIS_DATASTREAM=36099, STANDALONE=34845], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:25,377 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:25,377 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=cecbd130-d4c8-4cf7-8d9d-310da0bf428c to datanode:7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:25,378 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: cecbd130-d4c8-4cf7-8d9d-310da0bf428c, Nodes: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34583, RATIS=39571, RATIS_ADMIN=39571, RATIS_SERVER=39571, RATIS_DATASTREAM=36099, STANDALONE=34845], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:25.377Z[Etc/UTC]].
2023-01-03 14:06:25,378 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 2.
2023-01-03 14:06:25,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,527 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:25,527 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=e5c39811-52ae-4ced-85ba-023dda6062a6 close command to datanode edb1aef9-02a8-4817-80a7-afb47d970b52
2023-01-03 14:06:25,527 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: e5c39811-52ae-4ced-85ba-023dda6062a6, Nodes: edb1aef9-02a8-4817-80a7-afb47d970b52{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=46341, RATIS=40281, RATIS_ADMIN=40281, RATIS_SERVER=40281, RATIS_DATASTREAM=43563, STANDALONE=42305], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:edb1aef9-02a8-4817-80a7-afb47d970b52, CreationTimestamp2023-01-03T14:04:32.742Z[Etc/UTC]] removed.
2023-01-03 14:06:25,528 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/edb1aef9-02a8-4817-80a7-afb47d970b52
2023-01-03 14:06:25,528 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:25,528 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$close$4(272)) - Send pipeline:PipelineID=7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3 close command to datanode 89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:25,528 [EventQueue-DeadNodeForDeadNodeHandler] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:removePipeline(245)) - Pipeline Pipeline[ Id: 7dfaaaba-f6bd-4e95-abd5-cc0a89235ca3, Nodes: 89282906-b815-4a6d-bda0-404bb113e200{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45967, RATIS=46873, RATIS_ADMIN=46873, RATIS_SERVER=46873, RATIS_DATASTREAM=46133, STANDALONE=33109], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:CLOSED, leaderId:89282906-b815-4a6d-bda0-404bb113e200, CreationTimestamp2023-01-03T14:04:33.065Z[Etc/UTC]] removed.
2023-01-03 14:06:25,528 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/89282906-b815-4a6d-bda0-404bb113e200
2023-01-03 14:06:25,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,656 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,671 [IPC Server handler 19 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:25,671 [IPC Server handler 19 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 19aec3d0-bc58-440a-899b-3969d29112cc{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45245, RATIS=43677, RATIS_ADMIN=43677, RATIS_SERVER=43677, RATIS_DATASTREAM=39215, STANDALONE=44805], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:25,671 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:25,671 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=1d038acb-b53a-4a03-b0f2-2661c4d1f0c0 to datanode:19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:25,671 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 1d038acb-b53a-4a03-b0f2-2661c4d1f0c0, Nodes: 19aec3d0-bc58-440a-899b-3969d29112cc{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45245, RATIS=43677, RATIS_ADMIN=43677, RATIS_SERVER=43677, RATIS_DATASTREAM=39215, STANDALONE=44805], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:25.671Z[Etc/UTC]].
2023-01-03 14:06:25,672 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=422993b3-7658-48b0-9cb4-7662fb7dda7e to datanode:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:25,672 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=422993b3-7658-48b0-9cb4-7662fb7dda7e to datanode:7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:25,672 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=422993b3-7658-48b0-9cb4-7662fb7dda7e to datanode:19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:25,672 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: 422993b3-7658-48b0-9cb4-7662fb7dda7e, Nodes: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41099, RATIS=35277, RATIS_ADMIN=35277, RATIS_SERVER=35277, RATIS_DATASTREAM=32925, STANDALONE=44421], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7aee5cb6-4ed9-41f9-a897-fb72e55180cb{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34583, RATIS=39571, RATIS_ADMIN=39571, RATIS_SERVER=39571, RATIS_DATASTREAM=36099, STANDALONE=34845], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}19aec3d0-bc58-440a-899b-3969d29112cc{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45245, RATIS=43677, RATIS_ADMIN=43677, RATIS_SERVER=43677, RATIS_DATASTREAM=39215, STANDALONE=44805], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:25.672Z[Etc/UTC]].
2023-01-03 14:06:25,672 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:25,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,782 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:25,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:25,964 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:25,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Waiting for nodes to be ready. Got 6 of 7 DN Heartbeats.
2023-01-03 14:06:25,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:25,988 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:26,017 [IPC Server handler 16 on default port 42125] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/bc03f53a-8f38-42c1-b7a4-94894081fc1e
2023-01-03 14:06:26,017 [IPC Server handler 16 on default port 42125] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : bc03f53a-8f38-42c1-b7a4-94894081fc1e{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=44929, RATIS=33781, RATIS_ADMIN=33781, RATIS_SERVER=33781, RATIS_DATASTREAM=33549, STANDALONE=38729], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:26,018 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:26,018 [RatisPipelineUtilsThread - 0] INFO  pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$create$0(206)) - Sending CreatePipelineCommand for pipeline:PipelineID=f4e003f7-18cf-450a-985e-e4b8aa55d0e2 to datanode:bc03f53a-8f38-42c1-b7a4-94894081fc1e
2023-01-03 14:06:26,018 [RatisPipelineUtilsThread - 0] INFO  pipeline.PipelineStateManagerImpl (PipelineStateManagerImpl.java:addPipeline(103)) - Created pipeline Pipeline[ Id: f4e003f7-18cf-450a-985e-e4b8aa55d0e2, Nodes: bc03f53a-8f38-42c1-b7a4-94894081fc1e{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=44929, RATIS=33781, RATIS_ADMIN=33781, RATIS_SERVER=33781, RATIS_DATASTREAM=33549, STANDALONE=38729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-03T14:06:26.018Z[Etc/UTC]].
2023-01-03 14:06:26,019 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 1.
2023-01-03 14:06:26,183 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,189 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,204 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:26,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(140)) - The container #8 is unrecoverable. The available replicas are: [ContainerReplica{containerID=#8, state=CLOSED, datanodeDetails=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff, sequenceId=0, keyCount=5, bytesUsed=0,replicaIndex=3}].
2023-01-03 14:06:26,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(140)) - The container #11 is unrecoverable. The available replicas are: [ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e9b53549-c119-47d5-a583-bc601a9ace80, sequenceId=0, keyCount=2, bytesUsed=38,replicaIndex=1}, ContainerReplica{containerID=#11, state=CLOSED, datanodeDetails=773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=773b8dbf-6336-4037-abee-6d5bd5e00f08, sequenceId=0, keyCount=2, bytesUsed=38,replicaIndex=4}].
2023-01-03 14:06:26,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(140)) - The container #10 is unrecoverable. The available replicas are: [ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=e9b53549-c119-47d5-a583-bc601a9ace80, sequenceId=0, keyCount=6, bytesUsed=0,replicaIndex=2}, ContainerReplica{containerID=#10, state=CLOSED, datanodeDetails=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43709, RATIS=34451, RATIS_ADMIN=34451, RATIS_SERVER=34451, RATIS_DATASTREAM=44223, STANDALONE=38633], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=4db05c90-fb2b-44c1-a5c3-62f45e9c05ff, sequenceId=0, keyCount=6, bytesUsed=114,replicaIndex=5}].
2023-01-03 14:06:26,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processMissingIndexes(327)) - Cannot proceed for EC container reconstruction for #7, due to insufficient source replicas found. Number of source replicas needed: 3. Number of available source replicas are: 1. Available sources are: {5=(ContainerReplica{containerID=#7, state=CLOSED, datanodeDetails=773b8dbf-6336-4037-abee-6d5bd5e00f08{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=43073, RATIS=43245, RATIS_ADMIN=43245, RATIS_SERVER=43245, RATIS_DATASTREAM=46643, STANDALONE=45411], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, placeOfBirth=773b8dbf-6336-4037-abee-6d5bd5e00f08, sequenceId=0, keyCount=3, bytesUsed=57,replicaIndex=5},OperationalState: IN_SERVICE Health: HEALTHY OperationStateExpiry: 0)}
2023-01-03 14:06:26,214 [Under Replicated Processor] WARN  replication.ECUnderReplicationHandler (ECUnderReplicationHandler.java:processAndCreateCommands(225)) - Container #7 is under replicated, but no commands were created to correct it
2023-01-03 14:06:26,214 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 4 containers with health state counts {UNDER_REPLICATED=4},failed processing 0
2023-01-03 14:06:26,218 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(213)) - No healthy node found to allocate container.
2023-01-03 14:06:26,218 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1229)) - Exception while replicating container 1.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:214)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:180)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:122)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1193)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:540)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:345)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:661)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:26,219 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(213)) - No healthy node found to allocate container.
2023-01-03 14:06:26,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1229)) - Exception while replicating container 2.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:214)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:180)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:122)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1193)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:540)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:345)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:661)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:26,219 [ReplicationMonitor] ERROR scm.SCMCommonPlacementPolicy (SCMCommonPlacementPolicy.java:chooseDatanodesInternal(213)) - No healthy node found to allocate container.
2023-01-03 14:06:26,219 [ReplicationMonitor] WARN  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1229)) - Exception while replicating container 3.
org.apache.hadoop.hdds.scm.exceptions.SCMException: No healthy node found to allocate container.
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodesInternal(SCMCommonPlacementPolicy.java:214)
	at org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom.chooseDatanodesInternal(SCMContainerPlacementRandom.java:82)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:180)
	at org.apache.hadoop.hdds.scm.SCMCommonPlacementPolicy.chooseDatanodes(SCMCommonPlacementPolicy.java:122)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.handleUnderReplicatedContainer(LegacyReplicationManager.java:1193)
	at org.apache.hadoop.hdds.scm.container.replication.LegacyReplicationManager.processContainer(LegacyReplicationManager.java:540)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.processAll(ReplicationManager.java:345)
	at org.apache.hadoop.hdds.scm.container.replication.ReplicationManager.run(ReplicationManager.java:661)
	at java.lang.Thread.run(Thread.java:750)
2023-01-03 14:06:26,219 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #4 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:26,219 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #5 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:26,219 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendCloseCommand(1513)) - Sending close container command for container #6 to datanode e9b53549-c119-47d5-a583-bc601a9ace80{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=40163, RATIS=39941, RATIS_ADMIN=39941, RATIS_SERVER=39941, RATIS_DATASTREAM=35775, STANDALONE=46273], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}.
2023-01-03 14:06:26,219 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 11 containers.
2023-01-03 14:06:26,240 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:26,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:26,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:26,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:26,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,367 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,400 [Mini-Cluster-Provider-Reap] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/datanode-5/data-0/containers/hdds/ec40c89a-20d8-4cbf-9e36-c5ab83f38baa/DS-516e61a4-7fb5-483a-811f-abf3c63b4cf5/container.db for volume DS-516e61a4-7fb5-483a-811f-abf3c63b4cf5
2023-01-03 14:06:26,403 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:26,403 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:26,412 [Mini-Cluster-Provider-Reap] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:26,423 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@43120a77{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:26,426 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@1b120d48{HTTP/1.1, (http/1.1)}{0.0.0.0:34925}
2023-01-03 14:06:26,426 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:26,427 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@87f1201{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:26,428 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@539bb233{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:26,429 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopSCM(538)) - Stopping the StorageContainerManager
2023-01-03 14:06:26,429 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1518)) - Container Balancer is not running.
2023-01-03 14:06:26,429 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1525)) - Stopping Replication Manager Service.
2023-01-03 14:06:26,429 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(296)) - Stopping Replication Monitor Thread.
2023-01-03 14:06:26,429 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Under Replicated Processor interrupted. Exiting...
2023-01-03 14:06:26,430 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Over Replicated Processor interrupted. Exiting...
2023-01-03 14:06:26,434 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Stopping the Datanode Admin Monitor.
2023-01-03 14:06:26,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(666)) - Replication Monitor Thread is stopped
2023-01-03 14:06:26,435 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping datanode service RPC server
2023-01-03 14:06:26,435 [Mini-Cluster-Provider-Reap] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-01-03 14:06:26,436 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 43171
2023-01-03 14:06:26,437 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:26,441 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:26,444 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,467 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,528 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-01-03 14:06:26,528 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1547)) - Stopping block service RPC server
2023-01-03 14:06:26,529 [Mini-Cluster-Provider-Reap] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-01-03 14:06:26,530 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 35595
2023-01-03 14:06:26,532 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:26,534 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:26,534 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1554)) - Stopping the StorageContainerLocationProtocol RPC server
2023-01-03 14:06:26,534 [Mini-Cluster-Provider-Reap] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-01-03 14:06:26,536 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 40885
2023-01-03 14:06:26,538 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:06:26,539 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:26,539 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping Storage Container Manager HTTP server.
2023-01-03 14:06:26,542 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@67f654fa{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:26,543 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@74bf87e2{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:26,543 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:26,543 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@4b581d94{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-01-03 14:06:26,543 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1ff9cb93{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:26,547 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1567)) - Stopping SCM LayoutVersionManager Service.
2023-01-03 14:06:26,547 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Block Manager Service.
2023-01-03 14:06:26,547 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:26,547 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:26,547 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1597)) - Stopping SCM Event Queue.
2023-01-03 14:06:26,551 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1608)) - Stopping SCM HA services.
2023-01-03 14:06:26,551 [Mini-Cluster-Provider-Reap] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-01-03 14:06:26,551 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-01-03 14:06:26,551 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-01-03 14:06:26,551 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-01-03 14:06:26,552 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping StorageContainerManager metrics system...
2023-01-03 14:06:26,559 [prometheus] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:publishMetricsFromQueue(141)) - prometheus thread interrupted.
2023-01-03 14:06:26,559 [Mini-Cluster-Provider-Reap] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - StorageContainerManager metrics system stopped.
2023-01-03 14:06:26,559 [Mini-Cluster-Provider-Reap] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-01-03 14:06:26,559 [Mini-Cluster-Provider-Reap] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-01-03 14:06:26,559 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-01-03 14:06:26,559 [Mini-Cluster-Provider-Reap] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:26,560 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:26,560 [Mini-Cluster-Provider-Reap] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Replication Monitor Thread is not running.
2023-01-03 14:06:26,560 [Mini-Cluster-Provider-Reap] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-01-03 14:06:26,560 [Mini-Cluster-Provider-Reap] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1626)) - Stopping SCM MetadataStore.
2023-01-03 14:06:26,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,657 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,733 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:26,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:26,807 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,959 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,959 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - af27b707-902e-436a-b36c-df002345c922: addNew group-911A592A5DE1:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER] returns group-911A592A5DE1:java.util.concurrent.CompletableFuture@124df04[Not completed]
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - af27b707-902e-436a-b36c-df002345c922: new RaftServerImpl for group-911A592A5DE1:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: ConfigurationManager, init=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:26,960 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis] (custom)
2023-01-03 14:06:26,961 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:26,961 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:26,961 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:26,961 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:26,961 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:26,962 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:26,962 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:26,962 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:26,962 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:26,962 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:26,963 [pool-2519-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/7a992f2c-1f6d-4807-9430-911a592a5de1 does not exist. Creating ...
2023-01-03 14:06:26,966 [pool-2519-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/7a992f2c-1f6d-4807-9430-911a592a5de1/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:26,967 [pool-2519-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/7a992f2c-1f6d-4807-9430-911a592a5de1 has been successfully formatted.
2023-01-03 14:06:26,967 [pool-2519-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-911A592A5DE1: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:26,968 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 7a992f2c-1f6d-4807-9430-911a592a5de1, Nodes: af27b707-902e-436a-b36c-df002345c922{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=38645, RATIS=40275, RATIS_ADMIN=40275, RATIS_SERVER=40275, RATIS_DATASTREAM=42839, STANDALONE=40537], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:af27b707-902e-436a-b36c-df002345c922, CreationTimestamp2023-01-03T14:06:23.973Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:26,968 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:26,968 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/7a992f2c-1f6d-4807-9430-911a592a5de1
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:26,969 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:26,988 [Listener at 0.0.0.0/40427] INFO  volume.HddsVolume (HddsVolume.java:closeDbStore(338)) - SchemaV3 db is stopped at /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-4/data-0/containers/hdds/3c2c4fca-0adc-4555-9097-bcf769140b1a/DS-be2e17a7-d576-434c-ba3f-f9bde65bf023/container.db for volume DS-be2e17a7-d576-434c-ba3f-f9bde65bf023
2023-01-03 14:06:26,991 [Listener at 0.0.0.0/40427] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service BlockDeletingService
2023-01-03 14:06:26,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:26,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:26,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:26,993 [Listener at 0.0.0.0/40427] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service StaleRecoveringContainerScrubbingService
2023-01-03 14:06:26,994 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:26,995 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,000 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,000 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,000 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,000 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,000 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,007 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: start as a follower, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,007 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:27,007 [Listener at 0.0.0.0/40427] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(596)) - Ozone container server stopped.
2023-01-03 14:06:27,007 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,008 [pool-2519-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState
2023-01-03 14:06:27,009 [pool-2519-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-911A592A5DE1,id=af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:27,009 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,009 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,009 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,009 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,009 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,010 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,010 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=7a992f2c-1f6d-4807-9430-911a592a5de1
2023-01-03 14:06:27,010 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=7a992f2c-1f6d-4807-9430-911a592a5de1.
2023-01-03 14:06:27,010 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - af27b707-902e-436a-b36c-df002345c922: addNew group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] returns group-B90486F78806:java.util.concurrent.CompletableFuture@51b5bf8[Not completed]
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - af27b707-902e-436a-b36c-df002345c922: new RaftServerImpl for group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: ConfigurationManager, init=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis] (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:27,011 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:27,012 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,013 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:27,013 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:27,013 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:27,013 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:27,013 [pool-2519-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/80270caf-3929-4273-963a-b90486f78806 does not exist. Creating ...
2023-01-03 14:06:27,014 [pool-2519-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/80270caf-3929-4273-963a-b90486f78806/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:27,015 [pool-2519-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/80270caf-3929-4273-963a-b90486f78806 has been successfully formatted.
2023-01-03 14:06:27,016 [pool-2519-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-B90486F78806: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:27,016 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:27,016 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:27,016 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,016 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:27,016 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@501f3741{hddsDatanode,/,null,STOPPED}{jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
2023-01-03 14:06:27,016 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,017 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:27,017 [Listener at 0.0.0.0/40427] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@681f489c{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:06:27,017 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:27,018 [Listener at 0.0.0.0/40427] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:27,018 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,018 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@28a37585{static,/static,jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-container-service/1.4.0-SNAPSHOT/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,STOPPED}
2023-01-03 14:06:27,018 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@2569ec9e{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:27,018 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:27,018 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/80270caf-3929-4273-963a-b90486f78806
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:27,019 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:27,021 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:27,022 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: start as a follower, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,027 [pool-2519-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B90486F78806,id=af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:27,028 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,028 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,028 [pool-2519-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,029 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=80270caf-3929-4273-963a-b90486f78806
2023-01-03 14:06:27,034 [grpc-default-executor-10] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: addNew group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] returns group-B90486F78806:java.util.concurrent.CompletableFuture@4518791f[Not completed]
2023-01-03 14:06:27,034 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: new RaftServerImpl for group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: ConfigurationManager, init=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis] (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:27,035 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:27,037 [pool-2543-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/80270caf-3929-4273-963a-b90486f78806 does not exist. Creating ...
2023-01-03 14:06:27,038 [pool-2543-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/80270caf-3929-4273-963a-b90486f78806/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:27,039 [pool-2543-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/80270caf-3929-4273-963a-b90486f78806 has been successfully formatted.
2023-01-03 14:06:27,040 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,040 [pool-2543-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-B90486F78806: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:27,040 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:27,040 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:27,040 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,040 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:27,042 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:27,042 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/80270caf-3929-4273-963a-b90486f78806
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:27,043 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:27,044 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:27,045 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,051 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,051 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,051 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,051 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,051 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: start as a follower, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B90486F78806,id=56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:27,052 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,052 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,052 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,060 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: addNew group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] returns group-B90486F78806:java.util.concurrent.CompletableFuture@655f8db8[Not completed]
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: new RaftServerImpl for group-B90486F78806:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:27,060 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: ConfigurationManager, init=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis] (custom)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:27,061 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:27,062 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,062 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:27,062 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:27,063 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:27,063 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:27,063 [pool-2578-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/80270caf-3929-4273-963a-b90486f78806 does not exist. Creating ...
2023-01-03 14:06:27,063 [pool-2578-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/80270caf-3929-4273-963a-b90486f78806/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:27,064 [pool-2578-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/80270caf-3929-4273-963a-b90486f78806 has been successfully formatted.
2023-01-03 14:06:27,064 [pool-2578-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-B90486F78806: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:27,065 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,065 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/80270caf-3929-4273-963a-b90486f78806
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:27,066 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:27,067 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:27,067 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,072 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,072 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,072 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,072 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,072 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: start as a follower, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-B90486F78806,id=3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:27,073 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,073 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,073 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,082 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=80270caf-3929-4273-963a-b90486f78806.
2023-01-03 14:06:27,088 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,190 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,203 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,241 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:27,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:27,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:27,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:27,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,368 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,368 [EventQueue-StaleNodeForStaleNodeHandler] INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(59)) - Datanode 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0} moved to stale state. Finalizing its pipelines []
2023-01-03 14:06:27,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,464 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: addNew group-3FC619618735:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER] returns group-3FC619618735:java.util.concurrent.CompletableFuture@4b987f3[Not completed]
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: new RaftServerImpl for group-3FC619618735:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: ConfigurationManager, init=-1: peers:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:27,464 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis] (custom)
2023-01-03 14:06:27,465 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:27,465 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:27,465 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:27,465 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:27,465 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:27,466 [pool-2543-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/fde9ffad-ff0c-4976-a307-3fc619618735 does not exist. Creating ...
2023-01-03 14:06:27,467 [pool-2543-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/fde9ffad-ff0c-4976-a307-3fc619618735/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:27,468 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5036536516ns, electionTimeout:5035ms
2023-01-03 14:06:27,468 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7c948c4b-a779-4597-819f-06099ef104a1: shutdown 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:27,468 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:27,468 [pool-2543-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/fde9ffad-ff0c-4976-a307-3fc619618735 has been successfully formatted.
2023-01-03 14:06:27,468 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:27,468 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7c948c4b-a779-4597-819f-06099ef104a1: start 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103
2023-01-03 14:06:27,469 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,469 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: fde9ffad-ff0c-4976-a307-3fc619618735, Nodes: 56e9ebea-1da6-4510-b9da-2a36b64eada2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35233, RATIS=39427, RATIS_ADMIN=39427, RATIS_SERVER=39427, RATIS_DATASTREAM=35533, STANDALONE=33637], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:56e9ebea-1da6-4510-b9da-2a36b64eada2, CreationTimestamp2023-01-03T14:06:24.467Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-3FC619618735: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,470 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:27,470 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103 ELECTION round 0: submit vote requests at term 1 for -1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:27,470 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,470 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for a13c81fc-644c-4ecf-91c3-6e9a75ed36aa
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/fde9ffad-ff0c-4976-a307-3fc619618735
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:27,471 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:27,473 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,473 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,473 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:27,475 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: receive requestVote(ELECTION, 7c948c4b-a779-4597-819f-06099ef104a1, group-03ABF1FB5BF6, 1, (t:0, i:0))
2023-01-03 14:06:27,475 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FOLLOWER: accept ELECTION from 7c948c4b-a779-4597-819f-06099ef104a1: our priority 0 <= candidate's priority 1
2023-01-03 14:06:27,475 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:27,475 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: shutdown a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:27,475 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: start a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:27,475 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState was interrupted
2023-01-03 14:06:27,477 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: receive requestVote(ELECTION, 7c948c4b-a779-4597-819f-06099ef104a1, group-03ABF1FB5BF6, 1, (t:0, i:0))
2023-01-03 14:06:27,478 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(49)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FOLLOWER: accept ELECTION from 7c948c4b-a779-4597-819f-06099ef104a1: our priority 0 <= candidate's priority 1
2023-01-03 14:06:27,478 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:27,478 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:27,478 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: start f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:06:27,478 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:27,478 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState was interrupted
2023-01-03 14:06:27,478 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6 replies to ELECTION vote request: 7c948c4b-a779-4597-819f-06099ef104a1<-a13c81fc-644c-4ecf-91c3-6e9a75ed36aa#0:OK-t1. Peer's state: a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6:t1, leader=null, voted=7c948c4b-a779-4597-819f-06099ef104a1, raftlog=Memoized:a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,479 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,479 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,479 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 7c948c4b-a779-4597-819f-06099ef104a1<-a13c81fc-644c-4ecf-91c3-6e9a75ed36aa#0:OK-t1
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103 ELECTION round 0: result PASSED
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 7c948c4b-a779-4597-819f-06099ef104a1: shutdown 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-03ABF1FB5BF6 with new leaderId: 7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: change Leader from null to 7c948c4b-a779-4597-819f-06099ef104a1 at term 1 for becomeLeader, leader elected after 5121ms
2023-01-03 14:06:27,481 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:27,482 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:27,483 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-01-03 14:06:27,484 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6, Nodes: a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:7c948c4b-a779-4597-819f-06099ef104a1, CreationTimestamp2023-01-03T14:06:22.763Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:27,484 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,485 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-01-03 14:06:27,485 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6 replies to ELECTION vote request: 7c948c4b-a779-4597-819f-06099ef104a1<-f6318f2f-492d-4bd7-ad30-0c72f4db1bf2#0:OK-t1. Peer's state: f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6:t1, leader=null, voted=7c948c4b-a779-4597-819f-06099ef104a1, raftlog=Memoized:f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,485 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,485 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7c948c4b-a779-4597-819f-06099ef104a1: start 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderStateImpl
2023-01-03 14:06:27,486 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:27,487 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,487 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,488 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-5/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/current/log_inprogress_0
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: start as a follower, conf=-1: peers:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,489 [pool-2543-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,491 [pool-2543-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState
2023-01-03 14:06:27,494 [7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6-LeaderElection103] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6: set configuration 0: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,498 [pool-2543-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-3FC619618735,id=56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:27,498 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,498 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,498 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,498 [pool-2543-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,499 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,499 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,503 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-03ABF1FB5BF6 with new leaderId: 7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:27,503 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: change Leader from null to 7c948c4b-a779-4597-819f-06099ef104a1 at term 1 for appendEntries, leader elected after 5063ms
2023-01-03 14:06:27,503 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=fde9ffad-ff0c-4976-a307-3fc619618735
2023-01-03 14:06:27,503 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=fde9ffad-ff0c-4976-a307-3fc619618735.
2023-01-03 14:06:27,505 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-03ABF1FB5BF6 with new leaderId: 7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:27,505 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: change Leader from null to 7c948c4b-a779-4597-819f-06099ef104a1 at term 1 for appendEntries, leader elected after 5042ms
2023-01-03 14:06:27,507 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6: set configuration 0: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,507 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:27,510 [a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - a13c81fc-644c-4ecf-91c3-6e9a75ed36aa@group-03ABF1FB5BF6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/current/log_inprogress_0
2023-01-03 14:06:27,516 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: set configuration 0: peers:[a13c81fc-644c-4ecf-91c3-6e9a75ed36aa|rpc:10.1.0.35:42475|dataStream:10.1.0.35:44301|priority:0|startupRole:FOLLOWER, 7c948c4b-a779-4597-819f-06099ef104a1|rpc:10.1.0.35:34705|dataStream:10.1.0.35:35879|priority:1|startupRole:FOLLOWER, f6318f2f-492d-4bd7-ad30-0c72f4db1bf2|rpc:10.1.0.35:44879|dataStream:10.1.0.35:41193|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,516 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:27,517 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/current/log_inprogress_0
2023-01-03 14:06:27,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,657 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,671 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,777 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:27,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:27,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:27,787 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:27,806 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: addNew group-8EE01340381C:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] returns group-8EE01340381C:java.util.concurrent.CompletableFuture@33aa2824[Not completed]
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: new RaftServerImpl for group-8EE01340381C:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:27,806 [pool-2578-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: ConfigurationManager, init=-1: peers:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis] (custom)
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:27,807 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:27,808 [pool-2578-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/1d686bf7-d384-4098-b977-8ee01340381c does not exist. Creating ...
2023-01-03 14:06:27,809 [pool-2578-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/1d686bf7-d384-4098-b977-8ee01340381c/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:27,810 [pool-2578-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/1d686bf7-d384-4098-b977-8ee01340381c has been successfully formatted.
2023-01-03 14:06:27,811 [pool-2578-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-8EE01340381C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:27,811 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:27,811 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:27,811 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 1d686bf7-d384-4098-b977-8ee01340381c, Nodes: 3a3da11c-e5c3-43e0-8561-5c3126dc697f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42411, RATIS=45127, RATIS_ADMIN=45127, RATIS_SERVER=45127, RATIS_DATASTREAM=43551, STANDALONE=37815], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:3a3da11c-e5c3-43e0-8561-5c3126dc697f, CreationTimestamp2023-01-03T14:06:24.810Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:27,811 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:27,811 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,811 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:27,812 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/1d686bf7-d384-4098-b977-8ee01340381c
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:27,812 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:27,813 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:27,813 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:27,813 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:27,813 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:27,813 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:27,814 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:27,814 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:27,819 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:27,819 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:27,819 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:27,819 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,819 [pool-2578-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: start as a follower, conf=-1: peers:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8EE01340381C,id=3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:27,820 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:27,820 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:27,820 [pool-2578-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:27,821 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=1d686bf7-d384-4098-b977-8ee01340381c
2023-01-03 14:06:27,821 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=1d686bf7-d384-4098-b977-8ee01340381c.
2023-01-03 14:06:27,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:27,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:27,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:28,015 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,016 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,017 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,086 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: addNew group-5795C9144DAB:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER] returns group-5795C9144DAB:java.util.concurrent.CompletableFuture@67e5bcbd[Not completed]
2023-01-03 14:06:28,087 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,087 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: new RaftServerImpl for group-5795C9144DAB:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,087 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: ConfigurationManager, init=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis] (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,088 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,090 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/eae543f6-77ba-41c0-8e28-5795c9144dab does not exist. Creating ...
2023-01-03 14:06:28,091 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/eae543f6-77ba-41c0-8e28-5795c9144dab/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,092 [pool-2609-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/eae543f6-77ba-41c0-8e28-5795c9144dab has been successfully formatted.
2023-01-03 14:06:28,092 [pool-2609-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-5795C9144DAB: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,092 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,092 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,092 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,093 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: eae543f6-77ba-41c0-8e28-5795c9144dab, Nodes: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41099, RATIS=35277, RATIS_ADMIN=35277, RATIS_SERVER=35277, RATIS_DATASTREAM=32925, STANDALONE=44421], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, CreationTimestamp2023-01-03T14:06:25.089Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:28,092 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,093 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,093 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,093 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,093 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/eae543f6-77ba-41c0-8e28-5795c9144dab
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,094 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,095 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,095 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,160 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,161 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,161 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,161 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,162 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,162 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: start as a follower, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,162 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,162 [pool-2609-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState
2023-01-03 14:06:28,163 [pool-2609-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-5795C9144DAB,id=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:28,163 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,163 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,163 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,163 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,163 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,163 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,164 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=eae543f6-77ba-41c0-8e28-5795c9144dab
2023-01-03 14:06:28,164 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=eae543f6-77ba-41c0-8e28-5795c9144dab.
2023-01-03 14:06:28,164 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: addNew group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] returns group-7662FB7DDA7E:java.util.concurrent.CompletableFuture@63da3499[Not completed]
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: new RaftServerImpl for group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: ConfigurationManager, init=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis] (custom)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,166 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,167 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,167 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,167 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,168 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e does not exist. Creating ...
2023-01-03 14:06:28,171 [pool-2609-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,173 [pool-2609-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e has been successfully formatted.
2023-01-03 14:06:28,174 [pool-2609-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-7662FB7DDA7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,174 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,174 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,174 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,175 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,175 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,175 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,175 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,175 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,176 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,177 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,178 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,183 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,183 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,183 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,183 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,183 [pool-2609-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,185 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: start as a follower, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,185 [pool-2609-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,185 [pool-2609-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:28,186 [pool-2609-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7662FB7DDA7E,id=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:28,186 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,186 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,186 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,186 [pool-2609-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,187 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,187 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,187 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=422993b3-7658-48b0-9cb4-7662fb7dda7e
2023-01-03 14:06:28,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,193 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: addNew group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] returns group-7662FB7DDA7E:java.util.concurrent.CompletableFuture@2acf5730[Not completed]
2023-01-03 14:06:28,193 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: new RaftServerImpl for group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,193 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,193 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,193 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: ConfigurationManager, init=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis] (custom)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,194 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,195 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,195 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,195 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,195 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,195 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,196 [pool-2632-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e does not exist. Creating ...
2023-01-03 14:06:28,197 [pool-2632-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,198 [pool-2632-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e has been successfully formatted.
2023-01-03 14:06:28,198 [pool-2632-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-7662FB7DDA7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,199 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,199 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,200 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,201 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,202 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,206 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,206 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,211 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,211 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,211 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: start as a follower, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7662FB7DDA7E,id=7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:28,212 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,212 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,212 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,213 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,220 [grpc-default-executor-3] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 19aec3d0-bc58-440a-899b-3969d29112cc: addNew group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] returns group-7662FB7DDA7E:java.util.concurrent.CompletableFuture@7f8d0be9[Not completed]
2023-01-03 14:06:28,220 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 19aec3d0-bc58-440a-899b-3969d29112cc: new RaftServerImpl for group-7662FB7DDA7E:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: ConfigurationManager, init=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis] (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,221 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,223 [pool-2655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e does not exist. Creating ...
2023-01-03 14:06:28,224 [pool-2655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,225 [pool-2655-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e has been successfully formatted.
2023-01-03 14:06:28,225 [pool-2655-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-7662FB7DDA7E: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,225 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,226 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,226 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,226 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,226 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,226 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,226 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/422993b3-7658-48b0-9cb4-7662fb7dda7e
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,227 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,228 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,229 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,234 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,234 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,234 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: start as a follower, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-7662FB7DDA7E,id=19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:28,235 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,235 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,235 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,236 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,238 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS THREE PipelineID=422993b3-7658-48b0-9cb4-7662fb7dda7e.
2023-01-03 14:06:28,241 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:28,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:28,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:28,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:28,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,375 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: addNew group-310DA0BF428C:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER] returns group-310DA0BF428C:java.util.concurrent.CompletableFuture@84f9185[Not completed]
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: new RaftServerImpl for group-310DA0BF428C:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: ConfigurationManager, init=-1: peers:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,376 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis] (custom)
2023-01-03 14:06:28,377 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,377 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,377 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,377 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,377 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,378 [pool-2632-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/cecbd130-d4c8-4cf7-8d9d-310da0bf428c does not exist. Creating ...
2023-01-03 14:06:28,379 [pool-2632-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/cecbd130-d4c8-4cf7-8d9d-310da0bf428c/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,380 [pool-2632-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/cecbd130-d4c8-4cf7-8d9d-310da0bf428c has been successfully formatted.
2023-01-03 14:06:28,381 [pool-2632-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-310DA0BF428C: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,381 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,381 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,381 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: cecbd130-d4c8-4cf7-8d9d-310da0bf428c, Nodes: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34583, RATIS=39571, RATIS_ADMIN=39571, RATIS_SERVER=39571, RATIS_DATASTREAM=36099, STANDALONE=34845], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:7aee5cb6-4ed9-41f9-a897-fb72e55180cb, CreationTimestamp2023-01-03T14:06:25.377Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:28,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,381 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,382 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,382 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,382 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,382 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,382 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,382 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/cecbd130-d4c8-4cf7-8d9d-310da0bf428c
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,383 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,384 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,384 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,389 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,389 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,389 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: start as a follower, conf=-1: peers:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-310DA0BF428C,id=7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:28,390 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,390 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,390 [pool-2632-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,391 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=cecbd130-d4c8-4cf7-8d9d-310da0bf428c
2023-01-03 14:06:28,391 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=cecbd130-d4c8-4cf7-8d9d-310da0bf428c.
2023-01-03 14:06:28,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,469 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,657 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,670 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - 19aec3d0-bc58-440a-899b-3969d29112cc: addNew group-2661C4D1F0C0:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] returns group-2661C4D1F0C0:java.util.concurrent.CompletableFuture@1047fcaa[Not completed]
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - 19aec3d0-bc58-440a-899b-3969d29112cc: new RaftServerImpl for group-2661C4D1F0C0:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: ConfigurationManager, init=-1: peers:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis] (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:28,671 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:28,673 [pool-2655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/1d038acb-b53a-4a03-b0f2-2661c4d1f0c0 does not exist. Creating ...
2023-01-03 14:06:28,674 [pool-2655-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/1d038acb-b53a-4a03-b0f2-2661c4d1f0c0/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:28,675 [pool-2655-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/1d038acb-b53a-4a03-b0f2-2661c4d1f0c0 has been successfully formatted.
2023-01-03 14:06:28,675 [pool-2655-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-2661C4D1F0C0: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:28,676 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:28,676 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:28,676 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,676 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,676 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 1d038acb-b53a-4a03-b0f2-2661c4d1f0c0, Nodes: 19aec3d0-bc58-440a-899b-3969d29112cc{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=45245, RATIS=43677, RATIS_ADMIN=43677, RATIS_SERVER=43677, RATIS_DATASTREAM=39215, STANDALONE=44805], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:19aec3d0-bc58-440a-899b-3969d29112cc, CreationTimestamp2023-01-03T14:06:25.671Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:28,676 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/1d038acb-b53a-4a03-b0f2-2661c4d1f0c0
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:28,677 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:28,678 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:28,679 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:28,679 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:28,684 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:28,684 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:28,684 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: start as a follower, conf=-1: peers:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-2661C4D1F0C0,id=19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:28,685 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:28,685 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:28,685 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:28,686 [pool-2655-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:28,686 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=1d038acb-b53a-4a03-b0f2-2661c4d1f0c0
2023-01-03 14:06:28,686 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=1d038acb-b53a-4a03-b0f2-2661c4d1f0c0.
2023-01-03 14:06:28,728 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,777 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:28,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:28,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:28,787 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:28,812 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:28,993 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:28,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:28,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:29,014 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,015 [Command processor thread] INFO  server.RaftServer (RaftServerProxy.java:addNew(96)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: addNew group-E4B8AA55D0E2:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER] returns group-E4B8AA55D0E2:java.util.concurrent.CompletableFuture@6293a4eb[Not completed]
2023-01-03 14:06:29,016 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:<init>(195)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: new RaftServerImpl for group-E4B8AA55D0E2:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.min = 5s (custom)
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.timeout.max = 5200ms (custom)
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.sleep.time = 25ms (default)
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.slowness.timeout = 300s (custom)
2023-01-03 14:06:29,016 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.sleep.deviation.threshold = 300ms (default)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServer$Division (ServerState.java:<init>(118)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: ConfigurationManager, init=-1: peers:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.dir = [/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis] (custom)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.corruption.policy = EXCEPTION (default)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.storage.free-space.min = 0MB (=0) (default)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.notification.no-leader.timeout = 300s (custom)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.expirytime = 600000ms (custom)
2023-01-03 14:06:29,017 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.retrycache.statistics.expirytime = 100s (default)
2023-01-03 14:06:29,019 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:29,019 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.cached = true (default)
2023-01-03 14:06:29,019 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.server.size = 0 (default)
2023-01-03 14:06:29,020 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.cached = true (default)
2023-01-03 14:06:29,020 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.threadpool.client.size = 0 (default)
2023-01-03 14:06:29,020 [pool-2678-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:analyzeStorage(137)) - The storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis/f4e003f7-18cf-450a-985e-e4b8aa55d0e2 does not exist. Creating ...
2023-01-03 14:06:29,021 [pool-2678-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectoryImpl.java:tryLock(231)) - Lock on /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis/f4e003f7-18cf-450a-985e-e4b8aa55d0e2/in_use.lock acquired by nodename 2327@fv-az47-978
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  storage.RaftStorage (RaftStorageImpl.java:format(96)) - Storage directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis/f4e003f7-18cf-450a-985e-e4b8aa55d0e2 has been successfully formatted.
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(240)) - group-E4B8AA55D0E2: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.use.memory = false (default)
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.gap = 1000000 (custom)
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.read.timeout = 1000ms (default)
2023-01-03 14:06:29,022 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.preservation.log.num = 0 (default)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.num.max = 2 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:<init>(189)) - new bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis/f4e003f7-18cf-450a-985e-e4b8aa55d0e2
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.byte-limit = 4294967296 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.queue.element-limit = 1024 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.segment.size.max = 1048576 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.preallocated.size = 16384 (custom)
2023-01-03 14:06:29,023 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.force.sync.num = 128 (default)
2023-01-03 14:06:29,024 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync = true (default)
2023-01-03 14:06:29,024 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2023-01-03 14:06:29,024 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2023-01-03 14:06:29,025 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.write.buffer.size = 1048576 (custom)
2023-01-03 14:06:29,025 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:29,026 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,026 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: f4e003f7-18cf-450a-985e-e4b8aa55d0e2, Nodes: bc03f53a-8f38-42c1-b7a4-94894081fc1e{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=44929, RATIS=33781, RATIS_ADMIN=33781, RATIS_SERVER=33781, RATIS_DATASTREAM=33549, STANDALONE=38729], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:bc03f53a-8f38-42c1-b7a4-94894081fc1e, CreationTimestamp2023-01-03T14:06:26.018Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:29,026 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:29,031 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.unsafe-flush.enabled = false (default)
2023-01-03 14:06:29,032 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.async-flush.enabled = false (default)
2023-01-03 14:06:29,032 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2023-01-03 14:06:29,032 [pool-2678-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:29,032 [pool-2678-thread-1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:lambda$new$0(135)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
2023-01-03 14:06:29,038 [pool-2678-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:start(334)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: start as a follower, conf=-1: peers:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:29,038 [pool-2678-thread-1] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: changes role from      null to FOLLOWER at term 0 for startAsFollower
2023-01-03 14:06:29,038 [pool-2678-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: start bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState
2023-01-03 14:06:29,043 [pool-2678-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-E4B8AA55D0E2,id=bc03f53a-8f38-42c1-b7a4-94894081fc1e
2023-01-03 14:06:29,043 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2023-01-03 14:06:29,043 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2023-01-03 14:06:29,043 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.snapshot.retention.file.num = 5 (custom)
2023-01-03 14:06:29,043 [pool-2678-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.purge.upto.snapshot.index = false (default)
2023-01-03 14:06:29,043 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:29,043 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:29,044 [Command processor thread] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:addGroup(806)) - Created group PipelineID=f4e003f7-18cf-450a-985e-e4b8aa55d0e2
2023-01-03 14:06:29,044 [Command processor thread] INFO  commandhandler.CreatePipelineCommandHandler (CreatePipelineCommandHandler.java:handle(113)) - Created Pipeline RATIS ONE PipelineID=f4e003f7-18cf-450a-985e-e4b8aa55d0e2.
2023-01-03 14:06:29,174 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,175 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:29,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,206 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,241 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:29,242 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:29,286 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:29,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:29,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,443 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,469 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:29,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,590 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,657 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,676 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,676 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:29,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,777 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:29,783 [DatanodeAdminManager-0] INFO  node.DatanodeAdminMonitorImpl (DatanodeAdminMonitorImpl.java:run(169)) - There are 1 nodes tracked for decommission and maintenance.  0 pending nodes.
2023-01-03 14:06:29,783 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:29,787 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:29,813 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:29,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:29,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:29,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:29,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:30,016 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:30,016 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,022 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:30,022 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,175 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,210 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,245 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:30,245 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:30,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:30,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:30,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,381 [EventQueue-DeadNodeForDeadNodeHandler] INFO  node.DeadNodeHandler (DeadNodeHandler.java:onMessage(81)) - A dead datanode is detected. 8161063e-a6c1-4ab4-9440-f30963410d31{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=33721, RATIS=38537, RATIS_ADMIN=38537, RATIS_SERVER=38537, RATIS_DATASTREAM=36601, STANDALONE=35413], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_MAINTENANCE, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:30,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,381 [EventQueue-DeadNodeForDeadNodeHandler] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:remove(190)) - Removed a node: /default-rack/8161063e-a6c1-4ab4-9440-f30963410d31
2023-01-03 14:06:30,381 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:30,422 [Listener at 0.0.0.0/40427] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:restartStorageContainerManager(350)) - Restarting SCM in cluster class org.apache.hadoop.ozone.MiniOzoneClusterImpl
2023-01-03 14:06:30,422 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1518)) - Container Balancer is not running.
2023-01-03 14:06:30,422 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1525)) - Stopping Replication Manager Service.
2023-01-03 14:06:30,423 [Listener at 0.0.0.0/40427] INFO  replication.ReplicationManager (ReplicationManager.java:stop(296)) - Stopping Replication Monitor Thread.
2023-01-03 14:06:30,423 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1532)) - Stopping the Datanode Admin Monitor.
2023-01-03 14:06:30,423 [Under Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Under Replicated Processor interrupted. Exiting...
2023-01-03 14:06:30,423 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1539)) - Stopping datanode service RPC server
2023-01-03 14:06:30,423 [Listener at 0.0.0.0/40427] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(441)) - Stopping the RPC server for DataNodes
2023-01-03 14:06:30,423 [Listener at 0.0.0.0/40427] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 32791
2023-01-03 14:06:30,423 [Over Replicated Processor] WARN  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:run(141)) - Over Replicated Processor interrupted. Exiting...
2023-01-03 14:06:30,434 [IPC Server listener on 32791] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 32791
2023-01-03 14:06:30,434 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:run(666)) - Replication Monitor Thread is stopped
2023-01-03 14:06:30,442 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:30,443 [EndpointStateMachine task thread for /0.0.0.0:32791 - 0 ] WARN  statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(242)) - Unable to communicate to SCM server at 0.0.0.0:32791 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "fv-az47-978/10.1.0.35"; destination host is: "0.0.0.0":32791; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:862)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
	at com.sun.proxy.$Proxy54.submitRequest(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:149)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:185)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:87)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)
2023-01-03 14:06:30,469 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,481 [SCM Heartbeat Processing Thread - 0] WARN  node.NodeStateManager (NodeStateManager.java:scheduleNextHealthCheck(870)) - Current Thread is interrupted, shutting down HB processing thread for Node Manager.
2023-01-03 14:06:30,481 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1547)) - Stopping block service RPC server
2023-01-03 14:06:30,481 [Listener at 0.0.0.0/40427] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(161)) - Stopping the RPC server for Block Protocol
2023-01-03 14:06:30,482 [Listener at 0.0.0.0/40427] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 34621
2023-01-03 14:06:30,484 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:30,484 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1554)) - Stopping the StorageContainerLocationProtocol RPC server
2023-01-03 14:06:30,484 [Listener at 0.0.0.0/40427] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(179)) - Stopping the RPC server for Client Protocol
2023-01-03 14:06:30,484 [Listener at 0.0.0.0/40427] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 40427
2023-01-03 14:06:30,484 [IPC Server listener on 34621] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 34621
2023-01-03 14:06:30,488 [IPC Server listener on 40427] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 40427
2023-01-03 14:06:30,488 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1561)) - Stopping Storage Container Manager HTTP server.
2023-01-03 14:06:30,489 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@11ad327f{scm,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:30,491 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:06:30,492 [Listener at 0.0.0.0/40427] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@5ace6611{HTTP/1.1, (http/1.1)}{0.0.0.0:42719}
2023-01-03 14:06:30,492 [Listener at 0.0.0.0/40427] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:06:30,492 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@612531a3{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-01-03 14:06:30,492 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@218e186b{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:06:30,494 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1567)) - Stopping SCM LayoutVersionManager Service.
2023-01-03 14:06:30,494 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1575)) - Stopping Block Manager Service.
2023-01-03 14:06:30,494 [Listener at 0.0.0.0/40427] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:30,495 [Listener at 0.0.0.0/40427] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:30,495 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1597)) - Stopping SCM Event Queue.
2023-01-03 14:06:30,496 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1608)) - Stopping SCM HA services.
2023-01-03 14:06:30,496 [Listener at 0.0.0.0/40427] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(149)) - Stopping RatisPipelineUtilsThread.
2023-01-03 14:06:30,496 [RatisPipelineUtilsThread - 0] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:run(180)) - RatisPipelineUtilsThread is interrupted.
2023-01-03 14:06:30,496 [BackgroundPipelineScrubberThread] WARN  BackgroundPipelineScrubber (BackgroundSCMService.java:run(115)) - BackgroundPipelineScrubber is interrupted, exit
2023-01-03 14:06:30,496 [Listener at 0.0.0.0/40427] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(131)) - Stopping BackgroundPipelineScrubber Service.
2023-01-03 14:06:30,498 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(205)) - StorageContainerManager metrics system stopped (again)
2023-01-03 14:06:30,498 [Listener at 0.0.0.0/40427] WARN  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:stop(145)) - RatisPipelineUtilsThread is not running, just ignore.
2023-01-03 14:06:30,499 [Listener at 0.0.0.0/40427] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:stop(126)) - BackgroundPipelineScrubber Service is not running, skip stop.
2023-01-03 14:06:30,499 [Listener at 0.0.0.0/40427] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:stop(131)) - Stopping ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:30,499 [Listener at 0.0.0.0/40427] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service SCMBlockDeletingService
2023-01-03 14:06:30,499 [ExpiredContainerReplicaOpScrubberThread] WARN  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:run(115)) - ExpiredContainerReplicaOpScrubber is interrupted, exit
2023-01-03 14:06:30,499 [Listener at 0.0.0.0/40427] INFO  replication.ReplicationManager (ReplicationManager.java:stop(304)) - Replication Monitor Thread is not running.
2023-01-03 14:06:30,499 [Listener at 0.0.0.0/40427] WARN  balancer.ContainerBalancer (ContainerBalancer.java:stop(322)) - Cannot stop Container Balancer because it's not running or stopping
2023-01-03 14:06:30,500 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(1626)) - Stopping SCM MetadataStore.
2023-01-03 14:06:30,501 [Listener at 0.0.0.0/40427] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(148)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:30,502 [Listener at 0.0.0.0/40427] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(209)) - ServiceID for StorageContainerManager is null
2023-01-03 14:06:30,502 [Listener at 0.0.0.0/40427] INFO  ha.SCMHANodeDetails (SCMHANodeDetails.java:loadSCMHAConfig(214)) - ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
2023-01-03 14:06:30,502 [Listener at 0.0.0.0/40427] WARN  utils.HAUtils (HAUtils.java:getMetaDir(342)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:30,503 [Listener at 0.0.0.0/40427] WARN  db.DBStoreBuilder (DBStoreBuilder.java:applyDBDefinition(144)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2023-01-03 14:06:30,530 [Listener at 0.0.0.0/40427] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(129)) - Loading schema from [jar:file:/home/runner/.m2/repository/org/apache/ozone/hdds-common/1.4.0-SNAPSHOT/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
2023-01-03 14:06:30,530 [Listener at 0.0.0.0/40427] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(176)) - Loading network topology layer schema file
2023-01-03 14:06:30,533 [Listener at 0.0.0.0/40427] INFO  upgrade.AbstractLayoutVersionManager (AbstractLayoutVersionManager.java:init(83)) - Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
2023-01-03 14:06:30,579 [Listener at 0.0.0.0/40427] INFO  reflections.Reflections (Reflections.java:scan(232)) - Reflections took 45 ms to scan 7 urls, producing 146 keys and 350 values 
2023-01-03 14:06:30,580 [Listener at 0.0.0.0/40427] INFO  ha.SequenceIdGenerator (SequenceIdGenerator.java:<init>(220)) - Init the HA SequenceIdGenerator.
2023-01-03 14:06:30,583 [Listener at 0.0.0.0/40427] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(149)) - Entering startup safe mode.
2023-01-03 14:06:30,583 [Listener at 0.0.0.0/40427] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
2023-01-03 14:06:30,583 [Listener at 0.0.0.0/40427] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:30,584 [Listener at 0.0.0.0/40427] INFO  algorithms.LeaderChoosePolicyFactory (LeaderChoosePolicyFactory.java:getPolicy(57)) - Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
2023-01-03 14:06:30,584 [Listener at 0.0.0.0/40427] INFO  algorithms.ContainerPlacementPolicyFactory (ContainerPlacementPolicyFactory.java:getPolicyInternal(86)) - Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
2023-01-03 14:06:30,585 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineCreator.
2023-01-03 14:06:30,585 [Listener at 0.0.0.0/40427] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:start(124)) - Starting RatisPipelineUtilsThread.
2023-01-03 14:06:30,585 [Listener at 0.0.0.0/40427] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:start(68)) - Starting BackgroundPipelineScrubber Service.
2023-01-03 14:06:30,585 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service BackgroundPipelineScrubber.
2023-01-03 14:06:30,585 [Listener at 0.0.0.0/40427] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:start(68)) - Starting ExpiredContainerReplicaOpScrubber Service.
2023-01-03 14:06:30,586 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ExpiredContainerReplicaOpScrubber.
2023-01-03 14:06:30,587 [Listener at 0.0.0.0/40427] INFO  algorithms.PipelineChoosePolicyFactory (PipelineChoosePolicyFactory.java:createPipelineChoosePolicyFromClass(73)) - Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
2023-01-03 14:06:30,588 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service SCMBlockDeletingService.
2023-01-03 14:06:30,588 [Listener at 0.0.0.0/40427] INFO  replication.ReplicationManager (ReplicationManager.java:start(261)) - Starting Replication Monitor Thread.
2023-01-03 14:06:30,592 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ReplicationManager.
2023-01-03 14:06:30,592 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:30,593 [Listener at 0.0.0.0/40427] INFO  safemode.ContainerSafeModeRule (ContainerSafeModeRule.java:<init>(89)) - containers with one replica threshold count 3
2023-01-03 14:06:30,593 [Listener at 0.0.0.0/40427] INFO  safemode.HealthyPipelineSafeModeRule (HealthyPipelineSafeModeRule.java:initializeRule(169)) - Total pipeline count is 2, healthy pipeline threshold count is 1
2023-01-03 14:06:30,593 [Listener at 0.0.0.0/40427] INFO  safemode.OneReplicaPipelineSafeModeRule (OneReplicaPipelineSafeModeRule.java:initializeRule(180)) - Total pipeline count is 2, pipeline's with at least one datanode reported threshold count is 2
2023-01-03 14:06:30,593 [Listener at 0.0.0.0/40427] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:30,594 [Socket Reader #1 for port 32791] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 32791
2023-01-03 14:06:30,610 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,610 [Listener at 0.0.0.0/32791] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:30,611 [Socket Reader #1 for port 34621] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 34621
2023-01-03 14:06:30,611 [Listener at 0.0.0.0/34621] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(90)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2023-01-03 14:06:30,618 [Socket Reader #1 for port 40427] INFO  ipc.Server (Server.java:run(1273)) - Starting Socket Reader #1 for port 40427
2023-01-03 14:06:30,627 [Listener at 0.0.0.0/40427] INFO  ha.SCMServiceManager (SCMServiceManager.java:register(42)) - Registering service ContainerBalancer.
2023-01-03 14:06:30,627 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:<init>(398)) - 
Container Balancer status:
Key                            Value
Running                        true
Container Balancer Configuration values:
Key                                                Value
Threshold                                          10
Max Datanodes to Involve per Iteration(percent)    20
Max Size to Move per Iteration                     500GB
Max Size Entering Target per Iteration             26GB
Max Size Leaving Source per Iteration              26GB

2023-01-03 14:06:30,627 [Listener at 0.0.0.0/40427] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
2023-01-03 14:06:30,628 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1423)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:40427
2023-01-03 14:06:30,629 [Listener at 0.0.0.0/40427] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(136)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2023-01-03 14:06:30,631 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(378)) - Scheduled Metric snapshot period at 10 second(s).
2023-01-03 14:06:30,631 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2023-01-03 14:06:30,645 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSinkAdapter (MetricsSinkAdapter.java:start(204)) - Sink prometheus started
2023-01-03 14:06:30,645 [Listener at 0.0.0.0/40427] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:registerSink(305)) - Registered sink prometheus
2023-01-03 14:06:30,658 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,668 [Listener at 0.0.0.0/40427] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(170)) - RPC server for Client  is listening at /0.0.0.0:40427
2023-01-03 14:06:30,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:30,672 [IPC Server listener on 40427] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 40427: starting
2023-01-03 14:06:30,673 [Listener at 0.0.0.0/40427] INFO  server.StorageContainerManager (StorageContainerManager.java:start(1437)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34621
2023-01-03 14:06:30,673 [Listener at 0.0.0.0/40427] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(152)) - RPC server for Block Protocol is listening at /0.0.0.0:34621
2023-01-03 14:06:30,676 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:30,676 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,683 [IPC Server listener on 34621] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 34621: starting
2023-01-03 14:06:30,721 [Listener at 0.0.0.0/40427] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(194)) - ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:32791
2023-01-03 14:06:30,722 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1512)) - IPC Server Responder: starting
2023-01-03 14:06:30,725 [IPC Server listener on 32791] INFO  ipc.Server (Server.java:run(1352)) - IPC Server listener on 32791: starting
2023-01-03 14:06:30,767 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:newHttpServer2BuilderForOzone(213)) - Starting Web-server for scm at: http://0.0.0.0:42719
2023-01-03 14:06:30,767 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:<init>(108)) - Hadoop Security Enabled: false Ozone Security Enabled: false Ozone HTTP Security Enabled: false 
2023-01-03 14:06:30,768 [Listener at 0.0.0.0/40427] WARN  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets. Reason: Could not read signature secret file: /home/runner/hadoop-http-auth-signature-secret
2023-01-03 14:06:30,768 [Listener at 0.0.0.0/40427] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(103)) - Jetty request log can only be enabled using Log4j
2023-01-03 14:06:30,769 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(1031)) - Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
2023-01-03 14:06:30,770 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1007)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2023-01-03 14:06:30,770 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-01-03 14:06:30,770 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:addFilter(1015)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-01-03 14:06:30,770 [Listener at 0.0.0.0/40427] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1250)) - Jetty bound to port 42719
2023-01-03 14:06:30,770 [Listener at 0.0.0.0/40427] INFO  server.Server (Server.java:doStart(375)) - jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 1.8.0_352-b08
2023-01-03 14:06:30,770 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64745270] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2023-01-03 14:06:30,775 [Listener at 0.0.0.0/40427] INFO  server.session (DefaultSessionIdManager.java:doStart(334)) - DefaultSessionIdManager workerName=node0
2023-01-03 14:06:30,775 [Listener at 0.0.0.0/40427] INFO  server.session (DefaultSessionIdManager.java:doStart(339)) - No SessionScavenger set, using defaults
2023-01-03 14:06:30,775 [Listener at 0.0.0.0/40427] INFO  server.session (HouseKeeper.java:startScavenging(132)) - node0 Scavenging every 600000ms
2023-01-03 14:06:30,775 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@6fe91918{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,AVAILABLE}
2023-01-03 14:06:30,776 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.s.ServletContextHandler@f5b4ca6{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,AVAILABLE}
2023-01-03 14:06:30,778 [Listener at 0.0.0.0/40427] INFO  handler.ContextHandler (ContextHandler.java:doStart(921)) - Started o.e.j.w.WebAppContext@5c7d675c{scm,/,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm/,AVAILABLE}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/scm}
2023-01-03 14:06:30,788 [Listener at 0.0.0.0/40427] INFO  server.AbstractConnector (AbstractConnector.java:doStart(333)) - Started ServerConnector@73839f22{HTTP/1.1, (http/1.1)}{0.0.0.0:42719}
2023-01-03 14:06:30,788 [Listener at 0.0.0.0/40427] INFO  server.Server (Server.java:doStart(415)) - Started @189912ms
2023-01-03 14:06:30,788 [Listener at 0.0.0.0/40427] WARN  impl.MetricsSystemImpl (MetricsSystemImpl.java:register(279)) - Sink prometheus already exists!
2023-01-03 14:06:30,788 [Listener at 0.0.0.0/40427] INFO  http.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(333)) - HTTP server of scm listening at http://0.0.0.0:42719
2023-01-03 14:06:30,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:30,813 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:30,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:30,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:30,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:31,016 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,017 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,022 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,175 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,175 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,208 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,245 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:31,245 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:31,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:31,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:31,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,381 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,381 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,469 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,469 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,486 [EndpointStateMachine task thread for /0.0.0.0:32791 - 0 ] INFO  ipc.Client (Client.java:handleConnectionFailure(1010)) - Retrying connect to server: 0.0.0.0/0.0.0.0:32791. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
2023-01-03 14:06:31,496 [IPC Server handler 0 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,496 [IPC Server handler 1 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode c36dba4c-5c72-465b-8876-3f5e456990a2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34999, RATIS=37333, RATIS_ADMIN=37333, RATIS_SERVER=37333, RATIS_DATASTREAM=37189, STANDALONE=37423], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,497 [IPC Server handler 3 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode e673a28b-a4f0-4b9b-b939-463b757d484f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=39651, RATIS=32789, RATIS_ADMIN=32789, RATIS_SERVER=32789, RATIS_DATASTREAM=33659, STANDALONE=35199], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,497 [IPC Server handler 2 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,497 [IPC Server handler 5 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,497 [IPC Server handler 4 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,498 [IPC Server handler 7 on default port 32791] INFO  server.SCMDatanodeHeartbeatDispatcher (SCMDatanodeHeartbeatDispatcher.java:dispatch(108)) - SCM received heartbeat from an unregistered datanode 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}. Asking datanode to re-register.
2023-01-03 14:06:31,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:31,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,658 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,677 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,677 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,727 [IPC Server handler 6 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/c36dba4c-5c72-465b-8876-3f5e456990a2
2023-01-03 14:06:31,727 [IPC Server handler 6 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : c36dba4c-5c72-465b-8876-3f5e456990a2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=34999, RATIS=37333, RATIS_ADMIN=37333, RATIS_SERVER=37333, RATIS_DATASTREAM=37189, STANDALONE=37423], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:31,740 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 3 required.
2023-01-03 14:06:31,740 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-01-03 14:06:31,740 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-01-03 14:06:31,745 [IPC Server handler 9 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/e673a28b-a4f0-4b9b-b939-463b757d484f
2023-01-03 14:06:31,745 [IPC Server handler 9 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : e673a28b-a4f0-4b9b-b939-463b757d484f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=39651, RATIS=32789, RATIS_ADMIN=32789, RATIS_SERVER=32789, RATIS_DATASTREAM=33659, STANDALONE=35199], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:31,747 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 2 DataNodes registered, 3 required.
2023-01-03 14:06:31,747 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-01-03 14:06:31,749 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:31,749 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:31,754 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-01-03 14:06:31,760 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,760 [IPC Server handler 19 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/1f39c4a2-123f-4ca0-aca4-b650c3c85ddf
2023-01-03 14:06:31,761 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,761 [IPC Server handler 19 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:31,760 [IPC Server handler 16 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:06:31,761 [IPC Server handler 16 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 3 DataNodes registered, 3 required.
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - DataNodeSafeModeRule rule is successfully validated
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 0.0 % containers have at least one reported replica.
2023-01-03 14:06:31,761 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 1, required at least one datanode reported per pipeline count is 2
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:completePreCheck(229)) - All SCM safe mode pre check rules have passed
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
2023-01-03 14:06:31,761 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:31,761 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:31,761 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:31,763 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (ContainerSafeModeRule.java:process(127)) - SCM in safe mode. 100.0 % containers have at least one reported replica.
2023-01-03 14:06:31,763 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (OneReplicaPipelineSafeModeRule.java:process(120)) - SCM in safe mode. Pipelines with at least one datanode reported count is 2, required at least one datanode reported per pipeline count is 2
2023-01-03 14:06:31,765 [EventQueue-NodeRegistrationContainerReportForContainerSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - ContainerSafeModeRule rule is successfully validated
2023-01-03 14:06:31,765 [EventQueue-PipelineReportForOneReplicaPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - AtleastOneDatanodeReportedRule rule is successfully validated
2023-01-03 14:06:31,765 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(918)) - Service ReplicationManager transitions to RUNNING.
2023-01-03 14:06:31,766 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-01-03 14:06:31,813 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:31,814 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:31,994 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:31,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:31,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:32,017 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,017 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,022 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,022 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,090 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5062520285ns, electionTimeout:5062ms
2023-01-03 14:06:32,090 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - af27b707-902e-436a-b36c-df002345c922: shutdown af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState
2023-01-03 14:06:32,091 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:32,091 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:32,091 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104
2023-01-03 14:06:32,093 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104 ELECTION round 0: submit vote requests at term 1 for -1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,093 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:32,093 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:32,095 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:32,096 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:32,106 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: receive requestVote(ELECTION, af27b707-902e-436a-b36c-df002345c922, group-B90486F78806, 1, (t:0, i:0))
2023-01-03 14:06:32,106 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FOLLOWER: reject ELECTION from af27b707-902e-436a-b36c-df002345c922: our priority 1 > candidate's priority 0
2023-01-03 14:06:32,106 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:32,106 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: shutdown 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState
2023-01-03 14:06:32,106 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState
2023-01-03 14:06:32,106 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState was interrupted
2023-01-03 14:06:32,107 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:32,107 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:32,108 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806 replies to ELECTION vote request: af27b707-902e-436a-b36c-df002345c922<-3a3da11c-e5c3-43e0-8561-5c3126dc697f#0:FAIL-t1. Peer's state: 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806:t1, leader=null, voted=null, raftlog=Memoized:3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,108 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:32,108 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: af27b707-902e-436a-b36c-df002345c922<-3a3da11c-e5c3-43e0-8561-5c3126dc697f#0:FAIL-t1
2023-01-03 14:06:32,108 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104 ELECTION round 0: result REJECTED
2023-01-03 14:06:32,108 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-01-03 14:06:32,108 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - af27b707-902e-436a-b36c-df002345c922: shutdown af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104
2023-01-03 14:06:32,109 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-LeaderElection104] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState
2023-01-03 14:06:32,109 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: receive requestVote(ELECTION, af27b707-902e-436a-b36c-df002345c922, group-B90486F78806, 1, (t:0, i:0))
2023-01-03 14:06:32,109 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FOLLOWER: accept ELECTION from af27b707-902e-436a-b36c-df002345c922: our priority 0 <= candidate's priority 0
2023-01-03 14:06:32,109 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:32,109 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: shutdown 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState
2023-01-03 14:06:32,110 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState
2023-01-03 14:06:32,110 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState was interrupted
2023-01-03 14:06:32,110 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:32,110 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:32,114 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:32,114 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:32,115 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5106352570ns, electionTimeout:5105ms
2023-01-03 14:06:32,115 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806 replies to ELECTION vote request: af27b707-902e-436a-b36c-df002345c922<-56e9ebea-1da6-4510-b9da-2a36b64eada2#0:OK-t1. Peer's state: 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806:t1, leader=null, voted=af27b707-902e-436a-b36c-df002345c922, raftlog=Memoized:56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,115 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - af27b707-902e-436a-b36c-df002345c922: shutdown af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState
2023-01-03 14:06:32,115 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:32,115 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:32,115 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105 ELECTION round 0: submit vote requests at term 1 for -1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - af27b707-902e-436a-b36c-df002345c922: shutdown af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-911A592A5DE1 with new leaderId: af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: change Leader from null to af27b707-902e-436a-b36c-df002345c922 at term 1 for becomeLeader, leader elected after 5156ms
2023-01-03 14:06:32,117 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:32,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:32,118 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderStateImpl
2023-01-03 14:06:32,119 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:32,122 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/7a992f2c-1f6d-4807-9430-911a592a5de1/current/log_inprogress_0
2023-01-03 14:06:32,122 [af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1-LeaderElection105] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - af27b707-902e-436a-b36c-df002345c922@group-911A592A5DE1: set configuration 0: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,175 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,175 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,187 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,246 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:32,246 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:32,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:32,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:32,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,443 [IPC Server handler 0 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/a13c81fc-644c-4ecf-91c3-6e9a75ed36aa
2023-01-03 14:06:32,443 [IPC Server handler 0 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:32,443 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:32,470 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,470 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,485 [IPC Server handler 1 on default port 32791] INFO  net.NetworkTopologyImpl (NetworkTopologyImpl.java:add(112)) - Added a new node: /default-rack/7c948c4b-a779-4597-819f-06099ef104a1
2023-01-03 14:06:32,485 [IPC Server handler 1 on default port 32791] INFO  node.SCMNodeManager (SCMNodeManager.java:register(397)) - Registered Data node : 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
2023-01-03 14:06:32,485 [EventQueue-NewNodeForNewNodeHandler] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyEventTriggered(276)) - trigger a one-shot run on RatisPipelineUtilsThread.
2023-01-03 14:06:32,486 [RatisPipelineUtilsThread - 0] WARN  pipeline.PipelinePlacementPolicy (PipelinePlacementPolicy.java:filterViableNodes(158)) - Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
2023-01-03 14:06:32,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:32,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,668 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5177686172ns, electionTimeout:5169ms
2023-01-03 14:06:32,669 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: shutdown 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState
2023-01-03 14:06:32,669 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:32,669 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:32,669 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106
2023-01-03 14:06:32,670 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106 ELECTION round 0: submit vote requests at term 1 for -1: peers:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,670 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:32,670 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: shutdown 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106
2023-01-03 14:06:32,670 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:32,670 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-3FC619618735 with new leaderId: 56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: change Leader from null to 56e9ebea-1da6-4510-b9da-2a36b64eada2 at term 1 for becomeLeader, leader elected after 5205ms
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:32,671 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,671 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:32,671 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:32,672 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:32,672 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,672 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:32,672 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderStateImpl
2023-01-03 14:06:32,674 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:32,678 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-LeaderElection106] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735: set configuration 0: peers:[56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,682 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-3FC619618735-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/fde9ffad-ff0c-4976-a307-3fc619618735/current/log_inprogress_0
2023-01-03 14:06:32,683 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,683 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,812 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,913 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5093432579ns, electionTimeout:5093ms
2023-01-03 14:06:32,913 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: shutdown 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState
2023-01-03 14:06:32,914 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:32,914 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:32,914 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107 ELECTION round 0: submit vote requests at term 1 for -1: peers:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: shutdown 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-8EE01340381C with new leaderId: 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: change Leader from null to 3a3da11c-e5c3-43e0-8561-5c3126dc697f at term 1 for becomeLeader, leader elected after 5109ms
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,916 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:32,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:32,917 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderStateImpl
2023-01-03 14:06:32,917 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:32,923 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/1d686bf7-d384-4098-b977-8ee01340381c/current/log_inprogress_0
2023-01-03 14:06:32,924 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C-LeaderElection107] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-8EE01340381C: set configuration 0: peers:[3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:32,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:32,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:32,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:33,022 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,175 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,175 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,246 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:33,246 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:33,266 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5080429787ns, electionTimeout:5079ms
2023-01-03 14:06:33,266 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,266 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:33,266 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:33,266 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108
2023-01-03 14:06:33,268 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,269 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:33,270 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:33,270 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:33,270 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:33,287 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 1, (t:0, i:0))
2023-01-03 14:06:33,287 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:33,287 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:33,287 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,287 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,287 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:33,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:33,287 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 1, (t:0, i:0))
2023-01-03 14:06:33,288 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:33,288 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:33,288 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,288 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:33,288 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:33,288 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:33,288 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:33,288 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:33,289 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:33,289 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t1. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t1, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,289 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:33,289 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t1
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108 ELECTION round 0: result REJECTED
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection108] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:33,290 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t1. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t1, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:33,290 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:33,341 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5178253484ns, electionTimeout:5177ms
2023-01-03 14:06:33,341 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState
2023-01-03 14:06:33,341 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:33,341 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:33,341 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109 ELECTION round 0: submit vote requests at term 1 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-5795C9144DAB with new leaderId: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: change Leader from null to 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97 at term 1 for becomeLeader, leader elected after 5254ms
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:33,343 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:33,344 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,344 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderStateImpl
2023-01-03 14:06:33,344 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:33,352 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-LeaderElection109] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB: set configuration 0: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,353 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-5795C9144DAB-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-3/data/ratis/eae543f6-77ba-41c0-8e28-5795c9144dab/current/log_inprogress_0
2023-01-03 14:06:33,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,382 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,444 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,515 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5125462798ns, electionTimeout:5125ms
2023-01-03 14:06:33,516 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState
2023-01-03 14:06:33,516 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:33,516 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:33,516 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110
2023-01-03 14:06:33,517 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110 ELECTION round 0: submit vote requests at term 1 for -1: peers:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,517 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:33,517 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-310DA0BF428C with new leaderId: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: change Leader from null to 7aee5cb6-4ed9-41f9-a897-fb72e55180cb at term 1 for becomeLeader, leader elected after 5140ms
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:33,518 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,518 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:33,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderStateImpl
2023-01-03 14:06:33,519 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:33,524 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-LeaderElection110] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C: set configuration 0: peers:[7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,526 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-310DA0BF428C-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-4/data/ratis/cecbd130-d4c8-4cf7-8d9d-310da0bf428c/current/log_inprogress_0
2023-01-03 14:06:33,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:33,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,671 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,682 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,707 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5021541465ns, electionTimeout:5021ms
2023-01-03 14:06:33,707 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState
2023-01-03 14:06:33,707 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:33,707 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:33,707 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111 ELECTION round 0: submit vote requests at term 1 for -1: peers:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-2661C4D1F0C0 with new leaderId: 19aec3d0-bc58-440a-899b-3969d29112cc
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: change Leader from null to 19aec3d0-bc58-440a-899b-3969d29112cc at term 1 for becomeLeader, leader elected after 5037ms
2023-01-03 14:06:33,709 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:33,710 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,710 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,710 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,710 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderStateImpl
2023-01-03 14:06:33,711 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:33,715 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-LeaderElection111] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0: set configuration 0: peers:[19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:33,716 [19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-2661C4D1F0C0-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-5/data/ratis/1d038acb-b53a-4a03-b0f2-2661c4d1f0c0/current/log_inprogress_0
2023-01-03 14:06:33,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,917 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:33,917 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:33,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:33,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:33,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:34,023 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,023 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,086 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5048293155ns, electionTimeout:5043ms
2023-01-03 14:06:34,087 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: shutdown bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState
2023-01-03 14:06:34,087 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2023-01-03 14:06:34,087 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:34,087 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: start bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112 ELECTION round 0: submit vote requests at term 1 for -1: peers:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112 ELECTION round 0: result PASSED (term=1)
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: shutdown bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-E4B8AA55D0E2 with new leaderId: bc03f53a-8f38-42c1-b7a4-94894081fc1e
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: change Leader from null to bc03f53a-8f38-42c1-b7a4-94894081fc1e at term 1 for becomeLeader, leader elected after 5071ms
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:34,089 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:34,090 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:34,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:34,090 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e: start bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderStateImpl
2023-01-03 14:06:34,091 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:34,100 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-LeaderElection112] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2: set configuration 0: peers:[bc03f53a-8f38-42c1-b7a4-94894081fc1e|rpc:10.1.0.35:33781|dataStream:10.1.0.35:33549|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:34,101 [bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - bc03f53a-8f38-42c1-b7a4-94894081fc1e@group-E4B8AA55D0E2-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-6/data/ratis/f4e003f7-18cf-450a-985e-e4b8aa55d0e2/current/log_inprogress_0
2023-01-03 14:06:34,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,246 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:34,246 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:34,287 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:34,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:34,344 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,344 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,518 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,593 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:34,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,658 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,726 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,744 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:34,916 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:34,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:34,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:34,995 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:35,090 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:35,090 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,117 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:35,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,246 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:35,246 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:35,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:35,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:35,344 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,593 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:35,593 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1196)) - Container #1 is under replicated. Expected replica count is 3, but found 2.
2023-01-03 14:06:35,593 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1560)) - Sending replicate container command for container #1 to datanode a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:35,594 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1196)) - Container #2 is under replicated. Expected replica count is 3, but found 2.
2023-01-03 14:06:35,594 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1560)) - Sending replicate container command for container #2 to datanode 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41695, RATIS=33823, RATIS_ADMIN=33823, RATIS_SERVER=33823, RATIS_DATASTREAM=37695, STANDALONE=33365], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:35,594 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:handleUnderReplicatedContainer(1196)) - Container #5 is under replicated. Expected replica count is 3, but found 2.
2023-01-03 14:06:35,594 [ReplicationMonitor] INFO  replication.LegacyReplicationManager (LegacyReplicationManager.java:sendReplicateCommand(1560)) - Sending replicate container command for container #5 to datanode a13c81fc-644c-4ecf-91c3-6e9a75ed36aa{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42643, RATIS=42475, RATIS_ADMIN=42475, RATIS_SERVER=42475, RATIS_DATASTREAM=44301, STANDALONE=33991], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0} from datanodes [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:35,594 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:35,598 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:35,603 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,672 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:35,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,745 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:35,916 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:35,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:35,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:35,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:36,089 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,207 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,246 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:36,247 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:36,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:36,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:36,345 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,345 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:36,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,518 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:36,593 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:36,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:36,598 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:36,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,711 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:36,728 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,916 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:36,916 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:36,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:36,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Waiting for cluster to exit safe mode
2023-01-03 14:06:36,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:37,089 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,089 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:37,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,118 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:37,123 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5016569202ns, electionTimeout:5016ms
2023-01-03 14:06:37,123 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: shutdown 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState
2023-01-03 14:06:37,123 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-01-03 14:06:37,124 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:37,124 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113
2023-01-03 14:06:37,125 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113 ELECTION round 0: submit vote requests at term 2 for -1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,126 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:37,126 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113-1] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for af27b707-902e-436a-b36c-df002345c922
2023-01-03 14:06:37,126 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:37,126 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113-2] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:<init>(63)) - Build channel for 56e9ebea-1da6-4510-b9da-2a36b64eada2
2023-01-03 14:06:37,132 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: receive requestVote(ELECTION, 3a3da11c-e5c3-43e0-8561-5c3126dc697f, group-B90486F78806, 2, (t:0, i:0))
2023-01-03 14:06:37,132 [grpc-default-executor-3] INFO  impl.VoteContext (VoteContext.java:log(49)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FOLLOWER: accept ELECTION from 3a3da11c-e5c3-43e0-8561-5c3126dc697f: our priority 0 <= candidate's priority 1
2023-01-03 14:06:37,133 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:37,133 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - af27b707-902e-436a-b36c-df002345c922: shutdown af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState
2023-01-03 14:06:37,133 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - af27b707-902e-436a-b36c-df002345c922: start af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState
2023-01-03 14:06:37,133 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState was interrupted
2023-01-03 14:06:37,133 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: receive requestVote(ELECTION, 3a3da11c-e5c3-43e0-8561-5c3126dc697f, group-B90486F78806, 2, (t:0, i:0))
2023-01-03 14:06:37,133 [grpc-default-executor-10] INFO  impl.VoteContext (VoteContext.java:log(49)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FOLLOWER: accept ELECTION from 3a3da11c-e5c3-43e0-8561-5c3126dc697f: our priority 0 <= candidate's priority 1
2023-01-03 14:06:37,133 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:37,133 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: shutdown 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState
2023-01-03 14:06:37,135 [grpc-default-executor-10] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2: start 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState
2023-01-03 14:06:37,135 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState was interrupted
2023-01-03 14:06:37,135 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:37,135 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:37,135 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:37,135 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:37,136 [grpc-default-executor-3] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806 replies to ELECTION vote request: 3a3da11c-e5c3-43e0-8561-5c3126dc697f<-af27b707-902e-436a-b36c-df002345c922#0:OK-t2. Peer's state: af27b707-902e-436a-b36c-df002345c922@group-B90486F78806:t2, leader=null, voted=3a3da11c-e5c3-43e0-8561-5c3126dc697f, raftlog=Memoized:af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,136 [grpc-default-executor-10] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806 replies to ELECTION vote request: 3a3da11c-e5c3-43e0-8561-5c3126dc697f<-56e9ebea-1da6-4510-b9da-2a36b64eada2#0:OK-t2. Peer's state: 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806:t2, leader=null, voted=3a3da11c-e5c3-43e0-8561-5c3126dc697f, raftlog=Memoized:56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,136 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113: ELECTION PASSED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 3a3da11c-e5c3-43e0-8561-5c3126dc697f<-56e9ebea-1da6-4510-b9da-2a36b64eada2#0:OK-t2
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113 ELECTION round 0: result PASSED
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: shutdown 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-B90486F78806 with new leaderId: 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: change Leader from null to 3a3da11c-e5c3-43e0-8561-5c3126dc697f at term 2 for becomeLeader, leader elected after 10075ms
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.staging.catchup.gap = 1000 (default)
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout = 180s (custom)
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.timeout.denomination = 1s (default)
2023-01-03 14:06:37,137 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.watch.element-limit = 65536 (default)
2023-01-03 14:06:37,138 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.element-limit = 1024 (custom)
2023-01-03 14:06:37,138 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.write.follower.gap.ratio.max = -1.0 (default)
2023-01-03 14:06:37,138 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-01-03 14:06:37,138 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:37,138 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-01-03 14:06:37,139 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-01-03 14:06:37,139 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:37,139 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:37,139 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:37,139 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-01-03 14:06:37,140 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2023-01-03 14:06:37,142 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.rpc.request.timeout = 60s (custom)
2023-01-03 14:06:37,142 [EventQueue-PipelineReportForPipelineReportHandler] INFO  pipeline.PipelineManagerImpl (PipelineManagerImpl.java:openPipeline(367)) - Pipeline Pipeline[ Id: 80270caf-3929-4273-963a-b90486f78806, Nodes: 56e9ebea-1da6-4510-b9da-2a36b64eada2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=35233, RATIS=39427, RATIS_ADMIN=39427, RATIS_SERVER=39427, RATIS_DATASTREAM=35533, STANDALONE=33637], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}af27b707-902e-436a-b36c-df002345c922{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=38645, RATIS=40275, RATIS_ADMIN=40275, RATIS_SERVER=40275, RATIS_DATASTREAM=42839, STANDALONE=40537], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}3a3da11c-e5c3-43e0-8561-5c3126dc697f{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42411, RATIS=45127, RATIS_ADMIN=45127, RATIS_SERVER=45127, RATIS_DATASTREAM=43551, STANDALONE=37815], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:3a3da11c-e5c3-43e0-8561-5c3126dc697f, CreationTimestamp2023-01-03T14:06:24.810Z[Etc/UTC]] moved to OPEN state
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.install.snapshot.enabled = false (custom)
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  grpc.GrpcConfigKeys (ConfUtils.java:logGet(46)) - raft.grpc.server.heartbeat.channel = true (default)
2023-01-03 14:06:37,142 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.log.appender.wait-time.min = 10ms (default)
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (HealthyPipelineSafeModeRule.java:process(137)) - SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(200)) - HealthyPipelineSafeModeRule rule is successfully validated
2023-01-03 14:06:37,143 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f: start 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderStateImpl
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(215)) - ScmSafeModeManager, all rules are successfully validated
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(244)) - SCM exiting safe mode.
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ha.SCMContext (SCMContext.java:updateSafeModeStatus(228)) - Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  pipeline.BackgroundPipelineCreator (BackgroundPipelineCreator.java:notifyStatusChanged(254)) - Service BackgroundPipelineCreator transitions to RUNNING.
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  BackgroundPipelineScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service BackgroundPipelineScrubber transitions to RUNNING.
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  ExpiredContainerReplicaOpScrubber (BackgroundSCMService.java:notifyStatusChanged(82)) - Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO  replication.ReplicationManager (ReplicationManager.java:notifyStatusChanged(918)) - Service ReplicationManager transitions to RUNNING.
2023-01-03 14:06:37,143 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:37,143 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN  balancer.ContainerBalancer (ContainerBalancer.java:shouldRun(131)) - Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
2023-01-03 14:06:37,147 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-LeaderElection113] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806: set configuration 0: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,147 [3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 3a3da11c-e5c3-43e0-8561-5c3126dc697f@group-B90486F78806-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-2/data/ratis/80270caf-3929-4273-963a-b90486f78806/current/log_inprogress_0
2023-01-03 14:06:37,167 [af27b707-902e-436a-b36c-df002345c922-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-B90486F78806 with new leaderId: 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:37,167 [af27b707-902e-436a-b36c-df002345c922-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: change Leader from null to 3a3da11c-e5c3-43e0-8561-5c3126dc697f at term 2 for appendEntries, leader elected after 10155ms
2023-01-03 14:06:37,167 [56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread1] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:handleLeaderChangedNotification(904)) - Leader change notification received for group: group-B90486F78806 with new leaderId: 3a3da11c-e5c3-43e0-8561-5c3126dc697f
2023-01-03 14:06:37,168 [56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setLeader(313)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: change Leader from null to 3a3da11c-e5c3-43e0-8561-5c3126dc697f at term 2 for appendEntries, leader elected after 10132ms
2023-01-03 14:06:37,180 [af27b707-902e-436a-b36c-df002345c922-server-thread2] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806: set configuration 0: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,180 [af27b707-902e-436a-b36c-df002345c922-server-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:37,184 [af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - af27b707-902e-436a-b36c-df002345c922@group-B90486F78806-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-0/data/ratis/80270caf-3929-4273-963a-b90486f78806/current/log_inprogress_0
2023-01-03 14:06:37,184 [56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread1] INFO  server.RaftServer$Division (ServerState.java:setRaftConf(430)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806: set configuration 0: peers:[af27b707-902e-436a-b36c-df002345c922|rpc:10.1.0.35:40275|dataStream:10.1.0.35:42839|priority:0|startupRole:FOLLOWER, 56e9ebea-1da6-4510-b9da-2a36b64eada2|rpc:10.1.0.35:39427|dataStream:10.1.0.35:35533|priority:0|startupRole:FOLLOWER, 3a3da11c-e5c3-43e0-8561-5c3126dc697f|rpc:10.1.0.35:45127|dataStream:10.1.0.35:43551|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:37,186 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,187 [56e9ebea-1da6-4510-b9da-2a36b64eada2-server-thread1] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:startLogSegment(452)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker: Starting segment from index:0
2023-01-03 14:06:37,189 [56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:execute(656)) - 56e9ebea-1da6-4510-b9da-2a36b64eada2@group-B90486F78806-SegmentedRaftLogWorker: created new log segment /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-ea0dd9a4-adf3-421a-94f9-55ec37df1381/datanode-1/data/ratis/80270caf-3929-4273-963a-b90486f78806/current/log_inprogress_0
2023-01-03 14:06:37,192 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,209 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,247 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:37,247 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:37,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:37,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:37,345 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,445 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,593 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:37,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:37,599 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:37,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,751 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 2 from [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:37,758 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(55)) - Streaming container data (2) to other datanode with compression NO_COMPRESSION
2023-01-03 14:06:37,775 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 11776 bytes for container 2
2023-01-03 14:06:37,775 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 11776 bytes for container 2
2023-01-03 14:06:37,775 [grpc-default-executor-8] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(203)) - Container 2 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-2/data/replication/work/container-2.tar.gz
2023-01-03 14:06:37,777 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 2 is downloaded with size 11776, starting to import.
2023-01-03 14:06:37,815 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 2 is replicated successfully
2023-01-03 14:06:37,816 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(187)) - Container 2 is replicated.
2023-01-03 14:06:37,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:37,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(217)) - Nodes are ready. Got 7 of 7 DN Heartbeats.
2023-01-03 14:06:37,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(220)) - Cluster exits safe mode
2023-01-03 14:06:37,996 [Listener at 127.0.0.1/33881] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(222)) - SCM became leader
2023-01-03 14:06:38,089 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,118 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,140 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,210 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,211 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,247 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:38,247 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:38,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:38,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:38,329 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:38,329 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:38,345 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,387 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5097507555ns, electionTimeout:5097ms
2023-01-03 14:06:38,387 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,387 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2023-01-03 14:06:38,387 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:38,387 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114
2023-01-03 14:06:38,389 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114 ELECTION round 0: submit vote requests at term 2 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:38,389 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:38,389 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:38,390 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 2, (t:0, i:0))
2023-01-03 14:06:38,390 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:38,390 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:38,390 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,391 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,391 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:38,391 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 2, (t:0, i:0))
2023-01-03 14:06:38,391 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:38,391 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:38,392 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:38,391 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:38,392 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,392 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,392 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:38,392 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:38,392 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:38,392 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t2. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t2, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:38,393 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t2. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t2, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:38,393 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-01-03 14:06:38,393 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t2
2023-01-03 14:06:38,393 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t2
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114 ELECTION round 0: result REJECTED
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection114] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:38,394 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:38,445 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 1 from [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:38,448 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,449 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(105)) - Starting replication of container 5 from [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=41317, RATIS=44879, RATIS_ADMIN=44879, RATIS_SERVER=44879, RATIS_DATASTREAM=41193, STANDALONE=41437], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}, 7c948c4b-a779-4597-819f-06099ef104a1{ip: 10.1.0.35, host: fv-az47-978.mma5zatft5wupo5mzspaixdheh.bx.internal.cloudapp.net, ports: [REPLICATION=42005, RATIS=34705, RATIS_ADMIN=34705, RATIS_SERVER=34705, RATIS_DATASTREAM=35879, STANDALONE=43379], networkLocation: /default-rack, certSerialId: null, persistedOpState: IN_SERVICE, persistedOpStateExpiryEpochSec: 0}]
2023-01-03 14:06:38,450 [grpc-default-executor-2] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(55)) - Streaming container data (1) to other datanode with compression NO_COMPRESSION
2023-01-03 14:06:38,457 [grpc-default-executor-8] INFO  replication.GrpcReplicationService (GrpcReplicationService.java:download(55)) - Streaming container data (5) to other datanode with compression NO_COMPRESSION
2023-01-03 14:06:38,471 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 11776 bytes for container 5
2023-01-03 14:06:38,471 [grpc-default-executor-8] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 11776 bytes for container 5
2023-01-03 14:06:38,472 [grpc-default-executor-10] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(203)) - Container 5 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/replication/work/container-5.tar.gz
2023-01-03 14:06:38,472 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 5 is downloaded with size 11776, starting to import.
2023-01-03 14:06:38,475 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12800 bytes for container 1
2023-01-03 14:06:38,475 [grpc-default-executor-2] INFO  replication.GrpcOutputStream (GrpcOutputStream.java:close(104)) - Sent 12800 bytes for container 1
2023-01-03 14:06:38,476 [grpc-default-executor-8] INFO  replication.GrpcReplicationClient (GrpcReplicationClient.java:onCompleted(203)) - Container 1 is downloaded to /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-6/data/replication/work/container-1.tar.gz
2023-01-03 14:06:38,480 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(117)) - Container 1 is downloaded with size 12800, starting to import.
2023-01-03 14:06:38,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,507 [ContainerReplicationThread-0] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 1 is replicated successfully
2023-01-03 14:06:38,508 [ContainerReplicationThread-0] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(187)) - Container 1 is replicated.
2023-01-03 14:06:38,508 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,510 [ContainerReplicationThread-1] INFO  replication.DownloadAndImportReplicator (DownloadAndImportReplicator.java:replicate(122)) - Container 5 is replicated successfully
2023-01-03 14:06:38,510 [ContainerReplicationThread-1] INFO  replication.ReplicationSupervisor (ReplicationSupervisor.java:run(187)) - Container 5 is replicated.
2023-01-03 14:06:38,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,593 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:38,595 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:38,599 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:38,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:38,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,089 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,140 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,210 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,210 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,247 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:39,247 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:39,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(330)) - Replication Manager is not ready to run until 3000ms after safemode exit
2023-01-03 14:06:39,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:39,345 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,512 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,593 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:39,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:39,599 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:39,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:39,816 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,089 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,117 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,141 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,188 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,191 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,213 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,213 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,247 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,247 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,271 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,271 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,288 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:40,289 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:40,344 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,358 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,512 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,594 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,596 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:40,599 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:40,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,728 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:40,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,360 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:41,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:41,364 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,364 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,365 [JvmPauseMonitor40] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-a13c81fc-644c-4ecf-91c3-6e9a75ed36aa: Detected pause in JVM or host machine (eg GC): pause of approximately 114275793ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,365 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,365 [JvmPauseMonitor44] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-51ba1163-8388-41ac-b784-1dd4f62d306b: Detected pause in JVM or host machine (eg GC): pause of approximately 147027822ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor43] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-06e981fa-2395-4d42-a053-e3b5197e7f77: Detected pause in JVM or host machine (eg GC): pause of approximately 147932443ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor39] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-7c948c4b-a779-4597-819f-06099ef104a1: Detected pause in JVM or host machine (eg GC): pause of approximately 148952865ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor37] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: Detected pause in JVM or host machine (eg GC): pause of approximately 152113236ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor48] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-612e7161-302d-4bcf-a524-ec09f4414ff1: Detected pause in JVM or host machine (eg GC): pause of approximately 152160837ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor45] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-a89e0418-9005-4742-9592-8c0c855df8ce: Detected pause in JVM or host machine (eg GC): pause of approximately 152365942ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,365 [JvmPauseMonitor34] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-c36dba4c-5c72-465b-8876-3f5e456990a2: Detected pause in JVM or host machine (eg GC): pause of approximately 152645348ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor35] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-e673a28b-a4f0-4b9b-b939-463b757d484f: Detected pause in JVM or host machine (eg GC): pause of approximately 157025746ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor36] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-1f39c4a2-123f-4ca0-aca4-b650c3c85ddf: Detected pause in JVM or host machine (eg GC): pause of approximately 157132848ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor57] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-19aec3d0-bc58-440a-899b-3969d29112cc: Detected pause in JVM or host machine (eg GC): pause of approximately 157207950ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor46] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-25c9036e-1b5b-4734-abbe-c826b10abe90: Detected pause in JVM or host machine (eg GC): pause of approximately 158844086ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor42] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-64899d46-4b28-46dc-a6e3-98f7c12bf9be: Detected pause in JVM or host machine (eg GC): pause of approximately 161920755ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor47] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-302a8c77-15cc-4d7d-baad-75f44faccb3e: Detected pause in JVM or host machine (eg GC): pause of approximately 161948455ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor33] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 162046257ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,366 [JvmPauseMonitor41] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 162143359ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,370 [JvmPauseMonitor55] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: Detected pause in JVM or host machine (eg GC): pause of approximately 189111761ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,371 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,371 [JvmPauseMonitor58] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-bc03f53a-8f38-42c1-b7a4-94894081fc1e: Detected pause in JVM or host machine (eg GC): pause of approximately 306543578ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,372 [JvmPauseMonitor52] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-af27b707-902e-436a-b36c-df002345c922: Detected pause in JVM or host machine (eg GC): pause of approximately 329887199ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,372 [JvmPauseMonitor53] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-56e9ebea-1da6-4510-b9da-2a36b64eada2: Detected pause in JVM or host machine (eg GC): pause of approximately 346043659ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,372 [JvmPauseMonitor51] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-om1: Detected pause in JVM or host machine (eg GC): pause of approximately 412613543ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,372 [JvmPauseMonitor56] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-7aee5cb6-4ed9-41f9-a897-fb72e55180cb: Detected pause in JVM or host machine (eg GC): pause of approximately 447372918ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,373 [JvmPauseMonitor54] WARN  util.JvmPauseMonitor (JvmPauseMonitor.java:detectPause(126)) - JvmPauseMonitor-3a3da11c-e5c3-43e0-8561-5c3126dc697f: Detected pause in JVM or host machine (eg GC): pause of approximately 491986512ns.
GC pool 'PS MarkSweep' had collection(s): count=1 time=478ms
GC pool 'PS Scavenge' had collection(s): count=1 time=96ms
2023-01-03 14:06:41,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,594 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:41,599 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:41,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:41,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:42,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,370 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,370 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,371 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,371 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,371 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,375 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:42,493 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,594 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,597 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:42,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:42,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,727 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:42,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,359 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:43,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,370 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,370 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,371 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:43,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,407 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013605241ns, electionTimeout:5013ms
2023-01-03 14:06:43,407 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,408 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
2023-01-03 14:06:43,408 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:43,408 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115
2023-01-03 14:06:43,409 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115 ELECTION round 0: submit vote requests at term 3 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:43,410 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:43,410 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:43,413 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 3, (t:0, i:0))
2023-01-03 14:06:43,413 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:43,413 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:43,413 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,413 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,413 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:43,413 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 3, (t:0, i:0))
2023-01-03 14:06:43,413 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:43,413 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:43,413 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,414 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:43,414 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:43,414 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,414 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:43,414 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:43,414 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:43,415 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t3. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t3, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:43,415 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t3. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t3, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t3
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115 ELECTION round 0: result REJECTED
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 3 for REJECTED
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection115] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:43,416 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:43,417 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:43,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,594 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:43,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:43,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,659 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,730 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:43,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:44,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,370 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,371 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,371 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,371 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:44,485 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,519 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,594 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,598 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:44,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:44,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,711 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,730 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,746 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:44,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,361 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:45,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,373 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,376 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:45,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,519 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,595 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:45,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:45,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:45,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:46,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,373 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,376 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:46,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,522 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,595 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:46,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:46,604 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,712 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,747 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:46,749 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,362 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:47,363 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,373 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:47,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,522 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,595 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,599 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:47,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:47,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:47,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:48,363 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,373 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:48,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,454 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037392427ns, electionTimeout:5037ms
2023-01-03 14:06:48,454 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,454 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 3 for changeToCandidate
2023-01-03 14:06:48,454 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:48,454 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116
2023-01-03 14:06:48,456 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116 ELECTION round 0: submit vote requests at term 4 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:48,457 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:48,457 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:48,457 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 4, (t:0, i:0))
2023-01-03 14:06:48,457 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:48,458 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:48,458 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,458 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,458 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:48,458 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 4, (t:0, i:0))
2023-01-03 14:06:48,458 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:48,458 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 4 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:48,458 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,458 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,458 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:48,458 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:48,458 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:48,459 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:48,459 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:48,459 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t4. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t4, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:48,459 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t4. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t4, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t4
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t4
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116 ELECTION round 0: result REJECTED
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 4 for REJECTED
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116
2023-01-03 14:06:48,460 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection116] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:48,461 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:48,461 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:48,486 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,522 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,595 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:48,600 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:48,606 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,714 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:48,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:49,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,373 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,373 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,490 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,522 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,595 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:49,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:49,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:49,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,363 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:50,371 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,374 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,377 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:50,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,490 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,523 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,596 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,600 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:50,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:50,606 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,672 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:50,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:51,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,374 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:51,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,491 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,511 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,523 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,596 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:51,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:51,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:51,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,363 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:52,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,374 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,377 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,377 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,378 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:52,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,378 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,491 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,512 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,596 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:52,601 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:52,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,660 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,750 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:52,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:53,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,374 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:53,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,486 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:53,486 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:53,491 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,581 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5120317046ns, electionTimeout:5120ms
2023-01-03 14:06:53,581 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,581 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 4 for changeToCandidate
2023-01-03 14:06:53,581 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:53,581 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117
2023-01-03 14:06:53,584 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117 ELECTION round 0: submit vote requests at term 5 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:53,585 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:53,585 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:53,585 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 5, (t:0, i:0))
2023-01-03 14:06:53,585 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:53,585 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:53,585 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,586 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,586 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:53,586 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:53,586 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:53,587 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 5, (t:0, i:0))
2023-01-03 14:06:53,587 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:53,587 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 5 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:53,587 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,587 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,587 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:53,587 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:53,587 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:53,588 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t5. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t5, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:53,589 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t5. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t5, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117: ELECTION REJECTED received 2 response(s) and 0 exception(s):
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t5
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 1: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t5
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117 ELECTION round 0: result REJECTED
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 5 for REJECTED
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117
2023-01-03 14:06:53,589 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection117] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:53,592 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:53,593 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:53,596 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:53,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:53,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,674 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:53,753 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,363 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:54,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,374 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,374 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:54,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,399 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,400 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,491 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,523 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,596 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,601 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:54,602 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:54,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,715 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:54,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:55,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,373 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,375 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,379 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:55,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,493 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,597 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,602 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:55,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:55,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,716 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:55,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,364 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:56,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,375 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,375 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:56,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,491 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,516 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,597 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,602 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:56,603 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:56,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,716 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:56,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,362 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 0 containers.
2023-01-03 14:06:57,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,375 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,375 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,379 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:57,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,384 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,492 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,597 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,602 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:57,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:06:57,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,716 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:57,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,360 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:58,366 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,370 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,375 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,379 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:58,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,386 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,492 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,597 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,602 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:58,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:58,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,663 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:58,663 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:58,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,677 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(143)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5087386786ns, electionTimeout:5084ms
2023-01-03 14:06:58,677 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,677 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from  FOLLOWER to CANDIDATE at term 5 for changeToCandidate
2023-01-03 14:06:58,677 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(46)) - raft.server.leaderelection.pre-vote = false (custom)
2023-01-03 14:06:58,677 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118
2023-01-03 14:06:58,680 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(312)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118 ELECTION round 0: submit vote requests at term 6 for -1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:58,680 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:58,680 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:58,681 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 6, (t:0, i:0))
2023-01-03 14:06:58,681 [grpc-default-executor-8] INFO  impl.VoteContext (VoteContext.java:log(49)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FOLLOWER: reject ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 1 > candidate's priority 0
2023-01-03 14:06:58,681 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:58,681 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 19aec3d0-bc58-440a-899b-3969d29112cc: shutdown 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,682 [grpc-default-executor-8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 19aec3d0-bc58-440a-899b-3969d29112cc: start 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,682 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:58,682 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1218)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: receive requestVote(ELECTION, 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, group-7662FB7DDA7E, 6, (t:0, i:0))
2023-01-03 14:06:58,682 [grpc-default-executor-2] INFO  impl.VoteContext (VoteContext.java:log(49)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FOLLOWER: accept ELECTION from 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: our priority 0 <= candidate's priority 0
2023-01-03 14:06:58,682 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E: changes role from  FOLLOWER to FOLLOWER at term 6 for candidate:8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97
2023-01-03 14:06:58,682 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: shutdown 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,682 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:58,682 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState was interrupted
2023-01-03 14:06:58,682 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb: start 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,682 [19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:58,683 [grpc-default-executor-8] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t6. Peer's state: 19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E:t6, leader=null, voted=null, raftlog=Memoized:19aec3d0-bc58-440a-899b-3969d29112cc@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(90)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118: ELECTION REJECTED received 1 response(s) and 0 exception(s):
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(94)) -   Response 0: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-19aec3d0-bc58-440a-899b-3969d29112cc#0:FAIL-t6
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(314)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118 ELECTION round 0: result REJECTED
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  server.RaftServer$Division (RaftServerImpl.java:setRole(321)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E: changes role from CANDIDATE to FOLLOWER at term 6 for REJECTED
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(130)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: shutdown 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118
2023-01-03 14:06:58,684 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-LeaderElection118] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(139)) - 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97: start 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState
2023-01-03 14:06:58,684 [grpc-default-executor-2] INFO  server.RaftServer$Division (RaftServerImpl.java:requestVote(1251)) - 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E replies to ELECTION vote request: 8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97<-7aee5cb6-4ed9-41f9-a897-fb72e55180cb#0:OK-t6. Peer's state: 7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E:t6, leader=null, voted=8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97, raftlog=Memoized:7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97|rpc:10.1.0.35:35277|dataStream:10.1.0.35:32925|priority:0|startupRole:FOLLOWER, 7aee5cb6-4ed9-41f9-a897-fb72e55180cb|rpc:10.1.0.35:39571|dataStream:10.1.0.35:36099|priority:0|startupRole:FOLLOWER, 19aec3d0-bc58-440a-899b-3969d29112cc|rpc:10.1.0.35:43677|dataStream:10.1.0.35:39215|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
2023-01-03 14:06:58,686 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:58,686 [7aee5cb6-4ed9-41f9-a897-fb72e55180cb@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:58,686 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
2023-01-03 14:06:58,687 [8e52d604-a8c2-4427-a1ff-8f5ea7eb2e97@group-7662FB7DDA7E-FollowerState] INFO  server.RaftServerConfigKeys (ConfUtils.java:logFallback(53)) - raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
2023-01-03 14:06:58,716 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,751 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:58,759 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:59,366 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,380 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:06:59,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,382 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,383 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,387 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,492 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,518 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,525 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,597 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,602 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:06:59,604 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 6 containers.
2023-01-03 14:06:59,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,717 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,732 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:06:59,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,361 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,365 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:07:00,366 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,372 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,374 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,376 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,376 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,380 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,380 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 0 milliseconds for processing 0 containers.
2023-01-03 14:07:00,380 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,385 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,387 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,492 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,515 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,524 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,598 [Over Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,603 [Under Replicated Processor] INFO  replication.UnhealthyReplicationProcessor (UnhealthyReplicationProcessor.java:processAll(103)) - Processed 0 containers with health state counts {},failed processing 0
2023-01-03 14:07:00,605 [ReplicationMonitor] INFO  replication.ReplicationManager (ReplicationManager.java:processAll(363)) - Replication Monitor Thread took 1 milliseconds for processing 6 containers.
2023-01-03 14:07:00,605 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,661 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,673 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,717 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,731 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,752 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:00,758 [EventQueue-CommandQueueReportForCommandQueueReportHandler] WARN  events.EventQueue (EventQueue.java:fireEvent(216)) - No event handler registered for event TypedEvent{payloadType=DatanodeDetails, name='Datanode_Command_Queue_Updated'}
2023-01-03 14:07:01,062 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(449)) - Shutting down the Mini Ozone Cluster
2023-01-03 14:07:01,062 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(464)) - Stopping the Mini Ozone Cluster
2023-01-03 14:07:01,062 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopOM(546)) - Stopping the OzoneManager
2023-01-03 14:07:01,062 [Mini-Cluster-Provider-Reap] INFO  om.OzoneManager (OzoneManager.java:stop(2038)) - om1[localhost:0]: Stopping Ozone Manager
2023-01-03 14:07:01,082 [Mini-Cluster-Provider-Reap] INFO  ipc.Server (Server.java:stop(3428)) - Stopping server on 34645
2023-01-03 14:07:01,087 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1517)) - Stopping IPC Server Responder
2023-01-03 14:07:01,087 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - om1: close
2023-01-03 14:07:01,087 [IPC Server listener on 0] INFO  ipc.Server (Server.java:run(1384)) - Stopping IPC Server listener on 0
2023-01-03 14:07:01,087 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - om1: shutdown server GrpcServerProtocolService now
2023-01-03 14:07:01,087 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - om1: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:07:01,088 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa211a238, L:/0:0:0:0:0:0:0:0:34745] CLOSE
2023-01-03 14:07:01,088 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa211a238, L:/0:0:0:0:0:0:0:0:34745] INACTIVE
2023-01-03 14:07:01,088 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0xa211a238, L:/0:0:0:0:0:0:0:0:34745] UNREGISTERED
2023-01-03 14:07:01,096 [om1-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - om1@group-C5BA1605619E: shutdown
2023-01-03 14:07:01,096 [om1-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id="om1"
2023-01-03 14:07:01,096 [om1-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - om1: shutdown om1@group-C5BA1605619E-LeaderStateImpl
2023-01-03 14:07:01,096 [om1-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - om1@group-C5BA1605619E-PendingRequests: sendNotLeaderResponses
2023-01-03 14:07:01,110 [om1-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - om1@group-C5BA1605619E-StateMachineUpdater: set stopIndex = 86
2023-01-03 14:07:01,110 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:takeSnapshot(445)) - Current Snapshot Index (t:1, i:86)
2023-01-03 14:07:01,110 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - om1@group-C5BA1605619E-StateMachineUpdater: Took a snapshot at index 86
2023-01-03 14:07:01,110 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - om1@group-C5BA1605619E-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 86
2023-01-03 14:07:01,110 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-01-03 14:07:01,110 [om1@group-C5BA1605619E-StateMachineUpdater] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(466)) - Stopping OMDoubleBuffer flush thread
2023-01-03 14:07:01,110 [OMDoubleBufferFlushThread] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:flushTransactions(385)) - OMDoubleBuffer flush thread OMDoubleBufferFlushThread is interrupted and will exit.
2023-01-03 14:07:01,111 [om1-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - om1@group-C5BA1605619E: closes. applyIndex: 86
2023-01-03 14:07:01,111 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:07:01,112 [om1-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - om1@group-C5BA1605619E-SegmentedRaftLogWorker close()
2023-01-03 14:07:01,122 [JvmPauseMonitor33] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(111)) - JvmPauseMonitor-om1: Stopped
2023-01-03 14:07:01,122 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerStateMachine (OzoneManagerStateMachine.java:close(499)) - StateMachine has shutdown. Shutdown OzoneManager if not already shutdown.
2023-01-03 14:07:01,122 [Mini-Cluster-Provider-Reap] INFO  ratis.OzoneManagerDoubleBuffer (OzoneManagerDoubleBuffer.java:stop(478)) - OMDoubleBuffer flush thread is not running.
2023-01-03 14:07:01,122 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service KeyDeletingService
2023-01-03 14:07:01,123 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service DirectoryDeletingService
2023-01-03 14:07:01,123 [Mini-Cluster-Provider-Reap] INFO  utils.BackgroundService (BackgroundService.java:shutdown(141)) - Shutting down service OpenKeyCleanupService
2023-01-03 14:07:01,123 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.w.WebAppContext@5e96c895{ozoneManager,/,null,STOPPED}{file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/ozoneManager}
2023-01-03 14:07:01,125 [Mini-Cluster-Provider-Reap] INFO  server.AbstractConnector (AbstractConnector.java:doStop(383)) - Stopped ServerConnector@3a389618{HTTP/1.1, (http/1.1)}{0.0.0.0:0}
2023-01-03 14:07:01,125 [Mini-Cluster-Provider-Reap] INFO  server.session (HouseKeeper.java:stopScavenging(149)) - node0 Stopped scavenging
2023-01-03 14:07:01,125 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@7924b9f7{static,/static,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-classes/webapps/static,STOPPED}
2023-01-03 14:07:01,125 [Mini-Cluster-Provider-Reap] INFO  handler.ContextHandler (ContextHandler.java:doStop(1159)) - Stopped o.e.j.s.ServletContextHandler@1e95f027{logs,/logs,file:///home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/log,STOPPED}
2023-01-03 14:07:01,133 [Mini-Cluster-Provider-Reap] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stopDatanodes(523)) - Stopping the HddsDatanodes
2023-01-03 14:07:01,139 [Mini-Cluster-Provider-Reap] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:07:01,150 [Mini-Cluster-Provider-Reap] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: close
2023-01-03 14:07:01,151 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: shutdown
2023-01-03 14:07:01,151 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-03ABF1FB5BF6,id=f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:07:01,151 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(110)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState
2023-01-03 14:07:01,151 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown server GrpcServerProtocolService now
2023-01-03 14:07:01,151 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-03ABF1FB5BF6: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/sm/snapshot.1_0
2023-01-03 14:07:01,152 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:07:01,154 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 8161063e-a6c1-4ab4-9440-f30963410d31 Close channels
2023-01-03 14:07:01,155 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-03ABF1FB5BF6: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/7bb234e9-34d9-4a9e-92ac-03abf1fb5bf6/sm/snapshot.1_0 took: 3 ms
2023-01-03 14:07:01,155 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:07:01,155 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:07:01,156 [grpc-default-executor-3] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: installSnapshot onError, lastRequest: null: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:07:01,156 [grpc-default-executor-6] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-01-03 14:07:01,156 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60: shutdown
2023-01-03 14:07:01,156 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-A877367D9F60,id=f6318f2f-492d-4bd7-ad30-0c72f4db1bf2
2023-01-03 14:07:01,156 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-LeaderStateImpl
2023-01-03 14:07:01,156 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-PendingRequests: sendNotLeaderResponses
2023-01-03 14:07:01,156 [grpc-default-executor-2] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(122)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: installSnapshot onError, lastRequest: 7c948c4b-a779-4597-819f-06099ef104a1->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2#1-t1,previous=(t:0, i:0),leaderCommit=0,initializing? true,entries: size=1, first=(t:1, i:0), CONFIGURATIONENTRY(current:id: "a13c81fc-644c-4ecf-91c3-6e9a75ed36aa"
address: "10.1.0.35:42475"
dataStreamAddress: "10.1.0.35:44301"
clientAddress: "10.1.0.35:42475"
adminAddress: "10.1.0.35:42475"
startupRole: FOLLOWER
,id: "7c948c4b-a779-4597-819f-06099ef104a1"
address: "10.1.0.35:34705"
priority: 1
dataStreamAddress: "10.1.0.35:35879"
clientAddress: "10.1.0.35:34705"
adminAddress: "10.1.0.35:34705"
startupRole: FOLLOWER
,id: "f6318f2f-492d-4bd7-ad30-0c72f4db1bf2"
address: "10.1.0.35:44879"
dataStreamAddress: "10.1.0.35:41193"
clientAddress: "10.1.0.35:44879"
adminAddress: "10.1.0.35:44879"
startupRole: FOLLOWER
, old:): org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:07:01,156 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState] INFO  impl.FollowerState (FollowerState.java:run(152)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-FollowerState was interrupted
2023-01-03 14:07:01,159 [grpc-default-executor-5] WARN  server.GrpcLogAppender (LogUtils.java:warn(122)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-AppendLogResponseHandler: Failed appendEntries: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: RST_STREAM closed stream. HTTP/2 error code: CANCEL
2023-01-03 14:07:01,159 [grpc-default-executor-5] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-GrpcLogAppender: Leader has not got in touch with Follower 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2(c0,m0,n1, attendVote=true, lastRpcSendTime=1126, lastRpcResponseTime=1124) yet, just keep nextIndex unchanged and retry.
2023-01-03 14:07:01,163 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6: closes. applyIndex: 0
2023-01-03 14:07:01,164 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:07:01,164 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-03ABF1FB5BF6-SegmentedRaftLogWorker close()
2023-01-03 14:07:01,200 [ForkJoinPool.commonPool-worker-0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(417)) - Attempting to stop container services.
2023-01-03 14:07:01,200 [grpc-default-executor-6] WARN  server.GrpcLogAppender (GrpcLogAppender.java:resetClient(131)) - 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-GrpcLogAppender: Leader has not got in touch with Follower 7c948c4b-a779-4597-819f-06099ef104a1@group-03ABF1FB5BF6->f6318f2f-492d-4bd7-ad30-0c72f4db1bf2(c0,m0,n1, attendVote=true, lastRpcSendTime=1167, lastRpcResponseTime=1165) yet, just keep nextIndex unchanged and retry.
2023-01-03 14:07:01,200 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:07:01,201 [ForkJoinPool.commonPool-worker-0] INFO  server.RaftServer (RaftServerProxy.java:lambda$close$6(409)) - e673a28b-a4f0-4b9b-b939-463b757d484f: close
2023-01-03 14:07:01,201 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-A877367D9F60: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/f77849d2-e757-4ed6-a67d-a877367d9f60/sm/snapshot.1_0
2023-01-03 14:07:01,202 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-A877367D9F60: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-3/data/ratis/f77849d2-e757-4ed6-a67d-a877367d9f60/sm/snapshot.1_0 took: 2 ms
2023-01-03 14:07:01,203 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:07:01,203 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:07:01,203 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60: closes. applyIndex: 0
2023-01-03 14:07:01,210 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711: shutdown
2023-01-03 14:07:01,210 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5BA2C20E2711,id=e673a28b-a4f0-4b9b-b939-463b757d484f
2023-01-03 14:07:01,210 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - e673a28b-a4f0-4b9b-b939-463b757d484f: shutdown e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-LeaderStateImpl
2023-01-03 14:07:01,210 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-PendingRequests: sendNotLeaderResponses
2023-01-03 14:07:01,211 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater: set stopIndex = 0
2023-01-03 14:07:01,214 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcService (GrpcService.java:closeImpl(271)) - e673a28b-a4f0-4b9b-b939-463b757d484f: shutdown server GrpcServerProtocolService now
2023-01-03 14:07:01,215 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-5BA2C20E2711: Taking a snapshot at:(t:1, i:0) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-1/data/ratis/1723a702-18e5-4797-89d6-5ba2c20e2711/sm/snapshot.1_0
2023-01-03 14:07:01,215 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  server.RaftServer$Division (RaftServerImpl.java:lambda$close$4(458)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555: shutdown
2023-01-03 14:07:01,215 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-5D5576319555,id=e673a28b-a4f0-4b9b-b939-463b757d484f
2023-01-03 14:07:01,215 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(93)) - e673a28b-a4f0-4b9b-b939-463b757d484f: shutdown e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-LeaderStateImpl
2023-01-03 14:07:01,215 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:07:01,216 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-5BA2C20E2711: Finished taking a snapshot at:(t:1, i:0) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-1/data/ratis/1723a702-18e5-4797-89d6-5ba2c20e2711/sm/snapshot.1_0 took: 1 ms
2023-01-03 14:07:01,216 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - c36dba4c-5c72-465b-8876-3f5e456990a2: Completed APPEND_ENTRIES, lastRequest: e673a28b-a4f0-4b9b-b939-463b757d484f->c36dba4c-5c72-465b-8876-3f5e456990a2#171-t1,previous=(t:1, i:39),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:40), METADATAENTRY(c:38)
2023-01-03 14:07:01,216 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater: Took a snapshot at index 0
2023-01-03 14:07:01,216 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
2023-01-03 14:07:01,216 [grpc-default-executor-6] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - c36dba4c-5c72-465b-8876-3f5e456990a2: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:07:01,216 [grpc-default-executor-2] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:07:01,216 [grpc-default-executor-2] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2: nextIndex: updateUnconditionally 41 -> 40
2023-01-03 14:07:01,216 [grpc-default-executor-8] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:07:01,216 [grpc-default-executor-8] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->c36dba4c-5c72-465b-8876-3f5e456990a2: nextIndex: updateUnconditionally 40 -> 39
2023-01-03 14:07:01,216 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  server.RaftServer$Division (ServerState.java:close(466)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711: closes. applyIndex: 0
2023-01-03 14:07:01,217 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(282)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-PendingRequests: sendNotLeaderResponses
2023-01-03 14:07:01,217 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-GrpcLogAppender-LogAppenderDaemon] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(200)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-GrpcLogAppender: Wait interrupted by java.lang.InterruptedException
2023-01-03 14:07:01,217 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:07:01,217 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread2] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5BA2C20E2711-SegmentedRaftLogWorker close()
2023-01-03 14:07:01,217 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf: Completed APPEND_ENTRIES, lastRequest: e673a28b-a4f0-4b9b-b939-463b757d484f->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf#156-t1,previous=(t:1, i:39),leaderCommit=38,initializing? true,entries: size=1, first=(t:1, i:40), METADATAENTRY(c:38)
2023-01-03 14:07:01,218 [grpc-default-executor-6] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:07:01,218 [grpc-default-executor-6] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf: nextIndex: updateUnconditionally 41 -> 40
2023-01-03 14:07:01,218 [grpc-default-executor-5] INFO  server.GrpcServerProtocolService (GrpcServerProtocolService.java:onCompleted(143)) - 1f39c4a2-123f-4ca0-aca4-b650c3c85ddf: Completed APPEND_ENTRIES, lastRequest: null
2023-01-03 14:07:01,218 [grpc-default-executor-5] INFO  server.GrpcLogAppender (GrpcLogAppender.java:onCompleted(415)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf-AppendLogResponseHandler: follower responses appendEntries COMPLETED
2023-01-03 14:07:01,218 [grpc-default-executor-5] INFO  leader.FollowerInfo (FollowerInfoImpl.java:lambda$new$0(48)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555->1f39c4a2-123f-4ca0-aca4-b650c3c85ddf: nextIndex: updateUnconditionally 40 -> 39
2023-01-03 14:07:01,232 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:07:01,232 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2@group-A877367D9F60-SegmentedRaftLogWorker close()
2023-01-03 14:07:01,240 [ForkJoinPool.commonPool-worker-0] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - c36dba4c-5c72-465b-8876-3f5e456990a2 Close channels
2023-01-03 14:07:01,242 [grpc-default-executor-5] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:07:01,242 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(153)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater: set stopIndex = 40
2023-01-03 14:07:01,243 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(308)) - group-5D5576319555: Taking a snapshot at:(t:1, i:40) file /home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-1/data/ratis/9ab3fecf-8e2d-490d-9db2-5d5576319555/sm/snapshot.1_40
2023-01-03 14:07:01,242 [grpc-default-executor-2] WARN  server.GrpcClientProtocolService (LogUtils.java:warn(122)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: client cancelled
2023-01-03 14:07:01,252 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(319)) - group-5D5576319555: Finished taking a snapshot at:(t:1, i:40) file:/home/runner/work/ozone/ozone/hadoop-ozone/integration-test/target/test-dir/MiniOzoneClusterImpl-3c2c4fca-0adc-4555-9097-bcf769140b1a/datanode-1/data/ratis/9ab3fecf-8e2d-490d-9db2-5d5576319555/sm/snapshot.1_40 took: 10 ms
2023-01-03 14:07:01,252 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:takeSnapshot(287)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater: Took a snapshot at index 40
2023-01-03 14:07:01,253 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:lambda$new$0(92)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 40
2023-01-03 14:07:01,257 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  server.RaftServer$Division (ServerState.java:close(466)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555: closes. applyIndex: 40
2023-01-03 14:07:01,257 [e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-SegmentedRaftLogWorker] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:run(347)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2023-01-03 14:07:01,258 [e673a28b-a4f0-4b9b-b939-463b757d484f-impl-thread3] INFO  segmented.SegmentedRaftLogWorker (SegmentedRaftLogWorker.java:close(257)) - e673a28b-a4f0-4b9b-b939-463b757d484f@group-5D5576319555-SegmentedRaftLogWorker close()
2023-01-03 14:07:01,275 [Mini-Cluster-Provider-Reap] INFO  server.GrpcServerProtocolClient (GrpcServerProtocolClient.java:close(101)) - 7c948c4b-a779-4597-819f-06099ef104a1 Close channels
2023-01-03 14:07:01,282 [Mini-Cluster-Provider-Reap] INFO  server.GrpcService (GrpcService.java:closeImpl(280)) - f6318f2f-492d-4bd7-ad30-0c72f4db1bf2: shutdown server GrpcServerProtocolService successfully
2023-01-03 14:07:01,283 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1d1c2796, L:/0:0:0:0:0:0:0:0:41193] CLOSE
2023-01-03 14:07:01,283 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1d1c2796, L:/0:0:0:0:0:0:0:0:41193] INACTIVE
2023-01-03 14:07:01,284 [f6318f2f-492d-4bd7-ad30-0c72f4db1bf2-NettyServerStreamRpc-bossGroup--thread1] INFO  logging.LoggingHandler (AbstractInternalLogger.java:log(148)) - [id: 0x1d1c2796, L:/0:0:0:0:0:0:0:0:41193] UNREGISTERED
]]></system-out>
    <system-err><![CDATA[Jan 03, 2023 2:06:37 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@3dc5f58d
java.lang.IllegalStateException: call already closed
	at org.apache.ratis.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:502)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.closeInternal(ServerCallImpl.java:218)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.close(ServerCallImpl.java:211)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:395)
	at org.apache.hadoop.ozone.container.replication.GrpcOutputStream.close(GrpcOutputStream.java:106)
	at org.apache.hadoop.ozone.container.keyvalue.TarContainerPacker.pack(TarContainerPacker.java:186)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.packContainerToDestination(KeyValueContainer.java:883)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.exportContainerData(KeyValueContainer.java:611)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.exportContainer(KeyValueHandler.java:1041)
	at org.apache.hadoop.ozone.container.ozoneimpl.ContainerController.exportContainer(ContainerController.java:168)
	at org.apache.hadoop.ozone.container.replication.OnDemandContainerReplicationSource.copyData(OnDemandContainerReplicationSource.java:75)
	at org.apache.hadoop.ozone.container.replication.GrpcReplicationService.download(GrpcReplicationService.java:60)
	at org.apache.hadoop.hdds.protocol.datanode.proto.IntraDatanodeProtocolServiceGrpc$MethodHandlers.invoke(IntraDatanodeProtocolServiceGrpc.java:207)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener$SimpleForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:06:38 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@64948b3b
java.lang.IllegalStateException: call already closed
	at org.apache.ratis.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:502)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.closeInternal(ServerCallImpl.java:218)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.close(ServerCallImpl.java:211)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:395)
	at org.apache.hadoop.ozone.container.replication.GrpcOutputStream.close(GrpcOutputStream.java:106)
	at org.apache.hadoop.ozone.container.keyvalue.TarContainerPacker.pack(TarContainerPacker.java:186)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.packContainerToDestination(KeyValueContainer.java:883)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.exportContainerData(KeyValueContainer.java:611)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.exportContainer(KeyValueHandler.java:1041)
	at org.apache.hadoop.ozone.container.ozoneimpl.ContainerController.exportContainer(ContainerController.java:168)
	at org.apache.hadoop.ozone.container.replication.OnDemandContainerReplicationSource.copyData(OnDemandContainerReplicationSource.java:75)
	at org.apache.hadoop.ozone.container.replication.GrpcReplicationService.download(GrpcReplicationService.java:60)
	at org.apache.hadoop.hdds.protocol.datanode.proto.IntraDatanodeProtocolServiceGrpc$MethodHandlers.invoke(IntraDatanodeProtocolServiceGrpc.java:207)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener$SimpleForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:06:38 PM org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor run
SEVERE: Exception while executing runnable org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed@21037250
java.lang.IllegalStateException: call already closed
	at org.apache.ratis.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:502)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.closeInternal(ServerCallImpl.java:218)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl.close(ServerCallImpl.java:211)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$ServerCallStreamObserverImpl.onCompleted(ServerCalls.java:395)
	at org.apache.hadoop.ozone.container.replication.GrpcOutputStream.close(GrpcOutputStream.java:106)
	at org.apache.hadoop.ozone.container.keyvalue.TarContainerPacker.pack(TarContainerPacker.java:186)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.packContainerToDestination(KeyValueContainer.java:883)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueContainer.exportContainerData(KeyValueContainer.java:611)
	at org.apache.hadoop.ozone.container.keyvalue.KeyValueHandler.exportContainer(KeyValueHandler.java:1041)
	at org.apache.hadoop.ozone.container.ozoneimpl.ContainerController.exportContainer(ContainerController.java:168)
	at org.apache.hadoop.ozone.container.replication.OnDemandContainerReplicationSource.copyData(OnDemandContainerReplicationSource.java:75)
	at org.apache.hadoop.ozone.container.replication.GrpcReplicationService.download(GrpcReplicationService.java:60)
	at org.apache.hadoop.hdds.protocol.datanode.proto.IntraDatanodeProtocolServiceGrpc$MethodHandlers.invoke(IntraDatanodeProtocolServiceGrpc.java:207)
	at org.apache.ratis.thirdparty.io.grpc.stub.ServerCalls$UnaryServerCallHandler$UnaryServerCallListener.onHalfClose(ServerCalls.java:182)
	at org.apache.ratis.thirdparty.io.grpc.PartialForwardingServerCallListener.onHalfClose(PartialForwardingServerCallListener.java:35)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:23)
	at org.apache.ratis.thirdparty.io.grpc.ForwardingServerCallListener$SimpleForwardingServerCallListener.onHalfClose(ForwardingServerCallListener.java:40)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerCallImpl$ServerStreamListenerImpl.halfClosed(ServerCallImpl.java:354)
	at org.apache.ratis.thirdparty.io.grpc.internal.ServerImpl$JumpToApplicationThreadServerStreamListener$1HalfClosed.runInContext(ServerImpl.java:866)
	at org.apache.ratis.thirdparty.io.grpc.internal.ContextRunnable.run(ContextRunnable.java:37)
	at org.apache.ratis.thirdparty.io.grpc.internal.SerializingExecutor.run(SerializingExecutor.java:133)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1562, target=10.1.0.35:44757} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1474, target=10.1.0.35:44757} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1533, target=10.1.0.35:42305} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1440, target=10.1.0.35:44757} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1537, target=10.1.0.35:45411} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1499, target=10.1.0.35:38633} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1564, target=10.1.0.35:45411} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1560, target=10.1.0.35:33109} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1501, target=10.1.0.35:42305} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1505, target=10.1.0.35:46273} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1442, target=10.1.0.35:42305} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1476, target=10.1.0.35:44873} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1480, target=10.1.0.35:45411} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1558, target=10.1.0.35:46273} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1478, target=10.1.0.35:38633} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1566, target=10.1.0.35:44873} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1503, target=10.1.0.35:33109} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1529, target=10.1.0.35:44873} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1507, target=10.1.0.35:45411} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1444, target=10.1.0.35:46273} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1448, target=10.1.0.35:45411} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1531, target=10.1.0.35:46273} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1535, target=10.1.0.35:44757} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1482, target=10.1.0.35:33109} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

Jan 03, 2023 2:07:01 PM org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference cleanQueue
SEVERE: *~*~*~ Channel ManagedChannelImpl{logId=1446, target=10.1.0.35:38633} was not shutdown properly!!! ~*~*~*
    Make sure to call shutdown()/shutdownNow() and wait until awaitTermination() returns true.
java.lang.RuntimeException: ManagedChannel allocation site
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper$ManagedChannelReference.<init>(ManagedChannelOrphanWrapper.java:93)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:53)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelOrphanWrapper.<init>(ManagedChannelOrphanWrapper.java:44)
	at org.apache.ratis.thirdparty.io.grpc.internal.ManagedChannelImplBuilder.build(ManagedChannelImplBuilder.java:630)
	at org.apache.ratis.thirdparty.io.grpc.internal.AbstractManagedChannelImplBuilder.build(AbstractManagedChannelImplBuilder.java:297)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connectToDatanode(XceiverClientGrpc.java:188)
	at org.apache.hadoop.hdds.scm.XceiverClientGrpc.connect(XceiverClientGrpc.java:158)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:243)
	at org.apache.hadoop.hdds.scm.XceiverClientManager$2.call(XceiverClientManager.java:224)
	at com.google.common.cache.LocalCache$LocalManualCache$1.load(LocalCache.java:4868)
	at com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3533)
	at com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2282)
	at com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2159)
	at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2049)
	at com.google.common.cache.LocalCache.get(LocalCache.java:3966)
	at com.google.common.cache.LocalCache$LocalManualCache.get(LocalCache.java:4863)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.getClient(XceiverClientManager.java:224)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:168)
	at org.apache.hadoop.hdds.scm.XceiverClientManager.acquireClient(XceiverClientManager.java:141)
	at org.apache.hadoop.hdds.scm.storage.BlockOutputStream.<init>(BlockOutputStream.java:161)
	at org.apache.hadoop.hdds.scm.storage.ECBlockOutputStream.<init>(ECBlockOutputStream.java:78)
	at org.apache.hadoop.ozone.client.io.ECBlockOutputStreamEntry.checkStream(ECBlockOutputStreamEntry.java:101)
	at org.apache.hadoop.ozone.client.io.BlockOutputStreamEntry.write(BlockOutputStreamEntry.java:123)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeToOutputStream(ECKeyOutputStream.java:417)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.handleOutputStreamWrite(ECKeyOutputStream.java:401)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.writeDataCells(ECKeyOutputStream.java:354)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeToDatanodes(ECKeyOutputStream.java:571)
	at org.apache.hadoop.ozone.client.io.ECKeyOutputStream.flushStripeFromQueue(ECKeyOutputStream.java:555)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

]]></system-err>
  </testcase>
  <testcase name="testEnteringMaintenanceNodeCompletesAfterSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="13.161"/>
  <testcase name="testDecommissioningNodesCompleteDecommissionOnSCMRestart" classname="org.apache.hadoop.ozone.scm.node.TestDecommissionAndMaintenance" time="30.854"/>
</testsuite>