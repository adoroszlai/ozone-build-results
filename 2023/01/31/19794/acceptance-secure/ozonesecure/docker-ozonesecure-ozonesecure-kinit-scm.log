Attaching to ozonesecure_datanode_2, ozonesecure_om_1, ozonesecure_datanode_1, ozonesecure_kms_1, ozonesecure_s3g_1, ozonesecure_datanode_3, ozonesecure_recon_1, ozonesecure_scm_1, ozonesecure_kdc_1
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2023-01-31 07:46:33,682 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 43001ba40da4/172.18.0.9
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
datanode_2  | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | ************************************************************/
datanode_2  | 2023-01-31 07:46:34,053 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2023-01-31 07:46:34,575 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2023-01-31 07:46:35,619 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2023-01-31 07:46:37,345 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2023-01-31 07:46:37,345 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2023-01-31 07:46:38,533 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:43001ba40da4 ip:172.18.0.9
datanode_2  | 2023-01-31 07:46:43,872 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | 2023-01-31 07:46:44,831 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode_2  | 2023-01-31 07:46:44,835 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_2  | 2023-01-31 07:46:48,088 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_2  | 2023-01-31 07:46:48,097 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2023-01-31 07:46:48,098 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2023-01-31 07:46:48,103 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2023-01-31 07:46:58,169 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_2  | 2023-01-31 07:46:58,472 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.9,host:43001ba40da4
datanode_2  | 2023-01-31 07:46:58,475 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_2  | 2023-01-31 07:46:58,487 [main] ERROR client.DNCertificateClient: Invalid domain 43001ba40da4
datanode_2  | 2023-01-31 07:46:58,493 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@43001ba40da4
datanode_2  | 2023-01-31 07:47:02,780 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:04,783 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:06,786 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:08,788 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:10,803 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:12,805 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:14,807 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:16,810 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:18,814 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2023-01-31 07:46:34,082 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 6b0ee5ff6668/172.18.0.10
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_2  | 2023-01-31 07:47:20,826 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 43001ba40da4/172.18.0.9 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:25,481 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_2  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:27,486 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_2  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-31 07:47:31,385 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_2  | 2023-01-31 07:47:31,502 [main] INFO client.DNCertificateClient: Added certificate [
datanode_2  | [
datanode_2  |   Version: V3
datanode_2  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 
datanode_2  |   Key:  Sun RSA public key, 2048 bits
datanode_2  |   params: null
datanode_2  |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
datanode_2  |   public exponent: 65537
datanode_2  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_2  |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_2  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_2  |   SerialNumber: [    01]
datanode_2  | 
datanode_2  | Certificate Extensions: 3
datanode_2  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_2  | BasicConstraints:[
datanode_2  |   CA:true
datanode_2  |   PathLen:2147483647
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | ]
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): Loaded
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): setting up network...
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): set up 4 sockets
kdc_1       | Jan 31 07:46:18 kdc krb5kdc[7](info): commencing operation
kdc_1       | krb5kdc: starting...
kdc_1       | Jan 31 07:46:22 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:36 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.7: ISSUE: authtime 1675151196, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:44 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.6: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:44 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.9: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:44 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.10: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:48 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.3: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:46:48 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.8: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:47:17 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.4: ISSUE: authtime 1675151237, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:47:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.8: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 31 07:47:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.6: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  | 
datanode_2  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_2  | KeyUsage [
kdc_1       | Jan 31 07:47:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.10: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode_3  | 2023-01-31 07:46:33,896 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
datanode_1  | STARTUP_MSG:   java = 11.0.14.1
datanode_1  | ************************************************************/
datanode_1  | 2023-01-31 07:46:34,260 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2023-01-31 07:46:34,827 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2023-01-31 07:46:35,729 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2023-01-31 07:46:37,157 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2023-01-31 07:46:37,157 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2023-01-31 07:46:38,346 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:6b0ee5ff6668 ip:172.18.0.10
kdc_1       | Jan 31 07:47:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.3: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 31 07:47:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.9: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  |   Key_CertSign
datanode_3  | /************************************************************
kdc_1       | Jan 31 07:47:24 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151182, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  |   Crl_Sign
datanode_2  | ]
datanode_2  | 
kdc_1       | Jan 31 07:47:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151257, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | SubjectAlternativeName [
datanode_1  | 2023-01-31 07:46:43,830 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_1  | 2023-01-31 07:46:45,141 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
kdc_1       | Jan 31 07:47:58 kdc krb5kdc[7](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.8: ISSUE: authtime 1675151278, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
kdc_1       | Jan 31 07:48:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.8: ISSUE: authtime 1675151278, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 31 07:48:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151257, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  |   IPAddress: 172.18.0.4
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_3  | STARTUP_MSG:   host = f206954d6d35/172.18.0.6
datanode_3  | STARTUP_MSG:   args = []
kdc_1       | Jan 31 07:48:14 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:45,141 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
s3g_1       | 2023-01-31 07:46:37,346 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
scm_1       | 2023-01-31 07:46:43,210 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
datanode_3  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_2  | ]
kdc_1       | Jan 31 07:48:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.6: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:48,456 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
s3g_1       | 2023-01-31 07:46:37,351 [main] INFO s3.Gateway: S3Gateway login successful.
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2023-01-31 07:46:33,324 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
kdc_1       | Jan 31 07:48:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.10: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:48,474 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
s3g_1       | 2023-01-31 07:46:38,416 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
scm_1       | STARTUP_MSG: Starting StorageContainerManager
scm_1       | STARTUP_MSG:   host = scm/172.18.0.4
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 
datanode_2  | ]
kdc_1       | Jan 31 07:48:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.9: ISSUE: authtime 1675151204, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:48,475 [main] INFO client.DNCertificateClient: Certificate client init case: 0
s3g_1       | 2023-01-31 07:46:38,429 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om_1        | /************************************************************
recon_1     | 2023-01-31 07:46:32,883 [main] INFO recon.ReconServer: STARTUP_MSG: 
datanode_2  |   Algorithm: [SHA256withRSA]
datanode_2  |   Signature:
kdc_1       | Jan 31 07:48:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151294, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:48,481 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
s3g_1       | 2023-01-31 07:46:38,429 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
scm_1       | STARTUP_MSG:   args = [--init]
scm_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
recon_1     | /************************************************************
kdc_1       | Jan 31 07:48:27 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151307, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:54,216 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_1  | 2023-01-31 07:46:54,495 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.10,host:6b0ee5ff6668
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.8
datanode_3  | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | ************************************************************/
datanode_3  | 2023-01-31 07:46:33,973 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
kdc_1       | Jan 31 07:48:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151307, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:54,505 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
s3g_1       | 2023-01-31 07:46:38,866 [main] INFO util.log: Logging initialized @16881ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG: Starting ReconServer
om_1        | STARTUP_MSG:   args = [--init]
datanode_3  | 2023-01-31 07:46:34,792 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
kdc_1       | Jan 31 07:48:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.3: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:54,517 [main] ERROR client.DNCertificateClient: Invalid domain 6b0ee5ff6668
s3g_1       | 2023-01-31 07:46:40,413 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
recon_1     | STARTUP_MSG:   host = recon/172.18.0.3
om_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_3  | 2023-01-31 07:46:35,764 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
kdc_1       | Jan 31 07:48:37 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:54,532 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@6b0ee5ff6668
s3g_1       | 2023-01-31 07:46:40,502 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | STARTUP_MSG:   java = 11.0.14.1
recon_1     | STARTUP_MSG:   args = []
datanode_3  | 2023-01-31 07:46:37,238 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
datanode_3  | 2023-01-31 07:46:37,238 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
kdc_1       | Jan 31 07:48:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.3: ISSUE: authtime 1675151208, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
datanode_2  | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
datanode_2  | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
datanode_2  | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
datanode_3  | 2023-01-31 07:46:38,363 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:f206954d6d35 ip:172.18.0.6
datanode_3  | 2023-01-31 07:46:43,088 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
s3g_1       | 2023-01-31 07:46:40,529 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
kdc_1       | Jan 31 07:48:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
datanode_2  | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
datanode_2  | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
datanode_3  | 2023-01-31 07:46:44,592 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode_3  | 2023-01-31 07:46:44,593 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
recon_1     | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
s3g_1       | 2023-01-31 07:46:40,539 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
kdc_1       | Jan 31 07:48:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151335, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:49:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151335, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 31 07:49:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151349, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:49:17 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:49:17 kdc krb5kdc[7](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151357, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
datanode_3  | 2023-01-31 07:46:47,971 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
om_1        | STARTUP_MSG:   java = 11.0.14.1
s3g_1       | 2023-01-31 07:46:40,540 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
s3g_1       | 2023-01-31 07:46:40,593 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
kdc_1       | Jan 31 07:49:18 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:49:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:49:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:50:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:50:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:50:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:50:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-31 07:46:41,780 [main] INFO s3.Gateway: STARTUP_MSG: 
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.3.23.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.3.23.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.3.23.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.3.23.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.3.23.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar
recon_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
datanode_3  | 2023-01-31 07:46:47,989 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm_1       | ************************************************************/
scm_1       | 2023-01-31 07:46:43,370 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
s3g_1       | /************************************************************
kdc_1       | Jan 31 07:50:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:50:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:46:59,706 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-31 07:47:01,708 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:46:47,992 [main] INFO client.DNCertificateClient: Certificate client init case: 0
s3g_1       | STARTUP_MSG: Starting Gateway
kdc_1       | Jan 31 07:50:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:51:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:03,710 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-31 07:47:05,713 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:46:48,010 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
kdc_1       | Jan 31 07:51:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:51:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:51:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | STARTUP_MSG:   host = s3g/172.18.0.7
datanode_2  | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
datanode_3  | 2023-01-31 07:46:53,732 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
kdc_1       | Jan 31 07:51:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:07,722 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
s3g_1       | STARTUP_MSG:   args = []
datanode_3  | 2023-01-31 07:46:54,022 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.6,host:f206954d6d35
kdc_1       | Jan 31 07:51:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151358, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:09,724 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | ************************************************************/
datanode_2  | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
s3g_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_3  | 2023-01-31 07:46:54,033 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om_1        | ************************************************************/
om_1        | 2023-01-31 07:46:33,427 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
kdc_1       | Jan 31 07:51:38 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:11,726 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:46:32,963 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.34.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar
datanode_3  | 2023-01-31 07:46:54,047 [main] ERROR client.DNCertificateClient: Invalid domain f206954d6d35
kdc_1       | Jan 31 07:51:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:13,728 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:46:39,355 [main] INFO reflections.Reflections: Reflections took 1046 ms to scan 1 urls, producing 17 keys and 54 values 
datanode_2  | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
datanode_2  | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
datanode_3  | 2023-01-31 07:46:54,052 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@f206954d6d35
scm_1       | 2023-01-31 07:46:44,897 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-31 07:46:46,139 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2023-01-31 07:46:46,449 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
datanode_1  | 2023-01-31 07:47:15,730 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-31 07:47:17,739 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
datanode_3  | 2023-01-31 07:46:59,115 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-31 07:47:19,740 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 6b0ee5ff6668/172.18.0.10 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-31 07:47:25,518 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_2  | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
datanode_2  | 
kdc_1       | Jan 31 07:51:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151498, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:01,117 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:46:42,917 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
om_1        | 2023-01-31 07:46:46,516 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_1  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_2  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_2  | 2023-01-31 07:47:31,525 [main] INFO client.DNCertificateClient: Added certificate [
datanode_3  | 2023-01-31 07:47:03,120 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:51:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:51:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:52:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | [
s3g_1       | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | 2023-01-31 07:47:05,121 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm_1       | 2023-01-31 07:46:47,922 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm_1       | 2023-01-31 07:46:57,687 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm_1       | 2023-01-31 07:46:57,716 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 2023-01-31 07:46:46,591 [main] INFO recon.ReconServer: Initializing Recon server...
recon_1     | 2023-01-31 07:46:47,067 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
recon_1     | 2023-01-31 07:46:48,907 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
datanode_2  |   Version: V3
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 2023-01-31 07:46:48,908 [main] INFO recon.ReconServer: Recon login successful.
datanode_3  | 2023-01-31 07:47:07,134 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:09,136 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:11,139 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:13,146 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 2023-01-31 07:46:46,942 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.8:9862
datanode_2  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=dn@43001ba40da4
recon_1     | 2023-01-31 07:46:49,045 [main] INFO recon.ReconServer: ReconStorageConfig initialized.Initializing certificate.
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_3  | 2023-01-31 07:47:15,153 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:46:46,942 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2023-01-31 07:46:46,942 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
recon_1     | 2023-01-31 07:46:49,056 [main] INFO recon.ReconServer: Initializing secure Recon.
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2023-01-31 07:47:17,161 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:19,164 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From f206954d6d35/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:25,507 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
recon_1     | 2023-01-31 07:46:53,442 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_3  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 
recon_1     | 2023-01-31 07:46:53,459 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
s3g_1       | ************************************************************/
datanode_2  |   Key:  Sun RSA public key, 2048 bits
datanode_2  |   params: null
recon_1     | 2023-01-31 07:46:53,470 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
scm_1       | 2023-01-31 07:46:57,764 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
scm_1       | 2023-01-31 07:47:03,429 [main] INFO ha.HASecurityUtils: Init response: GETCERT
s3g_1       | 2023-01-31 07:46:41,862 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  |   modulus: 27949283793865716631542614476488057423619801288601389609725685668768679494291677125832701649778406624313138094468880425344625587538226191253799410426687454380078378602729072287569542893330802324059586889697235696056629022888200356741036975246327881704561644186261796415738726138546873623645172815347468730214528067201639081044373209423185383663132486892257850520949360361567171676467451843931380520612944041212030120095594216300091130743184185030807465263128912362033638820318201393016110510906398314590453824309504294113703995680977838266049371814427890513965205303408294767473769933392113468237520531080194371359179
datanode_2  |   public exponent: 65537
datanode_2  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
kdc_1       | Jan 31 07:52:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-31 07:46:58,216 [main] INFO recon.ReconServer: Init response: GETCERT
recon_1     | 2023-01-31 07:46:58,225 [main] INFO client.ReconCertificateClient: Creating CSR for Recon.
scm_1       | 2023-01-31 07:47:05,620 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.4,host:scm
s3g_1       | 2023-01-31 07:46:42,036 [main] INFO s3.Gateway: Starting Ozone S3 gateway
datanode_2  |                To: Wed Jan 31 00:00:00 UTC 2024]
datanode_2  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_2  |   SerialNumber: [    71c45569 b5]
kdc_1       | Jan 31 07:52:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151511, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
s3g_1       | 2023-01-31 07:46:42,971 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 
datanode_2  | Certificate Extensions: 2
datanode_2  | [1]: ObjectId: 2.5.29.15 Criticality=true
kdc_1       | Jan 31 07:52:23 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151543, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm_1       | 2023-01-31 07:47:05,621 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm_1       | 2023-01-31 07:47:05,818 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by CN=scm@scm,OU=6dfb726e-350e-430b-835b-cf79da791979,O=CID-5128c6ec-f311-4d77-b590-370d3e099e21 to CN=scm@scm,OU=6dfb726e-350e-430b-835b-cf79da791979,O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, valid from Tue Jan 31 00:00:00 UTC 2023 to Fri Mar 10 00:00:00 UTC 2028
scm_1       | 2023-01-31 07:47:05,903 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.4,host:scm
scm_1       | 2023-01-31 07:47:05,903 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
scm_1       | 2023-01-31 07:47:05,904 [main] ERROR client.SCMCertificateClient: Invalid domain scm
kdc_1       | Jan 31 07:52:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151543, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 2023-01-31 07:47:05,905 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm,scmId:6dfb726e-350e-430b-835b-cf79da791979,clusterId:CID-5128c6ec-f311-4d77-b590-370d3e099e21,subject:scm-sub@scm
scm_1       | 2023-01-31 07:47:06,081 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm_1       | 2023-01-31 07:47:06,263 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
s3g_1       | 2023-01-31 07:46:44,121 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:52:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151543, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 2023-01-31 07:47:06,397 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_2  | KeyUsage [
datanode_2  |   DigitalSignature
s3g_1       | 2023-01-31 07:46:44,121 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
datanode_1  | 2023-01-31 07:47:27,523 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
kdc_1       | Jan 31 07:52:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 2023-01-31 07:47:06,399 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
datanode_2  |   Key_Encipherment
datanode_2  |   Data_Encipherment
om_1        | 2023-01-31 07:46:49,036 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
om_1        | 2023-01-31 07:46:49,054 [main] INFO om.OzoneManager: Ozone Manager login successful.
kdc_1       | Jan 31 07:52:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 2023-01-31 07:47:06,400 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-31 07:47:06,401 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
scm_1       | 2023-01-31 07:47:06,401 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | 2023-01-31 07:47:06,401 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
s3g_1       | 2023-01-31 07:46:44,373 [main] INFO http.HttpServer2: Jetty bound to port 9878
kdc_1       | Jan 31 07:52:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151562, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:52:56 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151576, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  |   Key_Agreement
datanode_2  | ]
s3g_1       | 2023-01-31 07:46:44,378 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 2023-01-31 07:47:06,403 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
kdc_1       | Jan 31 07:53:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151576, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:53:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151576, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:53:09 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151589, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:53:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151589, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-31 07:46:45,020 [main] INFO server.session: DefaultSessionIdManager workerName=node0
scm_1       | 2023-01-31 07:47:06,405 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Jan 31 07:53:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151596, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:53:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151596, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:53:23 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:53:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-31 07:46:58,271 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.3,host:recon
recon_1     | 2023-01-31 07:46:58,285 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1     | 2023-01-31 07:46:58,306 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1     | 2023-01-31 07:47:02,137 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
s3g_1       | 2023-01-31 07:46:45,068 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2023-01-31 07:47:06,406 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
kdc_1       | Jan 31 07:53:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-31 07:47:04,141 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2023-01-31 07:47:06,407 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
kdc_1       | Jan 31 07:53:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-31 07:47:06,143 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-31 07:47:06,422 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
kdc_1       | Jan 31 07:53:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:53:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-31 07:46:45,118 [main] INFO server.session: node0 Scavenging every 600000ms
s3g_1       | 2023-01-31 07:46:45,258 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/s3g.keytab, for principal HTTP/s3g@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:06,427 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
kdc_1       | Jan 31 07:53:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151603, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:54:01 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151641, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 2023-01-31 07:46:45,312 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b672aa8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
s3g_1       | 2023-01-31 07:46:45,313 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@460f76a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2023-01-31 07:47:06,427 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_2  | 
s3g_1       | WARNING: An illegal reflective access operation has occurred
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
om_1        | 2023-01-31 07:46:49,092 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2023-01-31 07:46:49,953 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863]
om_1        | 2023-01-31 07:46:53,611 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:08,145 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:10,147 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | [2]: ObjectId: 2.5.29.17 Criticality=false
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
om_1        | 2023-01-31 07:46:55,613 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:46:57,615 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:12,149 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:54:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151641, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:06,751 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
datanode_2  | SubjectAlternativeName [
datanode_1  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 2023-01-31 07:46:59,616 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
scm_1       | 2023-01-31 07:47:06,766 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  |   IPAddress: 172.18.0.9
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-31 07:47:27,512 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 2023-01-31 07:47:01,618 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:14,151 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:16,153 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
scm_1       | 2023-01-31 07:47:06,908 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
datanode_2  | ]
datanode_3  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 2023-01-31 07:47:03,626 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:18,155 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:54:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151641, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:06,915 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
datanode_2  | 
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
s3g_1       | WARNING: All illegal access operations will be denied in a future release
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
kdc_1       | Jan 31 07:54:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151641, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:06,918 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
datanode_2  | ]
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 2023-01-31 07:47:20,157 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.3 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1       | 2023-01-31 07:47:00,460 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/s3g.keytab, for principal HTTP/s3g@EXAMPLE.COM
kdc_1       | Jan 31 07:54:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151641, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-31 07:47:05,629 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:07,632 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:09,634 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1       | Jan 31, 2023 7:47:03 AM org.glassfish.jersey.internal.Errors logErrors
datanode_2  |   Algorithm: [SHA256withRSA]
datanode_2  |   Signature:
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
kdc_1       | Jan 31 07:54:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151668, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2023-01-31 07:47:11,635 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:13,637 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:15,640 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
datanode_2  | 0000: 94 90 AB C1 11 43 0F F1   C6 07 18 31 EB B8 63 A2  .....C.....1..c.
datanode_2  | 0010: E6 F4 79 7C CF 77 73 FA   9A FC 9D A3 BC AC D5 40  ..y..ws........@
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
kdc_1       | Jan 31 07:54:28 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151668, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:54:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151668, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:54:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151675, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 07:54:35 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151675, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1     | 2023-01-31 07:47:25,554 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
s3g_1       | 
om_1        | 2023-01-31 07:47:17,642 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:19,644 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:21,652 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.8 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 15 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:25,456 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 2023-01-31 07:47:06,924 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
kdc_1       | Jan 31 07:54:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151675, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-31 07:47:03,516 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@60a4e619{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_4_0-SNAPSHOT_jar-_-any-475647158404517589/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/s3gateway}
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 2023-01-31 07:47:06,934 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
kdc_1       | Jan 31 07:54:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151682, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 2023-01-31 07:47:03,605 [main] INFO server.AbstractConnector: Started ServerConnector@5398edd0{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
scm_1       | 2023-01-31 07:47:06,937 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
kdc_1       | Jan 31 07:54:42 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151682, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 2023-01-31 07:47:06,945 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
kdc_1       | Jan 31 07:54:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151682, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-31 07:47:03,607 [main] INFO server.Server: Started @41623ms
s3g_1       | 2023-01-31 07:47:03,613 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2023-01-31 07:47:06,949 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = null (default)
kdc_1       | Jan 31 07:54:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151682, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | 2023-01-31 07:47:03,613 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
s3g_1       | 2023-01-31 07:47:03,615 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
kdc_1       | Jan 31 07:54:55 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151695, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2023-01-31 07:47:06,951 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
datanode_2  | 0020: EA E8 8C 8B 49 AF 4D FF   10 F4 3B 30 35 40 E7 96  ....I.M...;05@..
datanode_2  | 0030: 7E 74 A2 BD CB C9 75 95   35 71 48 96 FA CD 79 A5  .t....u.5qH...y.
datanode_2  | 0040: E1 56 80 90 CA 59 50 19   11 7E E8 B4 2E 7C E8 A2  .V...YP.........
kdc_1       | Jan 31 07:55:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151695, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-31 07:47:06,951 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
datanode_2  | 0050: 6C 75 1A 13 6D 39 DD 76   DC 45 AF 0B 98 3A 7E 5B  lu..m9.v.E...:.[
datanode_2  | 0060: C2 E5 8B 34 B0 40 CA D4   7A 65 E8 90 30 B2 C4 5F  ...4.@..ze..0.._
datanode_2  | 0070: CA 5B C8 79 A0 BA 2C A5   F1 D6 93 8A 6B 8C 49 DE  .[.y..,.....k.I.
kdc_1       | Jan 31 07:55:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151695, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:55:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151695, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:55:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151695, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
scm_1       | 2023-01-31 07:47:07,025 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_2  | 0080: A1 A8 5A 5E 1C 61 E0 55   7D 8C DC 58 8C EA 41 85  ..Z^.a.U...X..A.
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 2023-01-31 07:47:07,027 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2  | 0090: 5E 80 9C 2E 66 31 09 D4   17 79 FF 5D 7F 0D D3 B8  ^...f1...y.]....
datanode_2  | 00A0: 1A 6A 8B BA 91 8B B8 DB   50 33 C9 FA 0E F5 16 F3  .j......P3......
datanode_2  | 00B0: 37 4E 84 47 B6 42 12 2A   0A EA 50 04 84 5E 16 14  7N.G.B.*..P..^..
datanode_2  | 00C0: 12 D3 66 B8 E8 5C 63 5F   17 FC AD EF C9 EB C0 80  ..f..\c_........
datanode_2  | 00D0: 1B BF 63 EF 37 B6 9A 0A   4E 85 92 BC 49 E4 35 7F  ..c.7...N...I.5.
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
kdc_1       | Jan 31 07:55:21 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,027 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
datanode_2  | 00E0: 98 3D B8 B2 4D 41 71 5C   08 08 68 3D DA EB 69 BD  .=..MAq\..h=..i.
datanode_2  | 00F0: 84 7D 35 C6 D1 AE FD 7A   BB D4 10 08 24 AF 37 63  ..5....z....$.7c
datanode_2  | 
datanode_2  | ] from file:/data/metadata/dn/certs/488625236405.crt.
datanode_2  | 2023-01-31 07:47:31,579 [main] INFO client.DNCertificateClient: Added certificate [
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:55:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,027 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | [
datanode_2  |   Version: V3
datanode_2  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 
datanode_3  | 2023-01-31 07:47:30,894 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
kdc_1       | Jan 31 07:55:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,037 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
datanode_2  |   Key:  Sun RSA public key, 2048 bits
datanode_3  | 2023-01-31 07:47:30,970 [main] INFO client.DNCertificateClient: Added certificate [
datanode_3  | [
datanode_3  |   Version: V3
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_3  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
scm_1       | 2023-01-31 07:47:07,053 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72] REGISTERED
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  |   params: null
kdc_1       | Jan 31 07:55:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151721, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,061 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72] BIND: 0.0.0.0/0.0.0.0:0
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_3  | 
datanode_2  |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
kdc_1       | Jan 31 07:55:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,063 [main] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: addNew group-370D3E099E21:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|priority:0|startupRole:FOLLOWER] returns group-370D3E099E21:java.util.concurrent.CompletableFuture@20a967fe[Not completed]
scm_1       | 2023-01-31 07:47:07,068 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72, L:/0.0.0.0:38771] ACTIVE
datanode_1  | 2023-01-31 07:47:31,804 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_1  | 2023-01-31 07:47:31,930 [main] INFO client.DNCertificateClient: Added certificate [
datanode_1  | [
datanode_1  |   Version: V3
datanode_1  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 
datanode_1  |   Key:  Sun RSA public key, 2048 bits
datanode_1  |   params: null
datanode_1  |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
datanode_1  |   public exponent: 65537
datanode_1  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_1  |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_1  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_1  |   SerialNumber: [    01]
datanode_1  | 
datanode_1  | Certificate Extensions: 3
datanode_1  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | BasicConstraints:[
datanode_1  |   CA:true
datanode_1  |   PathLen:2147483647
datanode_1  | ]
datanode_1  | 
datanode_1  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  |   Key:  Sun RSA public key, 2048 bits
datanode_3  |   params: null
datanode_3  |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_3  |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_3  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_3  |   SerialNumber: [    01]
datanode_3  | 
datanode_1  | KeyUsage [
datanode_1  |   Key_CertSign
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
datanode_3  | Certificate Extensions: 3
datanode_1  |   Crl_Sign
datanode_1  | ]
kdc_1       | Jan 31 07:55:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_3  | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | , while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-31 07:47:27,564 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
scm_1       | 2023-01-31 07:47:07,123 [pool-2-thread-1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979: new RaftServerImpl for group-370D3E099E21:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
scm_1       | 2023-01-31 07:47:07,130 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
kdc_1       | Jan 31 07:55:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:56:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151745, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_3  | BasicConstraints:[
datanode_3  |   CA:true
datanode_3  |   PathLen:2147483647
kdc_1       | Jan 31 07:56:04 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 2023-01-31 07:47:07,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2023-01-31 07:47:07,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_3  | ]
datanode_3  | 
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_3  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | KeyUsage [
scm_1       | 2023-01-31 07:47:07,131 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_3  |   Key_CertSign
datanode_3  |   Crl_Sign
scm_1       | 2023-01-31 07:47:07,132 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2023-01-31 07:47:07,132 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_3  | ]
kdc_1       | Jan 31 07:56:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:56:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_3  | 
datanode_2  |   public exponent: 65537
kdc_1       | Jan 31 07:56:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,147 [pool-2-thread-1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: ConfigurationManager, init=-1: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | , while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 16 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-31 07:47:27,465 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_3  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
kdc_1       | Jan 31 07:56:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,148 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
datanode_1  | 
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
datanode_3  | SubjectAlternativeName [
datanode_2  |                To: Fri Mar 10 00:00:00 UTC 2028]
kdc_1       | Jan 31 07:56:33 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,160 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | [3]: ObjectId: 2.5.29.17 Criticality=false
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
kdc_1       | Jan 31 07:56:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,160 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | SubjectAlternativeName [
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_3  |   IPAddress: 172.18.0.4
datanode_2  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_2  |   SerialNumber: [    6c0d0934 9f]
kdc_1       | Jan 31 07:56:45 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,185 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  |   IPAddress: 172.18.0.4
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_3  | ]
datanode_2  | 
datanode_2  | Certificate Extensions: 3
kdc_1       | Jan 31 07:56:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,191 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
datanode_1  | ]
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
kdc_1       | Jan 31 07:56:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,192 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 
datanode_3  | 
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | BasicConstraints:[
recon_1     | , while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 31 07:57:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,284 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | ]
datanode_3  | ]
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-31 07:47:31,658 [main] INFO client.ReconCertificateClient: Loading certificate from location:/data/metadata/recon/certs.
recon_1     | 2023-01-31 07:47:31,779 [main] INFO client.ReconCertificateClient: Added certificate [
datanode_1  |   Algorithm: [SHA256withRSA]
datanode_3  |   Algorithm: [SHA256withRSA]
datanode_3  |   Signature:
datanode_3  | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
datanode_3  | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
datanode_3  | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
datanode_3  | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
datanode_3  | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
datanode_3  | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
datanode_3  | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
datanode_3  | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
datanode_3  | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
scm_1       | 2023-01-31 07:47:07,291 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1  |   Signature:
datanode_1  | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
datanode_1  | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
datanode_1  | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
datanode_1  | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
datanode_1  | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
datanode_1  | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
datanode_1  | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
datanode_1  | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
datanode_1  | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
datanode_3  | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
scm_1       | 2023-01-31 07:47:07,292 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1       | 2023-01-31 07:47:07,292 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1       | 2023-01-31 07:47:07,293 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1       | 2023-01-31 07:47:07,294 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21 does not exist. Creating ...
datanode_1  | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
datanode_3  | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
datanode_1  | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
datanode_1  | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
datanode_1  | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
datanode_1  | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
om_1        | , while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
kdc_1       | Jan 31 07:57:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
kdc_1       | Jan 31 07:57:16 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,300 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/in_use.lock acquired by nodename 13@scm
scm_1       | 2023-01-31 07:47:07,309 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21 has been successfully formatted.
scm_1       | 2023-01-31 07:47:07,314 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2023-01-31 07:47:07,322 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
kdc_1       | Jan 31 07:57:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,323 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-31 07:47:07,325 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1       | 2023-01-31 07:47:07,326 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-5128c6ec-f311-4d77-b590-370d3e099e21;layoutVersion=3
datanode_3  | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
kdc_1       | Jan 31 07:57:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:57:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:57:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,328 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1       | 2023-01-31 07:47:07,335 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  |   CA:true
om_1        | 2023-01-31 07:47:29,604 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
datanode_3  | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
kdc_1       | Jan 31 07:57:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:57:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 
recon_1     | [
recon_1     |   Version: V3
recon_1     |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
om_1        | 2023-01-31 07:47:29,604 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
datanode_3  | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
datanode_2  |   PathLen:2147483647
datanode_2  | ]
datanode_2  | 
om_1        | 2023-01-31 07:47:31,019 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
datanode_3  | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
datanode_1  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_1  | 2023-01-31 07:47:31,973 [main] INFO client.DNCertificateClient: Added certificate [
datanode_2  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_2  | KeyUsage [
scm_1       | 2023-01-31 07:47:07,336 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | value: 9862
datanode_3  | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 
recon_1     |   Key:  Sun RSA public key, 2048 bits
om_1        | ]
om_1        | 2023-01-31 07:47:31,040 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | [
datanode_1  |   Version: V3
recon_1     |   params: null
recon_1     |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
scm_1       | 2023-01-31 07:47:07,342 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21
om_1        | 2023-01-31 07:47:31,049 [main] INFO security.OMCertificateClient: Certificate client init case: 0
datanode_3  | 
datanode_1  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=dn@6b0ee5ff6668
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  |   DigitalSignature
recon_1     |   public exponent: 65537
recon_1     |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
recon_1     |                To: Fri Mar 10 00:00:00 UTC 2028]
om_1        | 2023-01-31 07:47:31,050 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
kdc_1       | Jan 31 07:58:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  |   Key_Encipherment
datanode_2  |   Data_Encipherment
scm_1       | 2023-01-31 07:47:07,342 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
scm_1       | 2023-01-31 07:47:07,343 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2023-01-31 07:47:35,225 [main] INFO om.OzoneManager: Init response: GETCERT
datanode_3  | 2023-01-31 07:47:31,000 [main] INFO client.DNCertificateClient: Added certificate [
datanode_2  |   Key_Agreement
datanode_2  |   Key_CertSign
datanode_2  |   Crl_Sign
scm_1       | 2023-01-31 07:47:07,344 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
scm_1       | 2023-01-31 07:47:07,345 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1        | 2023-01-31 07:47:35,429 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.8,host:om
om_1        | 2023-01-31 07:47:35,434 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | [
datanode_2  | ]
datanode_2  | 
datanode_2  | [3]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | 2023-01-31 07:47:07,345 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2023-01-31 07:47:07,346 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2023-01-31 07:47:35,463 [main] ERROR security.OMCertificateClient: Invalid domain om
om_1        | 2023-01-31 07:47:35,468 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_3  |   Version: V3
datanode_2  | SubjectAlternativeName [
datanode_2  |   IPAddress: 172.18.0.4
datanode_2  | ]
scm_1       | 2023-01-31 07:47:07,347 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2023-01-31 07:47:07,347 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=dn@f206954d6d35
datanode_2  | 
datanode_2  | ]
datanode_2  |   Algorithm: [SHA256withRSA]
scm_1       | 2023-01-31 07:47:07,358 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1       | 2023-01-31 07:47:07,358 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  |   Signature:
datanode_2  | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
datanode_2  | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
scm_1       | 2023-01-31 07:47:07,386 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-31 07:47:07,389 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-31 07:47:07,389 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
recon_1     |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
recon_1     |   SerialNumber: [    01]
scm_1       | 2023-01-31 07:47:07,398 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 
datanode_3  | 
datanode_2  | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
datanode_2  | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
kdc_1       | Jan 31 07:58:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,398 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-31 07:47:07,400 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: start as a follower, conf=-1: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  |   Key:  Sun RSA public key, 2048 bits
recon_1     | 
recon_1     | Certificate Extensions: 3
recon_1     | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  |   Key:  Sun RSA public key, 2048 bits
kdc_1       | Jan 31 07:58:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:58:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
datanode_3  |   params: null
datanode_3  |   modulus: 25986194431737750900062441816091149898800854158327090969281968705583366967449298734223937732595354331292371168583200276761728354508823668482888837644483436393937268366436774725485810659613666300990218696939736213867407917457243765852751426955378884831766007699107787663993021192578514595391835479081487529457168489088582414115275041316294119780578984386575065767531890881935906724718827932274872625184776715369926771415058573642146416284199672476699398706067257822603839162725716322026264951148171957644419286268308605536692539052548507858230205826535521435025940033059100291410470325955785102919926198913365352880631
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
om_1        | 2023-01-31 07:47:35,469 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.8:9862
scm_1       | 2023-01-31 07:47:07,401 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
datanode_2  | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
kdc_1       | Jan 31 07:58:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | BasicConstraints:[
recon_1     |   CA:true
recon_1     |   PathLen:2147483647
scm_1       | 2023-01-31 07:47:07,403 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState
datanode_1  |   params: null
datanode_1  |   modulus: 29342834276052117179704249541207650348657475512839870408089944263049938692837300899882754021607058707936026584114085613758163578554424367734638749855244575457742125935614834221360522611000094909074829710200802240561002217533405355170580874378398693247095569175186007788490354137866789371774585715759556204127853185926612551777195718573763211024037381889429442868944586468277067727795638842752332100083936258660613673925738111844362680019192473744239726095359323423490972426741219786743582056685512016864749225305754806908246353164378529210532503545332008406907856094854578413305691629836661603407411972411803955041967
datanode_1  |   public exponent: 65537
recon_1     | ]
recon_1     | 
om_1        | 2023-01-31 07:47:35,470 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
scm_1       | 2023-01-31 07:47:07,405 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
recon_1     | [2]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | KeyUsage [
recon_1     |   Key_CertSign
recon_1     |   Crl_Sign
kdc_1       | Jan 31 07:58:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:07,407 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
datanode_2  | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
datanode_2  | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
datanode_3  |                To: Wed Jan 31 00:00:00 UTC 2024]
datanode_3  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
scm_1       | 2023-01-31 07:47:07,409 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-370D3E099E21,id=6dfb726e-350e-430b-835b-cf79da791979
datanode_1  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_1  |                To: Wed Jan 31 00:00:00 UTC 2024]
datanode_1  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_3  |   SerialNumber: [    71a00026 d5]
datanode_3  | 
scm_1       | 2023-01-31 07:47:07,412 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_1  |   SerialNumber: [    71cd1802 41]
datanode_1  | 
datanode_1  | Certificate Extensions: 2
recon_1     | ]
recon_1     | 
scm_1       | 2023-01-31 07:47:07,412 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
datanode_1  | [1]: ObjectId: 2.5.29.15 Criticality=true
om_1        | 2023-01-31 07:47:35,470 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
om_1        | 2023-01-31 07:47:35,481 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om,ip:172.18.0.8,scmId:6dfb726e-350e-430b-835b-cf79da791979,clusterId:CID-5128c6ec-f311-4d77-b590-370d3e099e21,subject:om
recon_1     | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_3  | Certificate Extensions: 2
datanode_3  | [1]: ObjectId: 2.5.29.15 Criticality=true
kdc_1       | Jan 31 07:59:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | KeyUsage [
om_1        | 2023-01-31 07:47:37,248 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
om_1        | 2023-01-31 07:47:37,276 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
recon_1     | SubjectAlternativeName [
recon_1     |   IPAddress: 172.18.0.4
recon_1     | ]
recon_1     | 
scm_1       | 2023-01-31 07:47:07,413 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
scm_1       | 2023-01-31 07:47:07,414 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2023-01-31 07:47:07,417 [main] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: start RPC server
scm_1       | 2023-01-31 07:47:07,432 [main] INFO server.GrpcService: 6dfb726e-350e-430b-835b-cf79da791979: GrpcService started, listening on 9894
scm_1       | 2023-01-31 07:47:07,456 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-6dfb726e-350e-430b-835b-cf79da791979: Started
datanode_2  | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_2  | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
datanode_2  | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
datanode_2  | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
datanode_2  | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
kdc_1       | Jan 31 07:59:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:59:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:59:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
recon_1     | ]
om_1        | /************************************************************
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.8
datanode_3  | KeyUsage [
datanode_3  |   DigitalSignature
datanode_2  | 
datanode_2  | ] from file:/data/metadata/dn/certs/CA-464075175071.crt.
datanode_1  |   DigitalSignature
datanode_2  | 2023-01-31 07:47:31,634 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29088748407 ms and interval 86400000 ms.
datanode_2  | 2023-01-31 07:47:31,634 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_2  | 2023-01-31 07:47:31,825 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1  |   Key_Encipherment
datanode_2  | 2023-01-31 07:47:32,839 [main] INFO reflections.Reflections: Reflections took 780 ms to scan 2 urls, producing 100 keys and 224 values 
datanode_2  | 2023-01-31 07:47:33,612 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
kdc_1       | Jan 31 07:59:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  |   Key_Encipherment
scm_1       | 2023-01-31 07:47:12,457 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.FollowerState: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053450535ns, electionTimeout:5048ms
scm_1       | 2023-01-31 07:47:12,458 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: shutdown 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState
recon_1     |   Algorithm: [SHA256withRSA]
datanode_1  |   Data_Encipherment
datanode_1  |   Key_Agreement
datanode_1  | ]
datanode_1  | 
datanode_3  |   Data_Encipherment
kdc_1       | Jan 31 07:59:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:59:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 07:59:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | ************************************************************/
datanode_3  |   Key_Agreement
datanode_2  | 2023-01-31 07:47:34,641 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_2  | 2023-01-31 07:47:34,747 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_2  | 2023-01-31 07:47:34,858 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
kdc_1       | Jan 31 07:59:58 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:17 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:00:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675151764, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:22 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 08:01:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:01:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:12,458 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | ]
datanode_3  | 
datanode_3  | [2]: ObjectId: 2.5.29.17 Criticality=false
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2023-01-31 07:47:12,461 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     |   Signature:
recon_1     | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
datanode_3  | SubjectAlternativeName [
datanode_1  | [2]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | 2023-01-31 07:47:34,886 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_2  | 2023-01-31 07:47:35,098 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2023-01-31 07:47:35,199 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | 2023-01-31 07:47:12,461 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1
om_1        | 2023-01-31 07:47:46,020 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
datanode_3  |   IPAddress: 172.18.0.6
datanode_1  | SubjectAlternativeName [
datanode_1  |   IPAddress: 172.18.0.10
recon_1     | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
recon_1     | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
recon_1     | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
recon_1     | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
recon_1     | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
kdc_1       | Jan 31 08:01:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:35,214 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2  | 2023-01-31 07:47:35,224 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2  | 2023-01-31 07:47:35,225 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_2  | 2023-01-31 07:47:35,227 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_2  | 2023-01-31 07:47:35,511 [Thread-19] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_2  | 2023-01-31 07:47:35,514 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_2  | 2023-01-31 07:47:40,790 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
recon_1     | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
kdc_1       | Jan 31 08:01:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:12,466 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.LeaderElection: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-31 07:47:12,466 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.LeaderElection: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1 ELECTION round 0: result PASSED (term=1)
scm_1       | 2023-01-31 07:47:12,467 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: shutdown 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1
om_1        | STARTUP_MSG:   host = om/172.18.0.8
datanode_2  | 2023-01-31 07:47:41,510 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode_2  | 2023-01-31 07:47:41,530 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
datanode_2  | 2023-01-31 07:47:41,732 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | ]
datanode_3  | 
datanode_3  | ]
datanode_3  |   Algorithm: [SHA256withRSA]
recon_1     | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
datanode_3  |   Signature:
datanode_3  | 0000: 67 9F 12 35 26 47 8E 54   1F E7 1C 64 9E E2 88 67  g..5&G.T...d...g
datanode_3  | 0010: 4E 39 F1 24 1D 9E D0 3A   5B 92 0A 1D DC 3F 47 E4  N9.$...:[....?G.
datanode_3  | 0020: E5 02 05 71 FB 27 EF 31   1D 3D C4 12 07 13 63 96  ...q.'.1.=....c.
datanode_3  | 0030: FA 86 BA C7 21 D8 EF C6   6F 3E FF 18 91 CC 59 54  ....!...o>....YT
datanode_2  | 2023-01-31 07:47:42,368 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
recon_1     | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
datanode_3  | 0040: 02 06 8C 09 DA 7D 03 37   C1 07 67 31 34 B6 71 C0  .......7..g14.q.
datanode_3  | 0050: 17 85 66 20 5C F3 11 9A   CF 55 62 7C 2D 60 E1 F5  ..f \....Ub.-`..
scm_1       | 2023-01-31 07:47:12,467 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
scm_1       | 2023-01-31 07:47:12,467 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: change Leader from null to 6dfb726e-350e-430b-835b-cf79da791979 at term 1 for becomeLeader, leader elected after 5285ms
datanode_2  | 2023-01-31 07:47:43,217 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_2  | 2023-01-31 07:47:43,225 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
om_1        | STARTUP_MSG:   args = []
om_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
kdc_1       | Jan 31 08:02:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | ]
datanode_1  | 
scm_1       | 2023-01-31 07:47:12,474 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2023-01-31 07:47:43,225 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_2  | 2023-01-31 07:47:43,232 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_3  | 0060: 69 9C E7 62 0B E2 24 CC   80 29 5B 5A FB 2B 32 F2  i..b..$..)[Z.+2.
datanode_1  | ]
datanode_1  |   Algorithm: [SHA256withRSA]
kdc_1       | Jan 31 08:02:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:12,479 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_2  | 2023-01-31 07:47:43,233 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
om_1        | STARTUP_MSG:   java = 11.0.14.1
recon_1     | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
scm_1       | 2023-01-31 07:47:12,480 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
datanode_2  | 2023-01-31 07:47:43,233 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_2  | 2023-01-31 07:47:43,235 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  |   Signature:
datanode_1  | 0000: 16 72 77 2A 6A BE 0D 78   BC E6 F4 8D 13 BF BB EF  .rw*j..x........
datanode_3  | 0070: C6 D7 15 3F FC D8 C8 89   A8 88 9A C7 30 FB A7 67  ...?........0..g
kdc_1       | Jan 31 08:02:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:12,487 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_2  | 2023-01-31 07:47:43,258 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
recon_1     | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
kdc_1       | Jan 31 08:02:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:12,487 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | ************************************************************/
datanode_1  | 0010: 8A 63 E1 0A EB 32 0A 94   FC 0A 0E D7 DF 99 1A C1  .c...2..........
datanode_2  | 2023-01-31 07:47:43,259 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
recon_1     | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
recon_1     | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
recon_1     | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
scm_1       | 2023-01-31 07:47:12,488 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2023-01-31 07:47:46,074 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 0020: E8 0C C9 BB CD 5A 4B B9   55 2D 79 1B C2 E8 2B A8  .....ZK.U-y...+.
datanode_1  | 0030: A1 25 7C 0D BB C6 BD 45   91 BA B0 AA 82 EE FE 2C  .%.....E.......,
recon_1     | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
kdc_1       | Jan 31 08:02:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 0080: C2 07 F9 1D 90 D0 87 8F   6A 73 66 17 79 3C 2E 28  ........jsf.y<.(
scm_1       | 2023-01-31 07:47:12,495 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2023-01-31 07:47:52,811 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
datanode_2  | 2023-01-31 07:47:43,260 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 0040: 54 CA D9 CF 8F 86 59 1E   33 B9 09 87 D9 74 2B 60  T.....Y.3....t+`
recon_1     | 
recon_1     | ] from file:/data/metadata/recon/certs/ROOTCA-1.crt.
datanode_3  | 0090: 4E CF DC 27 D0 AD E6 6B   B6 93 F2 31 0D 49 C7 F4  N..'...k...1.I..
scm_1       | 2023-01-31 07:47:12,496 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2023-01-31 07:47:55,806 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2023-01-31 07:47:56,091 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.8:9862
datanode_1  | 0050: A9 65 9A CB 18 26 C3 21   F0 B2 47 03 B2 CF 8D 13  .e...&.!..G.....
recon_1     | 2023-01-31 07:47:31,823 [main] INFO client.ReconCertificateClient: Added certificate [
kdc_1       | Jan 31 08:02:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00A0: 75 CE 8A 48 28 0D B4 BC   1F 5D 24 71 70 08 43 CA  u..H(....]$qp.C.
scm_1       | 2023-01-31 07:47:12,498 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderStateImpl
om_1        | 2023-01-31 07:47:56,093 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2023-01-31 07:47:56,094 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
datanode_3  | 00B0: A2 D8 96 AC BF 45 98 10   51 F9 17 91 0C 58 1E 74  .....E..Q....X.t
datanode_2  | 2023-01-31 07:47:43,346 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om_1        | 2023-01-31 07:47:56,192 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | [
kdc_1       | Jan 31 08:02:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:02:48 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00C0: 62 D2 EC C8 14 86 59 CC   A6 B2 63 47 2A 80 F5 B6  b.....Y...cG*...
scm_1       | 2023-01-31 07:47:12,521 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2023-01-31 07:47:12,559 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: set configuration 0: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:47:43,381 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1        | 2023-01-31 07:47:56,372 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
om_1        | 2023-01-31 07:47:58,032 [main] INFO reflections.Reflections: Reflections took 1393 ms to scan 1 urls, producing 115 keys and 335 values [using 2 cores]
kdc_1       | Jan 31 08:02:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:03:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00D0: 32 40 1A 30 27 48 02 CF   97 B3 55 D6 53 4F 7C 32  2@.0'H....U.SO.2
datanode_3  | 00E0: AF 2F 5D 3D 4E 94 5D 87   AA 71 87 47 C9 2C 75 AB  ./]=N.]..q.G.,u.
scm_1       | 2023-01-31 07:47:12,617 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/log_inprogress_0
datanode_2  | 2023-01-31 07:47:43,381 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om_1        | 2023-01-31 07:47:59,163 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
recon_1     |   Version: V3
kdc_1       | Jan 31 08:03:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 0060: F3 DE E9 5B F6 CE 93 DC   F7 18 2B E3 61 8C 6A AB  ...[......+.a.j.
datanode_1  | 0070: 1B 33 F7 7A 47 EC 78 9A   C4 DA 87 AB BF 2F DE FF  .3.zG.x....../..
datanode_1  | 0080: C2 89 3D C1 05 91 C0 4E   42 56 90 39 FB 45 7B F2  ..=....NBV.9.E..
scm_1       | 2023-01-31 07:47:13,458 [main] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: close
datanode_2  | 2023-01-31 07:47:49,060 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
om_1        | 2023-01-31 07:47:59,176 [main] INFO om.OzoneManager: Ozone Manager login successful.
recon_1     |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=recon@recon
kdc_1       | Jan 31 08:03:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 0090: DC 9A 7E E0 0F D1 42 DC   4E 80 14 53 CD DF 89 F1  ......B.N..S....
datanode_1  | 00A0: 9C 94 36 59 50 1C 37 7C   3E E3 C8 32 72 B2 6F 11  ..6YP.7.>..2r.o.
datanode_1  | 00B0: 35 BA 3C 3B 5E BE 31 53   8E 34 09 23 97 5C 89 FB  5.<;^.1S.4.#.\..
scm_1       | 2023-01-31 07:47:13,459 [main] INFO server.GrpcService: 6dfb726e-350e-430b-835b-cf79da791979: shutdown server GrpcServerProtocolService now
datanode_2  | 2023-01-31 07:47:49,218 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
om_1        | 2023-01-31 07:47:59,177 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 
recon_1     |   Key:  Sun RSA public key, 2048 bits
recon_1     |   params: null
recon_1     |   modulus: 23036491351279151275289552169512011445576235969947737285795603626053255674345415665911264295441618643374093808132554213265852610808954313875728282743492954427693619046254688291826444767439082070711866954329782456801119280112307335082214381566714044974419038715145108183546452534704016989346346552820753747886282395823038375039490873349851381950610461844127615409701611638591461441941425760517093777744931182283397530420737226021760729842378922097505581566589797408354076882324620924040496718808343878297715405879532931488377281055811727799438110251714027235301099819820339650262093221912867540240238448097777797715979
recon_1     |   public exponent: 65537
recon_1     |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
recon_1     |                To: Wed Jan 31 00:00:00 UTC 2024]
recon_1     |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_1  | 00C0: 84 F1 E0 22 F9 B5 0F 4D   53 CD B8 C8 87 A7 C6 00  ..."...MS.......
datanode_1  | 00D0: 14 59 92 E4 09 70 34 5F   F6 3A 36 35 EA BE 89 4F  .Y...p4_.:65...O
datanode_3  | 00F0: 15 49 DC 0A 5D 73 52 71   24 93 F9 48 0D 06 74 D1  .I..]sRq$..H..t.
kdc_1       | Jan 31 08:03:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:03:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,218 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
om_1        | 2023-01-31 07:48:00,632 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863]
datanode_3  | 
kdc_1       | Jan 31 08:03:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:03:52 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,219 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
om_1        | 2023-01-31 07:48:00,915 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.4:9863]
datanode_3  | ] from file:/data/metadata/dn/certs/488015668949.crt.
kdc_1       | Jan 31 08:04:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:04:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,220 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_2  | 2023-01-31 07:47:49,267 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
scm_1       | 2023-01-31 07:47:13,459 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: shutdown
datanode_3  | 2023-01-31 07:47:31,035 [main] INFO client.DNCertificateClient: Added certificate [
datanode_3  | [
datanode_3  |   Version: V3
datanode_3  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
kdc_1       | Jan 31 08:04:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-31 07:47:13,460 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-370D3E099E21,id=6dfb726e-350e-430b-835b-cf79da791979
scm_1       | 2023-01-31 07:47:13,460 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: shutdown 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderStateImpl
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_3  | 
datanode_3  |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 00E0: 86 6E 2C 76 69 20 A7 DA   4E 95 4F F2 8F AA 84 5C  .n,vi ..N.O....\
datanode_1  | 00F0: CA FA 84 4A B6 18 EE 53   EB 13 E4 6D 1E EC E9 B7  ...J...S...m....
datanode_1  | 
kdc_1       | Jan 31 08:04:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-31 07:48:04,215 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
datanode_1  | ] from file:/data/metadata/dn/certs/488772207169.crt.
scm_1       | 2023-01-31 07:47:13,472 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO impl.PendingRequests: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-PendingRequests: sendNotLeaderResponses
om_1        | value: 9862
datanode_1  | 2023-01-31 07:47:31,999 [main] INFO client.DNCertificateClient: Added certificate [
scm_1       | 2023-01-31 07:47:13,482 [main] INFO server.GrpcService: 6dfb726e-350e-430b-835b-cf79da791979: shutdown server GrpcServerProtocolService successfully
kdc_1       | Jan 31 08:04:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | ]
recon_1     |   SerialNumber: [    71daa753 51]
scm_1       | 2023-01-31 07:47:13,483 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72, L:/0.0.0.0:38771] CLOSE
kdc_1       | Jan 31 08:04:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,268 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
datanode_2  | 2023-01-31 07:47:49,347 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
om_1        | 2023-01-31 07:48:04,233 [main] INFO security.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
datanode_1  | [
datanode_1  |   Version: V3
scm_1       | 2023-01-31 07:47:13,484 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72, L:/0.0.0.0:38771] INACTIVE
kdc_1       | Jan 31 08:04:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,349 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
datanode_2  | 2023-01-31 07:47:49,623 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
om_1        | 2023-01-31 07:48:04,738 [main] INFO security.OMCertificateClient: Added certificate [
recon_1     | 
datanode_1  |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
scm_1       | 2023-01-31 07:47:13,484 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x11921b72, L:/0.0.0.0:38771] UNREGISTERED
kdc_1       | Jan 31 08:04:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | [
recon_1     | Certificate Extensions: 2
recon_1     | [1]: ObjectId: 2.5.29.15 Criticality=true
scm_1       | 2023-01-31 07:47:13,486 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO impl.StateMachineUpdater: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater: Took a snapshot at index 0
kdc_1       | Jan 31 08:05:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | KeyUsage [
recon_1     |   DigitalSignature
scm_1       | 2023-01-31 07:47:13,486 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO impl.StateMachineUpdater: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
om_1        |   Version: V3
kdc_1       | Jan 31 08:05:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:05:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Key_Encipherment
recon_1     |   Data_Encipherment
scm_1       | 2023-01-31 07:47:13,489 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO impl.StateMachineUpdater: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater: set stopIndex = 0
scm_1       | 2023-01-31 07:47:13,496 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: closes. applyIndex: 0
kdc_1       | Jan 31 08:06:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:06:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:06:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:06:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152082, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Key_Agreement
recon_1     | ]
scm_1       | 2023-01-31 07:47:13,503 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
om_1        |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
kdc_1       | Jan 31 08:06:22 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 
scm_1       | 2023-01-31 07:47:13,517 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker close()
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
kdc_1       | Jan 31 08:06:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  |   params: null
recon_1     | 
recon_1     | [2]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | 2023-01-31 07:47:13,520 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-6dfb726e-350e-430b-835b-cf79da791979: Stopped
om_1        | 
kdc_1       | Jan 31 08:06:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:06:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:49,627 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
datanode_2  | 2023-01-31 07:47:50,079 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
recon_1     | SubjectAlternativeName [
recon_1     |   IPAddress: 172.18.0.3
scm_1       | 2023-01-31 07:47:13,521 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        |   Key:  Sun RSA public key, 2048 bits
datanode_3  |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_3  |                To: Fri Mar 10 00:00:00 UTC 2028]
recon_1     | ]
recon_1     | 
scm_1       | 2023-01-31 07:47:13,527 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-5128c6ec-f311-4d77-b590-370d3e099e21; layoutVersion=4; scmId=6dfb726e-350e-430b-835b-cf79da791979
om_1        |   params: null
om_1        |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
recon_1     | ]
recon_1     |   Algorithm: [SHA256withRSA]
scm_1       | 2023-01-31 07:47:14,521 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
datanode_3  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_3  |   SerialNumber: [    6c0d0934 9f]
datanode_3  | 
om_1        |   public exponent: 65537
om_1        |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
om_1        |                To: Fri Mar 10 00:00:00 UTC 2028]
recon_1     |   Signature:
om_1        |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_1  |   Key:  Sun RSA public key, 2048 bits
recon_1     | 0000: AA 9A 3F DA 01 2D 50 B2   86 CB 9A A7 0A 8C 03 C7  ..?..-P.........
om_1        |   SerialNumber: [    01]
datanode_1  |   params: null
recon_1     | 0010: FE D8 0E CE EF 35 40 51   1A 0D 85 DE 42 FC F0 ED  .....5@Q....B...
om_1        | 
datanode_1  |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
datanode_2  | 2023-01-31 07:47:50,080 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2  | 2023-01-31 07:47:50,085 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2023-01-31 07:47:50,085 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2023-01-31 07:47:50,147 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1     | 0020: BD F2 8C 2C E4 D8 56 BA   0B 02 13 69 79 B1 7D 23  ...,..V....iy..#
om_1        | Certificate Extensions: 3
datanode_1  |   public exponent: 65537
recon_1     | 0030: EE F2 BA AE BF 5B 96 B2   61 66 70 39 57 4F 81 6A  .....[..afp9WO.j
recon_1     | 0040: 88 24 A5 46 07 B9 51 94   A1 C9 8E 37 82 72 63 70  .$.F..Q....7.rcp
datanode_1  |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_1  |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_3  | Certificate Extensions: 3
datanode_3  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_3  | BasicConstraints:[
datanode_3  |   CA:true
datanode_1  |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_2  | 2023-01-31 07:47:50,330 [1e69a4e3-5301-4460-8965-9fee5bf32e29-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x729fdab6] REGISTERED
datanode_2  | 2023-01-31 07:47:50,362 [1e69a4e3-5301-4460-8965-9fee5bf32e29-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x729fdab6] BIND: 0.0.0.0/0.0.0.0:9855
datanode_3  |   PathLen:2147483647
datanode_3  | ]
datanode_3  | 
datanode_3  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | KeyUsage [
datanode_2  | 2023-01-31 07:47:50,367 [1e69a4e3-5301-4460-8965-9fee5bf32e29-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x729fdab6, L:/0.0.0.0:9855] ACTIVE
datanode_2  | 2023-01-31 07:47:50,885 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode_3  |   DigitalSignature
recon_1     | 0050: CE 1D 41 FC FD BC B7 69   D1 E8 48 D2 5B C6 09 3F  ..A....i..H.[..?
kdc_1       | Jan 31 08:06:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:06:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:07:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  |   SerialNumber: [    6c0d0934 9f]
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.4
kdc_1       | Jan 31 08:07:09 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:50,933 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
om_1        | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | 
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
kdc_1       | Jan 31 08:07:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152382, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:50,974 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_2  | 2023-01-31 07:47:52,114 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 488625236405
datanode_1  | Certificate Extensions: 3
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
scm_1       | 2023-01-31 07:47:16,319 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
kdc_1       | Jan 31 08:07:16 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:52,133 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 488625236405
om_1        | BasicConstraints:[
datanode_1  | [1]: ObjectId: 2.5.29.19 Criticality=true
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
kdc_1       | Jan 31 08:07:22 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:52,561 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
om_1        |   CA:true
datanode_1  | BasicConstraints:[
scm_1       | STARTUP_MSG:   host = scm/172.18.0.4
scm_1       | STARTUP_MSG:   args = []
kdc_1       | Jan 31 08:07:28 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:52,561 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
om_1        |   PathLen:2147483647
datanode_1  |   CA:true
scm_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/3393354472a02da9364dbf4f0da34f127eb4895d ; compiled by 'runner' on 2023-01-31T07:31Z
recon_1     | 0060: B8 C5 24 E6 A0 CC B2 35   11 9A DB 42 55 8F 16 70  ..$....5...BU..p
kdc_1       | Jan 31 08:07:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:52,561 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
om_1        | ]
datanode_1  |   PathLen:2147483647
scm_1       | STARTUP_MSG:   java = 11.0.14.1
datanode_3  |   Key_Encipherment
recon_1     | 0070: 39 69 79 B1 9F 87 73 6D   02 6C A8 7E 83 E9 43 64  9iy...sm.l....Cd
kdc_1       | Jan 31 08:07:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:52,755 [main] INFO util.log: Logging initialized @90825ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 
datanode_1  | ]
scm_1       | ************************************************************/
datanode_3  |   Data_Encipherment
kdc_1       | Jan 31 08:07:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:53,713 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2023-01-31 07:47:53,779 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 
scm_1       | 2023-01-31 07:47:16,341 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2023-01-31 07:47:16,433 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Jan 31 08:07:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:53,799 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
om_1        | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  |   Key_Agreement
datanode_3  |   Key_CertSign
kdc_1       | Jan 31 08:07:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:53,799 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_2  | 2023-01-31 07:47:53,802 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | KeyUsage [
datanode_3  |   Crl_Sign
scm_1       | 2023-01-31 07:47:16,481 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
kdc_1       | Jan 31 08:08:06 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152436, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:53,835 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_2  | 2023-01-31 07:47:54,222 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  |   DigitalSignature
datanode_3  | ]
scm_1       | 2023-01-31 07:47:16,500 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
recon_1     | 0080: 12 45 F7 0D A8 D7 31 FA   1F FF 57 C1 A6 F5 A4 06  .E....1...W.....
kdc_1       | Jan 31 08:08:07 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:54,235 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_2  | 2023-01-31 07:47:54,580 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  |   Key_Encipherment
datanode_3  | 
scm_1       | 2023-01-31 07:47:17,098 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
recon_1     | 0090: 4E 34 5F D9 B5 A0 4B 0D   6B 4B 3C 0F BF 59 1F EF  N4_...K.kK<..Y..
kdc_1       | Jan 31 08:08:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:26 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_3  | SubjectAlternativeName [
recon_1     | 00A0: 7F 86 CE 72 EF C6 AA D5   37 47 6F 85 ED 99 51 9E  ...r....7Go...Q.
scm_1       | 2023-01-31 07:47:17,319 [main] INFO client.SCMCertificateClient: Added certificate [
scm_1       | [
scm_1       |   Version: V3
datanode_1  |   Data_Encipherment
datanode_3  |   IPAddress: 172.18.0.4
kdc_1       | Jan 31 08:08:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  |   Key_Agreement
datanode_3  | ]
kdc_1       | Jan 31 08:08:55 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152487, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:08:57 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 08:09:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:09:13 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  |   Key_CertSign
datanode_3  | 
kdc_1       | Jan 31 08:09:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:54,580 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  | 2023-01-31 07:47:54,592 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_2  | 2023-01-31 07:47:54,714 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_1  |   Crl_Sign
datanode_1  | ]
recon_1     | 00B0: 78 FC C4 A5 C7 7D 22 39   A9 3F 88 1A A5 F2 8A 21  x....."9.?.....!
kdc_1       | Jan 31 08:09:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:54,733 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7a5b561b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2023-01-31 07:47:54,748 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4c0d7878{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2023-01-31 07:47:55,598 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_2  | 2023-01-31 07:47:55,769 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4149067d{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9456155576220341509/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_1  | 
recon_1     | 00C0: 1F 73 1B 73 4B A9 7A 9A   D1 75 8A FD 01 3A E1 08  .s.sK.z..u...:..
kdc_1       | Jan 31 08:09:32 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | KeyUsage [
om_1        |   Key_CertSign
om_1        |   Crl_Sign
om_1        | ]
datanode_1  | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | 00D0: 37 DF 03 CD DF 1E 25 7A   3A B5 EE 30 6F B3 24 5F  7.....%z:..0o.$_
recon_1     | 00E0: F3 B5 8F 9A A5 8D 03 6D   E9 90 5B BE 8A 57 E1 C0  .......m..[..W..
datanode_2  | 2023-01-31 07:47:55,876 [main] INFO server.AbstractConnector: Started ServerConnector@35cf7e98{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_2  | 2023-01-31 07:47:55,882 [main] INFO server.Server: Started @93964ms
datanode_2  | 2023-01-31 07:47:55,943 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
kdc_1       | Jan 31 08:09:37 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | SubjectAlternativeName [
om_1        | 
om_1        | [3]: ObjectId: 2.5.29.17 Criticality=false
om_1        | SubjectAlternativeName [
om_1        |   IPAddress: 172.18.0.4
kdc_1       | Jan 31 08:09:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  |   IPAddress: 172.18.0.4
datanode_2  | 2023-01-31 07:47:55,950 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | ]
datanode_3  | ]
kdc_1       | Jan 31 08:09:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152537, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | ]
datanode_2  | 2023-01-31 07:47:55,962 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2023-01-31 07:47:55,984 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
om_1        | 
datanode_3  |   Algorithm: [SHA256withRSA]
kdc_1       | Jan 31 08:09:51 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 
recon_1     | 00F0: 2C E3 16 4F 82 46 DC 98   E9 36 98 80 C2 6F 1F 28  ,..O.F...6...o.(
datanode_2  | 2023-01-31 07:47:56,188 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@368a7095] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2023-01-31 07:47:56,953 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.3:9891
om_1        | ]
datanode_3  |   Signature:
datanode_1  | ]
kdc_1       | Jan 31 08:09:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 
om_1        |   Algorithm: [SHA256withRSA]
datanode_3  | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
datanode_1  |   Algorithm: [SHA256withRSA]
kdc_1       | Jan 31 08:10:03 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | ] from file:/data/metadata/recon/certs/488999703377.crt.
om_1        |   Signature:
datanode_3  | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
datanode_1  |   Signature:
kdc_1       | Jan 31 08:10:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-31 07:47:31,878 [main] INFO client.ReconCertificateClient: Added certificate [
scm_1       |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_2  | 2023-01-31 07:47:57,020 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
om_1        | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
datanode_1  | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
kdc_1       | Jan 31 08:10:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | [
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 2023-01-31 07:47:59,248 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om_1        | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
datanode_1  | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
kdc_1       | Jan 31 08:10:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Version: V3
scm_1       | 
datanode_2  | 2023-01-31 07:48:00,204 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-560b00b5-abd5-466f-8031-d44bcb126408/container.db to cache
om_1        | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
kdc_1       | Jan 31 08:10:27 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
scm_1       |   Key:  Sun RSA public key, 2048 bits
datanode_2  | 2023-01-31 07:48:00,204 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-560b00b5-abd5-466f-8031-d44bcb126408/container.db for volume DS-560b00b5-abd5-466f-8031-d44bcb126408
datanode_2  | 2023-01-31 07:48:00,221 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
kdc_1       | Jan 31 08:10:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
scm_1       |   params: null
datanode_2  | 2023-01-31 07:48:00,240 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
om_1        | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
datanode_1  | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
kdc_1       | Jan 31 08:10:43 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152591, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:10:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 31 08:10:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-31 07:48:00,256 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2023-01-31 07:48:00,357 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode_3  | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
datanode_3  | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
datanode_3  | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
datanode_3  | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
datanode_3  | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
datanode_3  | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
datanode_3  | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
datanode_3  | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
datanode_3  | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_3  | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
datanode_3  | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
datanode_3  | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
datanode_2  | 2023-01-31 07:48:00,363 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 1e69a4e3-5301-4460-8965-9fee5bf32e29
datanode_2  | 2023-01-31 07:48:00,555 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.RaftServer: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start RPC server
datanode_2  | 2023-01-31 07:48:00,585 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 1e69a4e3-5301-4460-8965-9fee5bf32e29: GrpcService started, listening on 9858
datanode_2  | 2023-01-31 07:48:00,600 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 1e69a4e3-5301-4460-8965-9fee5bf32e29: GrpcService started, listening on 9856
datanode_2  | 2023-01-31 07:48:00,634 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 1e69a4e3-5301-4460-8965-9fee5bf32e29: GrpcService started, listening on 9857
datanode_2  | 2023-01-31 07:48:00,663 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1e69a4e3-5301-4460-8965-9fee5bf32e29 is started using port 9858 for RATIS
datanode_2  | 2023-01-31 07:48:00,664 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1e69a4e3-5301-4460-8965-9fee5bf32e29 is started using port 9857 for RATIS_ADMIN
datanode_2  | 2023-01-31 07:48:00,664 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1e69a4e3-5301-4460-8965-9fee5bf32e29 is started using port 9856 for RATIS_SERVER
datanode_2  | 2023-01-31 07:48:00,663 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-1e69a4e3-5301-4460-8965-9fee5bf32e29: Started
datanode_2  | 2023-01-31 07:48:00,664 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 1e69a4e3-5301-4460-8965-9fee5bf32e29 is started using port 9855 for RATIS_DATASTREAM
datanode_2  | 2023-01-31 07:48:01,260 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_3  | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
datanode_3  | 
datanode_3  | ] from file:/data/metadata/dn/certs/CA-464075175071.crt.
datanode_3  | 2023-01-31 07:47:31,069 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29088748955 ms and interval 86400000 ms.
datanode_3  | 2023-01-31 07:47:31,069 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_3  | 2023-01-31 07:47:31,159 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3  | 2023-01-31 07:47:32,238 [main] INFO reflections.Reflections: Reflections took 878 ms to scan 2 urls, producing 100 keys and 224 values 
scm_1       |   modulus: 25676308339770250972219436590984425646136236434047221822595011132161233968037993034350491579435918386240707377161976826322160646191473048400368941488234131435849149435679797560506687778467673432563319990491122370230542241955795045376436638063903171948344576341952124074410237013895540216288607458660302565144570139667838403315341858368899581424615666040027512718084905608021622161381528589575068134853393147619255635769481431178194714733898872750115001908286617077411139407275626202967161338165440275783306528399726402541949190654747896983468163650149286860456712986952478232505752835748759510783908172297771387257797
scm_1       |   public exponent: 65537
recon_1     | 
om_1        | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
datanode_2  | 2023-01-31 07:48:02,267 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
kdc_1       | Jan 31 08:10:56 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:32,611 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_1  | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
recon_1     |   Key:  Sun RSA public key, 2048 bits
recon_1     |   params: null
recon_1     |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
datanode_2  | 2023-01-31 07:48:03,271 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2023-01-31 07:47:33,635 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
kdc_1       | Jan 31 08:11:02 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
recon_1     |   public exponent: 65537
recon_1     |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
recon_1     |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_2  | 2023-01-31 07:48:04,272 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2023-01-31 07:47:33,790 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
kdc_1       | Jan 31 08:11:08 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
recon_1     |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
recon_1     |   SerialNumber: [    6c0d0934 9f]
recon_1     | 
datanode_2  | 2023-01-31 07:48:06,164 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_3  | 2023-01-31 07:47:33,794 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
kdc_1       | Jan 31 08:11:15 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:11:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:11:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
scm_1       |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_2  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_3  | 2023-01-31 07:47:33,810 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2023-01-31 07:47:34,155 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2023-01-31 07:47:34,381 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2023-01-31 07:47:34,401 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_3  | 2023-01-31 07:47:34,426 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
kdc_1       | Jan 31 08:11:35 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_3  | 2023-01-31 07:47:34,426 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_3  | 2023-01-31 07:47:34,427 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
om_1        | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
recon_1     | Certificate Extensions: 3
datanode_1  | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
kdc_1       | Jan 31 08:11:41 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
scm_1       |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
om_1        | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
recon_1     | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_3  | 2023-01-31 07:47:34,666 [Thread-20] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
kdc_1       | Jan 31 08:11:47 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   SerialNumber: [    01]
om_1        | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
datanode_1  | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_3  | 2023-01-31 07:47:34,693 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
scm_1       | 
kdc_1       | Jan 31 08:11:54 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
recon_1     | BasicConstraints:[
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_1  | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_3  | 2023-01-31 07:47:40,128 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
scm_1       | Certificate Extensions: 3
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
om_1        | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:322)
kdc_1       | Jan 31 08:12:00 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:12:07 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:12:14 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:12:20 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | Caused by: java.util.concurrent.TimeoutException
kdc_1       | Jan 31 08:12:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | BasicConstraints:[
datanode_3  | 2023-01-31 07:47:40,602 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode_3  | 2023-01-31 07:47:40,662 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
recon_1     |   CA:true
recon_1     |   PathLen:2147483647
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
kdc_1       | Jan 31 08:12:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:40,939 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       |   CA:true
scm_1       |   PathLen:2147483647
datanode_1  | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
kdc_1       | Jan 31 08:12:49 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:41,356 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2023-01-31 07:47:42,584 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | ]
recon_1     | ]
datanode_1  | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kdc_1       | Jan 31 08:12:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:42,636 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
kdc_1       | Jan 31 08:13:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 
recon_1     | 
datanode_1  | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
kdc_1       | Jan 31 08:13:10 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 	... 1 more
datanode_2  | 2023-01-31 07:48:09,280 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
kdc_1       | Jan 31 08:13:21 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | KeyUsage [
datanode_1  | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
datanode_2  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort 43001ba40da4/172.18.0.9:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.9:55936 remote=recon/172.18.0.3:9891]
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
kdc_1       | Jan 31 08:13:30 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   DigitalSignature
recon_1     |   Key_Encipherment
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
kdc_1       | Jan 31 08:13:36 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Data_Encipherment
recon_1     |   Key_Agreement
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
kdc_1       | Jan 31 08:13:42 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
om_1        | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
scm_1       | KeyUsage [
scm_1       |   Key_CertSign
scm_1       |   Crl_Sign
om_1        | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
om_1        | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
kdc_1       | Jan 31 08:13:51 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_3  | 2023-01-31 07:47:42,637 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2023-01-31 07:47:42,638 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
kdc_1       | Jan 31 08:13:57 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:14:04 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
scm_1       | ]
scm_1       | 
recon_1     |   Key_CertSign
datanode_3  | 2023-01-31 07:47:42,640 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_3  | 2023-01-31 07:47:42,640 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
kdc_1       | Jan 31 08:14:11 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3  | 2023-01-31 07:47:42,641 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
om_1        | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
kdc_1       | Jan 31 08:14:18 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     |   Crl_Sign
recon_1     | ]
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3  | 2023-01-31 07:47:42,644 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-31 07:47:42,668 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
kdc_1       | Jan 31 08:14:23 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:14:29 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 
datanode_1  | 
datanode_3  | 2023-01-31 07:47:42,671 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2023-01-31 07:47:42,806 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
kdc_1       | Jan 31 08:14:34 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | SubjectAlternativeName [
scm_1       |   IPAddress: 172.18.0.4
datanode_1  | ] from file:/data/metadata/dn/certs/CA-464075175071.crt.
datanode_3  | 2023-01-31 07:47:42,877 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1        | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
kdc_1       | Jan 31 08:14:40 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | ]
recon_1     | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | SubjectAlternativeName [
datanode_3  | 2023-01-31 07:47:42,878 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_3  | 2023-01-31 07:47:49,581 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Jan 31 08:14:46 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 
scm_1       | ]
scm_1       |   Algorithm: [SHA256withRSA]
datanode_3  | 2023-01-31 07:47:49,716 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
om_1        | 
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
kdc_1       | Jan 31 08:14:53 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   Signature:
scm_1       | 0000: 3D F0 C1 E6 19 F1 BB 7E   32 E7 0A 0F 9E 12 C6 DB  =.......2.......
scm_1       | 0010: E8 7A 2C 40 A8 0B E3 56   D6 1D FA CF 7A C4 E4 2D  .z,@...V....z..-
datanode_3  | 2023-01-31 07:47:49,735 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
om_1        | ] from file:/data/metadata/om/certs/ROOTCA-1.crt.
kdc_1       | Jan 31 08:14:59 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:32,015 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29088747991 ms and interval 86400000 ms.
datanode_1  | 2023-01-31 07:47:32,025 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
recon_1     |   IPAddress: 172.18.0.4
datanode_3  | 2023-01-31 07:47:49,741 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
datanode_3  | 2023-01-31 07:47:49,746 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
kdc_1       | Jan 31 08:15:05 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 2023-01-31 07:47:49,769 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
datanode_3  | 2023-01-31 07:47:49,783 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
datanode_2  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.9:55936 remote=recon/172.18.0.3:9891]
kdc_1       | Jan 31 08:15:12 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:32,201 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
recon_1     | ]
recon_1     | 
om_1        | 2023-01-31 07:48:04,763 [main] INFO security.OMCertificateClient: Added certificate [
datanode_3  | 2023-01-31 07:47:49,842 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
datanode_3  | 2023-01-31 07:47:49,855 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
kdc_1       | Jan 31 08:15:19 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:33,267 [main] INFO reflections.Reflections: Reflections took 835 ms to scan 2 urls, producing 100 keys and 224 values 
recon_1     | ]
recon_1     |   Algorithm: [SHA256withRSA]
om_1        | [
datanode_3  | 2023-01-31 07:47:50,331 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
datanode_3  | 2023-01-31 07:47:50,337 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
kdc_1       | Jan 31 08:15:25 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:33,890 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
scm_1       | 0020: 33 CB 07 51 78 DB 2A E1   AE 96 9D 88 BF 67 68 90  3..Qx.*......gh.
scm_1       | 0030: 31 A4 66 1A 82 AC A0 20   45 7C 43 43 BE 32 58 E2  1.f.... E.CC.2X.
om_1        |   Version: V3
datanode_3  | 2023-01-31 07:47:50,635 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_3  | 2023-01-31 07:47:50,646 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
kdc_1       | Jan 31 08:15:31 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:35,016 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
datanode_1  | 2023-01-31 07:47:35,124 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
datanode_1  | 2023-01-31 07:47:35,141 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
datanode_3  | 2023-01-31 07:47:50,647 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
om_1        |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=om
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     |   Signature:
scm_1       | 0040: 4C 7F 95 0F 9A 58 2B E2   A8 85 EB 65 FC D0 BB 85  L....X+....e....
datanode_1  | 2023-01-31 07:47:35,149 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_3  | 2023-01-31 07:47:50,647 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-31 07:47:50,668 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 
om_1        |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 2023-01-31 07:47:35,383 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2023-01-31 07:47:50,724 [14b917d5-325a-4f29-a0e8-e34b223e06de-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xdedfecd0] REGISTERED
datanode_3  | 2023-01-31 07:47:50,779 [14b917d5-325a-4f29-a0e8-e34b223e06de-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xdedfecd0] BIND: 0.0.0.0/0.0.0.0:9855
om_1        |   params: null
om_1        |   modulus: 18969088594558932160383780303281992195982964607395532507925810480316228822173607637831947499006983336189162806242726429873391856944987543944453743060763189131453845463676514153767076569517618364254921834393492744412047196254294994912789169515544027025136341086731442599174246295869418027486554807573851163703809435788389442871504613912171718503826639546537519217681935068168489228000465364598940789255756811954736328773500769346283992918503679608899583551492478470823282486834241359361942345410550345935977028266648736423203715266046038396392387790008913273572971664804294636227203076374284011751032378255405768418937
datanode_1  | 2023-01-31 07:47:35,545 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2023-01-31 07:47:50,818 [14b917d5-325a-4f29-a0e8-e34b223e06de-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xdedfecd0, L:/0.0.0.0:9855] ACTIVE
datanode_3  | 2023-01-31 07:47:51,018 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
om_1        |   public exponent: 65537
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
recon_1     | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
scm_1       | 0050: 38 D2 D0 54 E8 EC E9 F5   16 BF C8 AF C5 9C F4 05  8..T............
datanode_1  | 2023-01-31 07:47:35,558 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_3  | 2023-01-31 07:47:51,186 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
om_1        |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
kdc_1       | Jan 31 08:15:38 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 0060: 0C CE 63 56 10 95 B6 38   11 C4 BE EB 98 9C 6F 2A  ..cV...8......o*
datanode_1  | 2023-01-31 07:47:35,566 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
om_1        |                To: Wed Jan 31 00:00:00 UTC 2024]
om_1        |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
kdc_1       | Jan 31 08:15:44 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152645, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
recon_1     | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
recon_1     | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
om_1        |   SerialNumber: [    73441fc4 0e]
om_1        | 
datanode_1  | 2023-01-31 07:47:35,572 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
kdc_1       | Jan 31 08:15:45 kdc krb5kdc[7](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.4: ISSUE: authtime 1675152945, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
scm_1       | 0070: 2C E3 2E 13 70 E7 1E 3D   CE 34 69 7B 69 A0 20 12  ,...p..=.4i.i. .
scm_1       | 0080: C9 3D C8 37 CA 9E 29 8D   F8 78 3D 10 07 5D 4C BD  .=.7..)..x=..]L.
scm_1       | 0090: 9D 47 6A B0 C9 3E 90 07   FD 41 DD 7C CC 5D 4A F9  .Gj..>...A...]J.
om_1        | Certificate Extensions: 2
om_1        | [1]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
kdc_1       | Jan 31 08:15:50 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152945, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 31 08:16:01 kdc krb5kdc[7](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675152945, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | KeyUsage [
datanode_1  | 2023-01-31 07:47:35,573 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_1  | 2023-01-31 07:47:35,974 [Thread-20] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
datanode_1  | 2023-01-31 07:47:36,033 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
recon_1     | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
datanode_3  | 2023-01-31 07:47:51,250 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_3  | 2023-01-31 07:47:52,403 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 488015668949
datanode_3  | 2023-01-31 07:47:52,460 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 488015668949
om_1        |   DigitalSignature
scm_1       | 00A0: DA 37 F0 76 47 A6 F4 92   94 2C 7A 08 7D 36 B2 88  .7.vG....,z..6..
om_1        |   Key_Encipherment
om_1        |   Data_Encipherment
om_1        |   Key_Agreement
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
scm_1       | 00B0: 0E 01 C9 63 EF D1 58 C4   E3 52 94 15 50 59 6A F1  ...c..X..R..PYj.
scm_1       | 00C0: E8 4F 91 C6 79 66 81 27   CE 9F A0 D0 84 E5 F9 81  .O..yf.'........
om_1        | ]
om_1        | 
recon_1     | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
scm_1       | 00D0: 30 52 64 1C C4 0E 99 C9   2B 12 81 C4 24 1C E4 F4  0Rd.....+...$...
om_1        | [2]: ObjectId: 2.5.29.17 Criticality=false
om_1        | SubjectAlternativeName [
recon_1     | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
recon_1     | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
datanode_3  | 2023-01-31 07:47:52,773 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_2  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
scm_1       | 00E0: EF F9 05 A0 68 31 A5 F3   3F 4A 28 05 78 20 C0 51  ....h1..?J(.x .Q
scm_1       | 00F0: 75 00 D6 6B B7 EC 76 66   02 A9 21 F4 19 07 F4 C9  u..k..vf..!.....
om_1        |   IPAddress: 172.18.0.8
recon_1     | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
recon_1     | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_3  | 2023-01-31 07:47:52,773 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
datanode_1  | 2023-01-31 07:47:41,475 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_1  | 2023-01-31 07:47:42,278 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
om_1        |   Other-Name: Unrecognized ObjectIdentifier: 2.16.840.1.113730.3.1.34
om_1        | ]
om_1        | 
datanode_3  | 2023-01-31 07:47:52,773 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_2  | 	... 12 more
datanode_1  | 2023-01-31 07:47:42,419 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
scm_1       | 
recon_1     | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
datanode_3  | 2023-01-31 07:47:52,918 [main] INFO util.log: Logging initialized @90802ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.9:55936 remote=recon/172.18.0.3:9891]
datanode_1  | 2023-01-31 07:47:43,211 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
om_1        | ]
recon_1     | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_1  | 2023-01-31 07:47:43,600 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_3  | 2023-01-31 07:47:53,839 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
scm_1       | 2023-01-31 07:47:17,328 [main] INFO client.SCMCertificateClient: Added certificate [
om_1        |   Algorithm: [SHA256withRSA]
recon_1     | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
recon_1     | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_1  | 2023-01-31 07:47:44,063 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
datanode_3  | 2023-01-31 07:47:53,912 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | [
om_1        |   Signature:
recon_1     | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 2023-01-31 07:47:44,070 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
datanode_1  | 2023-01-31 07:47:44,072 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_1  | 2023-01-31 07:47:44,074 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1  | 2023-01-31 07:47:44,077 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
om_1        | 0000: 31 13 81 4C 38 15 D2 E0   76 43 9D D0 24 B1 6E 82  1..L8...vC..$.n.
om_1        | 0010: 86 33 D6 03 71 68 DC D8   56 A3 BA 4B C8 03 69 66  .3..qh..V..K..if
datanode_3  | 2023-01-31 07:47:53,926 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2023-01-31 07:47:53,927 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
scm_1       |   Version: V3
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
om_1        | 0020: 54 85 00 BC 78 DC 51 36   43 E0 F5 4A 29 6F EE 39  T...x.Q6C..J)o.9
recon_1     | 
datanode_3  | 2023-01-31 07:47:53,932 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2023-01-31 07:47:44,077 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
scm_1       |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
om_1        | 0030: 9C 52 22 D5 B6 48 4A 58   63 17 D3 0A E6 35 81 79  .R"..HJXc....5.y
datanode_3  | 2023-01-31 07:47:53,972 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_1  | 2023-01-31 07:47:44,079 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
recon_1     | ] from file:/data/metadata/recon/certs/CA-464075175071.crt.
om_1        | 0040: 2A 5D 4E 38 B9 70 A9 C1   91 B5 12 92 3D 2B 9B 8B  *]N8.p......=+..
datanode_3  | 2023-01-31 07:47:54,396 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2023-01-31 07:47:44,092 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
om_1        | 0050: 0B 30 2E 62 80 8A E7 E6   02 87 AF E6 1B F5 92 4E  .0.b...........N
datanode_3  | 2023-01-31 07:47:54,405 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_1  | 2023-01-31 07:47:44,096 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
scm_1       |   Key:  Sun RSA public key, 2048 bits
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
recon_1     | 2023-01-31 07:47:31,932 [main] INFO client.ReconCertificateClient: CertificateLifetimeMonitor for recon is started with first delay 29088748103 ms and interval 86400000 ms.
om_1        | 0060: 3C 38 EA 53 64 FB E8 A7   CF 47 2F 55 39 AB 8A 92  <8.Sd....G/U9...
datanode_3  | 2023-01-31 07:47:54,710 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_1  | 2023-01-31 07:47:44,099 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       |   params: null
datanode_2  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
recon_1     | 2023-01-31 07:47:31,932 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
om_1        | 0070: 4B 03 5F DC 23 38 F2 B4   FB 72 59 E0 B4 A5 50 E8  K._.#8...rY...P.
datanode_3  | 2023-01-31 07:47:54,710 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2023-01-31 07:47:44,147 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm_1       |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
scm_1       |   public exponent: 65537
recon_1     | 2023-01-31 07:47:34,425 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
om_1        | 0080: 55 B0 D0 6B 04 06 59 05   F3 1B 44 4D 89 B0 87 8D  U..k..Y...DM....
datanode_3  | 2023-01-31 07:47:54,735 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_1  | 2023-01-31 07:47:44,177 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
scm_1       |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
recon_1     | 2023-01-31 07:47:41,443 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
om_1        | 0090: 20 5C E5 03 66 64 9C D2   BC 15 D1 00 18 B4 9A 8F   \..fd..........
datanode_3  | 2023-01-31 07:47:54,935 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:44,191 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
scm_1       |                To: Fri Mar 10 00:00:00 UTC 2028]
recon_1     | WARNING: An illegal reflective access operation has occurred
om_1        | 00A0: 9D E4 54 7C AE 86 79 75   7D FD 14 F5 F1 2F 2C C1  ..T...yu...../,.
datanode_3  | 2023-01-31 07:47:54,951 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1435feb6{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_1  | 2023-01-31 07:47:49,589 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
scm_1       |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
om_1        | 00B0: CE 21 DE A2 F8 57 CF 96   AB 19 4E 01 30 76 17 C4  .!...W....N.0v..
datanode_3  | 2023-01-31 07:47:54,968 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3de8e614{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2023-01-31 07:47:49,757 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
scm_1       |   SerialNumber: [    6c0d0934 9f]
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
om_1        | 00C0: 68 E2 0D 4F 4E 48 D3 26   7C 20 96 D2 45 D4 2B 67  h..ONH.&. ..E.+g
datanode_3  | 2023-01-31 07:47:55,787 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_1  | 2023-01-31 07:47:49,758 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
datanode_3  | 2023-01-31 07:47:55,985 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@53f67af6{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-4226722775489148568/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | Certificate Extensions: 3
recon_1     | 2023-01-31 07:47:43,829 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
om_1        | 00D0: 9A 5C 4A 11 96 E5 91 2E   26 55 65 5B 2F F8 4E F0  .\J.....&Ue[/.N.
datanode_3  | 2023-01-31 07:47:56,051 [main] INFO server.AbstractConnector: Started ServerConnector@6ce365b7{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_1  | 2023-01-31 07:47:49,758 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | 2023-01-31 07:47:43,831 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.001 seconds to initialized 0 records to KEY_CONTAINER table
om_1        | 00E0: F2 16 24 56 92 51 66 52   D2 2C 98 DD 3D B8 EC 0B  ..$V.QfR.,..=...
datanode_3  | 2023-01-31 07:47:56,069 [main] INFO server.Server: Started @93956ms
datanode_1  | 2023-01-31 07:47:49,775 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
scm_1       | BasicConstraints:[
recon_1     | 2023-01-31 07:47:43,880 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
om_1        | 00F0: 8F 5E 11 D8 3A 79 4F 46   E0 73 3E D1 C3 C2 E2 23  .^..:yOF.s>....#
datanode_3  | 2023-01-31 07:47:56,096 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2023-01-31 07:47:49,796 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
datanode_2  | 	... 15 more
datanode_3  | 2023-01-31 07:47:56,097 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 
scm_1       |   CA:true
recon_1     | 2023-01-31 07:47:44,018 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
datanode_1  | 2023-01-31 07:47:49,796 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
datanode_3  | 2023-01-31 07:47:56,101 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2023-01-31 07:48:35,300 [Command processor thread] INFO server.RaftServer: 1e69a4e3-5301-4460-8965-9fee5bf32e29: addNew group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] returns group-95A0187A7678:java.util.concurrent.CompletableFuture@5048fa4e[Not completed]
om_1        | ] from file:/data/metadata/om/certs/495064171534.crt.
scm_1       |   PathLen:2147483647
recon_1     | 2023-01-31 07:47:44,034 [main] INFO recon.ReconServer: Creating Recon Schema.
datanode_1  | 2023-01-31 07:47:49,830 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
datanode_3  | 2023-01-31 07:47:56,132 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3  | 2023-01-31 07:47:56,452 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@29e3ecc] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2023-01-31 07:48:04,793 [main] INFO security.OMCertificateClient: Added certificate [
scm_1       | ]
recon_1     | 2023-01-31 07:47:50,354 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
datanode_1  | 2023-01-31 07:47:49,864 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
om_1        | [
datanode_3  | 2023-01-31 07:47:56,806 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.3:9891
recon_1     | 2023-01-31 07:47:50,358 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_1  | 2023-01-31 07:47:50,175 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
datanode_1  | 2023-01-31 07:47:50,176 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
scm_1       | 
om_1        |   Version: V3
recon_1     | 2023-01-31 07:47:50,359 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
datanode_1  | 2023-01-31 07:47:50,521 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_2  | 2023-01-31 07:48:35,347 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29: new RaftServerImpl for group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
om_1        |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
scm_1       | KeyUsage [
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 2023-01-31 07:47:50,395 [main] INFO util.log: Logging initialized @90919ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       |   DigitalSignature
om_1        | 
om_1        |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 2023-01-31 07:47:50,623 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2  | 2023-01-31 07:48:35,348 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2023-01-31 07:48:35,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       |   Key_Encipherment
datanode_1  | 2023-01-31 07:47:50,632 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2023-01-31 07:47:50,636 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-31 07:47:56,866 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
recon_1     | 2023-01-31 07:47:51,156 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
recon_1     | 2023-01-31 07:47:51,286 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       |   Data_Encipherment
datanode_2  | 2023-01-31 07:48:35,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2023-01-31 07:48:35,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2023-01-31 07:47:59,607 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2023-01-31 07:48:00,156 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-77b43bb3-aedf-4b47-9873-e07d31d92cbe/container.db to cache
datanode_3  | 2023-01-31 07:48:00,160 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-77b43bb3-aedf-4b47-9873-e07d31d92cbe/container.db for volume DS-77b43bb3-aedf-4b47-9873-e07d31d92cbe
recon_1     | 2023-01-31 07:47:51,308 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
datanode_1  | 2023-01-31 07:47:50,721 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2023-01-31 07:48:35,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        |   params: null
datanode_3  | 2023-01-31 07:48:00,176 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
scm_1       |   Key_Agreement
datanode_2  | 2023-01-31 07:48:35,353 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
datanode_3  | 2023-01-31 07:48:00,199 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_3  | 2023-01-31 07:48:00,310 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
recon_1     | 2023-01-31 07:47:51,312 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2023-01-31 07:47:50,728 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x38db6b93] REGISTERED
datanode_2  | 2023-01-31 07:48:35,371 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: ConfigurationManager, init=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
scm_1       |   Key_CertSign
scm_1       |   Crl_Sign
recon_1     | 2023-01-31 07:47:51,313 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2023-01-31 07:47:50,755 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x38db6b93] BIND: 0.0.0.0/0.0.0.0:9855
datanode_2  | 2023-01-31 07:48:35,371 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | ]
scm_1       | 
recon_1     | 2023-01-31 07:47:51,342 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
datanode_1  | 2023-01-31 07:47:50,763 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x38db6b93, L:/0.0.0.0:9855] ACTIVE
datanode_1  | 2023-01-31 07:47:51,049 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
om_1        |   public exponent: 65537
datanode_3  | 2023-01-31 07:48:00,316 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 14b917d5-325a-4f29-a0e8-e34b223e06de
datanode_3  | 2023-01-31 07:48:00,397 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.RaftServer: 14b917d5-325a-4f29-a0e8-e34b223e06de: start RPC server
datanode_2  | 2023-01-31 07:48:35,395 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
recon_1     | 2023-01-31 07:47:52,035 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
recon_1     | 2023-01-31 07:47:53,817 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
datanode_3  | 2023-01-31 07:48:00,399 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 14b917d5-325a-4f29-a0e8-e34b223e06de: GrpcService started, listening on 9858
datanode_3  | 2023-01-31 07:48:00,409 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 14b917d5-325a-4f29-a0e8-e34b223e06de: GrpcService started, listening on 9856
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | SubjectAlternativeName [
datanode_2  | 2023-01-31 07:48:35,395 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2023-01-31 07:48:35,442 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2023-01-31 07:48:35,454 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2023-01-31 07:48:35,454 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2023-01-31 07:48:36,122 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2023-01-31 07:48:36,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2  | 2023-01-31 07:48:36,159 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2  | 2023-01-31 07:48:36,160 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1  | 2023-01-31 07:47:51,073 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
scm_1       |   IPAddress: 172.18.0.4
scm_1       | ]
scm_1       | 
scm_1       | ]
datanode_1  | 2023-01-31 07:47:51,111 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_1  | 2023-01-31 07:47:52,205 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 488772207169
datanode_1  | 2023-01-31 07:47:52,245 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 488772207169
scm_1       |   Algorithm: [SHA256withRSA]
recon_1     | 2023-01-31 07:47:53,861 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
recon_1     | 2023-01-31 07:47:53,903 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
datanode_3  | 2023-01-31 07:48:00,413 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: 14b917d5-325a-4f29-a0e8-e34b223e06de: GrpcService started, listening on 9857
datanode_3  | 2023-01-31 07:48:00,421 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 14b917d5-325a-4f29-a0e8-e34b223e06de is started using port 9858 for RATIS
datanode_3  | 2023-01-31 07:48:00,421 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 14b917d5-325a-4f29-a0e8-e34b223e06de is started using port 9857 for RATIS_ADMIN
datanode_3  | 2023-01-31 07:48:00,421 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 14b917d5-325a-4f29-a0e8-e34b223e06de is started using port 9856 for RATIS_SERVER
datanode_3  | 2023-01-31 07:48:00,439 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 14b917d5-325a-4f29-a0e8-e34b223e06de is started using port 9855 for RATIS_DATASTREAM
recon_1     | 2023-01-31 07:47:54,069 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
scm_1       |   Signature:
scm_1       | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
om_1        |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_3  | 2023-01-31 07:48:00,440 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-14b917d5-325a-4f29-a0e8-e34b223e06de: Started
datanode_3  | 2023-01-31 07:48:00,619 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm_1       | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
scm_1       | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
scm_1       | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
om_1        |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_2  | 2023-01-31 07:48:36,178 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1       | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
scm_1       | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
datanode_3  | 2023-01-31 07:48:01,622 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_3  | 2023-01-31 07:48:02,628 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2023-01-31 07:48:36,195 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 does not exist. Creating ...
recon_1     | 2023-01-31 07:47:54,072 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
recon_1     | 2023-01-31 07:47:58,421 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2023-01-31 07:47:52,800 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_3  | 2023-01-31 07:48:03,629 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_2  | 2023-01-31 07:48:36,326 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/in_use.lock acquired by nodename 7@43001ba40da4
om_1        |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
scm_1       | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
scm_1       | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
datanode_1  | 2023-01-31 07:47:52,801 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2023-01-31 07:48:04,550 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_2  | 2023-01-31 07:48:36,419 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 has been successfully formatted.
om_1        |   SerialNumber: [    6c0d0934 9f]
scm_1       | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
recon_1     | 2023-01-31 07:48:00,102 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
scm_1       | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
recon_1     | 2023-01-31 07:48:00,593 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
datanode_2  | 2023-01-31 07:48:36,519 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-95A0187A7678: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2023-01-31 07:47:52,801 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
om_1        | 
scm_1       | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
scm_1       | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
datanode_2  | 2023-01-31 07:48:36,582 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2023-01-31 07:47:53,087 [main] INFO util.log: Logging initialized @91245ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
om_1        | Certificate Extensions: 3
scm_1       | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
recon_1     | 2023-01-31 07:48:00,593 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
recon_1     | 2023-01-31 07:48:01,068 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2023-01-31 07:47:54,211 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_2  | 2023-01-31 07:48:36,625 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | 2023-01-31 07:48:01,788 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1  | 2023-01-31 07:47:54,255 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
scm_1       | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
datanode_2  | 2023-01-31 07:48:36,626 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-31 07:48:36,643 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
recon_1     | 2023-01-31 07:48:02,106 [main] INFO reflections.Reflections: Reflections took 276 ms to scan 3 urls, producing 124 keys and 279 values 
datanode_1  | 2023-01-31 07:47:54,264 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
scm_1       | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_2  | 2023-01-31 07:48:36,655 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | BasicConstraints:[
recon_1     | 2023-01-31 07:48:02,846 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
datanode_1  | 2023-01-31 07:47:54,267 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:322)
datanode_2  | 2023-01-31 07:48:36,694 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        |   CA:true
recon_1     | 2023-01-31 07:48:03,184 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
datanode_1  | 2023-01-31 07:47:54,268 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | 2023-01-31 07:48:36,746 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        |   PathLen:2147483647
recon_1     | 2023-01-31 07:48:03,197 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
datanode_1  | 2023-01-31 07:47:54,296 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_3  | Caused by: java.util.concurrent.TimeoutException
scm_1       | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
datanode_2  | 2023-01-31 07:48:36,749 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | ]
recon_1     | 2023-01-31 07:48:03,197 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
datanode_1  | 2023-01-31 07:47:54,610 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_2  | 2023-01-31 07:48:36,779 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678
om_1        | 
recon_1     | 2023-01-31 07:48:03,248 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_1  | 2023-01-31 07:47:54,619 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
scm_1       | 
datanode_2  | 2023-01-31 07:48:36,783 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2023-01-31 07:48:36,784 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:48:03,304 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
datanode_1  | 2023-01-31 07:47:54,847 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/464075175071.crt.
datanode_2  | 2023-01-31 07:48:36,789 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | [2]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | 2023-01-31 07:48:03,343 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
datanode_1  | 2023-01-31 07:47:54,847 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 2023-01-31 07:47:17,332 [main] INFO client.SCMCertificateClient: Added certificate [
datanode_2  | 2023-01-31 07:48:36,789 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
om_1        | KeyUsage [
recon_1     | 2023-01-31 07:48:03,512 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
datanode_1  | 2023-01-31 07:47:54,863 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | [
datanode_2  | 2023-01-31 07:48:36,793 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        |   DigitalSignature
recon_1     | 2023-01-31 07:48:03,663 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_1  | 2023-01-31 07:47:55,035 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       |   Version: V3
datanode_2  | 2023-01-31 07:48:36,798 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        |   Key_Encipherment
recon_1     | 2023-01-31 07:48:03,697 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
datanode_1  | 2023-01-31 07:47:55,048 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5392c0a7{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       |   Subject: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm-sub@scm
datanode_2  | 2023-01-31 07:48:36,798 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        |   Data_Encipherment
recon_1     | 2023-01-31 07:48:03,961 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
datanode_1  | 2023-01-31 07:47:55,051 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5a349644{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | 	... 1 more
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 2023-01-31 07:48:36,807 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        |   Key_Agreement
om_1        |   Key_CertSign
recon_1     | 2023-01-31 07:48:04,528 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
datanode_3  | 2023-01-31 07:48:04,630 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
scm_1       | 
datanode_2  | 2023-01-31 07:48:36,861 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2023-01-31 07:47:55,793 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
om_1        |   Crl_Sign
recon_1     | 2023-01-31 07:48:04,544 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
datanode_3  | 2023-01-31 07:48:06,552 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
scm_1       |   Key:  Sun RSA public key, 2048 bits
datanode_2  | 2023-01-31 07:48:36,870 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-31 07:47:55,916 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@4d8458a1{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-9317261842524639658/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
om_1        | ]
recon_1     | 2023-01-31 07:48:05,021 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
scm_1       |   params: null
datanode_2  | 2023-01-31 07:48:36,944 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_1  | 2023-01-31 07:47:56,002 [main] INFO server.AbstractConnector: Started ServerConnector@6f54d397{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
om_1        | 
recon_1     | 2023-01-31 07:48:05,087 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
scm_1       |   modulus: 21839311498419451799433876903294052256117987518486748454425344509701319626060443054483593088214991524142839748338920791686728974018049225065317137235161680219333048021725533961054801273753044216325584875209393757958336911466534467598973117739939090025889161761364484331917543565376987818102646101618742624221922139462478240903980211528392124818767343209865282148575638299705707953189878866510751533355076734455084748058816891331236509420602490956071064271595190837734857306463923270847678378935598367816595968671034414744254962577523006139113115930489491729442469612162892236627521860724497123436434383248602133906293
datanode_2  | 2023-01-31 07:48:36,945 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2023-01-31 07:48:36,951 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
om_1        | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | 2023-01-31 07:48:05,087 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
scm_1       |   public exponent: 65537
datanode_1  | 2023-01-31 07:47:56,002 [main] INFO server.Server: Started @94165ms
datanode_2  | 2023-01-31 07:48:37,000 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | SubjectAlternativeName [
recon_1     | 2023-01-31 07:48:06,819 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
scm_1       |   Validity: [From: Tue Jan 31 00:00:00 UTC 2023,
datanode_1  | 2023-01-31 07:47:56,016 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2023-01-31 07:48:37,001 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        |   IPAddress: 172.18.0.4
recon_1     | 2023-01-31 07:48:06,824 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
scm_1       |                To: Fri Mar 10 00:00:00 UTC 2028]
datanode_1  | 2023-01-31 07:47:56,016 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2023-01-31 07:48:37,013 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: start as a follower, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | ]
recon_1     | 2023-01-31 07:48:07,025 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
scm_1       |   Issuer: O=CID-5128c6ec-f311-4d77-b590-370d3e099e21, OU=6dfb726e-350e-430b-835b-cf79da791979, CN=scm@scm
datanode_1  | 2023-01-31 07:47:56,029 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2023-01-31 07:48:37,014 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 
recon_1     | 2023-01-31 07:48:07,025 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
scm_1       |   SerialNumber: [    6c0d0934 9f]
datanode_1  | 2023-01-31 07:47:56,065 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_2  | 2023-01-31 07:48:37,022 [pool-24-thread-1] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
om_1        | ]
recon_1     | 2023-01-31 07:48:07,036 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:322)
scm_1       | 
datanode_1  | 2023-01-31 07:47:56,214 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ed6c37b] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        |   Algorithm: [SHA256withRSA]
recon_1     | 2023-01-31 07:48:07,120 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
scm_1       | Certificate Extensions: 3
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_2  | 2023-01-31 07:48:37,060 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-95A0187A7678,id=1e69a4e3-5301-4460-8965-9fee5bf32e29
om_1        |   Signature:
recon_1     | 2023-01-31 07:48:07,140 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4b89515b{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | BasicConstraints:[
datanode_1  | 2023-01-31 07:47:57,139 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.3:9891
datanode_2  | 2023-01-31 07:48:37,062 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
recon_1     | 2023-01-31 07:48:07,143 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@5482b32a{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_3  | Caused by: java.util.concurrent.TimeoutException
scm_1       |   CA:true
datanode_1  | 2023-01-31 07:47:57,258 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2023-01-31 07:48:37,062 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
om_1        | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
recon_1     | 2023-01-31 07:48:08,881 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
scm_1       |   PathLen:2147483647
scm_1       | ]
datanode_2  | 2023-01-31 07:48:37,062 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
recon_1     | 2023-01-31 07:48:08,897 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
scm_1       | 
datanode_1  | 2023-01-31 07:47:59,441 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om_1        | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
recon_1     | 2023-01-31 07:48:14,969 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@32252740{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_4_0-SNAPSHOT_jar-_-any-14657639466648001073/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/recon}
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | 2023-01-31 07:48:00,073 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-d3143470-6fa0-4895-a29c-c67f0e1246ee/container.db to cache
om_1        | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
recon_1     | 2023-01-31 07:48:15,066 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@2e895acb{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | KeyUsage [
scm_1       |   DigitalSignature
datanode_1  | 2023-01-31 07:48:00,074 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-5128c6ec-f311-4d77-b590-370d3e099e21/DS-d3143470-6fa0-4895-a29c-c67f0e1246ee/container.db for volume DS-d3143470-6fa0-4895-a29c-c67f0e1246ee
datanode_2  | 2023-01-31 07:48:37,063 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
recon_1     | 2023-01-31 07:48:15,066 [Listener at 0.0.0.0/9891] INFO server.Server: Started @115590ms
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       |   Key_Encipherment
datanode_1  | 2023-01-31 07:48:00,119 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2023-01-31 07:48:37,090 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
recon_1     | 2023-01-31 07:48:15,075 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
scm_1       |   Data_Encipherment
datanode_1  | 2023-01-31 07:48:00,129 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
om_1        | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
recon_1     | 2023-01-31 07:48:15,075 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       |   Key_Agreement
datanode_1  | 2023-01-31 07:48:00,264 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode_2  | 2023-01-31 07:48:37,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2023-01-31 07:48:37,226 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=defd148e-7304-4d1b-888f-95a0187a7678
om_1        | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
recon_1     | 2023-01-31 07:48:15,077 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2023-01-31 07:48:15,077 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
scm_1       |   Key_CertSign
datanode_1  | 2023-01-31 07:48:00,277 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis ee1a73fb-90e8-4573-a632-4d493b4c1d75
datanode_2  | 2023-01-31 07:48:37,538 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
om_1        | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
recon_1     | 2023-01-31 07:48:15,149 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
datanode_3  | 	... 1 more
scm_1       |   Crl_Sign
datanode_1  | 2023-01-31 07:48:00,378 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.RaftServer: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start RPC server
datanode_2  | 2023-01-31 07:48:42,215 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5193292941ns, electionTimeout:5117ms
om_1        | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_3  | 2023-01-31 07:48:09,647 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | 2023-01-31 07:48:00,400 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_2  | 2023-01-31 07:48:42,215 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
om_1        | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
scm_1       | ]
recon_1     | 2023-01-31 07:48:15,188 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
datanode_3  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort f206954d6d35/172.18.0.6:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:44660 remote=recon/172.18.0.3:9891]
datanode_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_2  | 2023-01-31 07:48:42,227 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
scm_1       | 
recon_1     | 2023-01-31 07:48:15,188 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2023-01-31 07:48:15,188 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | SubjectAlternativeName [
datanode_2  | 2023-01-31 07:48:42,327 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2023-01-31 07:48:42,327 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1
datanode_2  | 2023-01-31 07:48:42,361 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
om_1        | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
om_1        | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
scm_1       |   IPAddress: 172.18.0.4
datanode_2  | 2023-01-31 07:48:42,481 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-31 07:48:42,481 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-31 07:48:15,189 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
om_1        | 
scm_1       | ]
scm_1       | 
scm_1       | ]
scm_1       |   Algorithm: [SHA256withRSA]
scm_1       |   Signature:
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 2023-01-31 07:48:42,537 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for ee1a73fb-90e8-4573-a632-4d493b4c1d75
datanode_2  | 2023-01-31 07:48:42,537 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 14b917d5-325a-4f29-a0e8-e34b223e06de
datanode_2  | 2023-01-31 07:48:43,151 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_2  | 2023-01-31 07:48:44,669 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: receive requestVote(ELECTION, 14b917d5-325a-4f29-a0e8-e34b223e06de, group-95A0187A7678, 1, (t:0, i:0))
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
recon_1     | 2023-01-31 07:48:15,212 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
scm_1       | 0000: C5 2D 72 5B 08 D0 A2 57   15 24 FA B6 02 5C 7B CC  .-r[...W.$...\..
datanode_2  | 2023-01-31 07:48:44,674 [grpc-default-executor-0] INFO impl.VoteContext: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-CANDIDATE: reject ELECTION from 14b917d5-325a-4f29-a0e8-e34b223e06de: already has voted for 1e69a4e3-5301-4460-8965-9fee5bf32e29 at current term 1
datanode_2  | 2023-01-31 07:48:44,677 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678 replies to ELECTION vote request: 14b917d5-325a-4f29-a0e8-e34b223e06de<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t1. Peer's state: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678:t1, leader=null, voted=1e69a4e3-5301-4460-8965-9fee5bf32e29, raftlog=Memoized:1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:45,192 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
recon_1     | 2023-01-31 07:48:16,131 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 4 pipelines from SCM.
recon_1     | 2023-01-31 07:48:16,132 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
recon_1     | 2023-01-31 07:48:16,138 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 from SCM.
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_2  | 2023-01-31 07:48:45,192 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection:   Response 0: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:FAIL-t1
datanode_2  | 2023-01-31 07:48:45,192 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection:   Response 1: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-14b917d5-325a-4f29-a0e8-e34b223e06de#0:FAIL-t1
datanode_2  | 2023-01-31 07:48:45,193 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1 ELECTION round 0: result REJECTED
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_3  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
recon_1     | 2023-01-31 07:48:16,282 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: defd148e-7304-4d1b-888f-95a0187a7678, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.512Z[UTC]].
datanode_2  | 2023-01-31 07:48:45,195 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_2  | 2023-01-31 07:48:45,195 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:322)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
recon_1     | 2023-01-31 07:48:16,312 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=409651ee-63d0-4368-a01a-aa485fe71506 from SCM.
datanode_2  | 2023-01-31 07:48:45,195 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection1] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
om_1        | ] from file:/data/metadata/om/certs/CA-464075175071.crt.
om_1        | 2023-01-31 07:48:04,820 [main] INFO security.OMCertificateClient: CertificateLifetimeMonitor for om is started with first delay 29088715197 ms and interval 86400000 ms.
recon_1     | 2023-01-31 07:48:16,319 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 409651ee-63d0-4368-a01a-aa485fe71506, Nodes: ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.221Z[UTC]].
datanode_2  | 2023-01-31 07:48:45,247 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
recon_1     | 2023-01-31 07:48:16,320 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=02fede5b-9fce-4aaf-9e53-8eca883e33ad from SCM.
scm_1       | 0010: 86 78 67 BB 53 B7 A4 D7   5F 3C 17 0D 5D CB A1 FA  .xg.S..._<..]...
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.util.concurrent.TimeoutException
om_1        | 2023-01-31 07:48:04,924 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
recon_1     | 2023-01-31 07:48:16,325 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 02fede5b-9fce-4aaf-9e53-8eca883e33ad, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.559Z[UTC]].
recon_1     | 2023-01-31 07:48:16,328 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=7eb7c323-0301-4528-bfd5-9c2467a4d4e7 from SCM.
scm_1       | 0020: B6 0D 4D 8C A4 C3 25 87   5C BC E9 C2 EE 49 95 69  ..M...%.\....I.i
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
om_1        | 2023-01-31 07:48:05,686 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-31 07:48:16,334 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7eb7c323-0301-4528-bfd5-9c2467a4d4e7, Nodes: 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.592Z[UTC]].
datanode_2  | 2023-01-31 07:48:45,261 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-31 07:48:45,418 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678.
om_1        | 2023-01-31 07:48:05,697 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-31 07:48:16,337 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
recon_1     | 2023-01-31 07:48:16,345 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2023-01-31 07:48:16,353 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
om_1        | 2023-01-31 07:48:06,451 [main] INFO om.OzoneManager: S3 Multi-Tenancy is enabled
recon_1     | 2023-01-31 07:48:16,365 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2023-01-31 07:48:16,944 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:50724
datanode_2  | 2023-01-31 07:48:45,419 [Command processor thread] INFO server.RaftServer: 1e69a4e3-5301-4460-8965-9fee5bf32e29: addNew group-8ECA883E33AD:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] returns group-8ECA883E33AD:java.util.concurrent.CompletableFuture@3dfd0a21[Not completed]
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | 2023-01-31 07:48:06,475 [main] INFO om.OMMultiTenantManagerImpl: Loaded 0 tenants and 0 tenant users from the database
scm_1       | 0030: 95 48 3B F5 BB A0 D5 63   DA FD F7 43 2A E7 FF 39  .H;....c...C*..9
recon_1     | 2023-01-31 07:48:16,957 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41290
recon_1     | 2023-01-31 07:48:16,962 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:40658
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 2023-01-31 07:48:06,518 [OMRangerBGSyncService#0] WARN service.OMRangerBGSyncService: OzoneManagerRatisServer is not initialized yet
om_1        | 2023-01-31 07:48:06,569 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
recon_1     | 2023-01-31 07:48:16,968 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:48:16,979 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:48:16,983 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 0040: DB FB 6A C3 25 33 73 BA   30 10 E2 A4 76 BF 99 9F  ..j.%3s.0...v...
om_1        | 2023-01-31 07:48:06,569 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
om_1        | 2023-01-31 07:48:06,745 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29: new RaftServerImpl for group-8ECA883E33AD:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
recon_1     | 2023-01-31 07:48:34,233 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:41910
recon_1     | 2023-01-31 07:48:34,244 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:48:34,271 [IPC Server handler 9 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1e69a4e3-5301-4460-8965-9fee5bf32e29
scm_1       | 0050: 21 AD EC 9A F0 4B 27 1C   A9 56 E0 79 D6 BF 78 40  !....K'..V.y..x@
scm_1       | 0060: 65 74 E8 95 79 59 E8 82   2C B8 F7 DA 3D 10 96 31  et..yY..,...=..1
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
recon_1     | 2023-01-31 07:48:34,294 [IPC Server handler 9 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 1e69a4e3-5301-4460-8965-9fee5bf32e29{ip: 172.18.0.9, host: ozonesecure_datanode_2.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488625236405, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-31 07:48:34,316 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 1e69a4e3-5301-4460-8965-9fee5bf32e29 to Node DB.
om_1        | 2023-01-31 07:48:06,834 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2023-01-31 07:48:06,835 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 0070: 43 99 A0 06 DF 12 9B 0C   A8 8D 1A B4 26 5B FD 57  C...........&[.W
recon_1     | 2023-01-31 07:48:34,506 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:39424
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 2023-01-31 07:48:06,913 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2023-01-31 07:48:07,023 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 0080: 62 28 0E D7 C0 3E 46 4E   40 CC 7E 55 42 66 DD 89  b(...>FN@..UBf..
recon_1     | 2023-01-31 07:48:34,523 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:48:34,532 [IPC Server handler 64 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ee1a73fb-90e8-4573-a632-4d493b4c1d75
om_1        | 2023-01-31 07:48:07,190 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: om:9872
om_1        | 2023-01-31 07:48:07,273 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
datanode_3  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:44660 remote=recon/172.18.0.3:9891]
scm_1       | 0090: 2A 0A 99 5F 7D F2 7B 38   A3 98 3A DC 57 BC A6 29  *.._...8..:.W..)
datanode_1  | 	... 1 more
recon_1     | 2023-01-31 07:48:34,534 [IPC Server handler 64 on default port 9891] INFO node.SCMNodeManager: Registered Data node : ee1a73fb-90e8-4573-a632-4d493b4c1d75{ip: 172.18.0.10, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488772207169, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
scm_1       | 00A0: 78 33 17 0D CE DE 6C F9   DE 2D CF EC FA 66 A9 39  x3....l..-...f.9
datanode_1  | 2023-01-31 07:48:00,421 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: ee1a73fb-90e8-4573-a632-4d493b4c1d75: GrpcService started, listening on 9858
recon_1     | 2023-01-31 07:48:34,537 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node ee1a73fb-90e8-4573-a632-4d493b4c1d75 to Node DB.
recon_1     | 2023-01-31 07:48:34,633 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34406
recon_1     | 2023-01-31 07:48:34,661 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1     | 2023-01-31 07:48:34,668 [IPC Server handler 1 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/14b917d5-325a-4f29-a0e8-e34b223e06de
scm_1       | 00B0: B5 F9 0E A9 AE 5B C2 76   E4 38 D4 7D 51 61 80 B2  .....[.v.8..Qa..
scm_1       | 00C0: 3B 89 BF 0F F1 60 1B 89   84 DD D9 FE 91 71 74 53  ;....`.......qtS
scm_1       | 00D0: EA 5D 28 C0 2F D6 A6 EF   94 2D 5F FF C3 90 A1 EA  .](./....-_.....
datanode_2  | 2023-01-31 07:48:45,421 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: ConfigurationManager, init=-1: peers:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_2  | 2023-01-31 07:48:45,422 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
recon_1     | 2023-01-31 07:48:34,670 [IPC Server handler 1 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 14b917d5-325a-4f29-a0e8-e34b223e06de{ip: 172.18.0.6, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488015668949, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 00E0: 00 5A D6 A5 4A 07 4D ED   92 9F 64 3A C4 62 15 82  .Z..J.M...d:.b..
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 2023-01-31 07:48:45,433 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2023-01-31 07:48:45,433 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2023-01-31 07:48:45,433 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2023-01-31 07:48:45,433 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2023-01-31 07:48:45,433 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2023-01-31 07:48:45,434 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2023-01-31 07:48:45,434 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2  | 2023-01-31 07:48:45,434 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2  | 2023-01-31 07:48:45,434 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1       | 00F0: C2 CF E7 26 7A 20 FA 1D   3E 74 86 6C E3 4D 81 17  ...&z ..>t.l.M..
scm_1       | 
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
scm_1       | 2023-01-31 07:47:17,338 [main] INFO client.SCMCertificateClient: CertificateLifetimeMonitor for scm/sub-ca is started with first delay 158688762666 ms and interval 86400000 ms.
scm_1       | 2023-01-31 07:47:17,530 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
om_1        | 2023-01-31 07:48:07,534 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode_2  | 2023-01-31 07:48:45,435 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 2023-01-31 07:48:45,435 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/02fede5b-9fce-4aaf-9e53-8eca883e33ad does not exist. Creating ...
datanode_2  | 2023-01-31 07:48:45,488 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/02fede5b-9fce-4aaf-9e53-8eca883e33ad/in_use.lock acquired by nodename 7@43001ba40da4
datanode_1  | 2023-01-31 07:48:00,451 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2023-01-31 07:48:00,464 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: ee1a73fb-90e8-4573-a632-4d493b4c1d75: GrpcService started, listening on 9856
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 2023-01-31 07:48:07,563 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
om_1        | 2023-01-31 07:48:07,669 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1       | 2023-01-31 07:47:17,530 [main] INFO server.StorageContainerManager: SCM login successful.
recon_1     | 2023-01-31 07:48:34,671 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 14b917d5-325a-4f29-a0e8-e34b223e06de to Node DB.
recon_1     | 2023-01-31 07:48:35,207 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
datanode_2  | 2023-01-31 07:48:45,490 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/02fede5b-9fce-4aaf-9e53-8eca883e33ad has been successfully formatted.
om_1        | 2023-01-31 07:48:07,974 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-31 07:48:07,983 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
datanode_2  | 2023-01-31 07:48:45,491 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-8ECA883E33AD: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2023-01-31 07:47:17,603 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-31 07:47:17,806 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2023-01-31 07:48:07,986 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-31 07:48:07,991 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om_1        | 2023-01-31 07:48:07,991 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | 2023-01-31 07:47:18,191 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1       | 2023-01-31 07:47:18,192 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
scm_1       | 2023-01-31 07:47:18,274 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2023-01-31 07:47:18,295 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:6dfb726e-350e-430b-835b-cf79da791979
scm_1       | 2023-01-31 07:47:18,338 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
recon_1     | 2023-01-31 07:48:35,208 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
scm_1       | 2023-01-31 07:47:18,346 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm_1       | 2023-01-31 07:47:18,396 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
recon_1     | 2023-01-31 07:48:36,750 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_2.ozonesecure_default
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
datanode_3  | 	... 12 more
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
recon_1     | 2023-01-31 07:48:36,753 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)
datanode_3  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.6:44660 remote=recon/172.18.0.3:9891]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | 2023-01-31 07:48:07,992 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
datanode_1  | 2023-01-31 07:48:00,478 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO server.GrpcService: ee1a73fb-90e8-4573-a632-4d493b4c1d75: GrpcService started, listening on 9857
scm_1       | 2023-01-31 07:47:18,476 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-31 07:47:18,478 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
datanode_2  | 2023-01-31 07:48:45,492 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-31 07:48:45,525 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1     | 2023-01-31 07:48:37,464 [IPC Server handler 39 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_1.ozonesecure_default
recon_1     | 2023-01-31 07:48:37,469 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=409651ee-63d0-4368-a01a-aa485fe71506 reported by ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10)
recon_1     | 2023-01-31 07:48:37,471 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 409651ee-63d0-4368-a01a-aa485fe71506, Nodes: ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ee1a73fb-90e8-4573-a632-4d493b4c1d75, CreationTimestamp2023-01-31T07:48:03.221Z[UTC]] moved to OPEN state
recon_1     | 2023-01-31 07:48:37,670 [IPC Server handler 1 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_3.ozonesecure_default
recon_1     | 2023-01-31 07:48:37,681 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)
recon_1     | 2023-01-31 07:48:39,133 [IPC Server handler 0 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_1.ozonesecure_default
recon_1     | 2023-01-31 07:48:39,141 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10)
recon_1     | 2023-01-31 07:48:40,932 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1675151315208
recon_1     | 2023-01-31 07:48:40,935 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-31 07:48:40,937 [pool-30-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
datanode_1  | 2023-01-31 07:48:00,495 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee1a73fb-90e8-4573-a632-4d493b4c1d75 is started using port 9858 for RATIS
datanode_1  | 2023-01-31 07:48:00,495 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee1a73fb-90e8-4573-a632-4d493b4c1d75 is started using port 9857 for RATIS_ADMIN
datanode_1  | 2023-01-31 07:48:00,503 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee1a73fb-90e8-4573-a632-4d493b4c1d75 is started using port 9856 for RATIS_SERVER
datanode_1  | 2023-01-31 07:48:00,503 [EndpointStateMachine task thread for scm/172.18.0.4:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis ee1a73fb-90e8-4573-a632-4d493b4c1d75 is started using port 9855 for RATIS_DATASTREAM
datanode_1  | 2023-01-31 07:48:00,509 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-ee1a73fb-90e8-4573-a632-4d493b4c1d75: Started
datanode_1  | 2023-01-31 07:48:01,452 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om_1        | 2023-01-31 07:48:07,993 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1        | 2023-01-31 07:48:08,005 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-31 07:48:08,005 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2023-01-31 07:48:08,012 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
datanode_1  | 2023-01-31 07:48:02,453 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2023-01-31 07:48:03,455 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
datanode_1  | 2023-01-31 07:48:04,456 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] INFO ipc.Client: Retrying connect to server: recon/172.18.0.3:9891. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=15, sleepTime=1000 MILLISECONDS)
om_1        | 2023-01-31 07:48:08,047 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om_1        | 2023-01-31 07:48:08,060 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1        | 2023-01-31 07:48:08,069 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om_1        | 2023-01-31 07:48:10,090 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
om_1        | 2023-01-31 07:48:10,174 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
om_1        | 2023-01-31 07:48:10,183 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
om_1        | 2023-01-31 07:48:10,184 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
om_1        | 2023-01-31 07:48:10,187 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_1  | 2023-01-31 07:48:06,456 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
om_1        | 2023-01-31 07:48:10,195 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
om_1        | 2023-01-31 07:48:10,213 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
om_1        | 2023-01-31 07:48:10,238 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
om_1        | 2023-01-31 07:48:10,257 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
recon_1     | 2023-01-31 07:48:41,290 [pool-30-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1675151315208.
recon_1     | 2023-01-31 07:48:41,821 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
om_1        | 2023-01-31 07:48:10,746 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
om_1        | 2023-01-31 07:48:10,746 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
om_1        | 2023-01-31 07:48:10,949 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om_1        | 2023-01-31 07:48:10,950 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
recon_1     | 2023-01-31 07:48:41,862 [pool-52-thread-2] INFO tasks.NSSummaryTaskWithLegacy: Completed a reprocess run of NSSummaryTaskWithLegacy
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
om_1        | 2023-01-31 07:48:10,953 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2023-01-31 07:48:10,954 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2023-01-31 07:48:10,977 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2023-01-31 07:48:11,014 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc4b6e8af] REGISTERED
om_1        | 2023-01-31 07:48:11,027 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc4b6e8af] BIND: 0.0.0.0/0.0.0.0:0
recon_1     | 2023-01-31 07:48:41,863 [pool-52-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a reprocess run of NSSummaryTaskWithFSO
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_2  | 2023-01-31 07:48:45,525 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2023-01-31 07:48:45,525 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/02fede5b-9fce-4aaf-9e53-8eca883e33ad
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:48:43,161 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
om_1        | 2023-01-31 07:48:11,029 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@6c995c5d[Not completed]
om_1        | 2023-01-31 07:48:11,033 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
recon_1     | 2023-01-31 07:48:43,779 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:322)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:518)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
recon_1     | 2023-01-31 07:48:43,779 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
scm_1       | 2023-01-31 07:47:18,479 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
recon_1     | 2023-01-31 07:48:43,780 [pool-31-thread-1] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
scm_1       | 2023-01-31 07:47:18,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
datanode_1  | Caused by: java.util.concurrent.TimeoutException
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
recon_1     | 2023-01-31 07:48:43,785 [pool-31-thread-1] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
om_1        | 2023-01-31 07:48:11,049 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc4b6e8af, L:/0.0.0.0:44081] ACTIVE
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 2023-01-31 07:48:43,829 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
scm_1       | 2023-01-31 07:47:18,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om_1        | 2023-01-31 07:48:11,123 [pool-28-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1     | 2023-01-31 07:48:43,830 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.05 seconds to process 0 keys.
scm_1       | 2023-01-31 07:47:18,480 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
om_1        | 2023-01-31 07:48:11,136 [main] INFO om.OzoneManager: Creating RPC Server
om_1        | 2023-01-31 07:48:11,143 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2023-01-31 07:48:11,147 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2023-01-31 07:48:11,148 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
recon_1     | 2023-01-31 07:48:44,001 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
scm_1       | 2023-01-31 07:47:18,481 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1       | 2023-01-31 07:47:18,484 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-31 07:47:18,485 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
scm_1       | 2023-01-31 07:47:18,486 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
recon_1     | 2023-01-31 07:48:44,003 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
scm_1       | 2023-01-31 07:47:18,498 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm_1       | 2023-01-31 07:47:18,504 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
scm_1       | 2023-01-31 07:47:18,505 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1       | 2023-01-31 07:47:19,169 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
datanode_1  | 	... 1 more
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1     | 2023-01-31 07:48:45,430 [IPC Server handler 27 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_3.ozonesecure_default
scm_1       | 2023-01-31 07:47:19,333 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
scm_1       | 2023-01-31 07:47:19,340 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
scm_1       | 2023-01-31 07:47:19,341 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
scm_1       | 2023-01-31 07:47:19,342 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_1  | 2023-01-31 07:48:09,464 [EndpointStateMachine task thread for recon/172.18.0.3:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | 2023-01-31 07:48:45,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2023-01-31 07:48:45,430 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)
scm_1       | 2023-01-31 07:47:19,345 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
scm_1       | 2023-01-31 07:47:19,346 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
scm_1       | 2023-01-31 07:47:19,351 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
scm_1       | 2023-01-31 07:47:19,354 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
datanode_1  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort 6b0ee5ff6668/172.18.0.10:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.10:44002 remote=recon/172.18.0.3:9891]
datanode_2  | 2023-01-31 07:48:45,527 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
recon_1     | 2023-01-31 07:48:45,430 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=7eb7c323-0301-4528-bfd5-9c2467a4d4e7 reported by 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)
scm_1       | 2023-01-31 07:47:19,396 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
scm_1       | 2023-01-31 07:47:19,396 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
scm_1       | 2023-01-31 07:47:19,448 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1       | 2023-01-31 07:47:19,449 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 2023-01-31 07:48:45,528 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:48:45,431 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7eb7c323-0301-4528-bfd5-9c2467a4d4e7, Nodes: 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:14b917d5-325a-4f29-a0e8-e34b223e06de, CreationTimestamp2023-01-31T07:48:03.592Z[UTC]] moved to OPEN state
scm_1       | 2023-01-31 07:47:19,449 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 2023-01-31 07:48:45,587 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
recon_1     | 2023-01-31 07:48:45,528 [IPC Server handler 75 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_2.ozonesecure_default
datanode_3  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
scm_1       | 2023-01-31 07:47:19,449 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2023-01-31 07:47:19,453 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
recon_1     | 2023-01-31 07:48:45,529 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
om_1        | 2023-01-31 07:48:11,148 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
scm_1       | 2023-01-31 07:47:19,473 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: found a subdirectory /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21
scm_1       | 2023-01-31 07:47:19,481 [main] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: addNew group-370D3E099E21:[] returns group-370D3E099E21:java.util.concurrent.CompletableFuture@44faa4f2[Not completed]
scm_1       | 2023-01-31 07:47:19,496 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x3688343b] REGISTERED
recon_1     | 2023-01-31 07:48:45,534 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=02fede5b-9fce-4aaf-9e53-8eca883e33ad reported by 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
scm_1       | 2023-01-31 07:47:19,503 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x3688343b] BIND: 0.0.0.0/0.0.0.0:0
recon_1     | 2023-01-31 07:48:45,534 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 02fede5b-9fce-4aaf-9e53-8eca883e33ad, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1e69a4e3-5301-4460-8965-9fee5bf32e29, CreationTimestamp2023-01-31T07:48:03.559Z[UTC]] moved to OPEN state
om_1        | 2023-01-31 07:48:11,148 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
recon_1     | 2023-01-31 07:48:50,619 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)
scm_1       | 2023-01-31 07:47:19,509 [6dfb726e-350e-430b-835b-cf79da791979-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x3688343b, L:/0.0.0.0:46821] ACTIVE
om_1        | 2023-01-31 07:48:11,149 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
recon_1     | 2023-01-31 07:48:50,683 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)
scm_1       | 2023-01-31 07:47:19,525 [pool-17-thread-1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979: new RaftServerImpl for group-370D3E099E21:[] with SCMStateMachine:uninitialized
om_1        | 2023-01-31 07:48:11,210 [pool-28-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2023-01-31 07:48:11,216 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
recon_1     | 2023-01-31 07:48:55,119 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 reported by 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)
recon_1     | 2023-01-31 07:48:55,124 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: defd148e-7304-4d1b-888f-95a0187a7678, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:1e69a4e3-5301-4460-8965-9fee5bf32e29, CreationTimestamp2023-01-31T07:48:03.512Z[UTC]] moved to OPEN state
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
recon_1     | 2023-01-31 07:49:13,204 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48804
recon_1     | 2023-01-31 07:49:13,217 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-31 07:48:45,588 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2023-01-31 07:48:45,588 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2023-01-31 07:48:45,588 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-31 07:48:45,588 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
recon_1     | 2023-01-31 07:49:20,748 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60002
recon_1     | 2023-01-31 07:49:20,756 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_1  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
scm_1       | 2023-01-31 07:47:19,528 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
om_1        | 2023-01-31 07:48:11,254 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
datanode_2  | 2023-01-31 07:48:45,588 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: start as a follower, conf=-1: peers:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
recon_1     | 2023-01-31 07:49:25,157 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:56342
datanode_3  | 	... 15 more
om_1        | 2023-01-31 07:48:11,255 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2023-01-31 07:48:35,771 [Command processor thread] INFO server.RaftServer: 14b917d5-325a-4f29-a0e8-e34b223e06de: addNew group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] returns group-95A0187A7678:java.util.concurrent.CompletableFuture@623efb37[Not completed]
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 2023-01-31 07:49:25,217 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:19,528 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2023-01-31 07:48:11,293 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3  | 2023-01-31 07:48:36,335 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de: new RaftServerImpl for group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState
recon_1     | 2023-01-31 07:49:29,160 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure_datanode_2.ozonesecure_default.
scm_1       | 2023-01-31 07:47:19,529 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2023-01-31 07:48:11,314 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 2023-01-31 07:48:36,358 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-8ECA883E33AD,id=1e69a4e3-5301-4460-8965-9fee5bf32e29
recon_1     | 2023-01-31 07:49:29,494 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
scm_1       | 2023-01-31 07:47:19,529 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
om_1        | 2023-01-31 07:48:11,317 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 2023-01-31 07:48:36,368 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
recon_1     | 2023-01-31 07:49:29,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48722
scm_1       | 2023-01-31 07:47:19,529 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2023-01-31 07:48:11,620 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 2023-01-31 07:48:36,369 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
recon_1     | 2023-01-31 07:49:29,777 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:19,530 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2023-01-31 07:48:11,626 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | 2023-01-31 07:48:36,370 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2023-01-31 07:48:36,370 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
recon_1     | 2023-01-31 07:49:44,095 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:47:19,543 [pool-17-thread-1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2023-01-31 07:48:11,629 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.10:44002 remote=recon/172.18.0.3:9891]
datanode_3  | 2023-01-31 07:48:36,371 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2023-01-31 07:48:45,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,544 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om_1        | 2023-01-31 07:48:11,630 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
datanode_3  | 2023-01-31 07:48:36,488 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: ConfigurationManager, init=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_2  | 2023-01-31 07:48:45,590 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,549 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2023-01-31 07:48:11,631 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 2023-01-31 07:48:36,511 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2023-01-31 07:48:36,608 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,550 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1        | 2023-01-31 07:48:12,564 [main] INFO reflections.Reflections: Reflections took 1296 ms to scan 8 urls, producing 23 keys and 546 values [using 2 cores]
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2023-01-31 07:48:36,613 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2023-01-31 07:48:45,590 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,560 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
scm_1       | 2023-01-31 07:47:19,564 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 2023-01-31 07:48:36,741 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2023-01-31 07:48:45,641 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=02fede5b-9fce-4aaf-9e53-8eca883e33ad
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,564 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2023-01-31 07:48:12,787 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2023-01-31 07:48:36,762 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
scm_1       | 2023-01-31 07:47:19,601 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2023-01-31 07:48:12,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
datanode_2  | 2023-01-31 07:48:45,641 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=02fede5b-9fce-4aaf-9e53-8eca883e33ad.
datanode_2  | 2023-01-31 07:48:46,015 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: receive requestVote(ELECTION, ee1a73fb-90e8-4573-a632-4d493b4c1d75, group-95A0187A7678, 1, (t:0, i:0))
datanode_3  | 2023-01-31 07:48:36,786 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2023-01-31 07:48:37,173 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2023-01-31 07:47:19,602 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1        | 2023-01-31 07:48:16,211 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2023-01-31 07:48:46,016 [grpc-default-executor-0] INFO impl.VoteContext: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FOLLOWER: reject ELECTION from ee1a73fb-90e8-4573-a632-4d493b4c1d75: already has voted for 1e69a4e3-5301-4460-8965-9fee5bf32e29 at current term 1
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
datanode_2  | 2023-01-31 07:48:46,016 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678 replies to ELECTION vote request: ee1a73fb-90e8-4573-a632-4d493b4c1d75<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t1. Peer's state: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678:t1, leader=null, voted=1e69a4e3-5301-4460-8965-9fee5bf32e29, raftlog=Memoized:1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:49,976 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: receive requestVote(ELECTION, 14b917d5-325a-4f29-a0e8-e34b223e06de, group-95A0187A7678, 2, (t:0, i:0))
datanode_2  | 2023-01-31 07:48:49,977 [grpc-default-executor-0] INFO impl.VoteContext: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FOLLOWER: reject ELECTION from 14b917d5-325a-4f29-a0e8-e34b223e06de: our priority 1 > candidate's priority 0
datanode_2  | 2023-01-31 07:48:49,977 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:14b917d5-325a-4f29-a0e8-e34b223e06de
om_1        | 2023-01-31 07:48:16,258 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
recon_1     | 2023-01-31 07:49:44,099 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_2  | 2023-01-31 07:48:49,977 [grpc-default-executor-0] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
datanode_3  | 2023-01-31 07:48:37,179 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       | 2023-01-31 07:47:19,603 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om_1        | 2023-01-31 07:48:16,259 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
recon_1     | 2023-01-31 07:49:44,100 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 4 
datanode_2  | 2023-01-31 07:48:49,978 [grpc-default-executor-0] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
datanode_3  | 2023-01-31 07:48:37,199 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1       | 2023-01-31 07:47:19,603 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | 2023-01-31 07:48:16,398 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.8:9862
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
recon_1     | 2023-01-31 07:49:44,213 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
datanode_2  | 2023-01-31 07:48:49,978 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState was interrupted
datanode_2  | 2023-01-31 07:48:49,999 [grpc-default-executor-0] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678 replies to ELECTION vote request: 14b917d5-325a-4f29-a0e8-e34b223e06de<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t2. Peer's state: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678:t2, leader=null, voted=null, raftlog=Memoized:1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-31 07:47:19,604 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1        | 2023-01-31 07:48:16,404 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
datanode_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
recon_1     | 2023-01-31 07:49:44,213 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
datanode_3  | 2023-01-31 07:48:37,207 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2  | 2023-01-31 07:48:50,001 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2023-01-31 07:47:19,609 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
om_1        | 2023-01-31 07:48:16,412 [om1-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
recon_1     | 2023-01-31 07:49:44,254 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2023-01-31 07:48:37,208 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 2023-01-31 07:48:50,002 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-31 07:47:19,610 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2023-01-31 07:48:16,427 [om1-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 7@om
datanode_1  | 	... 12 more
recon_1     | 2023-01-31 07:49:44,261 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 07:49:44,595 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 07:49:44,622 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
datanode_3  | 2023-01-31 07:48:37,209 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 does not exist. Creating ...
datanode_1  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.10:44002 remote=recon/172.18.0.3:9891]
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_2  | 2023-01-31 07:48:50,593 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO impl.FollowerState: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5004573228ns, electionTimeout:5003ms
scm_1       | 2023-01-31 07:47:19,610 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm_1       | 2023-01-31 07:47:19,821 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3  | 2023-01-31 07:48:37,348 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/in_use.lock acquired by nodename 7@f206954d6d35
recon_1     | 2023-01-31 07:49:44,671 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-31 07:48:16,446 [om1-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
datanode_3  | 2023-01-31 07:48:37,417 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 has been successfully formatted.
datanode_3  | 2023-01-31 07:48:37,490 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-95A0187A7678: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
recon_1     | 2023-01-31 07:49:46,631 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
om_1        | 2023-01-31 07:48:16,457 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2023-01-31 07:48:50,594 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState
scm_1       | 2023-01-31 07:47:20,017 [main] INFO reflections.Reflections: Reflections took 130 ms to scan 3 urls, producing 124 keys and 279 values 
scm_1       | 2023-01-31 07:47:20,162 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
recon_1     | 2023-01-31 07:49:46,632 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
om_1        | 2023-01-31 07:48:16,490 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2023-01-31 07:48:50,594 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2023-01-31 07:48:50,594 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2023-01-31 07:48:50,595 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
om_1        | 2023-01-31 07:48:16,492 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-31 07:47:20,162 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
scm_1       | 2023-01-31 07:47:20,167 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1       | 2023-01-31 07:47:20,170 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
recon_1     | 2023-01-31 07:49:46,645 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
om_1        | 2023-01-31 07:48:16,499 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1        | 2023-01-31 07:48:16,510 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | 2023-01-31 07:48:16,523 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2023-01-31 07:48:16,538 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2023-01-31 07:48:37,502 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2023-01-31 07:48:37,585 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2023-01-31 07:48:50,607 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:50,608 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
om_1        | 2023-01-31 07:48:16,539 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2023-01-31 07:48:37,601 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:49:46,645 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2023-01-31 07:49:46,713 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 78 milliseconds to process 0 existing database records.
scm_1       | 2023-01-31 07:47:20,260 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
om_1        | 2023-01-31 07:48:16,566 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
recon_1     | 2023-01-31 07:49:46,764 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 51 milliseconds for processing 1 containers.
datanode_2  | 2023-01-31 07:48:50,608 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2
datanode_3  | 2023-01-31 07:48:37,602 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1       | 2023-01-31 07:47:20,260 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
om_1        | 2023-01-31 07:48:16,567 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2023-01-31 07:48:16,568 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
datanode_2  | 2023-01-31 07:48:50,608 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_3  | 2023-01-31 07:48:37,610 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm_1       | 2023-01-31 07:47:20,261 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
recon_1     | 2023-01-31 07:49:46,771 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
om_1        | 2023-01-31 07:48:16,573 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2023-01-31 07:48:16,575 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
datanode_3  | 2023-01-31 07:48:37,622 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 2023-01-31 07:47:20,267 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
recon_1     | 2023-01-31 07:49:46,779 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 125 milliseconds.
om_1        | 2023-01-31 07:48:16,577 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2023-01-31 07:48:16,579 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2023-01-31 07:48:37,708 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 2023-01-31 07:47:20,284 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
recon_1     | 2023-01-31 07:49:59,137 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:54204
om_1        | 2023-01-31 07:48:16,579 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2023-01-31 07:48:50,608 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-8ECA883E33AD with new leaderId: 1e69a4e3-5301-4460-8965-9fee5bf32e29
scm_1       | 2023-01-31 07:47:20,289 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
datanode_1  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
recon_1     | 2023-01-31 07:49:59,154 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:48:16,581 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2023-01-31 07:48:50,609 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: change Leader from null to 1e69a4e3-5301-4460-8965-9fee5bf32e29 at term 1 for becomeLeader, leader elected after 5175ms
scm_1       | 2023-01-31 07:47:20,303 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
recon_1     | 2023-01-31 07:49:59,770 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:36218
recon_1     | 2023-01-31 07:49:59,783 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38668
om_1        | 2023-01-31 07:48:16,628 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
datanode_3  | 2023-01-31 07:48:37,719 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2023-01-31 07:48:50,661 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2023-01-31 07:47:20,355 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
scm_1       | 2023-01-31 07:47:20,355 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 2023-01-31 07:48:37,779 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678
datanode_3  | 2023-01-31 07:48:37,780 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2023-01-31 07:48:50,694 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2023-01-31 07:48:50,697 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
scm_1       | 2023-01-31 07:47:20,364 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
datanode_3  | 2023-01-31 07:48:37,783 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
datanode_1  | 	... 15 more
datanode_3  | 2023-01-31 07:48:37,801 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2023-01-31 07:48:37,804 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_3  | 2023-01-31 07:48:37,805 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2023-01-31 07:48:16,629 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:49:59,789 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:37,806 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
scm_1       | 2023-01-31 07:47:20,365 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
datanode_2  | 2023-01-31 07:48:50,729 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
om_1        | 2023-01-31 07:48:16,661 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om_1        | 2023-01-31 07:48:16,663 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  | 2023-01-31 07:48:37,807 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2023-01-31 07:47:20,371 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1       | 2023-01-31 07:47:20,374 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
om_1        | 2023-01-31 07:48:16,665 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1        | 2023-01-31 07:48:16,732 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1     | 2023-01-31 07:49:59,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:37,825 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2023-01-31 07:48:16,749 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2023-01-31 07:48:16,776 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:50:29,152 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:59656
datanode_3  | 2023-01-31 07:48:37,877 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
om_1        | 2023-01-31 07:48:16,780 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2023-01-31 07:47:20,393 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
scm_1       | 2023-01-31 07:47:20,393 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
datanode_3  | 2023-01-31 07:48:37,899 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-31 07:48:50,735 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2023-01-31 07:48:35,994 [Command processor thread] INFO server.RaftServer: ee1a73fb-90e8-4573-a632-4d493b4c1d75: addNew group-AA485FE71506:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER] returns group-AA485FE71506:java.util.concurrent.CompletableFuture@22f5c3cc[Not completed]
datanode_1  | 2023-01-31 07:48:36,304 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75: new RaftServerImpl for group-AA485FE71506:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_3  | 2023-01-31 07:48:37,983 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-31 07:47:20,471 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
datanode_1  | 2023-01-31 07:48:36,324 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2023-01-31 07:48:36,338 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 2023-01-31 07:50:29,158 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:50:29,748 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:58774
datanode_3  | 2023-01-31 07:48:38,006 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_1  | 2023-01-31 07:48:36,340 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2023-01-31 07:48:36,341 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2023-01-31 07:48:36,341 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2023-01-31 07:48:36,343 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2023-01-31 07:48:36,476 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: ConfigurationManager, init=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2023-01-31 07:48:36,487 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2023-01-31 07:48:36,571 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2023-01-31 07:48:36,580 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2023-01-31 07:48:36,660 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2023-01-31 07:48:36,714 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2023-01-31 07:48:16,795 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
datanode_2  | 2023-01-31 07:48:50,748 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2023-01-31 07:48:36,715 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1       | 2023-01-31 07:47:20,496 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
scm_1       | 2023-01-31 07:47:20,631 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
om_1        | 2023-01-31 07:48:16,801 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-31 07:48:16,808 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-31 07:48:50,804 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2023-01-31 07:48:50,816 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm_1       | 2023-01-31 07:47:20,660 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1       | 2023-01-31 07:47:20,664 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:48:16,830 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1        | 2023-01-31 07:48:16,847 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2023-01-31 07:48:50,837 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderStateImpl
datanode_1  | 2023-01-31 07:48:36,996 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2023-01-31 07:47:20,695 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1       | 2023-01-31 07:47:20,703 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 07:50:29,754 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:48296
om_1        | 2023-01-31 07:48:16,850 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1        | 2023-01-31 07:48:16,851 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
datanode_2  | 2023-01-31 07:48:50,918 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2023-01-31 07:48:37,010 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       | 2023-01-31 07:47:20,706 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
scm_1       | 2023-01-31 07:47:20,778 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om_1        | 2023-01-31 07:48:16,852 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
om_1        | 2023-01-31 07:48:16,883 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
datanode_2  | 2023-01-31 07:48:51,001 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-LeaderElection2] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD: set configuration 0: peers:[1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:51,219 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-8ECA883E33AD-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/02fede5b-9fce-4aaf-9e53-8eca883e33ad/current/log_inprogress_0
datanode_1  | 2023-01-31 07:48:37,010 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
recon_1     | 2023-01-31 07:50:29,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:38,008 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2023-01-31 07:48:55,034 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5056053882ns, electionTimeout:5031ms
datanode_2  | 2023-01-31 07:48:55,034 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState
datanode_1  | 2023-01-31 07:48:37,017 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
recon_1     | 2023-01-31 07:50:29,768 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:48:16,922 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
datanode_3  | 2023-01-31 07:48:38,064 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-31 07:48:55,035 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
scm_1       | 2023-01-31 07:47:20,787 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
datanode_1  | 2023-01-31 07:48:37,018 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2023-01-31 07:48:37,025 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/409651ee-63d0-4368-a01a-aa485fe71506 does not exist. Creating ...
om_1        | 2023-01-31 07:48:16,942 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1        | 2023-01-31 07:48:16,943 [Listener at om/9862] INFO om.OzoneManager: Starting OM block token secret manager
scm_1       | 2023-01-31 07:47:20,795 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 464075175071 on primary SCM
datanode_1  | 2023-01-31 07:48:37,067 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/409651ee-63d0-4368-a01a-aa485fe71506/in_use.lock acquired by nodename 7@6b0ee5ff6668
datanode_1  | 2023-01-31 07:48:37,113 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/409651ee-63d0-4368-a01a-aa485fe71506 has been successfully formatted.
om_1        | 2023-01-31 07:48:16,946 [Listener at om/9862] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 495064171534
om_1        | 2023-01-31 07:48:16,949 [Listener at om/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
scm_1       | 2023-01-31 07:47:20,811 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
scm_1       | 2023-01-31 07:47:20,882 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2023-01-31 07:48:38,079 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2023-01-31 07:48:16,949 [Listener at om/9862] INFO security.OzoneDelegationTokenSecretManager: Updating current master key for generating tokens. Cert id 495064171534
datanode_2  | 2023-01-31 07:48:55,035 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2023-01-31 07:48:38,087 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: start as a follower, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:50:44,681 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 07:50:44,681 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:48:16,960 [Listener at om/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
om_1        | 2023-01-31 07:48:16,973 [Thread[Thread-16,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
datanode_3  | 2023-01-31 07:48:38,088 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from      null to FOLLOWER at term 0 for startAsFollower
recon_1     | 2023-01-31 07:50:44,681 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 17 
recon_1     | 2023-01-31 07:50:44,745 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 07:48:17,142 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2023-01-31 07:48:17,142 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2023-01-31 07:48:38,101 [pool-24-thread-1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:50:44,745 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
recon_1     | 2023-01-31 07:50:44,766 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:47:20,943 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1       | 2023-01-31 07:47:21,883 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
datanode_3  | 2023-01-31 07:48:38,110 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-31 07:48:38,113 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:38,124 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-95A0187A7678,id=14b917d5-325a-4f29-a0e8-e34b223e06de
datanode_3  | 2023-01-31 07:48:38,129 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2023-01-31 07:48:38,131 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2023-01-31 07:48:38,132 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2023-01-31 07:48:55,035 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3
datanode_2  | 2023-01-31 07:48:55,045 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3 ELECTION round 0: submit vote requests at term 3 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:55,060 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-31 07:48:38,133 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2023-01-31 07:48:38,203 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=defd148e-7304-4d1b-888f-95a0187a7678
datanode_3  | 2023-01-31 07:48:38,422 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_3  | 2023-01-31 07:48:40,166 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-14b917d5-325a-4f29-a0e8-e34b223e06de: Detected pause in JVM or host machine (eg GC): pause of approximately 130357235ns.
scm_1       | 2023-01-31 07:47:21,893 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       | 2023-01-31 07:47:21,894 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
scm_1       | 2023-01-31 07:47:21,952 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2023-01-31 07:47:21,961 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2023-01-31 07:50:44,767 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 07:50:45,032 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=128ms
datanode_2  | 2023-01-31 07:48:55,061 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-31 07:50:45,033 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2023-01-31 07:50:45,046 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2023-01-31 07:48:43,050 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_2  | 2023-01-31 07:48:55,070 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3: ELECTION PASSED received 1 response(s) and 0 exception(s):
recon_1     | 2023-01-31 07:50:59,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:52948
scm_1       | 2023-01-31 07:47:21,964 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
scm_1       | 2023-01-31 07:47:22,012 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
datanode_2  | 2023-01-31 07:48:55,070 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.LeaderElection:   Response 0: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:OK-t3
om_1        | 2023-01-31 07:48:17,142 [Listener at om/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
recon_1     | 2023-01-31 07:50:59,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:50:59,763 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33512
datanode_2  | 2023-01-31 07:48:55,071 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.LeaderElection: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3 ELECTION round 0: result PASSED
datanode_3  | 2023-01-31 07:48:43,175 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5079272926ns, electionTimeout:5050ms
recon_1     | 2023-01-31 07:50:59,782 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:50:59,802 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:51832
scm_1       | 2023-01-31 07:47:22,100 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_2  | 2023-01-31 07:48:55,071 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: shutdown 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3
om_1        | 2023-01-31 07:48:17,225 [Listener at om/9862] INFO util.log: Logging initialized @38920ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2023-01-31 07:48:43,186 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:50:59,810 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:51:29,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36410
scm_1       | 2023-01-31 07:47:22,102 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
datanode_2  | 2023-01-31 07:48:55,071 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
om_1        | 2023-01-31 07:48:17,893 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
om_1        | 2023-01-31 07:48:17,942 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
scm_1       | 2023-01-31 07:47:22,300 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
recon_1     | 2023-01-31 07:51:29,130 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:48:17,957 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
om_1        | 2023-01-31 07:48:17,962 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2023-01-31 07:48:37,257 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-AA485FE71506: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2023-01-31 07:48:37,259 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2023-01-31 07:47:22,308 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
om_1        | 2023-01-31 07:48:17,963 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | 2023-01-31 07:48:17,969 [Listener at om/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
datanode_1  | 2023-01-31 07:48:37,389 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2023-01-31 07:48:37,389 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | Container Balancer status:
om_1        | 2023-01-31 07:48:18,139 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
om_1        | 2023-01-31 07:48:18,141 [Listener at om/9862] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_1  | 2023-01-31 07:48:37,404 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1  | 2023-01-31 07:48:37,405 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm_1       | Key                            Value
om_1        | 2023-01-31 07:48:18,361 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2023-01-31 07:48:18,364 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
datanode_1  | 2023-01-31 07:48:37,408 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2023-01-31 07:48:37,480 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | Running                        true
datanode_3  | 2023-01-31 07:48:43,190 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2023-01-31 07:48:55,071 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-95A0187A7678 with new leaderId: 1e69a4e3-5301-4460-8965-9fee5bf32e29
scm_1       | Container Balancer Configuration values:
datanode_3  | 2023-01-31 07:48:43,202 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2023-01-31 07:48:18,369 [Listener at om/9862] INFO server.session: node0 Scavenging every 600000ms
om_1        | 2023-01-31 07:48:18,478 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/om.keytab, for principal HTTP/om@EXAMPLE.COM
scm_1       | Key                                                Value
recon_1     | 2023-01-31 07:51:29,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36450
om_1        | 2023-01-31 07:48:18,504 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69d021c1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_2  | 2023-01-31 07:48:55,072 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: change Leader from null to 1e69a4e3-5301-4460-8965-9fee5bf32e29 at term 3 for becomeLeader, leader elected after 19631ms
scm_1       | Threshold                                          10
datanode_1  | 2023-01-31 07:48:37,480 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2023-01-31 07:48:37,546 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/409651ee-63d0-4368-a01a-aa485fe71506
datanode_1  | 2023-01-31 07:48:37,547 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
scm_1       | Max Datanodes to Involve per Iteration(percent)    20
datanode_3  | 2023-01-31 07:48:43,203 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1
recon_1     | 2023-01-31 07:51:29,769 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:51:29,776 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:55794
datanode_2  | 2023-01-31 07:48:55,072 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_2  | 2023-01-31 07:48:55,073 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
scm_1       | Max Size to Move per Iteration                     500GB
datanode_1  | 2023-01-31 07:48:37,560 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:51:29,778 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-31 07:48:55,074 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
om_1        | 2023-01-31 07:48:18,518 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@731ab49b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2023-01-31 07:48:37,561 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | Max Size Entering Target per Iteration             26GB
datanode_2  | 2023-01-31 07:48:55,075 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2023-01-31 07:48:43,265 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:43,463 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-31 07:48:18,975 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/om.keytab, for principal HTTP/om@EXAMPLE.COM
datanode_1  | 2023-01-31 07:48:37,561 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | Max Size Leaving Source per Iteration              26GB
datanode_2  | 2023-01-31 07:48:55,077 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2023-01-31 07:48:43,463 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-31 07:51:45,086 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2023-01-31 07:48:19,018 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@3cc74fc4{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_4_0-SNAPSHOT_jar-_-any-5922034157814226906/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar!/webapps/ozoneManager}
datanode_1  | 2023-01-31 07:48:37,561 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2023-01-31 07:48:37,562 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2023-01-31 07:48:55,078 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2023-01-31 07:48:43,506 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for ee1a73fb-90e8-4573-a632-4d493b4c1d75
recon_1     | 2023-01-31 07:51:45,086 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:48:19,060 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@6d7556a8{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
datanode_1  | 2023-01-31 07:48:37,580 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 
datanode_2  | 2023-01-31 07:48:55,078 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2023-01-31 07:48:43,548 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 1e69a4e3-5301-4460-8965-9fee5bf32e29
recon_1     | 2023-01-31 07:51:45,086 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 36 
om_1        | 2023-01-31 07:48:19,064 [Listener at om/9862] INFO server.Server: Started @40756ms
datanode_1  | 2023-01-31 07:48:37,581 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2023-01-31 07:47:22,309 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
datanode_2  | 2023-01-31 07:48:55,078 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | 2023-01-31 07:48:44,114 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: receive requestVote(ELECTION, 1e69a4e3-5301-4460-8965-9fee5bf32e29, group-95A0187A7678, 1, (t:0, i:0))
recon_1     | 2023-01-31 07:51:45,187 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 10, SequenceNumber diff: 23, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 07:48:19,081 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_1  | 2023-01-31 07:48:37,638 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1       | 2023-01-31 07:47:22,325 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
datanode_2  | 2023-01-31 07:48:55,195 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_3  | 2023-01-31 07:48:44,116 [grpc-default-executor-1] INFO impl.VoteContext: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-CANDIDATE: reject ELECTION from 1e69a4e3-5301-4460-8965-9fee5bf32e29: already has voted for 14b917d5-325a-4f29-a0e8-e34b223e06de at current term 1
recon_1     | 2023-01-31 07:51:45,187 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 23 records
om_1        | 2023-01-31 07:48:19,082 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_1  | 2023-01-31 07:48:37,639 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-31 07:47:22,344 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
datanode_2  | 2023-01-31 07:48:55,195 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-31 07:48:44,178 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678 replies to ELECTION vote request: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-14b917d5-325a-4f29-a0e8-e34b223e06de#0:FAIL-t1. Peer's state: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678:t1, leader=null, voted=14b917d5-325a-4f29-a0e8-e34b223e06de, raftlog=Memoized:14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:44,704 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
recon_1     | 2023-01-31 07:51:45,191 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2023-01-31 07:48:19,084 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
datanode_1  | 2023-01-31 07:48:37,715 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-31 07:47:22,366 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/in_use.lock acquired by nodename 7@scm
datanode_2  | 2023-01-31 07:48:55,196 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_3  | 2023-01-31 07:48:44,705 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection:   Response 0: 14b917d5-325a-4f29-a0e8-e34b223e06de<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t1
recon_1     | 2023-01-31 07:51:45,191 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 2023-01-31 07:48:19,094 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_1  | 2023-01-31 07:48:37,716 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-31 07:47:22,377 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=6dfb726e-350e-430b-835b-cf79da791979} from /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/raft-meta
datanode_2  | 2023-01-31 07:48:55,205 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_3  | 2023-01-31 07:48:44,706 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1 ELECTION round 0: result REJECTED
recon_1     | 2023-01-31 07:51:45,416 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-31 07:48:19,121 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
datanode_1  | 2023-01-31 07:48:37,733 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2023-01-31 07:47:22,430 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: set configuration 0: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-31 07:48:55,206 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_3  | 2023-01-31 07:48:44,709 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
recon_1     | 2023-01-31 07:51:45,416 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 2023-01-31 07:48:19,426 [Listener at om/9862] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
datanode_1  | 2023-01-31 07:48:37,788 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-31 07:47:22,433 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2023-01-31 07:48:55,206 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2023-01-31 07:48:44,714 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1
datanode_3  | 2023-01-31 07:48:44,714 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
om_1        | 2023-01-31 07:48:19,436 [Listener at om/9862] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
datanode_1  | 2023-01-31 07:48:37,788 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-31 07:47:22,456 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2023-01-31 07:48:55,207 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
recon_1     | 2023-01-31 07:51:45,416 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2023-01-31 07:48:44,740 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-31 07:48:19,653 [Listener at om/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
om_1        | 2023-01-31 07:48:19,682 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5981f2c6] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2023-01-31 07:47:22,456 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-31 07:48:55,207 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
recon_1     | 2023-01-31 07:51:59,134 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34028
datanode_3  | 2023-01-31 07:48:44,743 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 2023-01-31 07:48:21,949 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5151219623ns, electionTimeout:5128ms
datanode_1  | 2023-01-31 07:48:37,802 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: start as a follower, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-31 07:47:22,461 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
recon_1     | 2023-01-31 07:51:59,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:45,359 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678.
om_1        | 2023-01-31 07:48:21,964 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1        | 2023-01-31 07:48:21,967 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2023-01-31 07:47:22,462 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_2  | 2023-01-31 07:48:55,215 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
recon_1     | 2023-01-31 07:51:59,727 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49220
datanode_3  | 2023-01-31 07:48:45,361 [Command processor thread] INFO server.RaftServer: 14b917d5-325a-4f29-a0e8-e34b223e06de: addNew group-9C2467A4D4E7:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER] returns group-9C2467A4D4E7:java.util.concurrent.CompletableFuture@2376afb5[Not completed]
om_1        | 2023-01-31 07:48:21,972 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2023-01-31 07:48:37,803 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2023-01-31 07:47:22,468 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode_2  | 2023-01-31 07:48:55,215 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:51:59,739 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:45,365 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de: new RaftServerImpl for group-9C2467A4D4E7:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
om_1        | 2023-01-31 07:48:21,974 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
datanode_1  | 2023-01-31 07:48:37,821 [pool-24-thread-1] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState
scm_1       | 2023-01-31 07:47:22,477 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2023-01-31 07:48:55,216 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
recon_1     | 2023-01-31 07:51:59,742 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:33324
datanode_3  | 2023-01-31 07:48:45,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2023-01-31 07:48:21,981 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-31 07:48:37,824 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2023-01-31 07:47:22,478 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2023-01-31 07:48:55,218 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
recon_1     | 2023-01-31 07:51:59,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:45,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2023-01-31 07:48:21,984 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2023-01-31 07:48:37,824 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-31 07:47:22,484 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21
datanode_2  | 2023-01-31 07:48:55,218 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
recon_1     | 2023-01-31 07:52:29,130 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33552
datanode_3  | 2023-01-31 07:48:45,372 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2023-01-31 07:48:21,985 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
datanode_1  | 2023-01-31 07:48:37,848 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AA485FE71506,id=ee1a73fb-90e8-4573-a632-4d493b4c1d75
scm_1       | 2023-01-31 07:47:22,484 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode_2  | 2023-01-31 07:48:55,219 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 2023-01-31 07:52:29,162 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:45,373 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
om_1        | 2023-01-31 07:48:21,988 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2023-01-31 07:48:37,850 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2023-01-31 07:47:22,485 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
scm_1       | 2023-01-31 07:47:22,486 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode_2  | 2023-01-31 07:48:55,219 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 2023-01-31 07:48:55,219 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_2  | 2023-01-31 07:48:55,221 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO impl.RoleInfo: 1e69a4e3-5301-4460-8965-9fee5bf32e29: start 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderStateImpl
om_1        | 2023-01-31 07:48:21,989 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 10695ms
datanode_1  | 2023-01-31 07:48:37,851 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2023-01-31 07:48:55,222 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2023-01-31 07:48:55,224 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/current/log_inprogress_0
datanode_2  | 2023-01-31 07:48:55,234 [1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678-LeaderElection3] INFO server.RaftServer$Division: 1e69a4e3-5301-4460-8965-9fee5bf32e29@group-95A0187A7678: set configuration 0: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-31 07:48:22,074 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2023-01-31 07:48:37,851 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_2  | 2023-01-31 07:49:28,657 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:495064171534.
recon_1     | 2023-01-31 07:52:29,796 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49024
om_1        | 2023-01-31 07:48:22,098 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
om_1        | 2023-01-31 07:48:22,101 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
datanode_1  | 2023-01-31 07:48:37,852 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2023-01-31 07:47:22,486 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
recon_1     | 2023-01-31 07:52:29,804 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44594
recon_1     | 2023-01-31 07:52:29,807 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:38,033 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=409651ee-63d0-4368-a01a-aa485fe71506
scm_1       | 2023-01-31 07:47:22,486 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
scm_1       | 2023-01-31 07:47:22,487 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
recon_1     | 2023-01-31 07:52:29,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:48:22,118 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
datanode_1  | 2023-01-31 07:48:38,042 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=409651ee-63d0-4368-a01a-aa485fe71506.
scm_1       | 2023-01-31 07:47:22,487 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2023-01-31 07:48:45,373 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-31 07:48:45,373 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2023-01-31 07:48:22,118 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
scm_1       | 2023-01-31 07:47:22,488 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2023-01-31 07:52:45,439 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2023-01-31 07:48:45,373 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: ConfigurationManager, init=-1: peers:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2023-01-31 07:48:38,042 [Command processor thread] INFO server.RaftServer: ee1a73fb-90e8-4573-a632-4d493b4c1d75: addNew group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] returns group-95A0187A7678:java.util.concurrent.CompletableFuture@fcda6ca[Not completed]
recon_1     | 2023-01-31 07:52:45,439 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 07:52:45,440 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 59 
datanode_1  | 2023-01-31 07:48:38,076 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75: new RaftServerImpl for group-95A0187A7678:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_3  | 2023-01-31 07:48:45,373 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2023-01-31 07:47:22,504 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode_1  | 2023-01-31 07:48:38,076 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2023-01-31 07:48:22,119 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 2023-01-31 07:52:45,489 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
datanode_3  | 2023-01-31 07:48:45,374 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
scm_1       | 2023-01-31 07:47:22,505 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-31 07:48:38,077 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_1  | 2023-01-31 07:48:38,077 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2023-01-31 07:48:22,144 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
recon_1     | 2023-01-31 07:52:45,489 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
datanode_3  | 2023-01-31 07:48:45,374 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2023-01-31 07:48:38,077 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
scm_1       | 2023-01-31 07:47:22,714 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om_1        | 2023-01-31 07:48:22,149 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
recon_1     | 2023-01-31 07:52:45,509 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2023-01-31 07:48:45,375 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2023-01-31 07:48:38,082 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2023-01-31 07:47:22,715 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
om_1        | 2023-01-31 07:48:22,157 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
recon_1     | 2023-01-31 07:52:45,510 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_3  | 2023-01-31 07:48:45,375 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_1  | 2023-01-31 07:48:38,082 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_1  | 2023-01-31 07:48:38,083 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: ConfigurationManager, init=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2023-01-31 07:48:22,283 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2023-01-31 07:48:45,375 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2023-01-31 07:48:38,083 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | 2023-01-31 07:47:22,716 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
om_1        | 2023-01-31 07:48:22,447 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:om:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:45,376 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2023-01-31 07:48:38,083 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2023-01-31 07:48:22,574 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
scm_1       | 2023-01-31 07:47:22,744 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: set configuration 0: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:52:45,836 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | 2023-01-31 07:48:45,381 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1        | 2023-01-31 07:48:22,810 [om1@group-C5BA1605619E-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
datanode_1  | 2023-01-31 07:48:38,083 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
recon_1     | 2023-01-31 07:52:45,839 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
scm_1       | 2023-01-31 07:47:22,746 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/log_inprogress_0
om_1        | [id: "om1"
datanode_1  | 2023-01-31 07:48:38,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
recon_1     | 2023-01-31 07:52:45,855 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 07:52:59,085 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49776
recon_1     | 2023-01-31 07:52:59,088 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | address: "om:9872"
scm_1       | 2023-01-31 07:47:22,748 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
datanode_3  | 2023-01-31 07:48:45,381 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
recon_1     | 2023-01-31 07:52:59,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41706
datanode_1  | 2023-01-31 07:48:38,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | startupRole: FOLLOWER
scm_1       | 2023-01-31 07:47:22,748 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2023-01-31 07:48:45,381 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
recon_1     | 2023-01-31 07:52:59,754 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:38,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | ]
scm_1       | 2023-01-31 07:47:22,851 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: start as a follower, conf=0: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:45,382 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
recon_1     | 2023-01-31 07:52:59,755 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:40896
recon_1     | 2023-01-31 07:52:59,760 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:48:35,551 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:36929
scm_1       | 2023-01-31 07:47:22,852 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm_1       | 2023-01-31 07:47:22,854 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState
datanode_1  | 2023-01-31 07:48:38,095 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
recon_1     | 2023-01-31 07:53:29,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49834
scm_1       | 2023-01-31 07:47:22,855 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-31 07:48:45,383 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/7eb7c323-0301-4528-bfd5-9c2467a4d4e7 does not exist. Creating ...
om_1        | 2023-01-31 07:48:35,642 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:38,100 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
recon_1     | 2023-01-31 07:53:29,101 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:22,855 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:45,388 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/7eb7c323-0301-4528-bfd5-9c2467a4d4e7/in_use.lock acquired by nodename 7@f206954d6d35
om_1        | 2023-01-31 07:48:36,524 [OMRangerBGSyncService#0] INFO service.OMRangerBGSyncService: Executing Multi-Tenancy Ranger Sync: run # 1, attempt # 1. Ranger service version: 0, DB service version: -1
datanode_1  | 2023-01-31 07:48:38,100 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
recon_1     | 2023-01-31 07:53:29,763 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38754
scm_1       | 2023-01-31 07:47:22,856 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-370D3E099E21,id=6dfb726e-350e-430b-835b-cf79da791979
datanode_3  | 2023-01-31 07:48:45,391 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/7eb7c323-0301-4528-bfd5-9c2467a4d4e7 has been successfully formatted.
om_1        | 2023-01-31 07:48:36,546 [OMRangerBGSyncService#0] INFO service.OMRangerBGSyncService: No Ranger policy with label OzoneTenant received.
datanode_1  | 2023-01-31 07:48:38,100 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
recon_1     | 2023-01-31 07:53:29,784 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:22,859 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2023-01-31 07:48:45,394 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-9C2467A4D4E7: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
om_1        | 2023-01-31 07:48:40,646 [qtp470092156-54] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
datanode_1  | 2023-01-31 07:48:38,100 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2023-01-31 07:48:38,100 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 does not exist. Creating ...
scm_1       | 2023-01-31 07:47:22,859 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
datanode_3  | 2023-01-31 07:48:45,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2023-01-31 07:48:40,707 [qtp470092156-54] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1675151320647 in 57 milliseconds
datanode_1  | 2023-01-31 07:48:38,106 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/in_use.lock acquired by nodename 7@6b0ee5ff6668
recon_1     | 2023-01-31 07:53:29,801 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:56108
scm_1       | 2023-01-31 07:47:22,860 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
datanode_3  | 2023-01-31 07:48:45,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2023-01-31 07:48:40,838 [qtp470092156-54] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 122 milliseconds
scm_1       | 2023-01-31 07:47:22,864 [6dfb726e-350e-430b-835b-cf79da791979-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2023-01-31 07:48:45,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-31 07:48:38,113 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678 has been successfully formatted.
datanode_1  | 2023-01-31 07:48:38,114 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-95A0187A7678: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2023-01-31 07:48:38,114 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
scm_1       | 2023-01-31 07:47:22,881 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 6dfb726e-350e-430b-835b-cf79da791979: start RPC server
datanode_3  | 2023-01-31 07:48:45,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1  | 2023-01-31 07:48:38,118 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2023-01-31 07:48:40,841 [qtp470092156-54] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1675151320647
om_1        | 2023-01-31 07:49:23,739 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39723
scm_1       | 2023-01-31 07:47:22,894 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 6dfb726e-350e-430b-835b-cf79da791979: GrpcService started, listening on 9894
datanode_3  | 2023-01-31 07:48:45,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_1  | 2023-01-31 07:48:38,118 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-31 07:49:23,768 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:49:24,696 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
scm_1       | 2023-01-31 07:47:22,895 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-6dfb726e-350e-430b-835b-cf79da791979: Started
datanode_3  | 2023-01-31 07:48:45,415 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2023-01-31 07:48:38,118 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
recon_1     | 2023-01-31 07:53:29,808 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:53:45,869 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:47:22,905 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm_1       | 2023-01-31 07:47:22,905 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
datanode_1  | 2023-01-31 07:48:38,119 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
recon_1     | 2023-01-31 07:53:45,869 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 07:53:45,870 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 78 
recon_1     | 2023-01-31 07:53:45,959 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4, SequenceNumber diff: 9, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:47:22,931 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
datanode_1  | 2023-01-31 07:48:38,119 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 2023-01-31 07:49:24,788 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
om_1        | 2023-01-31 07:49:38,159 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42481
recon_1     | 2023-01-31 07:53:45,959 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 9 records
scm_1       | 2023-01-31 07:47:22,931 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 464075175071
datanode_1  | 2023-01-31 07:48:38,121 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678
recon_1     | 2023-01-31 07:53:45,967 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:47:23,046 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
om_1        | 2023-01-31 07:49:38,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:49:44,131 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:43625
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
recon_1     | 2023-01-31 07:53:45,968 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 2023-01-31 07:49:44,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:50:08,817 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43381
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:53:46,201 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-31 07:47:23,064 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2023-01-31 07:50:08,843 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:45,415 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
recon_1     | 2023-01-31 07:53:46,203 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
scm_1       | 2023-01-31 07:47:23,064 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om_1        | 2023-01-31 07:50:09,767 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:60337-source for user:testuser
om_1        | 2023-01-31 07:50:16,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39263
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 2023-01-31 07:53:46,248 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-31 07:50:16,465 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:50:17,371 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:60337-target for user:testuser
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
recon_1     | 2023-01-31 07:53:59,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:35944
om_1        | 2023-01-31 07:50:23,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36349
datanode_3  | 2023-01-31 07:48:45,430 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1     | 2023-01-31 07:53:59,130 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:50:23,163 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/7eb7c323-0301-4528-bfd5-9c2467a4d4e7
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
recon_1     | 2023-01-31 07:53:59,717 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49540
om_1        | 2023-01-31 07:50:24,106 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 60337-source
om_1        | 2023-01-31 07:50:30,682 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41119
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1     | 2023-01-31 07:53:59,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44646
scm_1       | 2023-01-31 07:47:23,473 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
om_1        | 2023-01-31 07:50:30,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
recon_1     | 2023-01-31 07:53:59,760 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:23,473 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2023-01-31 07:50:42,256 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43029
om_1        | 2023-01-31 07:50:42,286 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:38,123 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2023-01-31 07:53:59,765 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:50:43,311 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 60337-source
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2023-01-31 07:48:38,128 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
recon_1     | 2023-01-31 07:54:29,138 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36170
scm_1       | 2023-01-31 07:47:23,474 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
om_1        | 2023-01-31 07:50:44,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:43447
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2023-01-31 07:48:38,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:54:29,173 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:23,505 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
om_1        | 2023-01-31 07:50:44,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
recon_1     | 2023-01-31 07:54:29,736 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42252
scm_1       | 2023-01-31 07:47:23,506 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
om_1        | 2023-01-31 07:50:49,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35573
om_1        | 2023-01-31 07:50:49,700 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:54:29,749 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:56826
scm_1       | 2023-01-31 07:47:23,507 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2023-01-31 07:48:39,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
recon_1     | 2023-01-31 07:54:29,767 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:45,431 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2023-01-31 07:48:45,432 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_1  | 2023-01-31 07:48:39,149 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
recon_1     | 2023-01-31 07:54:29,778 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:23,507 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
datanode_3  | 2023-01-31 07:48:45,476 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_3  | 2023-01-31 07:48:45,477 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-31 07:54:46,265 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:47:23,586 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
datanode_3  | 2023-01-31 07:48:45,552 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3  | 2023-01-31 07:48:45,552 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_1  | 2023-01-31 07:48:39,149 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
recon_1     | 2023-01-31 07:54:46,266 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2023-01-31 07:48:45,552 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_3  | 2023-01-31 07:48:45,556 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2023-01-31 07:48:39,150 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
recon_1     | 2023-01-31 07:54:46,267 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 87 
scm_1       | 2023-01-31 07:47:23,588 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2023-01-31 07:48:45,556 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_3  | 2023-01-31 07:48:45,556 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: start as a follower, conf=-1: peers:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:54:46,329 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:47:23,588 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
datanode_3  | 2023-01-31 07:48:45,556 [pool-24-thread-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2023-01-31 07:50:50,690 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 60337-target
datanode_1  | 2023-01-31 07:48:39,150 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-31 07:47:23,589 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
datanode_1  | 2023-01-31 07:48:39,149 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-ee1a73fb-90e8-4573-a632-4d493b4c1d75: Detected pause in JVM or host machine (eg GC): pause of approximately 513965890ns.
datanode_3  | 2023-01-31 07:48:45,557 [pool-24-thread-1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState
datanode_3  | 2023-01-31 07:48:45,558 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-9C2467A4D4E7,id=14b917d5-325a-4f29-a0e8-e34b223e06de
scm_1       | 2023-01-31 07:47:24,278 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@65f1bf2c] INFO util.JvmPauseMonitor: Starting JVM pause monitor
recon_1     | 2023-01-31 07:54:46,329 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
om_1        | 2023-01-31 07:50:56,435 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34669
scm_1       | 2023-01-31 07:47:24,462 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
recon_1     | 2023-01-31 07:54:46,337 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 07:54:46,337 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_1  | GC pool 'ParNew' had collection(s): count=1 time=101ms
om_1        | 2023-01-31 07:50:56,473 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:24,467 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1       | 2023-01-31 07:47:24,481 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
scm_1       | 2023-01-31 07:47:24,564 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42122
datanode_1  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=855ms
datanode_1  | 2023-01-31 07:48:39,192 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: start as a follower, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:45,558 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2023-01-31 07:48:45,559 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2023-01-31 07:47:24,565 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33037
om_1        | 2023-01-31 07:50:57,434 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 60337-target
om_1        | 2023-01-31 07:51:03,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45369
recon_1     | 2023-01-31 07:54:46,612 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | 2023-01-31 07:48:45,559 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2023-01-31 07:47:24,606 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-31 07:51:03,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:51:04,264 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 60337-target
recon_1     | 2023-01-31 07:54:46,612 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-31 07:54:46,612 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2023-01-31 07:47:24,654 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-31 07:47:24,683 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44165
scm_1       | 2023-01-31 07:47:24,691 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39654
datanode_1  | 2023-01-31 07:48:39,197 [pool-24-thread-1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2023-01-31 07:51:10,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42661
datanode_3  | 2023-01-31 07:48:45,559 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_3  | 2023-01-31 07:48:45,560 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2023-01-31 07:47:24,701 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9956ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_3  | 2023-01-31 07:48:45,560 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:45,560 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=7eb7c323-0301-4528-bfd5-9c2467a4d4e7
datanode_1  | 2023-01-31 07:48:39,197 [pool-24-thread-1] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
datanode_1  | 2023-01-31 07:48:39,197 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 2023-01-31 07:47:24,850 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:39812
scm_1       | 2023-01-31 07:47:24,851 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1     | 2023-01-31 07:54:46,768 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds to process 0 existing database records.
datanode_3  | 2023-01-31 07:48:45,561 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=7eb7c323-0301-4528-bfd5-9c2467a4d4e7.
scm_1       | 2023-01-31 07:47:24,858 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:45767
scm_1       | 2023-01-31 07:47:24,866 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
datanode_1  | 2023-01-31 07:48:39,197 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-95A0187A7678,id=ee1a73fb-90e8-4573-a632-4d493b4c1d75
datanode_1  | 2023-01-31 07:48:39,198 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2023-01-31 07:48:46,103 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: receive requestVote(ELECTION, ee1a73fb-90e8-4573-a632-4d493b4c1d75, group-95A0187A7678, 1, (t:0, i:0))
recon_1     | 2023-01-31 07:54:46,783 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 14 milliseconds for processing 1 containers.
datanode_1  | 2023-01-31 07:48:39,198 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_1  | 2023-01-31 07:48:39,198 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
datanode_3  | 2023-01-31 07:48:46,103 [grpc-default-executor-1] INFO impl.VoteContext: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FOLLOWER: reject ELECTION from ee1a73fb-90e8-4573-a632-4d493b4c1d75: already has voted for 14b917d5-325a-4f29-a0e8-e34b223e06de at current term 1
recon_1     | 2023-01-31 07:54:46,808 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
scm_1       | 2023-01-31 07:47:24,880 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1     | 2023-01-31 07:54:46,829 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 43 milliseconds.
datanode_3  | 2023-01-31 07:48:46,103 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678 replies to ELECTION vote request: ee1a73fb-90e8-4573-a632-4d493b4c1d75<-14b917d5-325a-4f29-a0e8-e34b223e06de#0:FAIL-t1. Peer's state: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678:t1, leader=null, voted=14b917d5-325a-4f29-a0e8-e34b223e06de, raftlog=Memoized:14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:49,931 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5216999065ns, electionTimeout:5188ms
om_1        | 2023-01-31 07:51:10,441 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:39,198 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | 2023-01-31 07:47:24,918 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-31 07:47:25,469 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#11 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:39654
recon_1     | 2023-01-31 07:54:59,111 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33680
recon_1     | 2023-01-31 07:54:59,130 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:51:16,883 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38061
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_1  | 2023-01-31 07:48:39,199 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:49,932 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
datanode_3  | 2023-01-31 07:48:49,933 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om_1        | 2023-01-31 07:51:16,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_1  | 2023-01-31 07:48:39,233 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=defd148e-7304-4d1b-888f-95a0187a7678
datanode_1  | 2023-01-31 07:48:39,315 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_1  | 2023-01-31 07:48:43,000 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO impl.FollowerState: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5179000588ns, electionTimeout:5159ms
datanode_1  | 2023-01-31 07:48:43,003 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState
recon_1     | 2023-01-31 07:54:59,719 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:55614
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 2023-01-31 07:51:23,963 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46105
om_1        | 2023-01-31 07:51:23,989 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:43,009 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
recon_1     | 2023-01-31 07:54:59,730 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:54:59,767 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35112
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 2023-01-31 07:51:30,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33015
om_1        | 2023-01-31 07:51:30,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:43,033 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     | 2023-01-31 07:54:59,771 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:55:29,146 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39400
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 2023-01-31 07:51:37,001 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33511
om_1        | 2023-01-31 07:51:37,024 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:43,038 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-FollowerState] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1
recon_1     | 2023-01-31 07:55:29,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:55:29,737 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35416
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 2023-01-31 07:51:44,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45889
om_1        | 2023-01-31 07:51:44,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:43,089 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO impl.LeaderElection: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:55:29,740 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39668
recon_1     | 2023-01-31 07:55:29,759 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2023-01-31 07:51:44,923 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 60337-target
om_1        | 2023-01-31 07:51:45,138 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:41213
datanode_1  | 2023-01-31 07:48:43,097 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO impl.LeaderElection: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1 ELECTION round 0: result PASSED (term=1)
recon_1     | 2023-01-31 07:55:29,766 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:55:46,635 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 2023-01-31 07:51:45,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:55:46,636 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 2023-01-31 07:51:50,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39395
datanode_1  | 2023-01-31 07:48:43,104 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1
recon_1     | 2023-01-31 07:55:46,636 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 98 
recon_1     | 2023-01-31 07:55:46,691 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 07:51:50,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:43,106 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
recon_1     | 2023-01-31 07:55:46,693 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
recon_1     | 2023-01-31 07:55:46,700 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2023-01-31 07:51:57,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39995
datanode_1  | 2023-01-31 07:48:43,108 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-AA485FE71506 with new leaderId: ee1a73fb-90e8-4573-a632-4d493b4c1d75
recon_1     | 2023-01-31 07:55:46,703 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 07:55:46,817 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-31 07:51:57,070 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-31 07:55:46,818 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2023-01-31 07:55:46,824 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2023-01-31 07:48:43,118 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: change Leader from null to ee1a73fb-90e8-4573-a632-4d493b4c1d75 at term 1 for becomeLeader, leader elected after 6453ms
om_1        | 2023-01-31 07:51:57,923 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 60337-target
datanode_3  | 2023-01-31 07:48:49,933 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2023-01-31 07:48:49,933 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2
datanode_1  | 2023-01-31 07:48:43,197 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2023-01-31 07:52:03,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40353
datanode_3  | 2023-01-31 07:48:49,937 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:49,949 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-31 07:48:43,990 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-ee1a73fb-90e8-4573-a632-4d493b4c1d75: Detected pause in JVM or host machine (eg GC): pause of approximately 783914845ns.
om_1        | 2023-01-31 07:52:03,308 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_3  | 2023-01-31 07:48:49,949 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:50,007 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
om_1        | 2023-01-31 07:52:04,100 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 60337-source
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 2023-01-31 07:48:50,008 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection:   Response 0: 14b917d5-325a-4f29-a0e8-e34b223e06de<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t2
datanode_3  | 2023-01-31 07:48:50,011 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2 ELECTION round 0: result REJECTED
datanode_1  | GC pool 'ParNew' had collection(s): count=1 time=787ms
om_1        | 2023-01-31 07:52:09,395 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36381
datanode_3  | 2023-01-31 07:48:50,011 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
datanode_3  | 2023-01-31 07:48:50,011 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2
datanode_1  | 2023-01-31 07:48:44,034 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
om_1        | 2023-01-31 07:52:09,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2023-01-31 07:48:50,012 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-LeaderElection2] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:55:59,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57194
om_1        | 2023-01-31 07:52:18,979 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36893
om_1        | 2023-01-31 07:52:18,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:55:59,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 2023-01-31 07:48:44,034 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
om_1        | 2023-01-31 07:52:28,753 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42239
om_1        | 2023-01-31 07:52:28,784 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:44,091 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 2023-01-31 07:55:59,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:50804
recon_1     | 2023-01-31 07:55:59,756 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34992
recon_1     | 2023-01-31 07:55:59,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:44,091 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2023-01-31 07:48:44,123 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2023-01-31 07:48:44,274 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:55:59,762 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:52:38,891 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33397
datanode_1  | 2023-01-31 07:48:44,305 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | 2023-01-31 07:48:50,024 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-31 07:56:29,126 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40642
recon_1     | 2023-01-31 07:56:29,136 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:44,375 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO impl.FollowerState: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5177961116ns, electionTimeout:5174ms
datanode_3  | 2023-01-31 07:48:50,026 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-31 07:47:25,472 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:42122
om_1        | 2023-01-31 07:52:38,921 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:52:45,465 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:46851
om_1        | 2023-01-31 07:52:45,482 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:50,655 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO impl.FollowerState: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5098274482ns, electionTimeout:5095ms
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
datanode_1  | 2023-01-31 07:48:44,397 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
om_1        | 2023-01-31 07:52:48,266 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40955
om_1        | 2023-01-31 07:52:48,307 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:52:55,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33043
om_1        | 2023-01-31 07:52:55,238 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:53:01,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46339
recon_1     | 2023-01-31 07:56:29,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:60196
datanode_1  | 2023-01-31 07:48:44,398 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2023-01-31 07:48:44,398 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderStateImpl
recon_1     | 2023-01-31 07:56:29,747 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:36896
datanode_3  | 2023-01-31 07:48:50,656 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState
datanode_3  | 2023-01-31 07:48:50,657 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2023-01-31 07:48:44,403 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_1  | 2023-01-31 07:48:44,418 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     | 2023-01-31 07:56:29,778 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:50,657 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2023-01-31 07:48:50,658 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-FollowerState] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3
datanode_1  | 2023-01-31 07:48:44,420 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2
datanode_1  | 2023-01-31 07:48:44,536 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:56:29,784 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:56:46,831 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 07:56:46,831 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:53:01,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_3  | 2023-01-31 07:48:50,675 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-31 07:48:44,630 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2023-01-31 07:56:46,832 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 117 
recon_1     | 2023-01-31 07:56:46,875 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 07:53:07,805 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38415
datanode_1  | 2023-01-31 07:48:44,641 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2023-01-31 07:48:44,678 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 1e69a4e3-5301-4460-8965-9fee5bf32e29
datanode_1  | 2023-01-31 07:48:44,689 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for 14b917d5-325a-4f29-a0e8-e34b223e06de
om_1        | 2023-01-31 07:53:07,841 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:53:14,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42357
om_1        | 2023-01-31 07:53:14,724 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:53:21,791 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45527
datanode_3  | 2023-01-31 07:48:50,676 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO impl.LeaderElection: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode_3  | 2023-01-31 07:48:50,676 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3
datanode_3  | 2023-01-31 07:48:50,677 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2023-01-31 07:48:44,793 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2023-01-31 07:48:44,973 [grpc-default-executor-0] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: receive requestVote(ELECTION, 1e69a4e3-5301-4460-8965-9fee5bf32e29, group-95A0187A7678, 1, (t:0, i:0))
recon_1     | 2023-01-31 07:56:46,875 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
recon_1     | 2023-01-31 07:56:46,883 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 07:56:46,883 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 07:56:47,049 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 07:56:47,049 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-31 07:56:47,049 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2023-01-31 07:48:44,974 [grpc-default-executor-0] INFO impl.VoteContext: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-CANDIDATE: reject ELECTION from 1e69a4e3-5301-4460-8965-9fee5bf32e29: already has voted for ee1a73fb-90e8-4573-a632-4d493b4c1d75 at current term 1
datanode_1  | 2023-01-31 07:48:45,022 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-LeaderElection1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506: set configuration 0: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:56:59,119 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:41602
recon_1     | 2023-01-31 07:56:59,161 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:56:59,775 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:45094
recon_1     | 2023-01-31 07:56:59,779 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39586
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 2023-01-31 07:53:21,816 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:45,033 [grpc-default-executor-0] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678 replies to ELECTION vote request: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:FAIL-t1. Peer's state: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678:t1, leader=null, voted=ee1a73fb-90e8-4573-a632-4d493b4c1d75, raftlog=Memoized:ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:56:59,794 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:56:59,815 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:53:28,399 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46087
datanode_1  | 2023-01-31 07:48:45,111 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: receive requestVote(ELECTION, 14b917d5-325a-4f29-a0e8-e34b223e06de, group-95A0187A7678, 1, (t:0, i:0))
recon_1     | 2023-01-31 07:57:29,143 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:52184
datanode_3  | 2023-01-31 07:48:50,677 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-9C2467A4D4E7 with new leaderId: 14b917d5-325a-4f29-a0e8-e34b223e06de
om_1        | 2023-01-31 07:53:28,423 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_1  | 2023-01-31 07:48:45,111 [grpc-default-executor-3] INFO impl.VoteContext: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-CANDIDATE: reject ELECTION from 14b917d5-325a-4f29-a0e8-e34b223e06de: already has voted for ee1a73fb-90e8-4573-a632-4d493b4c1d75 at current term 1
recon_1     | 2023-01-31 07:57:29,152 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:57:29,735 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45960
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 2023-01-31 07:53:34,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34635
recon_1     | 2023-01-31 07:57:29,780 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 07:57:29,828 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36942
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 2023-01-31 07:53:34,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:50,681 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: change Leader from null to 14b917d5-325a-4f29-a0e8-e34b223e06de at term 1 for becomeLeader, leader elected after 5301ms
datanode_3  | 2023-01-31 07:48:50,713 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 2023-01-31 07:53:41,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35457
datanode_3  | 2023-01-31 07:48:50,770 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2023-01-31 07:48:45,219 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678 replies to ELECTION vote request: 14b917d5-325a-4f29-a0e8-e34b223e06de<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:FAIL-t1. Peer's state: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678:t1, leader=null, voted=ee1a73fb-90e8-4573-a632-4d493b4c1d75, raftlog=Memoized:ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-31 07:48:45,819 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=defd148e-7304-4d1b-888f-95a0187a7678.
om_1        | 2023-01-31 07:53:41,481 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:53:45,890 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:40311
om_1        | 2023-01-31 07:53:45,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:53:48,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33243
om_1        | 2023-01-31 07:53:48,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:50,774 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
om_1        | 2023-01-31 07:53:53,846 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43367
om_1        | 2023-01-31 07:53:53,866 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:57:29,841 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:45,893 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-AA485FE71506-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/409651ee-63d0-4368-a01a-aa485fe71506/current/log_inprogress_0
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2023-01-31 07:54:00,031 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40461
datanode_3  | 2023-01-31 07:48:50,814 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 2023-01-31 07:57:47,058 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_1  | 2023-01-31 07:48:46,037 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 2023-01-31 07:54:00,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:50,815 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 2023-01-31 07:57:47,059 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_1  | 2023-01-31 07:48:46,038 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection:   Response 0: ee1a73fb-90e8-4573-a632-4d493b4c1d75<-1e69a4e3-5301-4460-8965-9fee5bf32e29#0:FAIL-t1
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_3  | 2023-01-31 07:48:50,816 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 2023-01-31 07:57:47,060 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 128 
datanode_1  | 2023-01-31 07:48:46,038 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.LeaderElection: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2 ELECTION round 0: result REJECTED
datanode_1  | 2023-01-31 07:48:46,039 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
om_1        | 2023-01-31 07:54:07,104 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43463
datanode_3  | 2023-01-31 07:48:50,840 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2023-01-31 07:57:47,101 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4, SequenceNumber diff: 8, SequenceNumber Lag from OM 0.
datanode_1  | 2023-01-31 07:48:46,040 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 2023-01-31 07:54:07,136 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:50,844 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
recon_1     | 2023-01-31 07:57:47,101 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 8 records
datanode_1  | 2023-01-31 07:48:46,040 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-LeaderElection2] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2023-01-31 07:54:08,059 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 60337-target
datanode_3  | 2023-01-31 07:48:50,856 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderStateImpl
recon_1     | 2023-01-31 07:57:47,113 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_1  | 2023-01-31 07:48:46,084 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2023-01-31 07:54:14,092 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38209
datanode_3  | 2023-01-31 07:48:50,913 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker: Starting segment from index:0
recon_1     | 2023-01-31 07:57:47,113 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_1  | 2023-01-31 07:48:46,087 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 2023-01-31 07:54:14,118 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:48:51,029 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-LeaderElection3] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7: set configuration 0: peers:[14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:57:47,319 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_1  | 2023-01-31 07:48:49,963 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: receive requestVote(ELECTION, 14b917d5-325a-4f29-a0e8-e34b223e06de, group-95A0187A7678, 2, (t:0, i:0))
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2023-01-31 07:54:14,945 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:60337-target
datanode_3  | 2023-01-31 07:48:51,113 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-9C2467A4D4E7-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/7eb7c323-0301-4528-bfd5-9c2467a4d4e7/current/log_inprogress_0
recon_1     | 2023-01-31 07:57:47,319 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
datanode_1  | 2023-01-31 07:48:49,964 [grpc-default-executor-3] INFO impl.VoteContext: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FOLLOWER: accept ELECTION from 14b917d5-325a-4f29-a0e8-e34b223e06de: our priority 0 <= candidate's priority 0
scm_1       | 2023-01-31 07:47:25,475 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
datanode_3  | 2023-01-31 07:48:55,116 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: receive requestVote(ELECTION, 1e69a4e3-5301-4460-8965-9fee5bf32e29, group-95A0187A7678, 3, (t:0, i:0))
recon_1     | 2023-01-31 07:57:47,319 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_1  | 2023-01-31 07:48:49,964 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:14b917d5-325a-4f29-a0e8-e34b223e06de
scm_1       | 2023-01-31 07:47:25,486 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.10:39812
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:207)
datanode_3  | 2023-01-31 07:48:55,116 [grpc-default-executor-1] INFO impl.VoteContext: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FOLLOWER: accept ELECTION from 1e69a4e3-5301-4460-8965-9fee5bf32e29: our priority 0 <= candidate's priority 1
recon_1     | 2023-01-31 07:57:59,098 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40470
datanode_1  | 2023-01-31 07:48:49,964 [grpc-default-executor-3] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
datanode_3  | 2023-01-31 07:48:55,116 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:1e69a4e3-5301-4460-8965-9fee5bf32e29
recon_1     | 2023-01-31 07:57:59,118 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:49,965 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO impl.FollowerState: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState was interrupted
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_3  | 2023-01-31 07:48:55,117 [grpc-default-executor-1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: shutdown 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:57:59,760 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:58640
datanode_1  | 2023-01-31 07:48:49,965 [grpc-default-executor-3] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
datanode_1  | 2023-01-31 07:48:50,010 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678 replies to ELECTION vote request: 14b917d5-325a-4f29-a0e8-e34b223e06de<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:OK-t2. Peer's state: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678:t2, leader=null, voted=14b917d5-325a-4f29-a0e8-e34b223e06de, raftlog=Memoized:ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:55,117 [grpc-default-executor-1] INFO impl.RoleInfo: 14b917d5-325a-4f29-a0e8-e34b223e06de: start 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:57:59,765 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-31 07:48:50,041 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-31 07:48:50,043 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-31 07:48:55,118 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-31 07:48:55,118 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
datanode_1  | 2023-01-31 07:48:55,061 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: receive requestVote(ELECTION, 1e69a4e3-5301-4460-8965-9fee5bf32e29, group-95A0187A7678, 3, (t:0, i:0))
datanode_1  | 2023-01-31 07:48:55,061 [grpc-default-executor-3] INFO impl.VoteContext: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FOLLOWER: accept ELECTION from 1e69a4e3-5301-4460-8965-9fee5bf32e29: our priority 0 <= candidate's priority 1
datanode_3  | 2023-01-31 07:48:55,122 [grpc-default-executor-1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678 replies to ELECTION vote request: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-14b917d5-325a-4f29-a0e8-e34b223e06de#0:OK-t3. Peer's state: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678:t3, leader=null, voted=1e69a4e3-5301-4460-8965-9fee5bf32e29, raftlog=Memoized:14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-31 07:48:55,122 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState] INFO impl.FollowerState: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-FollowerState was interrupted
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_1  | 2023-01-31 07:48:55,061 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:1e69a4e3-5301-4460-8965-9fee5bf32e29
datanode_1  | 2023-01-31 07:48:55,061 [grpc-default-executor-3] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: shutdown ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
datanode_3  | 2023-01-31 07:48:55,428 [14b917d5-325a-4f29-a0e8-e34b223e06de-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-95A0187A7678 with new leaderId: 1e69a4e3-5301-4460-8965-9fee5bf32e29
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_1  | 2023-01-31 07:48:55,061 [grpc-default-executor-3] INFO impl.RoleInfo: ee1a73fb-90e8-4573-a632-4d493b4c1d75: start ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState
recon_1     | 2023-01-31 07:57:59,765 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:53234
datanode_3  | 2023-01-31 07:48:55,430 [14b917d5-325a-4f29-a0e8-e34b223e06de-server-thread1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: change Leader from null to 1e69a4e3-5301-4460-8965-9fee5bf32e29 at term 3 for appendEntries, leader elected after 18692ms
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2023-01-31 07:48:55,062 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO impl.FollowerState: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState was interrupted
recon_1     | 2023-01-31 07:57:59,774 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-31 07:48:55,440 [14b917d5-325a-4f29-a0e8-e34b223e06de-server-thread1] INFO server.RaftServer$Division: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678: set configuration 0: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_1  | 2023-01-31 07:48:55,062 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2023-01-31 07:58:29,130 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:59452
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_1  | 2023-01-31 07:48:55,063 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-31 07:58:29,139 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_1  | 2023-01-31 07:48:55,065 [grpc-default-executor-3] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678 replies to ELECTION vote request: 1e69a4e3-5301-4460-8965-9fee5bf32e29<-ee1a73fb-90e8-4573-a632-4d493b4c1d75#0:OK-t3. Peer's state: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678:t3, leader=null, voted=1e69a4e3-5301-4460-8965-9fee5bf32e29, raftlog=Memoized:ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-31 07:58:29,747 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45512
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 2023-01-31 07:58:29,786 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:33122
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 2023-01-31 07:58:29,787 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | 2023-01-31 07:48:55,459 [14b917d5-325a-4f29-a0e8-e34b223e06de-server-thread1] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2023-01-31 07:48:55,467 [14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 14b917d5-325a-4f29-a0e8-e34b223e06de@group-95A0187A7678-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/current/log_inprogress_0
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-31 07:58:29,832 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:54:20,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34405
om_1        | 2023-01-31 07:54:20,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-31 07:49:29,204 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:495064171534.
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-31 07:58:47,325 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2023-01-31 07:54:21,260 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 60337-target
om_1        | 2023-01-31 07:54:26,856 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33925
om_1        | 2023-01-31 07:54:26,876 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:58:47,326 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 07:58:47,326 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 136 
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 2023-01-31 07:48:55,499 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-95A0187A7678 with new leaderId: 1e69a4e3-5301-4460-8965-9fee5bf32e29
datanode_1  | 2023-01-31 07:48:55,499 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-server-thread1] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: change Leader from null to 1e69a4e3-5301-4460-8965-9fee5bf32e29 at term 3 for appendEntries, leader elected after 17410ms
datanode_1  | 2023-01-31 07:48:55,520 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-server-thread2] INFO server.RaftServer$Division: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678: set configuration 0: peers:[ee1a73fb-90e8-4573-a632-4d493b4c1d75|rpc:172.18.0.10:9856|admin:172.18.0.10:9857|client:172.18.0.10:9858|dataStream:172.18.0.10:9855|priority:0|startupRole:FOLLOWER, 14b917d5-325a-4f29-a0e8-e34b223e06de|rpc:172.18.0.6:9856|admin:172.18.0.6:9857|client:172.18.0.6:9858|dataStream:172.18.0.6:9855|priority:0|startupRole:FOLLOWER, 1e69a4e3-5301-4460-8965-9fee5bf32e29|rpc:172.18.0.9:9856|admin:172.18.0.9:9857|client:172.18.0.9:9858|dataStream:172.18.0.9:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-31 07:54:27,842 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:60337-target
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
recon_1     | 2023-01-31 07:58:47,375 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
datanode_1  | 2023-01-31 07:48:55,557 [ee1a73fb-90e8-4573-a632-4d493b4c1d75-server-thread2] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:207)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
datanode_1  | 2023-01-31 07:48:55,567 [ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: ee1a73fb-90e8-4573-a632-4d493b4c1d75@group-95A0187A7678-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/defd148e-7304-4d1b-888f-95a0187a7678/current/log_inprogress_0
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-31 07:58:47,375 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
datanode_1  | 2023-01-31 07:49:29,169 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:495064171534.
scm_1       | 2023-01-31 07:47:25,538 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#11 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.3:45767
recon_1     | 2023-01-31 07:58:47,383 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
recon_1     | 2023-01-31 07:58:47,384 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1     | 2023-01-31 07:58:47,537 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2023-01-31 07:58:47,559 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | 2023-01-31 07:58:47,581 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 07:58:59,096 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42316
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 2023-01-31 07:54:34,055 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34987
recon_1     | 2023-01-31 07:58:59,102 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2023-01-31 07:54:34,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:58:59,777 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59072
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 2023-01-31 07:54:41,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46185
recon_1     | 2023-01-31 07:58:59,794 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:51608
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 2023-01-31 07:54:41,352 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:58:59,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 2023-01-31 07:54:42,115 [IPC Server handler 7 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:60337-target Bucket:unreadable-link 
recon_1     | 2023-01-31 07:58:59,833 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 2023-01-31 07:54:46,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:35541
recon_1     | 2023-01-31 07:59:29,109 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45542
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 2023-01-31 07:54:46,321 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 07:59:29,122 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2023-01-31 07:54:48,004 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37367
recon_1     | 2023-01-31 07:59:29,773 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:59054
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 2023-01-31 07:54:48,063 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:54:54,724 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39489
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2023-01-31 07:54:54,741 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,557 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | 2023-01-31 07:59:29,782 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:43642
om_1        | 2023-01-31 07:54:55,532 [IPC Server handler 4 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:60337-source Bucket:unreadable-bucket Key:
scm_1       | 2023-01-31 07:47:25,558 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
recon_1     | 2023-01-31 07:59:29,788 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:55:00,964 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34939
scm_1       | 2023-01-31 07:47:25,559 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2023-01-31 07:59:29,798 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:55:01,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,559 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2023-01-31 07:59:46,785 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
om_1        | 2023-01-31 07:55:01,922 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 60337-target
scm_1       | 2023-01-31 07:47:25,564 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
recon_1     | 2023-01-31 07:59:46,788 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 1 containers.
om_1        | 2023-01-31 07:55:08,276 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46039
scm_1       | 2023-01-31 07:47:25,645 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
recon_1     | 2023-01-31 07:59:46,872 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
om_1        | 2023-01-31 07:55:08,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,647 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
recon_1     | 2023-01-31 07:59:46,875 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 33 milliseconds.
om_1        | 2023-01-31 07:55:09,224 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 60337-target
scm_1       | 2023-01-31 07:47:25,665 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 07:59:47,590 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 07:59:47,590 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-31 07:47:25,742 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
recon_1     | 2023-01-31 07:59:47,591 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 153 
om_1        | 2023-01-31 07:55:14,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40539
scm_1       | 2023-01-31 07:47:25,742 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2023-01-31 07:59:47,636 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 07:55:14,264 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,744 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 600000ms
recon_1     | 2023-01-31 07:59:47,637 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
om_1        | 2023-01-31 07:55:15,174 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 60337-target
om_1        | 2023-01-31 07:55:20,409 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36163
recon_1     | 2023-01-31 07:59:47,640 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2023-01-31 07:55:20,431 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,759 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
recon_1     | 2023-01-31 07:59:47,641 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 2023-01-31 07:55:25,740 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34703
scm_1       | 2023-01-31 07:47:25,766 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@6f34d178{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2023-01-31 07:59:47,782 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-31 07:55:25,760 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,767 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@e6d9c25{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2023-01-31 07:59:47,783 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | 2023-01-31 07:55:26,677 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 60337-target
scm_1       | 2023-01-31 07:47:25,865 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
recon_1     | 2023-01-31 07:59:47,790 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-31 07:55:32,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42177
scm_1       | 2023-01-31 07:47:25,876 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@d4df4ce{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-13744798216734103821/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
recon_1     | 2023-01-31 07:59:59,094 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:55220
om_1        | 2023-01-31 07:55:32,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,885 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@6c927487{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
recon_1     | 2023-01-31 07:59:59,105 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:55:41,341 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44519
scm_1       | 2023-01-31 07:47:25,885 [Listener at 0.0.0.0/9860] INFO server.Server: Started @11140ms
recon_1     | 2023-01-31 07:59:59,769 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38494
om_1        | 2023-01-31 07:55:41,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,887 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2023-01-31 07:59:59,775 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:56420
om_1        | 2023-01-31 07:55:46,676 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:42619
scm_1       | 2023-01-31 07:47:25,887 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 2023-01-31 07:59:59,785 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:55:46,680 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:25,889 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
recon_1     | 2023-01-31 07:59:59,800 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:00:29,103 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49888
om_1        | 2023-01-31 07:55:51,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42577
scm_1       | 2023-01-31 07:47:27,483 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.9:39654
recon_1     | 2023-01-31 08:00:29,110 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:55:51,086 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:55:56,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43439
recon_1     | 2023-01-31 08:00:29,738 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33138
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
om_1        | 2023-01-31 07:55:56,578 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:00:29,740 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48714
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 2023-01-31 07:56:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 2023-01-31 08:00:29,744 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1     | 2023-01-31 08:00:29,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1     | 2023-01-31 08:00:47,807 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:00:47,807 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:00:47,807 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 170 
recon_1     | 2023-01-31 08:00:47,866 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-31 08:00:47,866 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:00:47,869 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-31 08:00:47,871 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:00:47,966 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:00:47,967 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-31 08:00:47,972 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:00:59,092 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49244
recon_1     | 2023-01-31 08:00:59,110 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-31 08:00:59,749 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38466
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:00:59,754 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:49826
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2023-01-31 07:56:00,011 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-31 08:00:59,759 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:27,509 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#13 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:42122
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
recon_1     | 2023-01-31 08:00:59,767 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-31 08:01:29,123 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:38540
recon_1     | 2023-01-31 08:01:29,137 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:01:29,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:49740
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 2023-01-31 08:01:29,751 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:58006
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:01:29,759 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:01:29,798 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:01:47,982 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 2023-01-31 08:01:47,982 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 2023-01-31 08:01:47,983 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 185 
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 2023-01-31 08:01:48,010 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:01:48,010 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-31 08:01:48,016 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-31 08:01:48,016 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2023-01-31 08:01:48,128 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2023-01-31 08:01:48,129 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 2023-01-31 07:56:00,023 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 2023-01-31 08:01:48,129 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-31 08:01:59,111 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:58180
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:47:27,520 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#13 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.10:39812
recon_1     | 2023-01-31 08:01:59,134 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
recon_1     | 2023-01-31 08:01:59,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:51118
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 2023-01-31 08:01:59,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43244
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 2023-01-31 08:01:59,744 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1     | 2023-01-31 08:01:59,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1     | 2023-01-31 08:02:29,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36866
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 2023-01-31 08:02:29,112 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 2023-01-31 08:02:29,718 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:52194
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 2023-01-31 08:02:29,721 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 2023-01-31 08:02:29,749 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:33224
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-31 08:02:29,756 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-31 08:02:48,140 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2023-01-31 08:02:48,141 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:56:02,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46803
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2023-01-31 07:56:02,888 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 2023-01-31 07:56:09,018 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41543
om_1        | 2023-01-31 07:56:09,043 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:02:48,141 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 198 
om_1        | 2023-01-31 07:56:09,753 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 60337-target
om_1        | 2023-01-31 07:56:15,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45481
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-31 07:47:27,560 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.3:45767
recon_1     | 2023-01-31 08:02:48,182 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4, SequenceNumber diff: 8, SequenceNumber Lag from OM 0.
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:6dfb726e-350e-430b-835b-cf79da791979 is not the leader. Could not determine the leader node.
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 2023-01-31 08:02:48,182 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 8 records
om_1        | 2023-01-31 07:56:15,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:56:15,816 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:60337-target
om_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
recon_1     | 2023-01-31 08:02:48,186 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1     | 2023-01-31 08:02:48,191 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-31 08:02:48,330 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-31 08:02:48,330 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:02:48,330 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 2023-01-31 07:56:20,971 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44907
scm_1       | 2023-01-31 07:47:27,919 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.FollowerState: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5066014008ns, electionTimeout:5063ms
om_1        | 2023-01-31 07:56:20,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:02:59,104 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37274
scm_1       | 2023-01-31 07:47:27,921 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: shutdown 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState
om_1        | 2023-01-31 07:56:27,318 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41083
scm_1       | 2023-01-31 07:47:27,922 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
om_1        | 2023-01-31 07:56:27,335 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:27,928 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     | 2023-01-31 08:02:59,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:02:59,741 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35248
om_1        | 2023-01-31 07:56:33,159 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33329
recon_1     | 2023-01-31 08:02:59,743 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38790
om_1        | 2023-01-31 07:56:33,198 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:27,928 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-FollowerState] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1
om_1        | 2023-01-31 07:56:33,989 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:58672-without-scheme for user:testuser
recon_1     | 2023-01-31 08:02:59,745 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:27,938 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.LeaderElection: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-31 07:56:38,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44619
scm_1       | 2023-01-31 07:47:27,939 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.LeaderElection: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1 ELECTION round 0: result PASSED (term=2)
recon_1     | 2023-01-31 08:02:59,751 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:03:29,104 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49780
scm_1       | 2023-01-31 07:47:27,940 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: shutdown 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1
scm_1       | 2023-01-31 07:47:27,940 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
om_1        | 2023-01-31 07:56:38,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:56:45,049 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34009
scm_1       | 2023-01-31 07:47:27,941 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm_1       | 2023-01-31 07:47:27,941 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
recon_1     | 2023-01-31 08:03:29,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:03:29,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49004
scm_1       | 2023-01-31 07:47:27,949 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: change Leader from null to 6dfb726e-350e-430b-835b-cf79da791979 at term 2 for becomeLeader, leader elected after 8380ms
scm_1       | 2023-01-31 07:47:27,956 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2023-01-31 07:56:45,082 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:56:46,858 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:34989
scm_1       | 2023-01-31 07:47:27,961 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
recon_1     | 2023-01-31 08:03:29,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:03:29,765 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:40702
scm_1       | 2023-01-31 07:47:27,961 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2023-01-31 07:47:27,967 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2023-01-31 07:47:27,967 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2023-01-31 07:56:46,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:56:51,246 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33271
scm_1       | 2023-01-31 07:47:27,968 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2023-01-31 07:47:27,973 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2023-01-31 07:47:27,974 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
scm_1       | 2023-01-31 07:47:27,977 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO impl.RoleInfo: 6dfb726e-350e-430b-835b-cf79da791979: start 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderStateImpl
recon_1     | 2023-01-31 08:03:29,768 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:03:48,353 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:47:27,982 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm_1       | 2023-01-31 07:47:27,987 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/log_inprogress_0 to /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/log_0-0
scm_1       | 2023-01-31 07:47:28,007 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-LeaderElection1] INFO server.RaftServer$Division: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21: set configuration 1: peers:[6dfb726e-350e-430b-835b-cf79da791979|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-31 07:56:51,263 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:56:57,654 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41657
om_1        | 2023-01-31 07:56:57,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:47:28,021 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/5128c6ec-f311-4d77-b590-370d3e099e21/current/log_inprogress_1
scm_1       | 2023-01-31 07:47:28,028 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm_1       | 2023-01-31 07:47:28,030 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1       | 2023-01-31 07:47:28,035 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:03:48,354 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:03:48,354 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 206 
scm_1       | 2023-01-31 07:47:28,036 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm_1       | 2023-01-31 07:47:28,036 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
om_1        | 2023-01-31 07:57:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-31 08:03:48,394 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:47:28,036 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:47:28,039 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:03:48,394 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
recon_1     | 2023-01-31 08:03:48,398 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 08:03:48,399 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-31 07:47:28,039 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
recon_1     | 2023-01-31 08:03:48,505 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:03:48,506 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2023-01-31 08:03:48,511 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2023-01-31 07:47:29,594 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn f206954d6d35, UUID: 14b917d5-325a-4f29-a0e8-e34b223e06de
recon_1     | 2023-01-31 08:03:59,101 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:52444
recon_1     | 2023-01-31 08:03:59,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:29,610 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 43001ba40da4, UUID: 1e69a4e3-5301-4460-8965-9fee5bf32e29
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:47:30,476 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:47:30,476 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:47:30,477 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
scm_1       | 2023-01-31 07:47:30,575 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 6b0ee5ff6668, UUID: ee1a73fb-90e8-4573-a632-4d493b4c1d75
scm_1       | 2023-01-31 07:47:30,665 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:03:59,742 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60972
recon_1     | 2023-01-31 08:03:59,751 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:49162
scm_1       | 2023-01-31 07:47:30,690 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:47:30,815 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 1d8e768e-bf20-436f-97b6-ed657305aaf6
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:47:30,891 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:47:31,215 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:03:59,758 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:03:59,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:35,666 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:47:36,870 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40695
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:47:36,877 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-31 07:47:36,903 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: f71d5860-3775-4bf5-b7bd-55b11729651b
recon_1     | 2023-01-31 08:04:29,103 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:59964
recon_1     | 2023-01-31 08:04:29,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:37,129 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:47:40,666 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:57:00,015 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 07:47:45,676 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:47:50,681 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:04:29,752 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:50220
recon_1     | 2023-01-31 08:04:29,779 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:55,682 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:47:58,342 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33148
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:47:58,367 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:47:58,565 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:55972
recon_1     | 2023-01-31 08:04:29,788 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:60996
recon_1     | 2023-01-31 08:04:29,806 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:47:58,586 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:47:58,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42222
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:47:58,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:48:00,688 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:04:46,789 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2023-01-31 08:04:46,791 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:48:01,521 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37581
scm_1       | 2023-01-31 07:48:01,601 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:48:02,706 [IPC Server handler 4 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/ee1a73fb-90e8-4573-a632-4d493b4c1d75
scm_1       | 2023-01-31 07:48:02,798 [IPC Server handler 58 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/1e69a4e3-5301-4460-8965-9fee5bf32e29
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:48:02,808 [IPC Server handler 58 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 1e69a4e3-5301-4460-8965-9fee5bf32e29{ip: 172.18.0.9, host: ozonesecure_datanode_2.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488625236405, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2023-01-31 07:48:02,818 [IPC Server handler 4 on default port 9861] INFO node.SCMNodeManager: Registered Data node : ee1a73fb-90e8-4573-a632-4d493b4c1d75{ip: 172.18.0.10, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488772207169, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2023-01-31 07:48:02,964 [IPC Server handler 21 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/14b917d5-325a-4f29-a0e8-e34b223e06de
scm_1       | 2023-01-31 07:48:02,966 [IPC Server handler 21 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 14b917d5-325a-4f29-a0e8-e34b223e06de{ip: 172.18.0.6, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 488015668949, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-31 08:04:46,903 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2023-01-31 08:04:46,906 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 27 milliseconds.
scm_1       | 2023-01-31 07:48:02,933 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-31 07:48:03,165 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-31 07:48:03,165 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:48:03,223 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=409651ee-63d0-4368-a01a-aa485fe71506 to datanode:ee1a73fb-90e8-4573-a632-4d493b4c1d75
scm_1       | 2023-01-31 07:48:03,200 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
recon_1     | 2023-01-31 08:04:48,519 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 08:04:48,519 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
recon_1     | 2023-01-31 08:04:48,519 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 223 
recon_1     | 2023-01-31 08:04:48,549 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 14, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
recon_1     | 2023-01-31 08:04:48,549 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 14 records
recon_1     | 2023-01-31 08:04:48,553 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
recon_1     | 2023-01-31 08:04:48,554 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:48:03,269 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
recon_1     | 2023-01-31 08:04:48,644 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:48:03,460 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 409651ee-63d0-4368-a01a-aa485fe71506, Nodes: ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.221Z[UTC]].
recon_1     | 2023-01-31 08:04:48,646 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:48:03,460 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:04:48,657 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:48:03,512 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 to datanode:1e69a4e3-5301-4460-8965-9fee5bf32e29
recon_1     | 2023-01-31 08:04:59,123 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:47474
om_1        | 2023-01-31 07:57:00,016 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-31 08:04:59,151 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 07:48:03,516 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 to datanode:14b917d5-325a-4f29-a0e8-e34b223e06de
recon_1     | 2023-01-31 08:04:59,760 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:57384
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:48:03,516 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=defd148e-7304-4d1b-888f-95a0187a7678 to datanode:ee1a73fb-90e8-4573-a632-4d493b4c1d75
recon_1     | 2023-01-31 08:04:59,781 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:48:03,530 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: defd148e-7304-4d1b-888f-95a0187a7678, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.512Z[UTC]].
recon_1     | 2023-01-31 08:04:59,789 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33382
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:04:59,798 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:03,534 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:05:29,115 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:60448
scm_1       | 2023-01-31 07:48:03,560 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=02fede5b-9fce-4aaf-9e53-8eca883e33ad to datanode:1e69a4e3-5301-4460-8965-9fee5bf32e29
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-31 08:05:29,119 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:03,580 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 02fede5b-9fce-4aaf-9e53-8eca883e33ad, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.559Z[UTC]].
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:48:03,581 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:05:29,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:48870
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:48:03,585 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-31 08:05:29,742 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:60582
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:48:03,592 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=7eb7c323-0301-4528-bfd5-9c2467a4d4e7 to datanode:14b917d5-325a-4f29-a0e8-e34b223e06de
recon_1     | 2023-01-31 08:05:29,743 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:48:03,603 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 7eb7c323-0301-4528-bfd5-9c2467a4d4e7, Nodes: 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-31T07:48:03.592Z[UTC]].
recon_1     | 2023-01-31 08:05:29,755 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-31 08:05:48,680 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 08:05:48,680 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:05:48,680 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 237 
recon_1     | 2023-01-31 08:05:48,709 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-31 08:05:48,709 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
recon_1     | 2023-01-31 08:05:48,712 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 08:05:48,716 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 08:05:48,814 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:05:48,816 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2023-01-31 08:05:48,824 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 08:05:59,137 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40398
recon_1     | 2023-01-31 08:05:59,145 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:48:03,604 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:05:59,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42858
recon_1     | 2023-01-31 08:05:59,741 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36792
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:48:03,625 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-31 08:05:59,750 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:48:05,688 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:05:59,757 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:57:03,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33335
om_1        | 2023-01-31 07:57:03,906 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:48:09,390 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46291
recon_1     | 2023-01-31 08:06:29,120 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33370
om_1        | 2023-01-31 07:57:04,892 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 58672-without-scheme
scm_1       | 2023-01-31 07:48:09,446 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1     | 2023-01-31 08:06:29,136 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:57:10,353 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32865
scm_1       | 2023-01-31 07:48:10,691 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:06:29,726 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:51122
om_1        | 2023-01-31 07:57:10,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:48:15,416 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:36057
recon_1     | 2023-01-31 08:06:29,735 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40642
recon_1     | 2023-01-31 08:06:29,740 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:06:29,741 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:15,449 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2023-01-31 07:57:16,408 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38935
recon_1     | 2023-01-31 08:06:48,834 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:48:15,692 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:57:16,444 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:48:20,692 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:06:48,835 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:57:22,717 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33109
scm_1       | 2023-01-31 07:48:23,871 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39921
recon_1     | 2023-01-31 08:06:48,835 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 255 
om_1        | 2023-01-31 07:57:22,746 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:48:23,898 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1     | 2023-01-31 08:06:48,862 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-31 08:06:48,863 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
om_1        | 2023-01-31 07:57:29,499 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43355
om_1        | 2023-01-31 07:57:29,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:06:48,883 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:48:25,692 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:48:30,693 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:57:35,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40171
recon_1     | 2023-01-31 08:06:48,883 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-31 07:48:32,585 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39747
scm_1       | 2023-01-31 07:48:32,629 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:48:33,629 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 07:57:35,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:57:42,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40613
scm_1       | 2023-01-31 07:48:34,223 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:52974
scm_1       | 2023-01-31 07:48:34,235 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:48:34,509 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48748
om_1        | 2023-01-31 07:57:42,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:57:47,076 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:41763
scm_1       | 2023-01-31 07:48:34,538 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:48:34,621 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:58982
scm_1       | 2023-01-31 07:48:34,639 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:48:35,694 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:06:48,977 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:06:48,977 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2023-01-31 07:48:37,412 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 409651ee-63d0-4368-a01a-aa485fe71506, Nodes: ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:ee1a73fb-90e8-4573-a632-4d493b4c1d75, CreationTimestamp2023-01-31T07:48:03.221Z[UTC]] moved to OPEN state
scm_1       | 2023-01-31 07:48:37,482 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om_1        | 2023-01-31 07:57:47,089 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:57:48,823 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42439
scm_1       | 2023-01-31 07:48:37,554 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:39,155 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
om_1        | 2023-01-31 07:57:48,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:57:55,729 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36595
scm_1       | 2023-01-31 07:48:40,695 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:06:48,977 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-31 07:57:55,750 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:48:43,164 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:45,416 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 7eb7c323-0301-4528-bfd5-9c2467a4d4e7, Nodes: 14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:14b917d5-325a-4f29-a0e8-e34b223e06de, CreationTimestamp2023-01-31T07:48:03.592Z[UTC]] moved to OPEN state
recon_1     | 2023-01-31 08:06:59,102 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36254
om_1        | 2023-01-31 07:58:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:48:45,426 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:48:45,457 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:45,551 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 02fede5b-9fce-4aaf-9e53-8eca883e33ad, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:1e69a4e3-5301-4460-8965-9fee5bf32e29, CreationTimestamp2023-01-31T07:48:03.559Z[UTC]] moved to OPEN state
scm_1       | 2023-01-31 07:48:45,573 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-31 08:06:59,120 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:06:59,744 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:47510
scm_1       | 2023-01-31 07:48:45,576 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2023-01-31 08:06:59,748 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:37040
recon_1     | 2023-01-31 08:06:59,755 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:45,696 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:06:59,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:07:29,096 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:54470
scm_1       | 2023-01-31 07:48:50,634 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:50,688 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:50,698 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:48:51,835 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39403
scm_1       | 2023-01-31 07:48:51,856 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:48:55,085 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: defd148e-7304-4d1b-888f-95a0187a7678, Nodes: 1e69a4e3-5301-4460-8965-9fee5bf32e29(ozonesecure_datanode_2.ozonesecure_default/172.18.0.9)14b917d5-325a-4f29-a0e8-e34b223e06de(ozonesecure_datanode_3.ozonesecure_default/172.18.0.6)ee1a73fb-90e8-4573-a632-4d493b4c1d75(ozonesecure_datanode_1.ozonesecure_default/172.18.0.10), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:1e69a4e3-5301-4460-8965-9fee5bf32e29, CreationTimestamp2023-01-31T07:48:03.512Z[UTC]] moved to OPEN state
scm_1       | 2023-01-31 07:48:55,111 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm_1       | 2023-01-31 07:48:55,124 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
recon_1     | 2023-01-31 08:07:29,106 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:07:29,733 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:42160
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
recon_1     | 2023-01-31 08:07:29,741 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60422
recon_1     | 2023-01-31 08:07:29,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1       | 2023-01-31 07:48:55,140 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:07:29,751 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:48:55,191 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-31 08:07:48,996 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:48:55,698 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:07:48,997 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:07:48,997 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 268 
recon_1     | 2023-01-31 08:07:49,031 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-31 08:07:49,031 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:07:49,037 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 08:07:49,037 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 08:07:49,117 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:07:49,117 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-31 08:07:49,118 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 08:07:59,095 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:58604
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-31 08:07:59,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:49:00,698 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:07:59,725 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:47980
recon_1     | 2023-01-31 08:07:59,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:34254
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:49:00,987 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45983
scm_1       | 2023-01-31 07:49:01,021 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:49:03,631 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:49:05,702 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:58:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-31 08:07:59,747 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:07:59,751 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:08:29,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:50426
recon_1     | 2023-01-31 08:08:29,123 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
recon_1     | 2023-01-31 08:08:29,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:47428
scm_1       | 2023-01-31 07:49:10,707 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:08:29,738 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60630
recon_1     | 2023-01-31 08:08:29,742 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-31 08:08:29,750 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:08:49,123 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-31 07:49:13,199 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:53436
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:08:49,124 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-31 07:49:13,211 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:49:15,707 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:16,378 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:43619
recon_1     | 2023-01-31 08:08:49,125 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 285 
scm_1       | 2023-01-31 07:49:16,389 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:49:20,719 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:08:49,165 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 9, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-31 08:08:49,165 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 9 records
scm_1       | 2023-01-31 07:49:20,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38338
scm_1       | 2023-01-31 07:49:20,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:08:49,170 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:08:49,170 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:49:24,904 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41023
scm_1       | 2023-01-31 07:49:24,924 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1     | 2023-01-31 08:08:49,272 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-31 07:49:24,950 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm_1       | 2023-01-31 07:49:24,978 [6dfb726e-350e-430b-835b-cf79da791979@group-370D3E099E21-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
scm_1       | 2023-01-31 07:49:24,982 [IPC Server handler 0 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:49:25,159 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:50140
scm_1       | 2023-01-31 07:49:25,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:08:49,272 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2023-01-31 07:49:25,719 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:28,758 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:44718
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:08:49,272 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:49:28,800 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1     | 2023-01-31 08:08:59,096 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:48634
recon_1     | 2023-01-31 08:08:59,107 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:58:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:49:29,256 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:55222
scm_1       | 2023-01-31 07:49:29,310 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:43235
recon_1     | 2023-01-31 08:08:59,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:56418
scm_1       | 2023-01-31 07:49:29,314 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-31 07:49:29,315 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46288
scm_1       | 2023-01-31 07:49:29,327 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-31 07:49:29,328 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
recon_1     | 2023-01-31 08:08:59,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38532
scm_1       | 2023-01-31 07:49:29,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59476
scm_1       | 2023-01-31 07:49:29,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:49:30,720 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:33,638 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:49:35,720 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:39,038 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:43957
recon_1     | 2023-01-31 08:08:59,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:49:39,050 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:49:40,722 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:45,722 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:49:46,714 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:39893
recon_1     | 2023-01-31 08:08:59,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:49:46,765 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:49:50,724 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-31 08:09:29,108 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34860
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:09:29,117 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:49:55,724 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:29,730 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33358
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:49:59,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:51816
recon_1     | 2023-01-31 08:09:29,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35472
om_1        | 2023-01-31 07:58:05,236 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42107
scm_1       | 2023-01-31 07:49:59,167 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:29,735 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:58:05,266 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:49:59,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35600
om_1        | 2023-01-31 07:58:14,931 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46777
om_1        | 2023-01-31 07:58:14,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:09:29,765 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 07:58:26,277 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36653
om_1        | 2023-01-31 07:58:26,300 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:58:36,423 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33013
om_1        | 2023-01-31 07:58:36,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:58:43,033 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42417
om_1        | 2023-01-31 07:58:43,053 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:09:46,792 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
om_1        | 2023-01-31 07:58:47,337 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:37151
om_1        | 2023-01-31 07:58:47,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:58:49,335 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33493
om_1        | 2023-01-31 07:58:49,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:09:46,795 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
om_1        | 2023-01-31 07:59:00,015 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:49:59,834 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:58954
recon_1     | 2023-01-31 08:09:46,937 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:09:46,939 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 30 milliseconds.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:49:59,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:49,302 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:49:59,846 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:49,302 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:50:00,724 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:09:49,302 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 294 
scm_1       | 2023-01-31 07:50:03,640 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:50:05,725 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:10,725 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:15,726 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:49,329 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:50:20,727 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:25,730 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:29,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:47378
scm_1       | 2023-01-31 07:50:29,152 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:49,329 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
scm_1       | 2023-01-31 07:50:29,798 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59776
scm_1       | 2023-01-31 07:50:29,813 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41336
scm_1       | 2023-01-31 07:50:29,824 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:50:29,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:49,333 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:50:30,732 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:31,898 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46497
scm_1       | 2023-01-31 07:50:31,916 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:50:33,642 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:50:35,733 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:40,733 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:49,334 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-31 07:50:45,734 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:50:50,734 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:09:49,467 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-31 07:59:00,021 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:50:55,735 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:49,469 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 07:50:59,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40276
recon_1     | 2023-01-31 08:09:49,486 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:50:59,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:09:59,122 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:60798
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:50:59,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:55450
scm_1       | 2023-01-31 07:50:59,849 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59638
scm_1       | 2023-01-31 07:50:59,852 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:50:59,866 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:51:00,735 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:59,150 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:09:59,732 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:54016
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:51:03,643 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-31 08:09:59,737 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34572
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:51:05,736 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:09:59,738 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:51:10,736 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-31 08:09:59,766 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:51:15,737 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:10:29,101 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45240
scm_1       | 2023-01-31 07:51:20,737 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:10:29,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:51:25,738 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-31 08:10:29,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:56564
scm_1       | 2023-01-31 07:51:29,140 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:54870
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:10:29,737 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43472
scm_1       | 2023-01-31 07:51:29,163 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-31 08:10:29,749 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:51:29,757 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45522
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:10:29,754 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:51:29,767 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 07:59:00,025 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:51:29,779 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:58810
recon_1     | 2023-01-31 08:10:49,500 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 07:51:29,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:10:49,501 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:10:49,501 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 309 
scm_1       | 2023-01-31 07:51:30,739 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:10:49,583 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:51:33,645 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-31 08:10:49,584 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2023-01-31 08:10:49,588 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 08:10:49,588 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 08:10:49,670 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:10:49,672 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2023-01-31 08:10:49,676 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 08:10:59,101 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37652
recon_1     | 2023-01-31 08:10:59,109 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:10:59,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:41942
recon_1     | 2023-01-31 08:10:59,745 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:10:59,765 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:57624
recon_1     | 2023-01-31 08:10:59,791 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:11:29,109 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:52362
recon_1     | 2023-01-31 08:11:29,121 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:51:35,740 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:11:29,728 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:47002
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:11:29,752 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35084
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:11:29,761 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:51:40,741 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:11:29,802 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 07:59:00,235 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40859
om_1        | 2023-01-31 07:59:00,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:51:45,742 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:51:50,743 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:11:49,687 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2023-01-31 07:59:08,980 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37439
scm_1       | 2023-01-31 07:51:55,743 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:59:09,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:59:15,172 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37873
recon_1     | 2023-01-31 08:11:49,687 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-31 07:59:15,189 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:49,688 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 322 
om_1        | 2023-01-31 07:59:21,490 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43965
om_1        | 2023-01-31 07:59:21,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:51:59,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49304
om_1        | 2023-01-31 07:59:31,874 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43091
recon_1     | 2023-01-31 08:11:49,721 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 4, SequenceNumber diff: 9, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:51:59,148 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 07:59:31,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:49,721 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 9 records
om_1        | 2023-01-31 07:59:38,290 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44855
scm_1       | 2023-01-31 07:51:59,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48408
om_1        | 2023-01-31 07:59:38,321 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 07:59:44,919 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43371
recon_1     | 2023-01-31 08:11:49,729 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:51:59,768 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:36654
om_1        | 2023-01-31 07:59:44,936 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:49,729 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 08:11:49,820 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-31 07:59:47,602 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:44163
scm_1       | 2023-01-31 07:51:59,777 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:11:49,821 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-31 08:11:49,821 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-31 07:59:47,616 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:59,115 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:54758
om_1        | 2023-01-31 07:59:51,801 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40503
recon_1     | 2023-01-31 08:11:59,118 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:51:59,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 07:59:51,826 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:59,746 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35330
scm_1       | 2023-01-31 07:52:00,744 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 07:59:58,864 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36083
om_1        | 2023-01-31 07:59:58,883 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:11:59,754 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:56156
scm_1       | 2023-01-31 07:52:03,648 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:52:05,744 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:11:59,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:11:59,784 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:52:10,407 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35707
scm_1       | 2023-01-31 07:52:10,424 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1     | 2023-01-31 08:12:29,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57944
recon_1     | 2023-01-31 08:12:29,114 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:12:29,757 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:34336
recon_1     | 2023-01-31 08:12:29,769 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:12:29,784 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:37698
recon_1     | 2023-01-31 08:12:29,798 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:00:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
recon_1     | 2023-01-31 08:12:49,827 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:12:49,827 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:52:10,745 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:15,745 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:12:49,827 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 331 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:12:49,856 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-31 07:52:20,746 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:25,747 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:29,092 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42086
recon_1     | 2023-01-31 08:12:49,856 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
scm_1       | 2023-01-31 07:52:29,110 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:52:29,823 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:52566
scm_1       | 2023-01-31 07:52:29,832 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:51264
recon_1     | 2023-01-31 08:12:49,879 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:52:29,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:52:29,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:52:29,877 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46185
recon_1     | 2023-01-31 08:12:49,880 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-31 07:52:29,879 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:52:30,747 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:33,650 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-31 08:12:49,942 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:12:49,943 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:12:49,947 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:12:59,105 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:33340
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:00:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-31 08:12:59,113 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 07:52:35,747 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:40,749 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:12:59,716 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44256
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:12:59,734 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:46514
recon_1     | 2023-01-31 08:12:59,735 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:52:45,750 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:50,751 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:52:55,752 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-31 07:52:59,094 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37936
recon_1     | 2023-01-31 08:12:59,742 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:13:29,113 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:54626
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:13:29,115 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:00:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:52:59,105 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:13:29,755 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:58140
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 07:52:59,770 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:52790
recon_1     | 2023-01-31 08:13:29,766 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:54658
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:52:59,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:50484
recon_1     | 2023-01-31 08:13:29,771 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:52:59,791 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:13:29,786 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:13:49,956 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 08:13:49,956 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:13:49,956 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 346 
recon_1     | 2023-01-31 08:13:49,987 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:52:59,792 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-31 08:13:49,987 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:53:00,753 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:13:49,991 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:13:49,992 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-31 07:53:03,653 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-31 08:13:50,083 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-31 07:53:05,753 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-31 08:13:50,084 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2023-01-31 08:13:50,089 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:53:10,754 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:13:59,103 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:43682
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:13:59,116 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:00:04,814 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34489
recon_1     | 2023-01-31 08:13:59,729 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39276
om_1        | 2023-01-31 08:00:04,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:53:15,754 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:13:59,747 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:13:59,752 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:43266
scm_1       | 2023-01-31 07:53:17,136 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36757
om_1        | 2023-01-31 08:00:10,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38081
om_1        | 2023-01-31 08:00:10,867 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:00:17,504 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45445
om_1        | 2023-01-31 08:00:17,532 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:53:17,143 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1     | 2023-01-31 08:13:59,765 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:00:23,904 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40501
recon_1     | 2023-01-31 08:14:29,106 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34360
scm_1       | 2023-01-31 07:53:17,229 [IPC Server handler 15 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
recon_1     | 2023-01-31 08:14:29,115 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:14:29,720 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39314
recon_1     | 2023-01-31 08:14:29,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:40548
scm_1       | 2023-01-31 07:53:20,754 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 08:00:23,941 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-31 08:14:29,742 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:14:29,758 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:14:46,796 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
om_1        | 2023-01-31 08:00:30,684 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33647
recon_1     | 2023-01-31 08:14:46,799 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 1 containers.
recon_1     | 2023-01-31 08:14:46,996 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
om_1        | 2023-01-31 08:00:30,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:53:25,754 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-31 08:00:36,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45723
recon_1     | 2023-01-31 08:14:46,999 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 55 milliseconds.
scm_1       | 2023-01-31 07:53:29,146 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57714
om_1        | 2023-01-31 08:00:37,018 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:00:43,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35617
om_1        | 2023-01-31 08:00:43,188 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:00:47,831 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:45839
scm_1       | 2023-01-31 07:53:29,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:14:50,093 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 08:14:50,093 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:14:50,093 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 363 
recon_1     | 2023-01-31 08:14:50,121 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 16, SequenceNumber Lag from OM 0.
om_1        | 2023-01-31 08:00:47,847 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:53:29,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:53908
recon_1     | 2023-01-31 08:14:50,121 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 16 records
recon_1     | 2023-01-31 08:14:50,130 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-31 08:14:50,131 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-31 08:14:50,173 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-31 08:14:50,174 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2023-01-31 08:14:50,176 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 08:14:59,099 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:58988
recon_1     | 2023-01-31 08:14:59,108 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:00:49,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33711
scm_1       | 2023-01-31 07:53:29,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60802
recon_1     | 2023-01-31 08:14:59,739 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:51920
om_1        | 2023-01-31 08:00:49,785 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:53:29,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:14:59,744 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60486
om_1        | 2023-01-31 08:00:55,866 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35665
scm_1       | 2023-01-31 07:53:29,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:14:59,747 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:00:55,890 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:14:59,772 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:15:29,100 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:60362
scm_1       | 2023-01-31 07:53:30,755 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-31 08:15:29,103 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:53:33,655 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-31 08:15:29,757 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35408
scm_1       | 2023-01-31 07:53:35,755 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-31 08:15:29,759 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35138
scm_1       | 2023-01-31 07:53:40,757 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-31 08:15:29,763 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-31 07:53:45,757 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-31 08:15:29,770 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:15:50,180 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-31 08:15:50,180 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-31 08:15:50,180 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 379 
recon_1     | 2023-01-31 08:15:50,220 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-31 08:15:50,220 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
recon_1     | 2023-01-31 08:15:50,222 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-31 07:53:50,759 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-31 08:15:50,222 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:53:55,762 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
recon_1     | 2023-01-31 08:15:50,285 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:53:59,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39558
recon_1     | 2023-01-31 08:15:50,286 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-31 08:15:50,286 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-31 08:15:54,097 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60966
recon_1     | 2023-01-31 08:15:54,121 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:15:54,122 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure_datanode_3.ozonesecure_default.
recon_1     | 2023-01-31 08:15:54,164 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
recon_1     | 2023-01-31 08:15:59,098 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:50878
recon_1     | 2023-01-31 08:15:59,100 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-31 08:15:59,727 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:45892
scm_1       | 2023-01-31 07:53:59,137 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-31 08:15:59,740 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-31 08:01:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 07:53:59,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35878
scm_1       | 2023-01-31 07:53:59,775 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42936
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:53:59,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:53:59,797 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:54:00,762 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:03,657 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:54:05,764 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:10,766 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:54:15,767 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:20,672 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:54:20,674 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:54:20,768 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:54:25,769 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:54:29,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:58154
scm_1       | 2023-01-31 07:54:29,179 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:54:29,802 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35410
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:54:29,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:54:29,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60188
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:54:29,848 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:54:30,772 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:33,661 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:54:35,773 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:40,774 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:45,775 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:01:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:54:46,800 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:41779
scm_1       | 2023-01-31 07:54:46,803 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:54:50,677 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:54:50,682 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:54:50,776 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:54:55,780 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:54:59,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49886
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:54:59,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:54:59,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49650
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:54:59,767 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36168
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:01:02,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40199
scm_1       | 2023-01-31 07:54:59,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:01:02,227 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:08,722 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36825
scm_1       | 2023-01-31 07:54:59,793 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:01:08,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:09,537 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:58672-without-scheme for user:testuser
scm_1       | 2023-01-31 07:55:00,781 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:01:15,223 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44445
scm_1       | 2023-01-31 07:55:03,662 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 08:01:15,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:55:05,781 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:10,782 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:01:22,390 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40453
scm_1       | 2023-01-31 07:55:15,784 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:20,677 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:55:20,682 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:55:20,785 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:25,785 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:01:22,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:29,879 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39381
om_1        | 2023-01-31 08:01:29,903 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:35,694 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36557
om_1        | 2023-01-31 08:01:35,720 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:36,467 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-with-host for user:testuser
om_1        | 2023-01-31 08:01:41,746 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39495
om_1        | 2023-01-31 08:01:41,773 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:55:29,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39016
scm_1       | 2023-01-31 07:55:29,156 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:55:29,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44388
scm_1       | 2023-01-31 07:55:29,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:55:29,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:60472
scm_1       | 2023-01-31 07:55:29,783 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:55:30,786 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:32,812 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38965
scm_1       | 2023-01-31 07:55:32,820 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:55:33,664 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 08:01:47,994 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:42927
scm_1       | 2023-01-31 07:55:35,787 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:40,787 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:01:48,001 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:48,761 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43555
scm_1       | 2023-01-31 07:55:45,788 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:01:48,777 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:01:55,705 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40411
scm_1       | 2023-01-31 07:55:50,678 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:01:55,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:55:50,683 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:02:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:02:00,020 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:02:02,433 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38639
om_1        | 2023-01-31 08:02:02,487 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:08,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42611
om_1        | 2023-01-31 08:02:08,745 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:09,530 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 39460-with-host
om_1        | 2023-01-31 08:02:14,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45125
om_1        | 2023-01-31 08:02:14,870 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:21,717 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36081
om_1        | 2023-01-31 08:02:21,742 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:28,892 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43873
om_1        | 2023-01-31 08:02:28,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:35,179 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33261
om_1        | 2023-01-31 08:02:35,203 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:41,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45427
scm_1       | 2023-01-31 07:55:50,789 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:55,790 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:55:59,086 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57506
scm_1       | 2023-01-31 07:55:59,096 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:55:59,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46798
scm_1       | 2023-01-31 07:55:59,768 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:55:59,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44672
scm_1       | 2023-01-31 07:55:59,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:00,790 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:03,665 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:56:05,791 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:10,792 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:15,793 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:20,678 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:56:20,683 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:56:20,795 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:25,796 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:29,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:38282
scm_1       | 2023-01-31 07:56:29,122 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:29,729 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49626
scm_1       | 2023-01-31 07:56:29,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:34604
scm_1       | 2023-01-31 07:56:29,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:29,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:30,801 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:33,667 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:56:35,805 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:40,806 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:45,807 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:50,679 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:56:50,683 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:56:50,807 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:55,809 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:56:59,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:46938
scm_1       | 2023-01-31 07:56:59,154 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:59,754 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38530
scm_1       | 2023-01-31 07:56:59,785 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:56:59,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39408
scm_1       | 2023-01-31 07:56:59,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:00,809 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:03,668 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:57:05,810 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:10,811 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:15,812 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:20,679 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:57:20,683 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:57:20,813 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:25,813 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:29,144 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34810
scm_1       | 2023-01-31 07:57:29,170 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:29,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:35870
scm_1       | 2023-01-31 07:57:29,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41402
scm_1       | 2023-01-31 07:57:29,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:29,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:30,814 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:33,670 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:57:35,814 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:40,815 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:45,816 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:50,680 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:57:50,684 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:57:50,818 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:55,819 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:57:56,684 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35003
scm_1       | 2023-01-31 07:57:56,695 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:57:59,121 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:49488
scm_1       | 2023-01-31 07:57:59,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:59,795 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34132
scm_1       | 2023-01-31 07:57:59,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:57:59,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:52500
scm_1       | 2023-01-31 07:57:59,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:58:00,819 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:58:03,671 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:58:05,822 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:58:10,823 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:58:15,824 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:58:15,854 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39359
scm_1       | 2023-01-31 07:58:15,861 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 07:58:20,681 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:58:20,684 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:58:20,825 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:02:41,632 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:48,164 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:46669
om_1        | 2023-01-31 08:02:48,178 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:48,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38463
om_1        | 2023-01-31 08:02:48,520 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:02:54,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36945
om_1        | 2023-01-31 08:02:54,923 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:00,011 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:03:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:03:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:03:01,535 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34389
om_1        | 2023-01-31 08:03:01,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:11,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34235
om_1        | 2023-01-31 08:03:11,299 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:20,334 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39825
om_1        | 2023-01-31 08:03:20,355 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:30,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42481
om_1        | 2023-01-31 08:03:30,908 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:40,062 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33477
om_1        | 2023-01-31 08:03:40,086 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:46,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36407
om_1        | 2023-01-31 08:03:46,582 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:48,382 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:40807
om_1        | 2023-01-31 08:03:48,388 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:03:52,778 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39933
om_1        | 2023-01-31 08:03:52,807 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:04:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:04:00,014 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:04:00,016 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:58:25,826 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:58:29,158 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:53430
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:58:29,162 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:58:29,810 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46074
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:04:02,895 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46383
om_1        | 2023-01-31 08:04:02,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:04:12,386 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46349
scm_1       | 2023-01-31 07:58:29,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:04:12,411 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:04:19,006 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39543
om_1        | 2023-01-31 08:04:19,024 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:58:29,833 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44812
om_1        | 2023-01-31 08:04:25,148 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41993
om_1        | 2023-01-31 08:04:25,170 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:58:29,837 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:04:34,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32837
om_1        | 2023-01-31 08:04:34,878 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:58:30,827 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:04:42,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37279
om_1        | 2023-01-31 08:04:42,631 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:04:48,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:36849
om_1        | 2023-01-31 08:04:48,544 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:58:33,674 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 08:04:49,308 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46649
om_1        | 2023-01-31 08:04:49,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 07:58:35,828 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:04:55,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36355
om_1        | 2023-01-31 08:04:55,436 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:05:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:58:40,828 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:58:45,829 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:58:50,398 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38531
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:58:50,402 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 07:58:50,681 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:58:50,684 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:58:50,830 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:58:55,831 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:58:59,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45082
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:58:59,125 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:58:59,793 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39694
om_1        | 2023-01-31 08:05:00,014 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:58:59,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 07:58:59,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:54318
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:58:59,850 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:59:00,832 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:59:03,677 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:59:05,833 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:59:10,835 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:59:15,836 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:59:17,106 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38261
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:59:17,110 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:59:20,682 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:59:20,685 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:59:20,837 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:05:00,015 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 07:59:25,838 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 07:59:29,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:48218
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:59:29,139 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 07:59:29,784 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:42376
scm_1       | 2023-01-31 07:59:29,794 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:58526
scm_1       | 2023-01-31 07:59:29,801 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 07:59:29,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:59:30,838 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 07:59:33,679 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 07:59:35,839 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:59:40,841 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 07:59:45,844 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:59:46,863 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:34181
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 07:59:46,868 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 07:59:50,683 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 07:59:50,685 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 07:59:50,844 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 07:59:55,845 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 07:59:59,113 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:38734
scm_1       | 2023-01-31 07:59:59,118 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 07:59:59,810 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:39140
scm_1       | 2023-01-31 07:59:59,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:51462
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 07:59:59,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 07:59:59,838 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:05:02,371 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41151
scm_1       | 2023-01-31 08:00:00,846 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:05:02,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:00:03,681 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:00:05,847 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:05:09,088 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37417
scm_1       | 2023-01-31 08:00:10,848 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:15,850 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:05:09,110 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:00:17,100 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33653
scm_1       | 2023-01-31 08:00:17,109 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:00:20,683 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:05:15,532 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35455
scm_1       | 2023-01-31 08:00:20,685 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:05:15,573 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:00:20,851 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:25,852 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:05:21,842 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35189
scm_1       | 2023-01-31 08:00:29,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:53718
om_1        | 2023-01-31 08:05:21,873 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:00:29,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:00:29,751 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38558
scm_1       | 2023-01-31 08:00:29,767 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:49884
om_1        | 2023-01-31 08:05:27,601 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34959
om_1        | 2023-01-31 08:05:27,629 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:05:34,091 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36349
scm_1       | 2023-01-31 08:00:29,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:05:34,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:00:29,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:00:30,853 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:33,685 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:00:35,854 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:40,856 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:45,857 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:50,684 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:05:40,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42599
om_1        | 2023-01-31 08:05:40,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:05:46,969 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38035
om_1        | 2023-01-31 08:05:46,990 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:05:48,691 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:44303
om_1        | 2023-01-31 08:05:48,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:05:53,689 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40611
om_1        | 2023-01-31 08:05:53,714 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:06:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 2023-01-31 08:00:50,685 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:00:50,858 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:55,859 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:00:59,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:36568
scm_1       | 2023-01-31 08:00:59,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:00:59,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:47440
scm_1       | 2023-01-31 08:00:59,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:53940
scm_1       | 2023-01-31 08:00:59,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:00:59,787 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:01:00,861 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:03,687 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:01:05,865 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:10,867 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:06:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:01:15,867 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:20,684 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:01:20,686 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 08:01:20,868 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:01:25,869 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:29,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:59410
scm_1       | 2023-01-31 08:01:29,124 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:01:29,749 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45262
scm_1       | 2023-01-31 08:01:29,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:37440
scm_1       | 2023-01-31 08:01:29,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:01:29,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:01:30,869 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:33,688 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:01:35,871 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:40,872 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:45,873 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 08:01:50,684 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:01:50,686 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:01:50,874 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:01:55,875 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:01:59,165 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57244
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:01:59,172 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:01:59,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43478
om_1        | 2023-01-31 08:06:00,246 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37691
scm_1       | 2023-01-31 08:01:59,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:06:00,274 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:06:06,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36033
om_1        | 2023-01-31 08:06:06,116 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:01:59,761 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:40762
om_1        | 2023-01-31 08:06:11,889 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35711
om_1        | 2023-01-31 08:06:11,911 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:06:12,656 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-with-host for user:testuser
scm_1       | 2023-01-31 08:01:59,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:06:18,414 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40845
om_1        | 2023-01-31 08:06:18,435 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:00,876 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:26,841 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45535
scm_1       | 2023-01-31 08:02:03,691 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:02:05,877 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:26,892 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:10,877 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:31,564 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41083
scm_1       | 2023-01-31 08:02:15,879 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:02:20,685 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:02:20,686 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:06:31,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:20,880 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:37,574 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36917
om_1        | 2023-01-31 08:06:37,594 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:25,880 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:06:38,357 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-with-errors for user:testuser
om_1        | 2023-01-31 08:06:43,482 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38865
scm_1       | 2023-01-31 08:02:29,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:56634
om_1        | 2023-01-31 08:06:43,503 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:06:48,847 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:41689
om_1        | 2023-01-31 08:06:48,856 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:29,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:06:53,696 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37087
om_1        | 2023-01-31 08:06:53,733 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:02:29,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:50222
om_1        | 2023-01-31 08:06:54,619 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 39460-with-errors
scm_1       | 2023-01-31 08:02:29,775 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:53196
om_1        | 2023-01-31 08:07:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:02:29,795 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:02:29,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 2023-01-31 08:02:30,881 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:02:33,692 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:02:35,881 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:02:40,882 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:02:45,882 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:02:50,685 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:02:50,686 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:02:50,884 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:02:55,886 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:02:59,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:47330
om_1        | 2023-01-31 08:07:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 08:02:59,136 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:02:59,774 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38610
scm_1       | 2023-01-31 08:02:59,784 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:46154
scm_1       | 2023-01-31 08:02:59,799 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:02:59,802 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:03:00,887 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:03:02,377 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36675
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:03:02,397 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:03:03,695 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:03:05,887 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:03:10,888 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:03:15,889 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:03:20,686 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:03:20,687 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:03:20,889 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:03:21,332 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36113
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:03:21,338 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:03:25,890 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:03:29,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:50802
om_1        | 2023-01-31 08:07:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 08:03:29,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:03:29,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:55282
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:03:29,798 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:03:29,811 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38720
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:03:29,816 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:03:30,891 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:03:33,696 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:03:35,892 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:07:00,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38029
om_1        | 2023-01-31 08:07:00,571 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:40,893 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:07:09,739 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35519
om_1        | 2023-01-31 08:07:09,763 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:45,894 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:07:15,779 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41275
om_1        | 2023-01-31 08:07:15,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:50,686 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:07:22,207 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36055
scm_1       | 2023-01-31 08:03:50,688 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:07:22,239 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:50,895 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:07:23,113 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-acls for user:testuser
scm_1       | 2023-01-31 08:03:53,822 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33939
om_1        | 2023-01-31 08:07:28,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36053
scm_1       | 2023-01-31 08:03:53,831 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-31 08:07:28,202 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:07:34,716 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35057
scm_1       | 2023-01-31 08:03:55,896 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:07:34,741 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:07:40,936 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34303
om_1        | 2023-01-31 08:07:40,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:59,105 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:59644
om_1        | 2023-01-31 08:07:47,513 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34847
om_1        | 2023-01-31 08:07:47,531 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:59,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:07:49,008 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:42899
om_1        | 2023-01-31 08:07:49,018 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:59,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45672
om_1        | 2023-01-31 08:07:53,665 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45087
om_1        | 2023-01-31 08:07:53,681 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:59,746 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:32906
om_1        | 2023-01-31 08:07:59,948 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39503
om_1        | 2023-01-31 08:07:59,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:03:59,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:08:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 2023-01-31 08:03:59,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:04:00,897 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:04:03,701 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:04:05,898 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:04:10,901 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:15,901 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:17,102 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40347
scm_1       | 2023-01-31 08:04:17,105 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:04:20,687 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:04:20,688 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:04:20,902 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:25,904 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:29,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40738
scm_1       | 2023-01-31 08:04:29,128 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:04:29,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60584
scm_1       | 2023-01-31 08:04:29,781 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:04:29,802 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59548
scm_1       | 2023-01-31 08:04:29,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:04:30,905 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:33,703 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:04:35,906 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:40,907 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:45,908 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:46,890 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:39747
scm_1       | 2023-01-31 08:04:46,899 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 08:04:50,688 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:04:50,688 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:04:50,910 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:55,911 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:04:59,134 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:43244
scm_1       | 2023-01-31 08:04:59,164 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:04:59,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:37356
scm_1       | 2023-01-31 08:04:59,776 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:04:59,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:56118
scm_1       | 2023-01-31 08:04:59,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:00,912 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:03,710 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:05:05,913 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:10,913 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:15,914 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:17,105 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46483
scm_1       | 2023-01-31 08:05:17,113 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:05:20,688 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:05:20,688 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:05:20,915 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:25,915 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:29,099 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37700
scm_1       | 2023-01-31 08:05:29,108 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:29,789 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:53182
scm_1       | 2023-01-31 08:05:29,796 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:45696
scm_1       | 2023-01-31 08:05:29,803 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:29,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:30,916 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:33,712 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:05:35,916 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:40,917 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:45,918 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:08:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:08:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:08:06,304 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44951
om_1        | 2023-01-31 08:08:06,327 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:13,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37409
om_1        | 2023-01-31 08:08:13,409 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:14,188 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 39460-acls
om_1        | 2023-01-31 08:08:19,833 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41193
om_1        | 2023-01-31 08:08:19,854 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:26,075 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37083
om_1        | 2023-01-31 08:08:26,096 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:26,788 [OM StateMachine ApplyTransaction Thread - 0] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /39460-acls/bb1 failed, because acl already exist
om_1        | 2023-01-31 08:08:31,915 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43847
om_1        | 2023-01-31 08:08:31,939 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:38,364 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45953
om_1        | 2023-01-31 08:08:38,383 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:05:50,689 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:05:50,689 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:05:50,919 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:55,920 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:05:59,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37200
scm_1       | 2023-01-31 08:05:59,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:59,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41874
scm_1       | 2023-01-31 08:05:59,776 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:54366
scm_1       | 2023-01-31 08:05:59,778 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:05:59,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:06:00,921 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:06:03,715 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:06:05,923 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:06:10,924 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:06:15,925 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:08:44,651 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33443
om_1        | 2023-01-31 08:08:44,675 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:49,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:42221
om_1        | 2023-01-31 08:08:49,158 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:50,632 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32991
om_1        | 2023-01-31 08:08:50,655 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:08:56,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36849
om_1        | 2023-01-31 08:08:56,054 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:09:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:09:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:09:03,220 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38897
om_1        | 2023-01-31 08:09:03,247 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:13,211 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45745
om_1        | 2023-01-31 08:09:13,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:19,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33523
om_1        | 2023-01-31 08:09:19,554 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:25,554 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35055
om_1        | 2023-01-31 08:09:25,576 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:32,317 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43747
om_1        | 2023-01-31 08:09:32,351 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:37,900 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32959
om_1        | 2023-01-31 08:09:37,935 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:44,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35037
om_1        | 2023-01-31 08:09:44,295 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:49,316 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:39587
om_1        | 2023-01-31 08:09:49,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:50,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44303
om_1        | 2023-01-31 08:09:50,395 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:09:57,165 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37961
om_1        | 2023-01-31 08:09:57,199 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:10:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:10:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:10:03,099 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35159
om_1        | 2023-01-31 08:10:03,122 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:08,934 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32949
om_1        | 2023-01-31 08:10:08,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:14,481 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38457
om_1        | 2023-01-31 08:10:14,506 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:21,147 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37709
om_1        | 2023-01-31 08:10:21,179 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:27,872 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42451
om_1        | 2023-01-31 08:10:27,904 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:34,552 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37087
om_1        | 2023-01-31 08:10:34,573 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:43,827 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43361
om_1        | 2023-01-31 08:10:43,852 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:49,518 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:35391
om_1        | 2023-01-31 08:10:49,533 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:50,561 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35951
om_1        | 2023-01-31 08:10:50,593 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:56,600 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45519
om_1        | 2023-01-31 08:10:56,637 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:10:57,385 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-without-host for user:testuser
om_1        | 2023-01-31 08:11:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:11:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:11:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:11:02,693 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46159
om_1        | 2023-01-31 08:11:02,729 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:08,997 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38737
om_1        | 2023-01-31 08:11:09,023 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:15,374 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44993
om_1        | 2023-01-31 08:11:15,393 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:21,982 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39179
om_1        | 2023-01-31 08:11:21,999 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:29,060 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34053
om_1        | 2023-01-31 08:11:29,139 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:30,178 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 39460-without-host
om_1        | 2023-01-31 08:11:35,369 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43599
om_1        | 2023-01-31 08:11:35,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:41,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34643
om_1        | 2023-01-31 08:11:41,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:47,942 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44663
om_1        | 2023-01-31 08:11:47,975 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:49,708 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:38551
om_1        | 2023-01-31 08:11:49,717 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:11:54,529 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43659
om_1        | 2023-01-31 08:11:54,561 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:00,021 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:12:00,023 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:12:00,023 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:06:20,689 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:06:20,689 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:06:20,926 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:06:25,927 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:06:29,143 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:56062
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:06:29,160 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:12:00,881 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35253
om_1        | 2023-01-31 08:12:00,922 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:07,715 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43643
scm_1       | 2023-01-31 08:06:29,782 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:52338
om_1        | 2023-01-31 08:12:07,739 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:14,051 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39861
om_1        | 2023-01-31 08:12:14,085 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:06:29,786 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:36330
om_1        | 2023-01-31 08:12:20,258 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43299
om_1        | 2023-01-31 08:12:20,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:30,627 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34441
scm_1       | 2023-01-31 08:06:29,803 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:12:30,646 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:40,125 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44567
scm_1       | 2023-01-31 08:06:29,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:12:40,150 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:49,845 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:35685
scm_1       | 2023-01-31 08:06:30,928 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:12:49,851 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:49,888 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45947
scm_1       | 2023-01-31 08:06:33,717 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 08:12:49,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:12:59,045 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44399
om_1        | 2023-01-31 08:12:59,071 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:06:35,928 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:13:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:06:40,929 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:06:45,930 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:06:50,689 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:06:50,690 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:06:50,930 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:06:55,931 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:06:59,118 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:57624
scm_1       | 2023-01-31 08:06:59,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:06:59,728 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60470
scm_1       | 2023-01-31 08:06:59,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:54224
scm_1       | 2023-01-31 08:06:59,738 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:06:59,739 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:13:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:07:00,932 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:03,720 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 08:07:05,933 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:07:10,934 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:07:15,937 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:07:20,690 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:07:20,690 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:07:20,938 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:25,939 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:29,110 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:53136
scm_1       | 2023-01-31 08:07:29,120 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:07:29,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39016
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:07:29,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:53350
scm_1       | 2023-01-31 08:07:29,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:07:29,774 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:07:30,940 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:07:33,723 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:07:35,941 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:40,942 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:07:45,943 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:50,690 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:07:50,691 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:07:50,943 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:07:55,944 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:07:59,124 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45830
scm_1       | 2023-01-31 08:07:59,130 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:07:59,727 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34634
scm_1       | 2023-01-31 08:07:59,750 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59580
om_1        | 2023-01-31 08:13:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:07:59,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:07:59,756 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 08:08:00,952 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 8 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:08:03,727 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:08:05,954 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:08:10,956 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:08:15,957 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:08:20,691 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:08:20,691 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:08:20,958 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:13:05,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45177
om_1        | 2023-01-31 08:13:05,213 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:13:11,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42043
scm_1       | 2023-01-31 08:08:25,959 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:13:11,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:13:21,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46717
scm_1       | 2023-01-31 08:08:29,135 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:37786
om_1        | 2023-01-31 08:13:21,705 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:13:30,495 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40315
scm_1       | 2023-01-31 08:08:29,147 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:13:30,518 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:13:36,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42185
om_1        | 2023-01-31 08:13:36,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:08:29,742 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48022
om_1        | 2023-01-31 08:13:42,210 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42215
om_1        | 2023-01-31 08:13:42,237 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:08:29,760 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:36842
om_1        | 2023-01-31 08:13:49,973 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:45871
om_1        | 2023-01-31 08:13:49,978 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:08:29,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:13:51,383 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34621
om_1        | 2023-01-31 08:13:51,402 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:08:29,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:13:57,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46289
om_1        | 2023-01-31 08:13:57,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:08:30,960 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:08:33,730 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:08:35,964 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 3 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:08:40,966 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:08:45,966 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:08:50,691 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:08:50,691 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:08:50,967 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:08:55,968 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:08:59,112 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:53664
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:08:59,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:08:59,724 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35296
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:08:59,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:50916
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:08:59,759 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:08:59,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:09:00,973 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
scm_1       | 2023-01-31 08:09:03,733 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:09:04,112 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39117
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:09:04,127 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:09:05,974 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:09:10,975 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:09:15,976 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:09:20,691 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:14:04,492 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:34651
scm_1       | 2023-01-31 08:09:20,692 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:14:04,515 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:14:11,252 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46373
om_1        | 2023-01-31 08:14:11,275 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:14:18,168 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45937
scm_1       | 2023-01-31 08:09:20,977 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:09:25,977 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:09:29,120 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:39242
om_1        | 2023-01-31 08:14:18,194 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:14:23,661 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33855
om_1        | 2023-01-31 08:14:23,684 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:14:29,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35419
om_1        | 2023-01-31 08:14:29,211 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:14:35,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43207
om_1        | 2023-01-31 08:14:35,045 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:29,127 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:09:29,781 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40470
om_1        | 2023-01-31 08:14:40,763 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42173
scm_1       | 2023-01-31 08:09:29,805 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:14:40,781 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:29,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:44636
om_1        | 2023-01-31 08:14:46,853 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35545
scm_1       | 2023-01-31 08:09:29,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:14:46,871 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:30,978 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:50,103 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:36349
scm_1       | 2023-01-31 08:09:33,735 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-31 08:14:50,115 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:35,979 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:53,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36239
scm_1       | 2023-01-31 08:09:40,979 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:53,139 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:45,981 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:14:59,568 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43269
om_1        | 2023-01-31 08:14:59,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:09:46,921 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:42621
om_1        | 2023-01-31 08:15:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 2023-01-31 08:09:46,933 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:09:50,692 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:09:50,692 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:09:50,981 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:09:55,982 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:09:59,153 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:55676
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:09:59,157 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:09:59,747 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59630
scm_1       | 2023-01-31 08:09:59,752 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:09:59,775 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40112
scm_1       | 2023-01-31 08:09:59,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:10:00,983 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:03,737 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:10:05,984 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:10,985 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:10:15,986 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:20,692 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:10:20,693 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:10:20,986 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:10:25,987 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:15:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:10:29,129 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:34288
scm_1       | 2023-01-31 08:10:29,142 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 08:10:29,756 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33832
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:10:29,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:57274
scm_1       | 2023-01-31 08:10:29,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:10:29,770 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:10:30,988 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:10:33,745 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:10:35,431 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37533
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:10:35,443 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:10:35,989 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-31 08:10:40,990 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:45,991 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:50,692 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:10:50,693 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:10:50,992 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:55,992 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:10:59,111 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:40982
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:10:59,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:10:59,753 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:54260
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:10:59,772 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:36762
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:10:59,784 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-31 08:10:59,794 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:15:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:11:00,993 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:11:03,746 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:11:05,995 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-31 08:11:10,997 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-31 08:11:15,997 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:11:20,693 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:11:20,693 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:15:05,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33771
om_1        | 2023-01-31 08:15:05,898 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:11:20,998 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:15:12,455 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37141
om_1        | 2023-01-31 08:15:12,483 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:11:25,999 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:15:19,054 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44705
om_1        | 2023-01-31 08:15:19,079 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:11:29,131 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:42618
om_1        | 2023-01-31 08:15:25,063 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43015
om_1        | 2023-01-31 08:15:25,104 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:11:29,143 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:15:25,877 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:39460-without-host for user:testuser
om_1        | 2023-01-31 08:15:31,253 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41741
scm_1       | 2023-01-31 08:11:29,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33410
om_1        | 2023-01-31 08:15:31,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:15:38,143 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:33587
scm_1       | 2023-01-31 08:11:29,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38706
om_1        | 2023-01-31 08:15:38,163 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:15:44,912 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41661
scm_1       | 2023-01-31 08:11:29,780 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:15:44,930 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:15:46,051 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 39460-without-host
scm_1       | 2023-01-31 08:11:29,810 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:15:50,205 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:33497
om_1        | 2023-01-31 08:15:50,212 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:15:50,609 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:38073
scm_1       | 2023-01-31 08:11:31,000 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-31 08:15:50,638 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-31 08:16:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:11:33,749 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 60337-target
scm_1       | 2023-01-31 08:11:36,001 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-31 08:11:41,002 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-31 08:11:46,003 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-31 08:11:50,693 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-31 08:16:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 60337-target
scm_1       | 2023-01-31 08:11:50,694 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:11:51,004 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:11:56,005 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:16:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-31 08:11:59,117 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:53470
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 60337-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-31 08:11:59,132 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-31 08:11:59,731 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49980
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-31 08:11:59,750 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-31 08:11:59,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:53434
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-31 08:16:01,052 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37739
scm_1       | 2023-01-31 08:11:59,772 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-31 08:16:01,077 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-31 08:12:01,006 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:03,752 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:12:06,007 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:11,007 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:16,012 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:20,694 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:12:20,694 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:12:21,014 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:21,252 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44513
scm_1       | 2023-01-31 08:12:21,263 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:12:26,015 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:29,119 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:41818
scm_1       | 2023-01-31 08:12:29,126 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:12:29,744 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:48140
scm_1       | 2023-01-31 08:12:29,812 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:12:29,830 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:50410
scm_1       | 2023-01-31 08:12:29,844 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:12:31,019 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:33,753 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:12:36,019 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:41,020 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:41,049 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44301
scm_1       | 2023-01-31 08:12:41,054 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:12:46,021 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:50,694 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:12:50,694 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:12:51,021 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:56,022 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:12:59,123 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45356
scm_1       | 2023-01-31 08:12:59,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:12:59,748 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:52422
scm_1       | 2023-01-31 08:12:59,760 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:12:59,762 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:59284
scm_1       | 2023-01-31 08:12:59,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:01,023 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:03,755 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:13:06,024 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:11,025 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:12,122 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34019
scm_1       | 2023-01-31 08:13:12,126 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:13:16,026 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:20,694 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:13:20,695 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:13:21,027 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:26,028 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:29,115 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:51708
scm_1       | 2023-01-31 08:13:29,134 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:29,755 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:53364
scm_1       | 2023-01-31 08:13:29,758 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:58584
scm_1       | 2023-01-31 08:13:29,765 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:29,790 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:31,029 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:33,758 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:13:36,029 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:41,030 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:46,031 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:50,695 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:13:50,695 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:13:51,032 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:56,032 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:13:59,098 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:56552
scm_1       | 2023-01-31 08:13:59,114 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:59,765 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:49286
scm_1       | 2023-01-31 08:13:59,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:56204
scm_1       | 2023-01-31 08:13:59,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:13:59,775 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:01,033 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:03,761 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:14:06,033 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:11,035 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:16,037 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:17,156 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36871
scm_1       | 2023-01-31 08:14:17,185 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:14:20,695 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:14:20,696 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:14:21,038 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:26,038 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:29,125 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45158
scm_1       | 2023-01-31 08:14:29,146 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:29,736 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:34870
scm_1       | 2023-01-31 08:14:29,744 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:29,769 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44736
scm_1       | 2023-01-31 08:14:29,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:31,040 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:33,762 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:14:36,040 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:41,041 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:46,042 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:46,981 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:41227
scm_1       | 2023-01-31 08:14:46,989 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 08:14:50,696 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:14:50,696 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:14:51,043 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:56,043 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:14:59,122 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:56070
scm_1       | 2023-01-31 08:14:59,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:59,759 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:49766
scm_1       | 2023-01-31 08:14:59,764 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43560
scm_1       | 2023-01-31 08:14:59,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:14:59,800 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:01,045 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:03,764 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:15:06,045 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:11,046 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:16,048 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:17,144 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37041
scm_1       | 2023-01-31 08:15:17,153 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:15:20,696 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:15:20,696 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:15:21,049 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:26,050 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:29,116 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:44908
scm_1       | 2023-01-31 08:15:29,119 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:29,740 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:60304
scm_1       | 2023-01-31 08:15:29,773 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:29,782 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:38530
scm_1       | 2023-01-31 08:15:29,786 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:31,050 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:33,766 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:15:36,052 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:41,053 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:46,053 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:50,696 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:15:50,697 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:15:51,055 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-31 08:15:51,476 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40399
scm_1       | 2023-01-31 08:15:51,482 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-31 08:15:54,114 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46896
scm_1       | 2023-01-31 08:15:54,123 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:54,147 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.3:39871
scm_1       | 2023-01-31 08:15:54,158 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 08:15:56,057 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm_1       | 2023-01-31 08:15:59,122 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.9:45858
scm_1       | 2023-01-31 08:15:59,141 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:15:59,734 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.10:34100
scm_1       | 2023-01-31 08:15:59,751 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-31 08:16:01,060 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm_1       | 2023-01-31 08:16:01,913 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33223
scm_1       | 2023-01-31 08:16:01,917 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-31 08:16:03,767 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-31 08:16:06,061 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm_1       | 2023-01-31 08:16:11,062 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm_1       | 2023-01-31 08:16:16,062 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
scm_1       | 2023-01-31 08:16:20,697 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:16:20,698 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-31 08:16:21,063 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
