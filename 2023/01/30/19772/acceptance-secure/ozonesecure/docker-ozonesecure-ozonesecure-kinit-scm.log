Attaching to ozonesecure_kms_1, ozonesecure_kdc_1, ozonesecure_datanode_2, ozonesecure_datanode_1, ozonesecure_scm_1, ozonesecure_recon_1, ozonesecure_datanode_3, ozonesecure_om_1, ozonesecure_s3g_1
datanode_1  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_1  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2023-01-30 11:59:49,266 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_1  | /************************************************************
datanode_1  | STARTUP_MSG: Starting HddsDatanodeService
datanode_1  | STARTUP_MSG:   host = 5ffad95da0eb/172.18.0.7
datanode_1  | STARTUP_MSG:   args = []
datanode_1  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_1  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode_1  | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
datanode_1  | STARTUP_MSG:   java = 11.0.14.1
datanode_1  | ************************************************************/
datanode_1  | 2023-01-30 11:59:49,425 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2023-01-30 11:59:49,963 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_1  | 2023-01-30 11:59:50,911 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2023-01-30 11:59:51,846 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_1  | 2023-01-30 11:59:51,850 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_1  | 2023-01-30 11:59:52,775 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:5ffad95da0eb ip:172.18.0.7
datanode_1  | 2023-01-30 11:59:57,657 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_1  | 2023-01-30 11:59:58,873 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode_1  | 2023-01-30 11:59:58,873 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_1  | 2023-01-30 12:00:01,847 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2023-01-30 12:00:01,848 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_1  | 2023-01-30 12:00:01,857 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_1  | 2023-01-30 12:00:01,868 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_1  | 2023-01-30 12:00:06,656 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_1  | 2023-01-30 12:00:06,897 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.7,host:5ffad95da0eb
datanode_1  | 2023-01-30 12:00:06,898 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_1  | 2023-01-30 12:00:06,929 [main] ERROR client.DNCertificateClient: Invalid domain 5ffad95da0eb
datanode_1  | 2023-01-30 12:00:06,930 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@5ffad95da0eb
datanode_1  | 2023-01-30 12:00:11,702 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:13,706 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:15,708 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:17,710 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:19,718 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:21,721 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:23,723 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:25,725 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:27,728 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:29,738 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 5ffad95da0eb/172.18.0.7 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:36,405 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_1  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:38,411 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_1  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_1  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_1  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_1  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_1  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_1  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_1  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:42,187 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_1  | 2023-01-30 12:00:42,290 [main] INFO client.DNCertificateClient: Added certificate [
datanode_1  | [
datanode_1  |   Version: V3
datanode_1  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 
datanode_1  |   Key:  Sun RSA public key, 2048 bits
datanode_1  |   params: null
datanode_1  |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
datanode_1  |   public exponent: 65537
datanode_1  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_1  |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_1  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_1  |   SerialNumber: [    01]
datanode_1  | 
datanode_1  | Certificate Extensions: 3
datanode_1  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | BasicConstraints:[
datanode_1  |   CA:true
datanode_1  |   PathLen:2147483647
datanode_1  | ]
datanode_1  | 
datanode_1  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | KeyUsage [
datanode_1  |   Key_CertSign
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): Loaded
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](Error): preauth spake failed to initialize: No SPAKE preauth groups configured
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): setting up network...
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): setsockopt(8,IPV6_V6ONLY,1) worked
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): setsockopt(10,IPV6_V6ONLY,1) worked
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): set up 4 sockets
kdc_1       | Jan 30 11:59:36 kdc krb5kdc[8](info): commencing operation
kdc_1       | krb5kdc: starting...
kdc_1       | Jan 30 11:59:38 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675079978, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 11:59:49 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.3: ISSUE: authtime 1675079989, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, s3g/s3g@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 11:59:56 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.4: ISSUE: authtime 1675079996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 11:59:58 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.2: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 11:59:58 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.7: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 11:59:58 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.8: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:00:03 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.6: ISSUE: authtime 1675080003, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:00:28 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.5: ISSUE: authtime 1675080028, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, scm/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675079978, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.2: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675079996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.8: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.7: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.6: ISSUE: authtime 1675080003, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:00:48 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080048, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:01:06 kdc krb5kdc[8](info): AS_REQ (2 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17)}) 172.18.0.2: ISSUE: authtime 1675080066, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:01:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.2: ISSUE: authtime 1675080066, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, om/om@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:01:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080048, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
datanode_2  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_2  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 2023-01-30 11:59:48,873 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  | /************************************************************
datanode_2  | STARTUP_MSG: Starting HddsDatanodeService
datanode_2  | STARTUP_MSG:   host = 2850eee4085e/172.18.0.8
datanode_2  | STARTUP_MSG:   args = []
datanode_2  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_1  |   Crl_Sign
datanode_1  | ]
datanode_1  | 
datanode_1  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_1  | SubjectAlternativeName [
datanode_1  |   IPAddress: 172.18.0.5
datanode_1  | ]
datanode_1  | 
datanode_1  | ]
datanode_1  |   Algorithm: [SHA256withRSA]
datanode_1  |   Signature:
datanode_1  | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
datanode_1  | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
datanode_1  | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
datanode_1  | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
datanode_1  | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
datanode_1  | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
datanode_1  | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
datanode_1  | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
datanode_1  | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
datanode_1  | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
datanode_1  | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
datanode_1  | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
datanode_1  | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
datanode_1  | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
datanode_1  | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
datanode_1  | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
datanode_1  | 
datanode_1  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_1  | 2023-01-30 12:00:42,337 [main] INFO client.DNCertificateClient: Added certificate [
datanode_1  | [
datanode_1  |   Version: V3
datanode_2  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
datanode_2  | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
datanode_2  | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | ************************************************************/
datanode_2  | 2023-01-30 11:59:48,962 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_2  | 2023-01-30 11:59:49,531 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_2  | 2023-01-30 11:59:50,348 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_2  | 2023-01-30 11:59:51,656 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
datanode_2  | 2023-01-30 11:59:51,657 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_2  | 2023-01-30 11:59:52,808 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:2850eee4085e ip:172.18.0.8
datanode_2  | 2023-01-30 11:59:57,669 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
datanode_2  | 2023-01-30 11:59:59,104 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode_2  | 2023-01-30 11:59:59,105 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_2  | 2023-01-30 12:00:01,819 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_2  | 2023-01-30 12:00:01,839 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_2  | 2023-01-30 12:00:01,844 [main] INFO client.DNCertificateClient: Certificate client init case: 0
datanode_2  | 2023-01-30 12:00:01,849 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_2  | 2023-01-30 12:00:08,445 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
datanode_2  | 2023-01-30 12:00:08,717 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.8,host:2850eee4085e
datanode_2  | 2023-01-30 12:00:08,721 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_2  | 2023-01-30 12:00:08,753 [main] ERROR client.DNCertificateClient: Invalid domain 2850eee4085e
datanode_2  | 2023-01-30 12:00:08,755 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@2850eee4085e
datanode_2  | 2023-01-30 12:00:13,179 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:15,182 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:17,183 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:19,185 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:21,197 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:23,200 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:25,201 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:27,203 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:29,205 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 30 12:01:24 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:01:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.7: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jan 30 12:01:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.8: ISSUE: authtime 1675079998, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jan 30 12:01:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.4: ISSUE: authtime 1675079996, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, dn/dn@EXAMPLE.COM for recon/recon@EXAMPLE.COM
kdc_1       | Jan 30 12:01:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080084, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:01:36 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080096, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:01:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080096, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:01:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.6: ISSUE: authtime 1675080003, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:01:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.6: ISSUE: authtime 1675080003, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, recon/recon@EXAMPLE.COM for HTTP/om@EXAMPLE.COM
kdc_1       | Jan 30 12:01:45 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080105, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:01:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080105, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:02:01 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:02:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for scm/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:02:14 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080134, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:02:22 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:02:22 kdc krb5kdc[8](info): TGS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, HTTP/scm@EXAMPLE.COM for HTTP/scm@EXAMPLE.COM
kdc_1       | Jan 30 12:02:22 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=dn@5ffad95da0eb
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 
datanode_1  |   Key:  Sun RSA public key, 2048 bits
datanode_1  |   params: null
datanode_1  |   modulus: 26853218150054564271352687135164368587565125546538960888336951061348237012806116609677832981905029186764467775538147922298233183376612519250661343452263397586122352028236842689902456052779477822166383746584428694973160561703494018781800739141214900096067787917894667601558219262314909405410819137409357729781268569572777213398376897493230670211765467673629446362549875619378892384649165407974496075483175315640429108633179638670957951890468119820137043480935981571086718646173837733641438988395508541619915033215610125408228917712273420398549474114540978547431939954229399785529071795918752230369746200221917533485103
datanode_1  |   public exponent: 65537
datanode_1  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_1  |                To: Tue Jan 30 00:00:00 UTC 2024]
datanode_1  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
datanode_1  |   SerialNumber: [    4118e2fb 5a]
datanode_1  | 
datanode_1  | Certificate Extensions: 2
datanode_1  | [1]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | KeyUsage [
datanode_1  |   DigitalSignature
datanode_1  |   Key_Encipherment
datanode_1  |   Data_Encipherment
datanode_1  |   Key_Agreement
datanode_1  | ]
datanode_1  | 
datanode_1  | [2]: ObjectId: 2.5.29.17 Criticality=false
datanode_1  | SubjectAlternativeName [
datanode_1  |   IPAddress: 172.18.0.7
datanode_1  | ]
datanode_1  | 
datanode_1  | ]
datanode_1  |   Algorithm: [SHA256withRSA]
datanode_1  |   Signature:
datanode_1  | 0000: 1D 72 91 6B FB A4 9D BD   5E 3F 54 C6 CA 83 0C 5D  .r.k....^?T....]
datanode_1  | 0010: 8F 2D 82 6E 22 58 63 45   A1 01 CB 2F 80 8B B5 7E  .-.n"XcE.../....
datanode_1  | 0020: E4 99 5E B9 EC 61 74 77   1F BA 6D 30 80 39 5F 1F  ..^..atw..m0.9_.
datanode_1  | 0030: E1 27 CE F4 E6 E6 31 81   18 F4 62 41 92 49 1E BB  .'....1...bA.I..
datanode_1  | 0040: 56 72 79 46 CB D9 27 95   BE 2C 37 38 90 00 F1 54  VryF..'..,78...T
datanode_1  | 0050: 0C B7 E5 84 B1 ED 90 87   5D E4 82 56 35 B0 15 C0  ........]..V5...
datanode_1  | 0060: F3 57 42 0C 14 6F 05 C5   92 DB F0 81 1C BA C0 F3  .WB..o..........
datanode_1  | 0070: 82 CB 17 D5 94 46 FA 18   DE FA 1C C0 78 8C 09 99  .....F......x...
datanode_1  | 0080: 6B 6F FD 20 53 0A 43 D5   5A BC C5 9B B2 86 31 0A  ko. S.C.Z.....1.
datanode_1  | 0090: 82 D8 AE 24 08 10 D1 A5   51 4B F0 4D 4F E8 1E A8  ...$....QK.MO...
datanode_1  | 00A0: 73 86 4D F8 55 FE C4 AE   6E 72 2F 28 5B 69 9F 6B  s.M.U...nr/([i.k
datanode_1  | 00B0: C0 E2 24 F7 E8 36 98 2A   3D AB 33 D7 21 55 41 63  ..$..6.*=.3.!UAc
datanode_1  | 00C0: 01 5C 59 79 94 49 0C E3   90 0A 2A E8 68 49 B0 FC  .\Yy.I....*.hI..
datanode_1  | 00D0: 24 1E C2 1D D1 29 9B 72   B9 38 28 52 B3 AD 17 41  $....).r.8(R...A
datanode_1  | 00E0: 01 7E A6 60 40 20 5B 60   FB 71 7D D2 1F 25 F9 89  ...`@ [`.q...%..
datanode_1  | 00F0: E8 DF BE B2 44 1E 26 63   3D DD 8F D6 62 3D 26 33  ....D.&c=...b=&3
datanode_1  | 
datanode_1  | ] from file:/data/metadata/dn/certs/279590402906.crt.
datanode_1  | 2023-01-30 12:00:42,367 [main] INFO client.DNCertificateClient: Added certificate [
datanode_1  | [
datanode_1  |   Version: V3
datanode_1  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
datanode_1  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 
datanode_1  |   Key:  Sun RSA public key, 2048 bits
datanode_1  |   params: null
datanode_1  |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
datanode_1  |   public exponent: 65537
datanode_1  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_1  |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_1  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_1  |   SerialNumber: [    3b882292 67]
datanode_1  | 
datanode_1  | Certificate Extensions: 3
datanode_1  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | BasicConstraints:[
datanode_1  |   CA:true
datanode_1  |   PathLen:2147483647
datanode_1  | ]
datanode_1  | 
datanode_1  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_1  | KeyUsage [
datanode_1  |   DigitalSignature
datanode_1  |   Key_Encipherment
datanode_1  |   Data_Encipherment
datanode_1  |   Key_Agreement
datanode_1  |   Key_CertSign
datanode_1  |   Crl_Sign
datanode_1  | ]
datanode_1  | 
datanode_1  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_1  | SubjectAlternativeName [
datanode_1  |   IPAddress: 172.18.0.5
datanode_1  | ]
datanode_1  | 
datanode_1  | ]
datanode_1  |   Algorithm: [SHA256withRSA]
datanode_1  |   Signature:
datanode_1  | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
datanode_1  | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
datanode_1  | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
datanode_1  | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
datanode_1  | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
datanode_1  | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
datanode_1  | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
datanode_1  | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
datanode_1  | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
datanode_1  | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
datanode_2  | 2023-01-30 12:00:31,215 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 2850eee4085e/172.18.0.8 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:36,420 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_2  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:38,427 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_2  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_2  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_2  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_2  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 2023-01-30 12:00:42,857 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_2  | 2023-01-30 12:00:43,007 [main] INFO client.DNCertificateClient: Added certificate [
datanode_2  | [
datanode_2  |   Version: V3
datanode_2  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_3  | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
datanode_3  | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_2  | 
datanode_2  |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
datanode_1  | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
datanode_3  | 2023-01-30 11:59:47,041 [main] INFO ozone.HddsDatanodeService: STARTUP_MSG: 
datanode_2  |   params: null
datanode_2  |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
datanode_1  | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
datanode_1  | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
datanode_3  | /************************************************************
datanode_3  | STARTUP_MSG: Starting HddsDatanodeService
datanode_3  | STARTUP_MSG:   host = 51f838724954/172.18.0.4
datanode_1  | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
datanode_1  | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
datanode_3  | STARTUP_MSG:   args = []
datanode_2  |   public exponent: 65537
kdc_1       | Jan 30 12:02:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:02:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:03:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:03:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
kdc_1       | Jan 30 12:03:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:03:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:03:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2023-01-30 11:59:45,817 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
om_1        | STARTUP_MSG: Starting OzoneManager
om_1        | STARTUP_MSG:   host = om/172.18.0.2
om_1        | STARTUP_MSG:   args = [--init]
datanode_1  | 
datanode_1  | ] from file:/data/metadata/dn/certs/CA-255687037543.crt.
datanode_2  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
om_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_3  | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-datanode-1.4.0-SNAPSHOT.jar
kdc_1       | Jan 30 12:03:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kms_1       | WARNING: /opt/hadoop/temp does not exist. Creating.
datanode_1  | 2023-01-30 12:00:42,411 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29073557630 ms and interval 86400000 ms.
datanode_1  | 2023-01-30 12:00:42,411 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_1  | 2023-01-30 12:00:42,617 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1  | 2023-01-30 12:00:43,843 [main] INFO reflections.Reflections: Reflections took 1044 ms to scan 2 urls, producing 100 keys and 224 values 
datanode_1  | 2023-01-30 12:00:44,413 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_1  | 2023-01-30 12:00:45,951 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
kdc_1       | Jan 30 12:03:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
datanode_2  |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_2  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_2  |   SerialNumber: [    01]
datanode_2  | 
datanode_2  | Certificate Extensions: 3
datanode_2  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_3  | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
datanode_3  | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | ************************************************************/
kdc_1       | Jan 30 12:03:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | BasicConstraints:[
datanode_2  |   CA:true
datanode_3  | 2023-01-30 11:59:47,144 [main] INFO ozone.HddsDatanodeService: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_3  | 2023-01-30 11:59:47,815 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
datanode_3  | 2023-01-30 11:59:48,712 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
kdc_1       | Jan 30 12:03:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  |   PathLen:2147483647
datanode_2  | ]
datanode_2  | 
recon_1     | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
kdc_1       | Jan 30 12:04:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:04:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1     | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2023-01-30 12:00:46,094 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
datanode_2  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | 2023-01-30 11:59:50,131 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
kdc_1       | Jan 30 12:04:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
s3g_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
recon_1     | 2023-01-30 11:59:49,772 [main] INFO recon.ReconServer: STARTUP_MSG: 
datanode_1  | 2023-01-30 12:00:46,113 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
om_1        | STARTUP_MSG:   java = 11.0.14.1
kdc_1       | Jan 30 12:04:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080142, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-30 11:59:49,887 [main] INFO security.UserGroupInformation: Login successful for user s3g/s3g@EXAMPLE.COM using keytab file s3g.keytab. Keytab auto renewal enabled : false
s3g_1       | 2023-01-30 11:59:49,888 [main] INFO s3.Gateway: S3Gateway login successful.
recon_1     | /************************************************************
om_1        | ************************************************************/
datanode_1  | 2023-01-30 12:00:46,125 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
kdc_1       | Jan 30 12:04:19 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080259, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 2023-01-30 11:59:50,626 [main] INFO http.BaseHttpServer: Starting Web-server for s3gateway at: http://0.0.0.0:9878
s3g_1       | 2023-01-30 11:59:50,640 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
recon_1     | STARTUP_MSG: Starting ReconServer
om_1        | 2023-01-30 11:59:45,876 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2023-01-30 12:00:46,431 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
kdc_1       | Jan 30 12:04:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080259, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-30 11:59:50,640 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.s3g.http.auth.type = kerberos
s3g_1       | 2023-01-30 11:59:51,111 [main] INFO util.log: Logging initialized @14938ms to org.eclipse.jetty.util.log.Slf4jLog
recon_1     | STARTUP_MSG:   host = recon/172.18.0.6
om_1        | 2023-01-30 11:59:53,025 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
datanode_1  | 2023-01-30 12:00:46,557 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_3  | 2023-01-30 11:59:50,131 [main] INFO impl.MetricsSystemImpl: HddsDatanode metrics system started
datanode_3  | 2023-01-30 11:59:50,995 [main] INFO ozone.HddsDatanodeService: HddsDatanodeService host:51f838724954 ip:172.18.0.4
kdc_1       | Jan 30 12:04:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080259, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-30 11:59:52,327 [main] INFO http.HttpRequestLog: Http request log for http.requests.s3gateway is not defined
s3g_1       | 2023-01-30 11:59:52,451 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
recon_1     | STARTUP_MSG:   args = []
om_1        | 2023-01-30 11:59:56,439 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_1  | 2023-01-30 12:00:46,571 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
s3g_1       | 2023-01-30 11:59:52,452 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context s3gateway
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
kdc_1       | Jan 30 12:04:30 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:04:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 11:59:56,853 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
datanode_1  | 2023-01-30 12:00:46,578 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
s3g_1       | 2023-01-30 11:59:52,452 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
scm_1       | 2023-01-30 12:00:00,296 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
kdc_1       | Jan 30 12:04:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:04:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 11:59:56,853 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2023-01-30 11:59:56,853 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
s3g_1       | 2023-01-30 11:59:52,452 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
recon_1     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/sqlite-jdbc-3.25.2.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/guice-4.0.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-core-5.3.23.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/jersey-entity-filtering-2.34.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/derby-10.14.2.0.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/spring-jcl-5.3.23.jar:/opt/hadoop/share/ozone/lib/jooq-codegen-3.11.10.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/guice-servlet-4.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/guice-bridge-2.5.0.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/spring-jdbc-5.3.23.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-tools-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/aopalliance-1.0.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-media-json-jackson-2.34.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guice-multibindings-4.0.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/ozone-reconcodegen-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/spring-beans-5.3.23.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/bonecp-0.8.0.RELEASE.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/spring-tx-5.3.23.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/guice-assistedinject-4.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/jooq-meta-3.11.10.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-2.34.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar
kdc_1       | Jan 30 12:04:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080270, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:00:46,578 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
om_1        | 2023-01-30 11:59:59,114 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
s3g_1       | 2023-01-30 11:59:52,525 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.s3g.http.auth.kerberos.principal keytabKey: ozone.s3g.http.auth.kerberos.keytab
recon_1     | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
recon_1     | STARTUP_MSG:   java = 11.0.14.1
datanode_1  | 2023-01-30 12:00:46,579 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
scm_1       | /************************************************************
om_1        | 2023-01-30 11:59:59,114 [main] INFO om.OzoneManager: Ozone Manager login successful.
recon_1     | ************************************************************/
datanode_1  | 2023-01-30 12:00:46,913 [Thread-19] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
scm_1       | STARTUP_MSG: Starting StorageContainerManager
om_1        | 2023-01-30 11:59:59,159 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | KeyUsage [
datanode_2  |   Key_CertSign
s3g_1       | 2023-01-30 11:59:53,417 [main] INFO s3.Gateway: STARTUP_MSG: 
kdc_1       | Jan 30 12:04:59 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080299, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1     | 2023-01-30 11:59:49,850 [main] INFO recon.ReconServer: registered UNIX signal handlers for [TERM, HUP, INT]
datanode_1  | 2023-01-30 12:00:46,928 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
scm_1       | STARTUP_MSG:   host = scm/172.18.0.5
om_1        | 2023-01-30 11:59:59,785 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863]
datanode_2  |   Crl_Sign
datanode_3  | 2023-01-30 11:59:55,971 [main] INFO ozone.HddsDatanodeService: Ozone security is enabled. Attempting login for Hdds Datanode user. Principal: dn/dn@EXAMPLE.COM,keytab: /etc/security/keytabs/dn.keytab
s3g_1       | /************************************************************
kdc_1       | Jan 30 12:05:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080299, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-30 11:59:55,403 [main] INFO reflections.Reflections: Reflections took 714 ms to scan 1 urls, producing 17 keys and 54 values 
datanode_1  | 2023-01-30 12:00:52,697 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
om_1        | 2023-01-30 12:00:03,627 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | ]
datanode_2  | 
datanode_3  | 2023-01-30 11:59:56,940 [main] INFO security.UserGroupInformation: Login successful for user dn/dn@EXAMPLE.COM using keytab file dn.keytab. Keytab auto renewal enabled : false
datanode_3  | 2023-01-30 11:59:56,966 [main] INFO ozone.HddsDatanodeService: Hdds Datanode login successful.
datanode_3  | 2023-01-30 12:00:00,090 [main] INFO ozone.HddsDatanodeService: Initializing secure Datanode.
datanode_1  | 2023-01-30 12:00:53,932 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
om_1        | 2023-01-30 12:00:05,629 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_3  | 2023-01-30 12:00:00,095 [main] ERROR client.DNCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
datanode_3  | 2023-01-30 12:00:00,110 [main] INFO client.DNCertificateClient: Certificate client init case: 0
recon_1     | 2023-01-30 12:00:01,403 [main] INFO recon.ReconServer: Initializing Recon server...
datanode_1  | 2023-01-30 12:00:54,064 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
s3g_1       | STARTUP_MSG: Starting Gateway
scm_1       | STARTUP_MSG:   args = [--init]
om_1        | 2023-01-30 12:00:07,632 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:01,906 [main] INFO recon.ReconServer: Ozone security is enabled. Attempting login for Recon service. Principal: recon/recon@EXAMPLE.COM, keytab: /etc/security/keytabs/recon.keytab
datanode_1  | 2023-01-30 12:00:54,310 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
s3g_1       | STARTUP_MSG:   host = s3g/172.18.0.3
scm_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om_1        | 2023-01-30 12:00:09,634 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:00,116 [main] INFO client.DNCertificateClient: Creating keypair for client as keypair and certificate not found.
datanode_3  | 2023-01-30 12:00:04,949 [main] INFO ozone.HddsDatanodeService: Init response: GETCERT
recon_1     | 2023-01-30 12:00:03,381 [main] INFO security.UserGroupInformation: Login successful for user recon/recon@EXAMPLE.COM using keytab file recon.keytab. Keytab auto renewal enabled : false
datanode_1  | 2023-01-30 12:00:54,948 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
s3g_1       | STARTUP_MSG:   args = []
om_1        | 2023-01-30 12:00:11,636 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | SubjectAlternativeName [
datanode_2  |   IPAddress: 172.18.0.5
datanode_2  | ]
datanode_2  | 
recon_1     | 2023-01-30 12:00:03,381 [main] INFO recon.ReconServer: Recon login successful.
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
datanode_1  | 2023-01-30 12:00:55,406 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
s3g_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
om_1        | 2023-01-30 12:00:13,639 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | ]
datanode_2  |   Algorithm: [SHA256withRSA]
datanode_2  |   Signature:
datanode_2  | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
recon_1     | 2023-01-30 12:00:03,454 [main] INFO recon.ReconServer: ReconStorageConfig initialized.Initializing certificate.
datanode_1  | 2023-01-30 12:00:55,424 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
s3g_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/hk2-utils-2.5.0.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jakarta.inject-2.6.1.jar:/opt/hadoop/share/ozone/lib/hk2-locator-2.6.1.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/aopalliance-repackaged-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/javax.interceptor-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/javax.el-api-3.0.0.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jakarta.ws.rs-api-2.1.6.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/jakarta.xml.bind-api-2.3.3.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/jersey-server-2.34.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jersey-container-servlet-core-2.34.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/cdi-api-1.2.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/activation-1.1.1.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jersey-cdi1x-2.34.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/hk2-api-2.5.0.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.inject-1.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/jackson-module-jaxb-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/jakarta.validation-api-2.0.2.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/jersey-client-2.34.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jakarta.annotation-api-1.3.5.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/osgi-resource-locator-1.0.3.jar:/opt/hadoop/share/ozone/lib/jackson-dataformat-xml-2.13.4.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-common-2.34.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-hk2-2.34.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/jersey-media-jaxb-2.34.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar
s3g_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
s3g_1       | STARTUP_MSG:   java = 11.0.14.1
datanode_3  | 2023-01-30 12:00:05,236 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.4,host:51f838724954
datanode_3  | 2023-01-30 12:00:05,259 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
recon_1     | 2023-01-30 12:00:03,454 [main] INFO recon.ReconServer: Initializing secure Recon.
om_1        | 2023-01-30 12:00:15,641 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:55,424 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
datanode_2  | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
datanode_2  | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
datanode_2  | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
datanode_2  | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
datanode_3  | 2023-01-30 12:00:05,280 [main] ERROR client.DNCertificateClient: Invalid domain 51f838724954
recon_1     | 2023-01-30 12:00:07,306 [main] ERROR client.ReconCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
om_1        | 2023-01-30 12:00:17,646 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:55,425 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
datanode_1  | 2023-01-30 12:00:55,425 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
datanode_1  | 2023-01-30 12:00:55,425 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
datanode_1  | 2023-01-30 12:00:55,433 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
datanode_1  | 2023-01-30 12:00:55,434 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-30 12:00:05,281 [main] INFO client.DNCertificateClient: Created csr for DN-> subject:dn@51f838724954
datanode_3  | 2023-01-30 12:00:10,279 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:07,312 [main] INFO client.ReconCertificateClient: Certificate client init case: 0
om_1        | 2023-01-30 12:00:19,649 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:55,434 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
recon_1     | 2023-01-30 12:00:07,324 [main] INFO client.ReconCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2023-01-30 12:00:21,651 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
datanode_2  | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
recon_1     | 2023-01-30 12:00:13,303 [main] INFO recon.ReconServer: Init response: GETCERT
datanode_3  | 2023-01-30 12:00:12,281 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:14,285 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:16,287 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-30 12:00:23,653 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-30 12:00:25,655 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:13,310 [main] INFO client.ReconCertificateClient: Creating CSR for Recon.
datanode_3  | 2023-01-30 12:00:18,299 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 30 12:05:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080299, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:17 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2023-01-30 12:00:27,657 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-30 12:00:29,659 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 14 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:13,346 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.6,host:recon
kdc_1       | Jan 30 12:05:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080317, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:30 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:05:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080330, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080342, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
recon_1     | 2023-01-30 12:00:13,347 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | 2023-01-30 12:00:20,308 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:22,310 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:24,312 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 2023-01-30 12:00:31,664 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From om/172.18.0.2 to scm:9863 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 15 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
datanode_2  | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
recon_1     | 2023-01-30 12:00:13,364 [main] ERROR client.ReconCertificateClient: Invalid domain recon
recon_1     | 2023-01-30 12:00:16,511 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 1 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 30 12:05:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080342, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:05:49 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080349, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
om_1        | 2023-01-30 12:00:36,347 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_3  | 2023-01-30 12:00:26,314 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
datanode_2  | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
datanode_2  | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
recon_1     | 2023-01-30 12:00:18,513 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 2 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:20,515 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 3 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_1  | 2023-01-30 12:00:55,435 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
datanode_2  | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
datanode_2  | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
datanode_3  | 2023-01-30 12:00:28,327 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | STARTUP_MSG:   java = 11.0.14.1
kdc_1       | Jan 30 12:05:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080349, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 
s3g_1       | ************************************************************/
s3g_1       | 2023-01-30 11:59:53,478 [main] INFO s3.Gateway: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm_1       | ************************************************************/
recon_1     | 2023-01-30 12:00:22,519 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 4 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:30,329 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From 51f838724954/172.18.0.4 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 11 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_2  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_2  | 2023-01-30 12:00:43,033 [main] INFO client.DNCertificateClient: Added certificate [
datanode_2  | [
datanode_2  |   Version: V3
kdc_1       | Jan 30 12:05:55 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:05:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080355, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:31 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:06:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 2023-01-30 12:00:24,521 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 5 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
datanode_1  | 2023-01-30 12:00:55,514 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
recon_1     | 2023-01-30 12:00:26,523 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 6 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:36,412 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_3  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
s3g_1       | 2023-01-30 11:59:53,774 [main] INFO s3.Gateway: Starting Ozone S3 gateway
s3g_1       | 2023-01-30 11:59:54,601 [main] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
s3g_1       | 2023-01-30 11:59:55,853 [main] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
datanode_1  | 2023-01-30 12:00:55,551 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
recon_1     | 2023-01-30 12:00:28,526 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 7 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
s3g_1       | 2023-01-30 11:59:55,853 [main] INFO impl.MetricsSystemImpl: S3Gateway metrics system started
s3g_1       | 2023-01-30 11:59:56,207 [main] INFO http.HttpServer2: Jetty bound to port 9878
s3g_1       | 2023-01-30 11:59:56,217 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 2023-01-30 12:00:00,620 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2023-01-30 12:00:01,977 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
s3g_1       | 2023-01-30 11:59:56,946 [main] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_2  | 
datanode_2  |   Key:  Sun RSA public key, 2048 bits
kdc_1       | Jan 30 12:06:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
s3g_1       | 2023-01-30 11:59:56,946 [main] INFO server.session: No SessionScavenger set, using defaults
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  |   params: null
datanode_2  |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
kdc_1       | Jan 30 12:06:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:06:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080391, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
s3g_1       | 2023-01-30 11:59:56,980 [main] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2023-01-30 12:00:30,528 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: java.net.ConnectException: Call From recon/172.18.0.6 to scm:9961 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused, while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 8 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_2  |   public exponent: 65537
datanode_2  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
kdc_1       | Jan 30 12:06:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080413, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:06:53 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080413, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
s3g_1       | 2023-01-30 11:59:57,191 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/s3g.keytab, for principal HTTP/s3g@EXAMPLE.COM
recon_1     | 2023-01-30 12:00:36,382 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_2  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_2  |   SerialNumber: [    3b882292 67]
datanode_2  | 
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
s3g_1       | 2023-01-30 11:59:57,257 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@b672aa8{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
datanode_2  | Certificate Extensions: 3
datanode_2  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_2  | BasicConstraints:[
kdc_1       | Jan 30 12:06:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080413, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
s3g_1       | 2023-01-30 11:59:57,258 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@460f76a6{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  |   CA:true
kdc_1       | Jan 30 12:07:00 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:00 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080420, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
s3g_1       | WARNING: An illegal reflective access operation has occurred
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_2  |   PathLen:2147483647
datanode_2  | ]
datanode_2  | 
datanode_2  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
s3g_1       | WARNING: Illegal reflective access by org.jboss.weld.util.reflection.Formats (file:/opt/hadoop/share/ozone/lib/weld-servlet-2.4.7.Final.jar) to constructor com.sun.org.apache.bcel.internal.classfile.ClassParser(java.io.InputStream,java.lang.String)
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | KeyUsage [
datanode_2  |   DigitalSignature
datanode_2  |   Key_Encipherment
datanode_2  |   Data_Encipherment
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
s3g_1       | WARNING: Please consider reporting this to the maintainers of org.jboss.weld.util.reflection.Formats
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | , while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 16 failover attempts. Trying to failover after sleeping for 2000ms.
kdc_1       | Jan 30 12:07:05 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:05 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
s3g_1       | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
datanode_2  |   Key_Agreement
datanode_2  |   Key_CertSign
om_1        | 2023-01-30 12:00:38,357 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
kdc_1       | Jan 30 12:07:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080425, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser2/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:07:18 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
s3g_1       | WARNING: All illegal access operations will be denied in a future release
datanode_2  |   Crl_Sign
datanode_2  | ]
om_1        | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
s3g_1       | 2023-01-30 12:00:12,580 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/s3g.keytab, for principal HTTP/s3g@EXAMPLE.COM
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
kdc_1       | Jan 30 12:07:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:07:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:07:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080438, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:00:55,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_1  | 2023-01-30 12:01:01,681 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
om_1        | 	at org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocolServerSideTranslatorPB.send(ScmBlockLocationProtocolServerSideTranslatorPB.java:109)
s3g_1       | Jan 30, 2023 12:00:15 PM org.glassfish.jersey.internal.Errors logErrors
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | 	at org.apache.hadoop.hdds.protocol.proto.ScmBlockLocationProtocolProtos$ScmBlockLocationProtocolService$2.callBlockingMethod(ScmBlockLocationProtocolProtos.java:14202)
s3g_1       | WARNING: The following warnings have been detected: WARNING: A HTTP GET method, public javax.ws.rs.core.Response org.apache.hadoop.ozone.s3.endpoint.ObjectEndpoint.get(java.lang.String,java.lang.String,java.lang.String,int,java.lang.String,java.io.InputStream) throws java.io.IOException,org.apache.hadoop.ozone.s3.exception.OS3Exception, should not consume any entity.
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 12 failover attempts. Trying to failover after sleeping for 2000ms.
s3g_1       | 
s3g_1       | 2023-01-30 12:00:15,704 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2bb3f39e{s3gateway,/,file:///tmp/jetty-0_0_0_0-9878-ozone-s3gateway-1_4_0-SNAPSHOT_jar-_-any-4065043965793275020/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-s3gateway-1.4.0-SNAPSHOT.jar!/webapps/s3gateway}
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
datanode_3  | 2023-01-30 12:00:38,421 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_1  | 2023-01-30 12:01:01,809 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
datanode_1  | 2023-01-30 12:01:01,812 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
datanode_1  | 2023-01-30 12:01:01,813 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
datanode_1  | 2023-01-30 12:01:01,836 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_1  | 2023-01-30 12:01:01,857 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
s3g_1       | 2023-01-30 12:00:15,725 [main] INFO server.AbstractConnector: Started ServerConnector@5398edd0{HTTP/1.1, (http/1.1)}{0.0.0.0:9878}
s3g_1       | 2023-01-30 12:00:15,725 [main] INFO server.Server: Started @39553ms
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_3  | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
kdc_1       | Jan 30 12:07:42 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:07:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:07:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:08:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080462, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:08:06 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
s3g_1       | 2023-01-30 12:00:15,743 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
s3g_1       | 2023-01-30 12:00:15,743 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_3  | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_3  | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
datanode_3  | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
s3g_1       | 2023-01-30 12:00:15,746 [main] INFO http.BaseHttpServer: HTTP server of s3gateway listening at http://0.0.0.0:9878
datanode_3  | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
kdc_1       | Jan 30 12:08:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 
scm_1       | 2023-01-30 12:00:02,871 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
scm_1       | 2023-01-30 12:00:03,157 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
scm_1       | 2023-01-30 12:00:04,227 [main] INFO ha.HASecurityUtils: Initializing secure StorageContainerManager.
scm_1       | 2023-01-30 12:00:10,712 [main] ERROR client.SCMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
scm_1       | 2023-01-30 12:00:10,722 [main] INFO client.SCMCertificateClient: Certificate client init case: 0
om_1        | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
kdc_1       | Jan 30 12:08:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | SubjectAlternativeName [
om_1        | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 2023-01-30 12:00:10,736 [main] INFO client.SCMCertificateClient: Creating keypair for client as keypair and certificate not found.
kdc_1       | Jan 30 12:08:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080486, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:08:23 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:08:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:08:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  |   IPAddress: 172.18.0.5
scm_1       | 2023-01-30 12:00:15,429 [main] INFO ha.HASecurityUtils: Init response: GETCERT
kdc_1       | Jan 30 12:08:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:01,864 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
datanode_1  | 2023-01-30 12:01:01,912 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
datanode_2  | ]
scm_1       | 2023-01-30 12:00:17,024 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.5,host:scm
kdc_1       | Jan 30 12:08:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:01,922 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
datanode_1  | 2023-01-30 12:01:02,379 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
om_1        | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 
om_1        | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2023-01-30 12:00:17,024 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | ]
om_1        | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 2023-01-30 12:00:17,310 [main] INFO utils.SelfSignedCertificate: Certificate 1 is issued by CN=scm@scm,OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5,O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545 to CN=scm@scm,OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5,O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, valid from Mon Jan 30 00:00:00 UTC 2023 to Thu Mar 09 00:00:00 UTC 2028
datanode_3  | , while invoking $Proxy18.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 13 failover attempts. Trying to failover after sleeping for 2000ms.
datanode_3  | 2023-01-30 12:00:42,463 [main] INFO client.DNCertificateClient: Loading certificate from location:/data/metadata/dn/certs.
datanode_2  |   Algorithm: [SHA256withRSA]
datanode_2  |   Signature:
datanode_1  | 2023-01-30 12:01:02,380 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
datanode_3  | 2023-01-30 12:00:42,611 [main] INFO client.DNCertificateClient: Added certificate [
kdc_1       | Jan 30 12:08:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:08:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:09:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
datanode_2  | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
datanode_3  | [
kdc_1       | Jan 30 12:09:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:09:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:09:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
datanode_2  | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
datanode_3  |   Version: V3
kdc_1       | Jan 30 12:09:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:09:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:09:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
datanode_2  | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
datanode_3  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
kdc_1       | Jan 30 12:09:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
datanode_2  | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
datanode_2  | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
kdc_1       | Jan 30 12:09:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
kdc_1       | Jan 30 12:09:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
om_1        | , while invoking $Proxy31.send over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863 after 17 failover attempts. Trying to failover after sleeping for 2000ms.
om_1        | OM initialization succeeded.Current cluster id for sd=/data/metadata/om;cid=CID-b04a1c74-af13-4571-b723-87e6e2d1e545;layoutVersion=3
datanode_1  | 2023-01-30 12:01:02,776 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_3  | 
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-30 12:00:17,419 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.5,host:scm
scm_1       | 2023-01-30 12:00:17,421 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
datanode_3  |   Key:  Sun RSA public key, 2048 bits
recon_1     | , while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 9 failover attempts. Trying to failover after sleeping for 2000ms.
recon_1     | 2023-01-30 12:00:38,388 [main] INFO retry.RetryInvocationHandler: com.google.protobuf.ServiceException: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdds.ratis.ServerNotLeaderException): Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
scm_1       | 2023-01-30 12:00:17,423 [main] ERROR client.SCMCertificateClient: Invalid domain scm
datanode_2  | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
datanode_1  | 2023-01-30 12:01:02,776 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_1  | 2023-01-30 12:01:02,776 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_1  | 2023-01-30 12:01:02,776 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  |   params: null
recon_1     | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
kdc_1       | Jan 30 12:10:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:10:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:10:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:10:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_3  |                To: Thu Mar 09 00:00:00 UTC 2028]
kdc_1       | Jan 30 12:10:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:02,836 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_1  | 2023-01-30 12:01:02,924 [6295590c-c30d-436f-ae9f-b085e438c72d-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x29e33c20] REGISTERED
datanode_1  | 2023-01-30 12:01:02,926 [6295590c-c30d-436f-ae9f-b085e438c72d-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x29e33c20] BIND: 0.0.0.0/0.0.0.0:9855
datanode_3  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_3  |   SerialNumber: [    01]
datanode_3  | 
datanode_3  | Certificate Extensions: 3
datanode_1  | 2023-01-30 12:01:02,936 [6295590c-c30d-436f-ae9f-b085e438c72d-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x29e33c20, L:/0.0.0.0:9855] ACTIVE
kdc_1       | Jan 30 12:10:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:00:40,467 [main] INFO om.OzoneManager: OM storage initialized. Initializing security
om_1        | 2023-01-30 12:00:40,467 [main] INFO om.OzoneManager: Initializing secure OzoneManager.
datanode_1  | 2023-01-30 12:01:03,404 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode_1  | 2023-01-30 12:01:03,439 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode_1  | 2023-01-30 12:01:03,507 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_1  | 2023-01-30 12:01:04,627 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 279590402906
kdc_1       | Jan 30 12:10:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_1  | 2023-01-30 12:01:04,647 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 279590402906
scm_1       | 2023-01-30 12:00:17,429 [main] INFO ha.HASecurityUtils: Creating csr for SCM->hostName:scm,scmId:82e918d1-ff68-4821-a2f0-f9af71d19ea5,clusterId:CID-b04a1c74-af13-4571-b723-87e6e2d1e545,subject:scm-sub@scm
scm_1       | 2023-01-30 12:00:17,574 [main] INFO ha.HASecurityUtils: Successfully stored SCM signed certificate.
scm_1       | 2023-01-30 12:00:17,796 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
kdc_1       | Jan 30 12:10:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:00:41,401 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
datanode_3  | BasicConstraints:[
datanode_1  | 2023-01-30 12:01:05,109 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2023-01-30 12:00:17,900 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-30 12:00:17,902 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
scm_1       | 2023-01-30 12:00:17,903 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-30 12:00:17,904 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
datanode_3  |   CA:true
datanode_1  | 2023-01-30 12:01:05,109 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
scm_1       | 2023-01-30 12:00:17,905 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | 2023-01-30 12:00:17,905 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
scm_1       | 2023-01-30 12:00:17,907 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
scm_1       | 2023-01-30 12:00:17,909 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  |   PathLen:2147483647
datanode_1  | 2023-01-30 12:01:05,109 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
datanode_2  | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
datanode_2  | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
datanode_2  | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
datanode_2  | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
datanode_3  | ]
datanode_1  | 2023-01-30 12:01:05,347 [main] INFO util.log: Logging initialized @87026ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2023-01-30 12:01:06,178 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
datanode_1  | 2023-01-30 12:01:06,209 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2023-01-30 12:01:06,229 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_1  | 2023-01-30 12:01:06,229 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | value: 9862
recon_1     | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
datanode_2  | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
datanode_2  | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
datanode_2  | 
om_1        | ]
datanode_3  | 
datanode_1  | 2023-01-30 12:01:06,229 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
recon_1     | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_3  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | KeyUsage [
datanode_1  | 2023-01-30 12:01:06,240 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
kdc_1       | Jan 30 12:11:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:11:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:11:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  |   Key_CertSign
datanode_3  |   Crl_Sign
datanode_1  | 2023-01-30 12:01:06,528 [main] INFO http.HttpServer2: Jetty bound to port 9882
kdc_1       | Jan 30 12:11:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:11:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | ] from file:/data/metadata/dn/certs/CA-255687037543.crt.
kdc_1       | Jan 30 12:11:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:06,541 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_2  | 2023-01-30 12:00:43,054 [main] INFO client.DNCertificateClient: Added certificate [
datanode_3  | ]
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 2023-01-30 12:00:17,910 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2023-01-30 12:00:41,424 [main] ERROR security.OMCertificateClient: Default certificate serial id is not set. Can't locate the default certificate for this client.
kdc_1       | Jan 30 12:11:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | [
datanode_3  | 
recon_1     | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 2023-01-30 12:00:17,911 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
om_1        | 2023-01-30 12:00:41,430 [main] INFO security.OMCertificateClient: Certificate client init case: 0
kdc_1       | Jan 30 12:11:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:06,840 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  |   Version: V3
datanode_3  | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2023-01-30 12:00:17,921 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
scm_1       | 2023-01-30 12:00:17,925 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
kdc_1       | Jan 30 12:11:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:06,846 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_2  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=dn@2850eee4085e
datanode_3  | SubjectAlternativeName [
datanode_3  |   IPAddress: 172.18.0.5
recon_1     | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 2023-01-30 12:00:17,925 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1       | 2023-01-30 12:00:18,190 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
kdc_1       | Jan 30 12:12:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:06,858 [main] INFO server.session: node0 Scavenging every 600000ms
datanode_2  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_3  | ]
datanode_3  | 
recon_1     | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 2023-01-30 12:00:18,206 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2023-01-30 12:00:18,336 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
kdc_1       | Jan 30 12:12:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:07,125 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_2  | 
datanode_3  | ]
datanode_3  |   Algorithm: [SHA256withRSA]
recon_1     | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-30 12:00:18,336 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
scm_1       | 2023-01-30 12:00:18,338 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
scm_1       | 2023-01-30 12:00:18,339 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_2  |   Key:  Sun RSA public key, 2048 bits
datanode_2  |   params: null
datanode_3  |   Signature:
recon_1     | , while invoking $Proxy39.submitRequest over nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9961 after 10 failover attempts. Trying to failover after sleeping for 2000ms.
scm_1       | 2023-01-30 12:00:18,346 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
scm_1       | 2023-01-30 12:00:18,348 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
scm_1       | 2023-01-30 12:00:18,354 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
datanode_2  |   modulus: 23064875240539142820924535866735945299864828565830782720543261628723608295707983521070770049308532665941839096952064763372524195081946818188254016487664242123694617483451772199388628940321440739385661020405630883292199932428548109634100440147400759864056593747136970963469997237699544698165031310420367702493517605048548101378454097118472736950766290647357722187315092421320538538025070121259552895045575444050431958809491702275795726871343644818547331976441694419731662828207693750952231514128781044239648490746701683733862948670784713246126371386892604596146057106357362215568715506253349088408652532901767084922557
datanode_2  |   public exponent: 65537
datanode_3  | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
recon_1     | 2023-01-30 12:00:41,533 [main] INFO client.ReconCertificateClient: Loading certificate from location:/data/metadata/recon/certs.
scm_1       | 2023-01-30 12:00:18,355 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = null (default)
scm_1       | 2023-01-30 12:00:18,359 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
scm_1       | 2023-01-30 12:00:18,360 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
datanode_2  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_2  |                To: Tue Jan 30 00:00:00 UTC 2024]
datanode_3  | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
recon_1     | 2023-01-30 12:00:41,592 [main] INFO client.ReconCertificateClient: Added certificate [
datanode_2  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
datanode_2  |   SerialNumber: [    412ef9fe af]
datanode_3  | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
recon_1     | [
datanode_2  | 
datanode_2  | Certificate Extensions: 2
datanode_3  | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
recon_1     |   Version: V3
recon_1     |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 
recon_1     |   Key:  Sun RSA public key, 2048 bits
recon_1     |   params: null
recon_1     |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
datanode_2  | [1]: ObjectId: 2.5.29.15 Criticality=true
datanode_2  | KeyUsage [
datanode_2  |   DigitalSignature
datanode_1  | 2023-01-30 12:01:07,169 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@47b5c247{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
scm_1       | 2023-01-30 12:00:18,422 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1       | 2023-01-30 12:00:18,423 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1       | 2023-01-30 12:00:18,424 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
scm_1       | 2023-01-30 12:00:18,424 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  |   Key_Encipherment
datanode_1  | 2023-01-30 12:01:07,170 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@69a8191e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_1  | 2023-01-30 12:01:07,820 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,428 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
om_1        | 2023-01-30 12:00:41,433 [main] INFO security.OMCertificateClient: Creating keypair for client as keypair and certificate not found.
om_1        | 2023-01-30 12:00:43,940 [main] INFO om.OzoneManager: Init response: GETCERT
om_1        | 2023-01-30 12:00:44,122 [main] INFO ozone.OzoneSecurityUtil: Adding ip:172.18.0.2,host:om
datanode_2  |   Data_Encipherment
datanode_1  | 2023-01-30 12:01:07,895 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@620ba19c{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-17559396767172990966/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
kdc_1       | Jan 30 12:12:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  |   Key_Agreement
datanode_1  | 2023-01-30 12:01:07,938 [main] INFO server.AbstractConnector: Started ServerConnector@12ec5e73{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
kdc_1       | Jan 30 12:12:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | ]
datanode_3  | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
kdc_1       | Jan 30 12:12:27 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 
om_1        | 2023-01-30 12:00:44,135 [main] INFO ozone.OzoneSecurityUtil: ip:127.0.0.1 not returned.
om_1        | 2023-01-30 12:00:44,150 [main] ERROR security.OMCertificateClient: Invalid domain om
kdc_1       | Jan 30 12:12:33 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,467 [main] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: addNew group-87E6E2D1E545:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|priority:0|startupRole:FOLLOWER] returns group-87E6E2D1E545:java.util.concurrent.CompletableFuture@682abca7[Not completed]
scm_1       | 2023-01-30 12:00:18,460 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed] REGISTERED
datanode_2  | [2]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | SubjectAlternativeName [
kdc_1       | Jan 30 12:12:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,472 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed] BIND: 0.0.0.0/0.0.0.0:0
scm_1       | 2023-01-30 12:00:18,474 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed, L:/0.0.0.0:46081] ACTIVE
datanode_2  |   IPAddress: 172.18.0.8
datanode_2  | ]
om_1        | 2023-01-30 12:00:44,159 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
om_1        | 2023-01-30 12:00:44,162 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
kdc_1       | Jan 30 12:12:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 
datanode_2  | ]
om_1        | 2023-01-30 12:00:44,163 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2023-01-30 12:00:44,163 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
kdc_1       | Jan 30 12:12:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,516 [pool-2-thread-1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: new RaftServerImpl for group-87E6E2D1E545:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|priority:0|startupRole:FOLLOWER] with SCMStateMachine:uninitialized
scm_1       | 2023-01-30 12:00:18,517 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
datanode_2  |   Algorithm: [SHA256withRSA]
datanode_2  |   Signature:
kdc_1       | Jan 30 12:12:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2023-01-30 12:00:18,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 0000: 5F A2 97 A4 E3 53 BE 5B   F9 8F 90 09 05 2F 1D 0D  _....S.[...../..
datanode_2  | 0010: 86 4B BF 2C 6E F4 D7 64   01 25 15 21 38 B6 22 D3  .K.,n..d.%.!8.".
kdc_1       | Jan 30 12:13:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
recon_1     |   public exponent: 65537
datanode_1  | 2023-01-30 12:01:07,938 [main] INFO server.Server: Started @89628ms
datanode_1  | 2023-01-30 12:01:08,003 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 0020: A4 F7 30 55 39 DC F2 B2   47 F0 6D 56 6F 43 6A 39  ..0U9...G.mVoCj9
datanode_3  | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
kdc_1       | Jan 30 12:13:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
recon_1     |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_1  | 2023-01-30 12:01:08,003 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
om_1        | 2023-01-30 12:00:44,168 [main] INFO security.OMCertificateClient: Creating csr for OM->dns:om,ip:172.18.0.2,scmId:82e918d1-ff68-4821-a2f0-f9af71d19ea5,clusterId:CID-b04a1c74-af13-4571-b723-87e6e2d1e545,subject:om
datanode_2  | 0030: 3B 55 03 D8 D6 7B EF DA   82 BC D6 0B 16 F7 4A 7B  ;U............J.
kdc_1       | Jan 30 12:13:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,518 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1     |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_1  | 2023-01-30 12:01:08,007 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
om_1        | 2023-01-30 12:00:45,389 [main] INFO om.OzoneManager: Successfully stored SCM signed certificate.
datanode_2  | 0040: B1 82 40 E8 86 21 B7 FB   6C CF 4E AF 85 CE 14 A0  ..@..!..l.N.....
kdc_1       | Jan 30 12:13:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,525 [pool-2-thread-1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: ConfigurationManager, init=-1: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
scm_1       | 2023-01-30 12:00:18,525 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
datanode_1  | 2023-01-30 12:01:08,019 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
om_1        | 2023-01-30 12:00:45,413 [shutdown-hook-0] INFO om.OzoneManagerStarter: SHUTDOWN_MSG: 
datanode_2  | 0050: 2D D0 1B 36 E5 E9 13 9F   E5 1D 9C 03 38 8C AF 99  -..6........8...
kdc_1       | Jan 30 12:13:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:13:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,530 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2023-01-30 12:01:08,298 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22fdda97] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | /************************************************************
datanode_2  | 0060: 3D 6E 8B DB 79 C1 F7 1D   C0 1D A9 6F 0C 5C E9 E1  =n..y......o.\..
recon_1     |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
recon_1     |   SerialNumber: [    01]
scm_1       | 2023-01-30 12:00:18,531 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_1  | 2023-01-30 12:01:08,772 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.6:9891
om_1        | SHUTDOWN_MSG: Shutting down OzoneManager at om/172.18.0.2
datanode_2  | 0070: BD 68 27 0F 76 76 76 66   68 EC 07 38 92 0B 35 05  .h'.vvvfh..8..5.
datanode_3  | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
recon_1     | 
recon_1     | Certificate Extensions: 3
datanode_1  | 2023-01-30 12:01:08,814 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
om_1        | ************************************************************/
datanode_2  | 0080: 8E 92 EA 14 29 B4 6B 15   CF D6 79 22 74 C2 89 30  ....).k...y"t..0
datanode_3  | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
recon_1     | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | BasicConstraints:[
scm_1       | 2023-01-30 12:00:18,538 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_1  | 2023-01-30 12:01:13,021 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-4a31f989-8746-47f2-928f-a0175df9c5ef/container.db to cache
datanode_2  | 0090: 9E CE CB B2 12 07 90 6C   F9 FA D1 4C D7 D0 79 91  .......l...L..y.
datanode_3  | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
recon_1     |   CA:true
recon_1     |   PathLen:2147483647
scm_1       | 2023-01-30 12:00:18,541 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
datanode_1  | 2023-01-30 12:01:13,021 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-4a31f989-8746-47f2-928f-a0175df9c5ef/container.db for volume DS-4a31f989-8746-47f2-928f-a0175df9c5ef
datanode_1  | 2023-01-30 12:01:13,025 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_1  | 2023-01-30 12:01:13,037 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_1  | 2023-01-30 12:01:13,139 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode_1  | 2023-01-30 12:01:13,147 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 6295590c-c30d-436f-ae9f-b085e438c72d
kdc_1       | Jan 30 12:13:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,542 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
datanode_3  | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
datanode_1  | 2023-01-30 12:01:13,291 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.RaftServer: 6295590c-c30d-436f-ae9f-b085e438c72d: start RPC server
om_1        | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
recon_1     | ]
recon_1     | 
datanode_1  | 2023-01-30 12:01:13,306 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 6295590c-c30d-436f-ae9f-b085e438c72d: GrpcService started, listening on 9858
datanode_1  | 2023-01-30 12:01:13,330 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 6295590c-c30d-436f-ae9f-b085e438c72d: GrpcService started, listening on 9856
datanode_3  | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
datanode_3  | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
recon_1     | [2]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | KeyUsage [
recon_1     |   Key_CertSign
datanode_1  | 2023-01-30 12:01:13,335 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 6295590c-c30d-436f-ae9f-b085e438c72d: GrpcService started, listening on 9857
datanode_1  | 2023-01-30 12:01:13,349 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6295590c-c30d-436f-ae9f-b085e438c72d is started using port 9858 for RATIS
datanode_3  | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
datanode_3  | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
datanode_3  | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
datanode_3  | 
kdc_1       | Jan 30 12:13:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080503, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:13:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:13:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 00A0: DA 1F 42 AA F7 A3 A6 CF   49 32 CD B3 7E 52 61 C3  ..B.....I2...Ra.
om_1        | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
om_1        | 2023-01-30 12:00:53,646 [main] INFO om.OzoneManagerStarter: STARTUP_MSG: 
om_1        | /************************************************************
datanode_1  | 2023-01-30 12:01:13,349 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6295590c-c30d-436f-ae9f-b085e438c72d is started using port 9857 for RATIS_ADMIN
scm_1       | 2023-01-30 12:00:18,585 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
kdc_1       | Jan 30 12:13:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:13:58 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:13,350 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6295590c-c30d-436f-ae9f-b085e438c72d is started using port 9856 for RATIS_SERVER
kdc_1       | Jan 30 12:14:04 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,586 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       | 2023-01-30 12:00:18,586 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1       | 2023-01-30 12:00:18,586 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1       | 2023-01-30 12:00:18,587 [pool-2-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2023-01-30 12:01:13,351 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 6295590c-c30d-436f-ae9f-b085e438c72d is started using port 9855 for RATIS_DATASTREAM
datanode_1  | 2023-01-30 12:01:13,352 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-6295590c-c30d-436f-ae9f-b085e438c72d: Started
kdc_1       | Jan 30 12:14:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,592 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545 does not exist. Creating ...
recon_1     |   Crl_Sign
recon_1     | ]
recon_1     | 
datanode_1  | 2023-01-30 12:01:15,391 [EndpointStateMachine task thread for recon/172.18.0.6:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_1  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort 5ffad95da0eb/172.18.0.7:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:36190 remote=recon/172.18.0.6:9891]
datanode_2  | 00B0: 81 2F 75 CA 37 0E 5A E9   7A 47 D6 D2 88 0D 6F 1F  ./u.7.Z.zG....o.
datanode_2  | 00C0: ED 4F 9F C0 5C FC CD BB   92 10 23 0F 75 02 5C 4F  .O..\.....#.u.\O
datanode_2  | 00D0: 8E DA AA 92 AD E8 13 03   A1 CD 9C F1 2F 35 BE 2C  ............/5.,
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_1  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 00E0: B7 F9 21 DC 9D DB 6E A4   68 70 B2 42 F4 5A F1 6A  ..!...n.hp.B.Z.j
datanode_2  | 00F0: CF EB 76 A8 7E 68 1C B4   1F AF 25 D4 08 B0 D3 FF  ..v..h....%.....
datanode_2  | 
datanode_2  | ] from file:/data/metadata/dn/certs/279961009839.crt.
datanode_2  | 2023-01-30 12:00:43,087 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29073556927 ms and interval 86400000 ms.
datanode_2  | 2023-01-30 12:00:43,087 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
datanode_1  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_1  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
kdc_1       | Jan 30 12:14:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
scm_1       | 2023-01-30 12:00:18,602 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/in_use.lock acquired by nodename 13@scm
datanode_2  | 2023-01-30 12:00:43,300 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3  | ] from file:/data/metadata/dn/certs/ROOTCA-1.crt.
datanode_3  | 2023-01-30 12:00:42,630 [main] INFO client.DNCertificateClient: Added certificate [
om_1        | STARTUP_MSG: Starting OzoneManager
datanode_1  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
datanode_1  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_2  | 2023-01-30 12:00:44,638 [main] INFO reflections.Reflections: Reflections took 1067 ms to scan 2 urls, producing 100 keys and 224 values 
datanode_3  | [
datanode_3  |   Version: V3
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_2  | 2023-01-30 12:00:45,256 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
datanode_3  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_1  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_2  | 2023-01-30 12:00:46,207 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
om_1        | STARTUP_MSG:   host = om/172.18.0.2
datanode_1  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
kdc_1       | Jan 30 12:14:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:00:46,289 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
om_1        | STARTUP_MSG:   args = []
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
kdc_1       | Jan 30 12:14:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | SubjectAlternativeName [
recon_1     |   IPAddress: 172.18.0.5
datanode_2  | 2023-01-30 12:00:46,297 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
om_1        | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
datanode_1  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
recon_1     | ]
scm_1       | 2023-01-30 12:00:18,610 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545 has been successfully formatted.
scm_1       | 2023-01-30 12:00:18,614 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2023-01-30 12:00:46,299 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/ozone-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/jna-platform-5.2.0.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/orc-core-1.5.8.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-aarch_64.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-osx-x86_64.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/httpmime-4.5.6.jar:/opt/hadoop/share/ozone/lib/proto-google-common-protos-2.9.0.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/grpc-core-1.51.1.jar:/opt/hadoop/share/ozone/lib/httpasyncclient-4.1.3.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugin-classloader-2.3.0.jar:/opt/hadoop/share/ozone/lib/grpc-context-1.51.1.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-x86_64.jar:/opt/hadoop/share/ozone/lib/netty-codec-http2-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/ozone-interface-storage-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-lang-2.6.jar:/opt/hadoop/share/ozone/lib/grpc-stub-1.51.1.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jetty-client-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jna-5.2.0.jar:/opt/hadoop/share/ozone/lib/aspectjweaver-1.9.7.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-proxy-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-classes-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/annotations-4.1.1.4.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-linux-aarch_64.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-cred-2.3.0.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/aspectjrt-1.9.7.jar:/opt/hadoop/share/ozone/lib/netty-codec-socks-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/hppc-0.8.0.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/joda-time-2.10.6.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-audit-2.3.0.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final.jar:/opt/hadoop/share/ozone/lib/netty-tcnative-boringssl-static-2.0.54.Final-windows-x86_64.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/ozone-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jersey-client-1.19.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-lite-1.51.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/gethostname4j-0.0.2.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/animal-sniffer-annotations-1.21.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/ranger-intg-2.3.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/ranger-plugins-common-2.3.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/grpc-api-1.51.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/grpc-protobuf-1.51.1.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/netty-codec-http-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/perfmark-api-0.25.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/httpcore-nio-4.4.6.jar:/opt/hadoop/share/ozone/lib/grpc-netty-1.51.1.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/lib/ozone-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar
recon_1     | 
scm_1       | 2023-01-30 12:00:18,623 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2023-01-30 12:00:18,623 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-30 12:00:46,406 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_2  | 2023-01-30 12:00:46,526 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
datanode_2  | 2023-01-30 12:00:46,540 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2  | 2023-01-30 12:00:46,542 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2  | 2023-01-30 12:00:46,543 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_2  | 2023-01-30 12:00:46,546 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
datanode_2  | 2023-01-30 12:00:46,721 [Thread-19] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
scm_1       | 2023-01-30 12:00:18,625 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 
datanode_3  |   Key:  Sun RSA public key, 2048 bits
kdc_1       | Jan 30 12:14:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
datanode_2  | 2023-01-30 12:00:46,725 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
recon_1     | ]
recon_1     |   Algorithm: [SHA256withRSA]
kdc_1       | Jan 30 12:14:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | STARTUP_MSG:   java = 11.0.14.1
datanode_2  | 2023-01-30 12:00:52,608 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:36190 remote=recon/172.18.0.6:9891]
recon_1     |   Signature:
kdc_1       | Jan 30 12:14:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:14:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | ************************************************************/
om_1        | 2023-01-30 12:00:53,712 [main] INFO om.OzoneManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
om_1        | 2023-01-30 12:00:59,967 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for OMAudit to [].
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
datanode_3  |   params: null
datanode_3  |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
kdc_1       | Jan 30 12:14:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:15:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:15:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
kdc_1       | Jan 30 12:15:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:15:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:02,296 [main] INFO ha.OMHANodeDetails: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_3  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
kdc_1       | Jan 30 12:15:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:15:44 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:02,661 [main] INFO ha.OMHANodeDetails: Configuration does not have ozone.om.address set. Falling back to the default OM address om/172.18.0.2:9862
datanode_2  | 2023-01-30 12:00:53,363 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm_1       | 2023-01-30 12:00:18,626 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  |   SerialNumber: [    3b882292 67]
datanode_3  | 
datanode_3  | Certificate Extensions: 3
om_1        | 2023-01-30 12:01:02,661 [main] INFO ha.OMHANodeDetails: OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
om_1        | 2023-01-30 12:01:02,670 [main] INFO ha.OMHANodeDetails: OM Node ID is not set. Setting it to the default ID: om1
kdc_1       | Jan 30 12:15:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,652 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
datanode_3  | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_3  | BasicConstraints:[
datanode_3  |   CA:true
datanode_2  | 2023-01-30 12:00:53,706 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
om_1        | 2023-01-30 12:01:02,825 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
kdc_1       | Jan 30 12:15:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,664 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
datanode_3  |   PathLen:2147483647
datanode_2  | 2023-01-30 12:00:54,154 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2023-01-30 12:01:03,169 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = MULTITENANCY_SCHEMA (version = 3), software layout = MULTITENANCY_SCHEMA (version = 3)
kdc_1       | Jan 30 12:16:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,670 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode_3  | ]
datanode_2  | 2023-01-30 12:00:54,587 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1        | 2023-01-30 12:01:05,026 [main] INFO reflections.Reflections: Reflections took 1359 ms to scan 1 urls, producing 115 keys and 335 values [using 2 cores]
kdc_1       | Jan 30 12:16:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,689 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545
datanode_1  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
recon_1     | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
datanode_3  | 
datanode_2  | 2023-01-30 12:00:55,225 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-30 12:01:06,379 [main] INFO security.UserGroupInformation: Login successful for user om/om@EXAMPLE.COM using keytab file om.keytab. Keytab auto renewal enabled : false
kdc_1       | Jan 30 12:16:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,690 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
recon_1     | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
datanode_3  | [2]: ObjectId: 2.5.29.15 Criticality=true
datanode_2  | 2023-01-30 12:00:55,255 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
om_1        | 2023-01-30 12:01:06,379 [main] INFO om.OzoneManager: Ozone Manager login successful.
kdc_1       | Jan 30 12:16:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:16:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	... 12 more
recon_1     | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
datanode_3  | KeyUsage [
datanode_2  | 2023-01-30 12:00:55,259 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-30 12:01:06,390 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-30 12:00:18,702 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
datanode_1  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.7:36190 remote=recon/172.18.0.6:9891]
recon_1     | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
datanode_3  |   DigitalSignature
datanode_2  | 2023-01-30 12:00:55,259 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
kdc_1       | Jan 30 12:16:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:16:46 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,713 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
datanode_1  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
recon_1     | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
datanode_3  |   Key_Encipherment
datanode_2  | 2023-01-30 12:00:55,259 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
kdc_1       | Jan 30 12:16:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:07,607 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863]
scm_1       | 2023-01-30 12:00:18,714 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
recon_1     | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
recon_1     | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
datanode_2  | 2023-01-30 12:00:55,260 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
kdc_1       | Jan 30 12:16:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:07,859 [main] INFO proxy.SCMBlockLocationFailoverProxyProvider: Created block location fail-over proxy with 1 nodes: [nodeId=scmNodeId,nodeAddress=scm/172.18.0.5:9863]
scm_1       | 2023-01-30 12:00:18,714 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_1  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
datanode_2  | 2023-01-30 12:00:55,261 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
kdc_1       | Jan 30 12:17:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:11,337 [main] INFO om.OzoneManager: OzoneManager ports added:[name: "RPC"
om_1        | value: 9862
datanode_1  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
recon_1     | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
datanode_3  |   Data_Encipherment
datanode_2  | 2023-01-30 12:00:55,276 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
kdc_1       | Jan 30 12:17:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | ]
scm_1       | 2023-01-30 12:00:18,716 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
recon_1     | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
recon_1     | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
datanode_2  | 2023-01-30 12:00:55,286 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
kdc_1       | Jan 30 12:17:14 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:11,379 [main] INFO security.OMCertificateClient: Loading certificate from location:/data/metadata/om/certs.
om_1        | 2023-01-30 12:01:12,096 [main] INFO security.OMCertificateClient: Added certificate [
om_1        | [
om_1        |   Version: V3
om_1        |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
om_1        | 
om_1        |   Key:  Sun RSA public key, 2048 bits
om_1        |   params: null
datanode_2  | 2023-01-30 12:00:55,287 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_2  | 2023-01-30 12:00:55,394 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_2  | 2023-01-30 12:00:55,451 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
datanode_2  | 2023-01-30 12:00:55,466 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
datanode_2  | 2023-01-30 12:01:01,963 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
datanode_2  | 2023-01-30 12:01:02,178 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
datanode_2  | 2023-01-30 12:01:02,204 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
datanode_2  | 2023-01-30 12:01:02,215 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
datanode_1  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
kdc_1       | Jan 30 12:17:20 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:17:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:17:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:17:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
datanode_2  | 2023-01-30 12:01:02,229 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_2  | 2023-01-30 12:01:02,252 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
datanode_2  | 2023-01-30 12:01:02,258 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
datanode_2  | 2023-01-30 12:01:02,314 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
datanode_2  | 2023-01-30 12:01:02,326 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
datanode_2  | 2023-01-30 12:01:02,577 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
kdc_1       | Jan 30 12:17:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:02,588 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
datanode_2  | 2023-01-30 12:01:03,036 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
datanode_3  |   Key_Agreement
scm_1       | 2023-01-30 12:00:18,716 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
kdc_1       | Jan 30 12:17:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_2  | 2023-01-30 12:01:03,043 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
recon_1     | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
recon_1     | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
recon_1     | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
recon_1     | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
datanode_3  |   Key_CertSign
datanode_3  |   Crl_Sign
datanode_3  | ]
datanode_3  | 
datanode_3  | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_3  | SubjectAlternativeName [
datanode_3  |   IPAddress: 172.18.0.5
recon_1     | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
recon_1     | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
recon_1     | 
recon_1     | ] from file:/data/metadata/recon/certs/ROOTCA-1.crt.
recon_1     | 2023-01-30 12:00:41,611 [main] INFO client.ReconCertificateClient: Added certificate [
recon_1     | [
recon_1     |   Version: V3
recon_1     |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 
datanode_1  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_1  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_1  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
datanode_1  | 	... 15 more
datanode_1  | 2023-01-30 12:01:18,406 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_1  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
scm_1       | 2023-01-30 12:00:18,717 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2023-01-30 12:00:18,735 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
scm_1       | 2023-01-30 12:00:18,735 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-30 12:00:18,766 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:18,766 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:18,767 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
kdc_1       | Jan 30 12:17:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:03,045 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
recon_1     |   Key:  Sun RSA public key, 2048 bits
recon_1     |   params: null
datanode_3  | ]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
scm_1       | 2023-01-30 12:00:18,778 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
kdc_1       | Jan 30 12:18:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:03,140 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
recon_1     |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
recon_1     |   public exponent: 65537
recon_1     |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
recon_1     |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:320)
kdc_1       | Jan 30 12:18:06 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675080821, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:41 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:18:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:50 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:18:56 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:03,173 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2023-01-30 12:01:03,347 [01074a56-f4fb-4406-b467-549b4df46db9-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x6b09918c] REGISTERED
datanode_2  | 2023-01-30 12:01:03,377 [01074a56-f4fb-4406-b467-549b4df46db9-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x6b09918c] BIND: 0.0.0.0/0.0.0.0:9855
datanode_2  | 2023-01-30 12:01:03,418 [01074a56-f4fb-4406-b467-549b4df46db9-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x6b09918c, L:/0.0.0.0:9855] ACTIVE
datanode_2  | 2023-01-30 12:01:03,946 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
datanode_2  | 2023-01-30 12:01:03,975 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode_1  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:516)
datanode_1  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_1  | Caused by: java.util.concurrent.TimeoutException
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_1  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_1  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_3  | 
datanode_3  | ]
recon_1     |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_2  | 2023-01-30 12:01:04,045 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
datanode_2  | 2023-01-30 12:01:05,013 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 279961009839
scm_1       | 2023-01-30 12:00:18,778 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-30 12:00:18,780 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: start as a follower, conf=-1: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  |   Algorithm: [SHA256withRSA]
kdc_1       | Jan 30 12:19:10 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   SerialNumber: [    3b882292 67]
datanode_2  | 2023-01-30 12:01:05,039 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 279961009839
scm_1       | 2023-01-30 12:00:18,782 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2023-01-30 12:00:18,784 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState
scm_1       | 2023-01-30 12:00:18,788 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87E6E2D1E545,id=82e918d1-ff68-4821-a2f0-f9af71d19ea5
kdc_1       | Jan 30 12:19:25 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:31 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081121, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:32 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:05,453 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
scm_1       | 2023-01-30 12:00:18,792 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2023-01-30 12:00:18,788 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
datanode_3  |   Signature:
datanode_3  | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
datanode_3  | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
datanode_3  | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
datanode_3  | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
datanode_2  | 2023-01-30 12:01:05,458 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_2  | 2023-01-30 12:01:05,458 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
om_1        |   public exponent: 65537
om_1        |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
om_1        |                To: Thu Mar 09 00:00:00 UTC 2028]
scm_1       | 2023-01-30 12:00:18,793 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
datanode_1  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
om_1        |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
om_1        |   SerialNumber: [    01]
kdc_1       | Jan 30 12:19:37 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,794 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:01:05,734 [main] INFO util.log: Logging initialized @87492ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_1  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
kdc_1       | Jan 30 12:19:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:19:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:20:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:18,794 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
datanode_1  | 	... 1 more
om_1        | 
datanode_2  | 2023-01-30 12:01:06,632 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
kdc_1       | Jan 30 12:20:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:20:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 
scm_1       | 2023-01-30 12:00:18,795 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2023-01-30 12:01:47,442 [Command processor thread] INFO server.RaftServer: 6295590c-c30d-436f-ae9f-b085e438c72d: addNew group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] returns group-CE3F4E13DA16:java.util.concurrent.CompletableFuture@688a3256[Not completed]
scm_1       | 2023-01-30 12:00:18,798 [main] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start RPC server
recon_1     | Certificate Extensions: 3
om_1        | Certificate Extensions: 3
om_1        | [1]: ObjectId: 2.5.29.19 Criticality=true
om_1        | BasicConstraints:[
datanode_3  | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
datanode_1  | 2023-01-30 12:01:47,538 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d: new RaftServerImpl for group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
scm_1       | 2023-01-30 12:00:18,815 [main] INFO server.GrpcService: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: GrpcService started, listening on 9894
recon_1     | [1]: ObjectId: 2.5.29.19 Criticality=true
om_1        |   CA:true
kdc_1       | Jan 30 12:20:16 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081172, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:06,666 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2023-01-30 12:01:06,681 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_2  | 2023-01-30 12:01:06,681 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_1  | 2023-01-30 12:01:47,542 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2023-01-30 12:00:18,818 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-82e918d1-ff68-4821-a2f0-f9af71d19ea5: Started
recon_1     | BasicConstraints:[
om_1        |   PathLen:2147483647
kdc_1       | Jan 30 12:20:18 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
datanode_1  | 2023-01-30 12:01:47,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2023-01-30 12:00:23,811 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.FollowerState: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027253813ns, electionTimeout:5016ms
recon_1     |   CA:true
datanode_2  | 2023-01-30 12:01:06,681 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
om_1        | ]
kdc_1       | Jan 30 12:20:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
datanode_1  | 2023-01-30 12:01:47,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_1  | 2023-01-30 12:01:47,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
scm_1       | 2023-01-30 12:00:23,813 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState
recon_1     |   PathLen:2147483647
datanode_2  | 2023-01-30 12:01:06,706 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
om_1        | 
datanode_2  | 2023-01-30 12:01:06,974 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_1  | 2023-01-30 12:01:47,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_1  | 2023-01-30 12:01:47,546 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_3  | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
scm_1       | 2023-01-30 12:00:23,813 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | 2023-01-30 12:00:23,816 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     | ]
kdc_1       | Jan 30 12:20:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:06,985 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_2  | 2023-01-30 12:01:07,214 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_2  | 2023-01-30 12:01:07,214 [main] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2023-01-30 12:00:23,816 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1
datanode_3  | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
datanode_1  | 2023-01-30 12:01:47,576 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: ConfigurationManager, init=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2023-01-30 12:01:47,577 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Jan 30 12:20:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:20:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | [2]: ObjectId: 2.5.29.15 Criticality=true
scm_1       | 2023-01-30 12:00:23,826 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.LeaderElection: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:01:47,595 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2023-01-30 12:01:47,597 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
datanode_2  | 2023-01-30 12:01:07,249 [main] INFO server.session: node0 Scavenging every 600000ms
kdc_1       | Jan 30 12:20:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:20:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:23,828 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.LeaderElection: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2023-01-30 12:01:47,632 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2023-01-30 12:01:47,646 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_3  | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
datanode_2  | 2023-01-30 12:01:07,357 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
kdc_1       | Jan 30 12:20:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:02 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081218, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:04 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:47,647 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_1  | 2023-01-30 12:01:47,863 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | KeyUsage [
scm_1       | 2023-01-30 12:00:23,828 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1
datanode_1  | 2023-01-30 12:01:47,867 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_1  | 2023-01-30 12:01:47,870 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_1  | 2023-01-30 12:01:47,872 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
scm_1       | 2023-01-30 12:00:23,829 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2023-01-30 12:01:47,873 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_1  | 2023-01-30 12:01:47,876 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 does not exist. Creating ...
datanode_1  | 2023-01-30 12:01:47,901 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/in_use.lock acquired by nodename 7@5ffad95da0eb
datanode_1  | 2023-01-30 12:01:47,924 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 has been successfully formatted.
scm_1       | 2023-01-30 12:00:23,829 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: change Leader from null to 82e918d1-ff68-4821-a2f0-f9af71d19ea5 at term 1 for becomeLeader, leader elected after 5291ms
scm_1       | 2023-01-30 12:00:23,840 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2023-01-30 12:00:23,847 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_1  | 2023-01-30 12:01:47,983 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-CE3F4E13DA16: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_1  | 2023-01-30 12:01:47,988 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_1  | 2023-01-30 12:01:48,111 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_1  | 2023-01-30 12:01:48,112 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-30 12:01:48,142 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1       | 2023-01-30 12:00:23,848 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
kdc_1       | Jan 30 12:21:08 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
datanode_3  | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
datanode_1  | 2023-01-30 12:01:48,143 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_1  | 2023-01-30 12:01:48,169 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
recon_1     | 
recon_1     | [2]: ObjectId: 2.5.29.15 Criticality=true
scm_1       | 2023-01-30 12:00:23,856 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
kdc_1       | Jan 30 12:21:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
datanode_3  | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
datanode_1  | 2023-01-30 12:01:48,210 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_2  | 2023-01-30 12:01:07,397 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4057eb76{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | KeyUsage [
recon_1     |   DigitalSignature
recon_1     |   Key_Encipherment
recon_1     |   Data_Encipherment
datanode_3  | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
datanode_3  | 
datanode_1  | 2023-01-30 12:01:48,215 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2023-01-30 12:01:07,404 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@3ab7b0f{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     |   Key_Agreement
scm_1       | 2023-01-30 12:00:23,856 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        |   Key_CertSign
om_1        |   Crl_Sign
datanode_3  | ] from file:/data/metadata/dn/certs/CA-255687037543.crt.
datanode_3  | 2023-01-30 12:00:42,683 [main] INFO client.DNCertificateClient: Added certificate [
datanode_1  | 2023-01-30 12:01:48,264 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
datanode_2  | 2023-01-30 12:01:08,055 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
recon_1     |   Key_CertSign
scm_1       | 2023-01-30 12:00:23,857 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2023-01-30 12:00:23,864 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2023-01-30 12:00:23,865 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_3  | [
datanode_3  |   Version: V3
datanode_1  | 2023-01-30 12:01:48,281 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_2  | 2023-01-30 12:01:08,135 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@179367ff{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-10673044774529948668/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
recon_1     |   Crl_Sign
recon_1     | ]
scm_1       | 2023-01-30 12:00:23,868 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderStateImpl
scm_1       | 2023-01-30 12:00:23,889 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: Starting segment from index:0
scm_1       | 2023-01-30 12:00:23,928 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: set configuration 0: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-30 12:00:23,980 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/log_inprogress_0
scm_1       | 2023-01-30 12:00:24,820 [main] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: close
scm_1       | 2023-01-30 12:00:24,821 [main] INFO server.GrpcService: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown server GrpcServerProtocolService now
scm_1       | 2023-01-30 12:00:24,821 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: shutdown
scm_1       | 2023-01-30 12:00:24,821 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO util.JmxRegister: Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-87E6E2D1E545,id=82e918d1-ff68-4821-a2f0-f9af71d19ea5
scm_1       | 2023-01-30 12:00:24,822 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderStateImpl
recon_1     | 
recon_1     | [3]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | SubjectAlternativeName [
recon_1     |   IPAddress: 172.18.0.5
recon_1     | ]
recon_1     | 
recon_1     | ]
recon_1     |   Algorithm: [SHA256withRSA]
recon_1     |   Signature:
recon_1     | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
recon_1     | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
recon_1     | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
recon_1     | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
scm_1       | 2023-01-30 12:00:24,828 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO impl.PendingRequests: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-PendingRequests: sendNotLeaderResponses
scm_1       | 2023-01-30 12:00:24,833 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO impl.StateMachineUpdater: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater: set stopIndex = 0
scm_1       | 2023-01-30 12:00:24,834 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO impl.StateMachineUpdater: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater: Took a snapshot at index 0
scm_1       | 2023-01-30 12:00:24,835 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO impl.StateMachineUpdater: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater: snapshotIndex: updateIncreasingly -1 -> 0
scm_1       | 2023-01-30 12:00:24,844 [main] INFO server.GrpcService: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown server GrpcServerProtocolService successfully
scm_1       | 2023-01-30 12:00:24,848 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: closes. applyIndex: 0
scm_1       | 2023-01-30 12:00:24,850 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed, L:/0.0.0.0:46081] CLOSE
datanode_1  | 2023-01-30 12:01:48,282 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_1  | 2023-01-30 12:01:48,290 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_1  | 2023-01-30 12:01:48,293 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2023-01-30 12:01:08,189 [main] INFO server.AbstractConnector: Started ServerConnector@145c6e4d{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
scm_1       | 2023-01-30 12:00:24,853 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed, L:/0.0.0.0:46081] INACTIVE
scm_1       | 2023-01-30 12:00:24,853 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x5c9226ed, L:/0.0.0.0:46081] UNREGISTERED
recon_1     | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
recon_1     | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
recon_1     | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
recon_1     | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
datanode_3  |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=dn@51f838724954
datanode_2  | 2023-01-30 12:01:08,189 [main] INFO server.Server: Started @89948ms
datanode_2  | 2023-01-30 12:01:08,198 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_2  | 2023-01-30 12:01:08,198 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_2  | 2023-01-30 12:01:08,204 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_2  | 2023-01-30 12:01:08,239 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3  |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
datanode_3  | 
kdc_1       | Jan 30 12:21:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:48,295 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_1  | 2023-01-30 12:01:48,302 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_1  | 2023-01-30 12:01:48,311 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_1  | 2023-01-30 12:01:48,313 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_3  |   Key:  Sun RSA public key, 2048 bits
recon_1     | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
recon_1     | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
recon_1     | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
datanode_3  |   params: null
datanode_3  |   modulus: 23238218334939521590270055651374082125849894868350112299655190694748643694945379787642443129476325875553883111794784421107539581583775909750214183720039642585753266417032435759750854183683503509492882238612333979312955533782967304017576347624479768532124860277541975923976385280788404992441252042616626790205628558516411523795868911548429635538995056367286463699942164930459255916133931083921959419020981873907253362661678444893661153785774487368074166541559515933208751742312815495100793434475576103823456865465666732397748578531327167981985070941406831628462188654757421256063900069373685019289216175598151871988517
recon_1     | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
recon_1     | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
recon_1     | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
recon_1     | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
recon_1     | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
recon_1     | 
recon_1     | ] from file:/data/metadata/recon/certs/CA-255687037543.crt.
datanode_3  |   public exponent: 65537
datanode_3  |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
scm_1       | 2023-01-30 12:00:24,860 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
scm_1       | 2023-01-30 12:00:24,871 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker close()
scm_1       | 2023-01-30 12:00:24,877 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-82e918d1-ff68-4821-a2f0-f9af71d19ea5: Stopped
scm_1       | 2023-01-30 12:00:24,877 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-30 12:00:24,881 [main] INFO server.StorageContainerManager: SCM initialization succeeded. Current cluster id for sd=/data/metadata/scm; cid=CID-b04a1c74-af13-4571-b723-87e6e2d1e545; layoutVersion=4; scmId=82e918d1-ff68-4821-a2f0-f9af71d19ea5
datanode_3  |                To: Tue Jan 30 00:00:00 UTC 2024]
datanode_1  | 2023-01-30 12:01:48,402 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_1  | 2023-01-30 12:01:48,414 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | ]
om_1        | 
om_1        | [3]: ObjectId: 2.5.29.17 Criticality=false
om_1        | SubjectAlternativeName [
om_1        |   IPAddress: 172.18.0.5
datanode_3  |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
datanode_1  | 2023-01-30 12:01:48,472 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
om_1        | ]
om_1        | 
om_1        | ]
om_1        |   Algorithm: [SHA256withRSA]
om_1        |   Signature:
om_1        | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
datanode_1  | 2023-01-30 12:01:48,480 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  |   SerialNumber: [    41258715 10]
datanode_3  | 
datanode_1  | 2023-01-30 12:01:48,482 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2023-01-30 12:00:25,869 [shutdown-hook-0] INFO server.StorageContainerManagerStarter: SHUTDOWN_MSG: 
recon_1     | 2023-01-30 12:00:41,636 [main] INFO client.ReconCertificateClient: Added certificate [
recon_1     | [
datanode_2  | 2023-01-30 12:01:08,426 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@35310757] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_2  | 2023-01-30 12:01:08,859 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.6:9891
datanode_1  | 2023-01-30 12:01:48,530 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_1  | 2023-01-30 12:01:48,530 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | /************************************************************
scm_1       | SHUTDOWN_MSG: Shutting down StorageContainerManager at scm/172.18.0.5
scm_1       | ************************************************************/
scm_1       | No '-XX:...' jvm parameters are set. Adding safer GC settings '-XX:ParallelGCThreads=8 -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled' to the OZONE_OPTS
scm_1       | OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.
datanode_1  | 2023-01-30 12:01:48,554 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: start as a follower, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:01:48,556 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from      null to FOLLOWER at term 0 for startAsFollower
kdc_1       | Jan 30 12:21:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:39 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:45 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:08,898 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_2  | 2023-01-30 12:01:12,704 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-f0b5a7ed-a995-441b-a8dc-8f205877eff1/container.db to cache
datanode_1  | 2023-01-30 12:01:48,560 [pool-24-thread-1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
datanode_3  | Certificate Extensions: 2
datanode_3  | [1]: ObjectId: 2.5.29.15 Criticality=true
datanode_3  | KeyUsage [
datanode_3  |   DigitalSignature
recon_1     |   Version: V3
recon_1     |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=recon@recon
recon_1     |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 
datanode_1  | 2023-01-30 12:01:48,606 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
kdc_1       | Jan 30 12:21:51 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081264, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:21:52 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
datanode_3  |   Key_Encipherment
recon_1     |   Key:  Sun RSA public key, 2048 bits
recon_1     |   params: null
recon_1     |   modulus: 21660826695829584094562946549514954826334075726361688343455539090205428941974194621927810965315387529254155260495391159327445805830123455751469997451250061542029754076944088638075859812705835845508099461817076685944714715288463829038620186213314517270945338649468732590111822506605010589723480109199457540270463685470679998918116200931735479777241552717637480862797327093366676786577865095666642138379521911212233684169481445842776254393747014983585454289361925560818507523401770381372597692346356515612824885244006187939884089662420514290616376179749468306648271066004719573074555423140537209556719028903588112167217
recon_1     |   public exponent: 65537
datanode_2  | 2023-01-30 12:01:12,712 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-f0b5a7ed-a995-441b-a8dc-8f205877eff1/container.db for volume DS-f0b5a7ed-a995-441b-a8dc-8f205877eff1
datanode_1  | 2023-01-30 12:01:48,607 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2023-01-30 12:01:48,608 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE3F4E13DA16,id=6295590c-c30d-436f-ae9f-b085e438c72d
datanode_3  |   Data_Encipherment
om_1        | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
om_1        | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
kdc_1       | Jan 30 12:21:57 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:03 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:15 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:48,621 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  |   Key_Agreement
datanode_3  | ]
datanode_3  | 
datanode_3  | [2]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | 2023-01-30 12:00:27,413 [main] INFO server.StorageContainerManagerStarter: STARTUP_MSG: 
scm_1       | /************************************************************
scm_1       | STARTUP_MSG: Starting StorageContainerManager
datanode_1  | 2023-01-30 12:01:48,621 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2023-01-30 12:01:12,739 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_2  | 2023-01-30 12:01:12,742 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_2  | 2023-01-30 12:01:12,817 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode_2  | 2023-01-30 12:01:12,840 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis 01074a56-f4fb-4406-b467-549b4df46db9
datanode_2  | 2023-01-30 12:01:12,922 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.RaftServer: 01074a56-f4fb-4406-b467-549b4df46db9: start RPC server
datanode_1  | 2023-01-30 12:01:48,627 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
om_1        | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
om_1        | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
om_1        | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
om_1        | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
om_1        | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
datanode_1  | 2023-01-30 12:01:48,628 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
scm_1       | STARTUP_MSG:   host = scm/172.18.0.5
scm_1       | STARTUP_MSG:   args = []
scm_1       | STARTUP_MSG:   version = 1.4.0-SNAPSHOT
scm_1       | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop/share/ozone/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/ozone/lib/slf4j-reload4j-1.7.36.jar:/opt/hadoop/share/ozone/lib/netty-resolver-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/ozone/lib/jaxb-core-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/istack-commons-runtime-3.0.5.jar:/opt/hadoop/share/ozone/lib/commons-validator-1.6.jar:/opt/hadoop/share/ozone/lib/hdds-erasurecode-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/bcpkix-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/netty-codec-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/commons-net-3.9.0.jar:/opt/hadoop/share/ozone/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-protobuf_3_7-1.1.1.jar:/opt/hadoop/share/ozone/lib/jsr305-3.0.0.jar:/opt/hadoop/share/ozone/lib/j2objc-annotations-1.3.jar:/opt/hadoop/share/ozone/lib/jetty-webapp-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/picocli-4.6.1.jar:/opt/hadoop/share/ozone/lib/javassist-3.21.0-GA.jar:/opt/hadoop/share/ozone/lib/jaxb-api-2.3.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-admin-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-codec-1.15.jar:/opt/hadoop/share/ozone/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-1.6.21.jar:/opt/hadoop/share/ozone/lib/log4j-core-2.17.1.jar:/opt/hadoop/share/ozone/lib/commons-logging-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-thirdparty-misc-1.0.3.jar:/opt/hadoop/share/ozone/lib/jetty-security-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/accessors-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/ozone/lib/txw2-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/httpcore-4.4.13.jar:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/guava-31.1-jre.jar:/opt/hadoop/share/ozone/lib/opentracing-tracerresolver-0.1.8.jar:/opt/hadoop/share/ozone/lib/ratis-grpc-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hadoop-auth-3.3.4.jar:/opt/hadoop/share/ozone/lib/libthrift-0.14.1.jar:/opt/hadoop/share/ozone/lib/stax-ex-1.7.8.jar:/opt/hadoop/share/ozone/lib/error_prone_annotations-2.2.0.jar:/opt/hadoop/share/ozone/lib/hdds-hadoop-dependency-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/zstd-jni-1.5.2-5.jar:/opt/hadoop/share/ozone/lib/httpclient-4.5.13.jar:/opt/hadoop/share/ozone/lib/ratis-proto-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jaeger-client-1.6.0.jar:/opt/hadoop/share/ozone/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-annotations-2.13.4.jar:/opt/hadoop/share/ozone/lib/commons-io-2.11.0.jar:/opt/hadoop/share/ozone/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/ozone/lib/hadoop-annotations-3.3.4.jar:/opt/hadoop/share/ozone/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/ozone/lib/netty-buffer-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/jetty-util-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/json-smart-2.4.7.jar:/opt/hadoop/share/ozone/lib/jetty-io-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/ozone/lib/jetty-server-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/commons-beanutils-1.9.4.jar:/opt/hadoop/share/ozone/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/ozone/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/ozone/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-xml-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/hadoop-common-3.3.4.jar:/opt/hadoop/share/ozone/lib/disruptor-3.4.2.jar:/opt/hadoop/share/ozone/lib/reflections-0.9.11.jar:/opt/hadoop/share/ozone/lib/gson-2.9.0.jar:/opt/hadoop/share/ozone/lib/snakeyaml-1.33.jar:/opt/hadoop/share/ozone/lib/nimbus-jose-jwt-9.8.1.jar:/opt/hadoop/share/ozone/lib/hdds-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/ratis-common-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/annotations-13.0.jar:/opt/hadoop/share/ozone/lib/simpleclient_common-0.7.0.jar:/opt/hadoop/share/ozone/lib/jaeger-thrift-1.6.0.jar:/opt/hadoop/share/ozone/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/ozone/lib/rocksdbjni-7.7.3.jar:/opt/hadoop/share/ozone/lib/bcprov-jdk15on-1.67.jar:/opt/hadoop/share/ozone/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/ozone/lib/token-provider-1.0.1.jar:/opt/hadoop/share/ozone/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/ozone/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/opt/hadoop/share/ozone/lib/jaeger-tracerresolver-1.6.0.jar:/opt/hadoop/share/ozone/lib/slf4j-api-1.7.36.jar:/opt/hadoop/share/ozone/lib/commons-lang3-3.7.jar:/opt/hadoop/share/ozone/lib/re2j-1.1.jar:/opt/hadoop/share/ozone/lib/jackson-datatype-jsr310-2.13.4.jar:/opt/hadoop/share/ozone/lib/netty-transport-native-unix-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient_dropwizard-0.7.0.jar:/opt/hadoop/share/ozone/lib/netty-transport-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/simpleclient-0.7.0.jar:/opt/hadoop/share/ozone/lib/ratis-metrics-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jakarta.activation-api-1.2.2.jar:/opt/hadoop/share/ozone/lib/asm-5.0.4.jar:/opt/hadoop/share/ozone/lib/netty-handler-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/ozone/lib/failureaccess-1.0.1.jar:/opt/hadoop/share/ozone/lib/jackson-databind-2.13.4.2.jar:/opt/hadoop/share/ozone/lib/okio-2.8.0.jar:/opt/hadoop/share/ozone/lib/jetty-servlet-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/jsp-api-2.1.jar:/opt/hadoop/share/ozone/lib/jsch-0.1.54.jar:/opt/hadoop/share/ozone/lib/reload4j-1.2.22.jar:/opt/hadoop/share/ozone/lib/woodstox-core-5.4.0.jar:/opt/hadoop/share/ozone/lib/commons-pool2-2.6.0.jar:/opt/hadoop/share/ozone/lib/opentracing-api-0.33.0.jar:/opt/hadoop/share/ozone/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/ozone/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/ozone/lib/jetty-util-ajax-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/opentracing-noop-0.33.0.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-client-3.3.4.jar:/opt/hadoop/share/ozone/lib/kotlin-stdlib-common-1.6.21.jar:/opt/hadoop/share/ozone/lib/jersey-core-1.19.jar:/opt/hadoop/share/ozone/lib/commons-compress-1.21.jar:/opt/hadoop/share/ozone/lib/jaxb-runtime-2.3.0.1.jar:/opt/hadoop/share/ozone/lib/hadoop-hdfs-3.3.4.jar:/opt/hadoop/share/ozone/lib/jackson-core-2.13.4.jar:/opt/hadoop/share/ozone/lib/hdds-annotation-processing-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/opentracing-util-0.33.0.jar:/opt/hadoop/share/ozone/lib/stax2-api-4.2.1.jar:/opt/hadoop/share/ozone/lib/netty-common-4.1.86.Final.jar:/opt/hadoop/share/ozone/lib/snappy-java-1.1.8.2.jar:/opt/hadoop/share/ozone/lib/ratis-netty-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-config-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-cli-1.2.jar:/opt/hadoop/share/ozone/lib/log4j-api-2.17.1.jar:/opt/hadoop/share/ozone/lib/javax.annotation-api-1.2.jar:/opt/hadoop/share/ozone/lib/ratis-server-api-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-interface-client-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/ozone/lib/okhttp-4.9.3.jar:/opt/hadoop/share/ozone/lib/checker-qual-3.12.0.jar:/opt/hadoop/share/ozone/lib/hdds-interface-server-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-digester-1.8.1.jar:/opt/hadoop/share/ozone/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/ozone/lib/jaeger-core-1.6.0.jar:/opt/hadoop/share/ozone/lib/ratis-client-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/commons-text-1.4.jar:/opt/hadoop/share/ozone/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/ozone/lib/ratis-server-2.4.2-8b8bdda-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jetty-http-9.4.49.v20220914.jar:/opt/hadoop/share/ozone/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/ozone/lib/FastInfoset-1.2.13.jar:/opt/hadoop/share/ozone/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/ozone/lib/hdds-server-framework-1.4.0-SNAPSHOT.jar:/opt/hadoop/share/ozone/lib/jersey-server-1.19.jar:/opt/hadoop/share/ozone/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/ozone/web:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar
scm_1       | STARTUP_MSG:   build = https://github.com/apache/ozone/38733cfff1fa0132afba0bf245facd97d33048aa ; compiled by 'runner' on 2023-01-30T11:44Z
kdc_1       | Jan 30 12:22:21 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:26 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:48,783 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
datanode_2  | 2023-01-30 12:01:12,939 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 01074a56-f4fb-4406-b467-549b4df46db9: GrpcService started, listening on 9858
datanode_2  | 2023-01-30 12:01:12,955 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 01074a56-f4fb-4406-b467-549b4df46db9: GrpcService started, listening on 9856
datanode_2  | 2023-01-30 12:01:12,965 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: 01074a56-f4fb-4406-b467-549b4df46db9: GrpcService started, listening on 9857
datanode_2  | 2023-01-30 12:01:13,007 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-01074a56-f4fb-4406-b467-549b4df46db9: Started
datanode_2  | 2023-01-30 12:01:13,019 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 01074a56-f4fb-4406-b467-549b4df46db9 is started using port 9858 for RATIS
datanode_2  | 2023-01-30 12:01:13,019 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 01074a56-f4fb-4406-b467-549b4df46db9 is started using port 9857 for RATIS_ADMIN
datanode_1  | 2023-01-30 12:01:48,892 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_2  | 2023-01-30 12:01:13,019 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 01074a56-f4fb-4406-b467-549b4df46db9 is started using port 9856 for RATIS_SERVER
datanode_2  | 2023-01-30 12:01:13,019 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis 01074a56-f4fb-4406-b467-549b4df46db9 is started using port 9855 for RATIS_DATASTREAM
kdc_1       | Jan 30 12:22:32 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081312, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:22:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
kdc_1       | Jan 30 12:22:47 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
recon_1     |                To: Tue Jan 30 00:00:00 UTC 2024]
recon_1     |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
om_1        | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
om_1        | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
om_1        | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
kdc_1       | Jan 30 12:22:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:53,370 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
om_1        | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
scm_1       | STARTUP_MSG:   java = 11.0.14.1
scm_1       | ************************************************************/
scm_1       | 2023-01-30 12:00:27,421 [main] INFO server.StorageContainerManagerStarter: registered UNIX signal handlers for [TERM, HUP, INT]
scm_1       | 2023-01-30 12:00:27,486 [main] WARN server.ServerUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-30 12:00:27,549 [main] INFO ha.SCMHANodeDetails: ServiceID for StorageContainerManager is null
om_1        | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
om_1        | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
kdc_1       | Jan 30 12:22:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:12 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | SubjectAlternativeName [
om_1        | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
om_1        | 
om_1        | ] from file:/data/metadata/om/certs/ROOTCA-1.crt.
om_1        | 2023-01-30 12:01:12,117 [main] INFO security.OMCertificateClient: Added certificate [
om_1        | [
om_1        |   Version: V3
om_1        |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
om_1        | 
recon_1     |   SerialNumber: [    40f89e3d e3]
datanode_3  |   IPAddress: 172.18.0.4
datanode_3  | ]
kdc_1       | Jan 30 12:23:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:35 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:41 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:23:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 
kdc_1       | Jan 30 12:23:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
recon_1     | 
datanode_3  | ]
datanode_2  | 2023-01-30 12:01:15,523 [EndpointStateMachine task thread for recon/172.18.0.6:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_2  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort 2850eee4085e/172.18.0.8:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:42032 remote=recon/172.18.0.6:9891]
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_2  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_2  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
recon_1     | Certificate Extensions: 2
scm_1       | 2023-01-30 12:00:27,574 [main] INFO ha.SCMHANodeDetails: ozone.scm.default.service.id is not defined, falling back to ozone.scm.service.ids to find serviceID for StorageContainerManager if it is HA enabled cluster
datanode_3  |   Algorithm: [SHA256withRSA]
datanode_2  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_2  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
datanode_2  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_1  | 2023-01-30 12:01:53,613 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5053320793ns, electionTimeout:5000ms
scm_1       | 2023-01-30 12:00:28,283 [main] INFO client.SCMCertificateClient: Loading certificate from location:/data/metadata/scm/sub-ca/certs.
datanode_3  |   Signature:
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_2  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_1  | 2023-01-30 12:01:53,613 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
scm_1       | 2023-01-30 12:00:28,442 [main] INFO client.SCMCertificateClient: Added certificate [
datanode_3  | 0000: 23 56 F7 3A 1B C4 2F CA   71 71 29 C4 FA D0 F0 6F  #V.:../.qq)....o
datanode_2  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_2  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_1  | 2023-01-30 12:01:53,626 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
scm_1       | [
datanode_3  | 0010: 87 61 B0 A8 43 C9 8D 74   9C 50 B1 CE 26 97 AE 2B  .a..C..t.P..&..+
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_1  | 2023-01-30 12:01:53,635 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       |   Version: V3
datanode_3  | 0020: 5E 41 7F 65 AA 37 53 CD   54 29 C5 E6 C8 06 78 24  ^A.e.7S.T)....x$
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | [1]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | KeyUsage [
recon_1     |   DigitalSignature
scm_1       |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
scm_1       | 
recon_1     |   Key_Encipherment
recon_1     |   Data_Encipherment
recon_1     |   Key_Agreement
recon_1     | ]
recon_1     | 
recon_1     | [2]: ObjectId: 2.5.29.17 Criticality=false
recon_1     | SubjectAlternativeName [
recon_1     |   IPAddress: 172.18.0.6
om_1        |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 2023-01-30 12:01:53,635 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1
datanode_1  | 2023-01-30 12:01:53,671 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:01:53,733 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-30 12:01:53,733 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2023-01-30 12:01:53,756 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for c8ea7a3f-965d-439b-b69f-d2205a7da823
datanode_1  | 2023-01-30 12:01:53,758 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 01074a56-f4fb-4406-b467-549b4df46db9
om_1        |   params: null
om_1        |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
recon_1     | ]
recon_1     | 
datanode_3  | 0030: 9A A8 24 52 69 47 0B AE   2B 25 12 A7 F8 73 E1 DA  ..$RiG..+%...s..
datanode_2  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:42032 remote=recon/172.18.0.6:9891]
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
kdc_1       | Jan 30 12:24:22 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   Key:  Sun RSA public key, 2048 bits
datanode_3  | 0040: 80 13 7E E8 C9 00 3A E9   DC 41 93 A8 F4 8C 1D DF  ......:..A......
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
kdc_1       | Jan 30 12:24:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:24:54 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:25:00 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   params: null
scm_1       |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
scm_1       |   public exponent: 65537
datanode_3  | 0050: E2 B0 EB B2 F6 CC 06 6A   1F 51 27 3B 2C 0D 4A CB  .......j.Q';,.J.
datanode_1  | 2023-01-30 12:01:54,463 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: receive requestVote(ELECTION, 01074a56-f4fb-4406-b467-549b4df46db9, group-CE3F4E13DA16, 1, (t:0, i:0))
kdc_1       | Jan 30 12:25:09 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        |   public exponent: 65537
om_1        |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
scm_1       |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_3  | 0060: 22 60 C0 01 38 12 EC 2C   C0 F7 1C 5C 79 ED 64 8F  "`..8..,...\y.d.
datanode_1  | 2023-01-30 12:01:54,468 [grpc-default-executor-1] INFO impl.VoteContext: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-CANDIDATE: reject ELECTION from 01074a56-f4fb-4406-b467-549b4df46db9: already has voted for 6295590c-c30d-436f-ae9f-b085e438c72d at current term 1
kdc_1       | Jan 30 12:25:18 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:25:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:25:28 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
datanode_3  | 0070: 0B BE 97 36 D7 8B 63 A6   D7 29 0E E0 A2 EF 2B EF  ...6..c..)....+.
datanode_3  | 0080: 7F 63 3A E0 CD 77 26 3B   8C 12 B1 B0 4F CE 89 8F  .c:..w&;....O...
kdc_1       | Jan 30 12:25:38 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:25:43 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:25:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
scm_1       |   SerialNumber: [    3b882292 67]
datanode_3  | 0090: 89 1E C6 2C CF 7B 91 30   B4 5E 72 A0 5E D5 B8 8F  ...,...0.^r.^...
datanode_3  | 00A0: E9 59 C8 2F 67 3E 8F 44   B1 BD A2 78 99 34 5A 7A  .Y./g>.D...x.4Zz
kdc_1       | Jan 30 12:25:55 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:26:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:26:07 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | 
scm_1       | Certificate Extensions: 3
datanode_3  | 00B0: 07 69 E6 B9 AF C9 19 D5   71 44 25 74 24 4F 67 3D  .i......qD%t$Og=
datanode_1  | 2023-01-30 12:01:54,515 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16 replies to ELECTION vote request: 01074a56-f4fb-4406-b467-549b4df46db9<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t1. Peer's state: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16:t1, leader=null, voted=6295590c-c30d-436f-ae9f-b085e438c72d, raftlog=Memoized:6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode_1  | 2023-01-30 12:01:55,082 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16.
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
datanode_2  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
recon_1     | ]
recon_1     |   Algorithm: [SHA256withRSA]
recon_1     |   Signature:
recon_1     | 0000: 1D 05 F7 68 82 B9 07 B1   29 0A CF 62 C4 15 4D 3D  ...h....)..b..M=
recon_1     | 0010: 78 62 FF 53 EA 31 E8 A2   A2 87 C8 04 FC C5 E6 4A  xb.S.1.........J
datanode_2  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
datanode_2  | 	... 12 more
scm_1       | BasicConstraints:[
recon_1     | 0020: D9 EC C1 C0 C0 2E 64 2D   66 EB 81 31 35 02 10 F1  ......d-f..15...
recon_1     | 0030: 41 CF CC 67 EC 30 42 C9   CE 59 C4 4E 61 00 0D 14  A..g.0B..Y.Na...
recon_1     | 0040: 2A 8D 7E FD 0D D3 3F 0A   5D 48 5A D0 68 2E 66 5A  *.....?.]HZ.h.fZ
recon_1     | 0050: 3A 1D B3 5D 0C E3 D9 E0   B2 31 B2 7B 9F CF C7 4B  :..].....1.....K
scm_1       |   CA:true
om_1        |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_2  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.8:42032 remote=recon/172.18.0.6:9891]
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d: new RaftServerImpl for group-D14D9BFCC8C3:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
kdc_1       | Jan 30 12:26:13 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00C0: 39 27 64 30 67 03 E1 11   C4 82 BB C5 34 2F 7C 64  9'd0g.......4/.d
scm_1       |   PathLen:2147483647
scm_1       | ]
datanode_2  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
recon_1     | 0060: 51 E5 89 FF 99 F1 C3 84   49 63 6F 48 EA 7B DE 56  Q.......IcoH...V
recon_1     | 0070: A0 B3 07 91 9C B6 97 24   B4 C8 21 01 7B 70 29 B5  .......$..!..p).
recon_1     | 0080: E5 32 86 2B 1A C2 35 D3   DB B9 C8 87 89 4B 6E E4  .2.+..5......Kn.
datanode_3  | 00D0: 8C F4 71 26 B9 7B 2A 8A   0D A0 A4 83 E3 8F D5 C6  ..q&..*.........
datanode_3  | 00E0: D3 1A DA 2A 96 32 27 22   BF 81 83 2E 18 14 78 9B  ...*.2'"......x.
om_1        |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_2  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
recon_1     | 0090: 14 AB EB BC 49 6F E0 65   60 A6 24 79 4F 5A DE A9  ....Io.e`.$yOZ..
recon_1     | 00A0: E6 8F 8E 9A BB C5 92 CB   96 D1 F3 65 9F 0A EF 61  ...........e...a
recon_1     | 00B0: DA 3F 22 25 BA 9D 9D CC   DC 5F 2E 0E 50 4D AC 63  .?"%....._..PM.c
recon_1     | 00C0: 38 84 F8 56 08 38 AE 34   92 DD 32 4C 0B 5D 9E A0  8..V.8.4..2L.]..
recon_1     | 00D0: 41 C5 29 9E 38 6E 94 E5   6E 3A DB 76 1F 98 FC 5B  A.).8n..n:.v...[
recon_1     | 00E0: 8C 95 15 4B B6 B2 ED D4   09 58 3A DF 41 5C 4A E3  ...K.....X:.A\J.
recon_1     | 00F0: B7 68 F7 1C C9 04 EC 0F   D0 8E 5E 3D 5D E9 89 78  .h........^=]..x
recon_1     | 
recon_1     | ] from file:/data/metadata/recon/certs/279049027043.crt.
recon_1     | 2023-01-30 12:00:41,665 [main] INFO client.ReconCertificateClient: CertificateLifetimeMonitor for recon is started with first delay 29073558362 ms and interval 86400000 ms.
scm_1       | 
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
scm_1       | KeyUsage [
scm_1       |   DigitalSignature
scm_1       |   Key_Encipherment
scm_1       |   Data_Encipherment
scm_1       |   Key_Agreement
om_1        |   SerialNumber: [    3b882292 67]
om_1        | 
om_1        | Certificate Extensions: 3
om_1        | [1]: ObjectId: 2.5.29.19 Criticality=true
om_1        | BasicConstraints:[
om_1        |   CA:true
datanode_2  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_2  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
om_1        |   PathLen:2147483647
om_1        | ]
om_1        | 
om_1        | [2]: ObjectId: 2.5.29.15 Criticality=true
om_1        | KeyUsage [
om_1        |   DigitalSignature
om_1        |   Key_Encipherment
om_1        |   Data_Encipherment
datanode_2  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
om_1        |   Key_Agreement
om_1        |   Key_CertSign
om_1        |   Crl_Sign
om_1        | ]
om_1        | 
om_1        | [3]: ObjectId: 2.5.29.17 Criticality=false
om_1        | SubjectAlternativeName [
datanode_2  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_2  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
om_1        |   IPAddress: 172.18.0.5
om_1        | ]
recon_1     | 2023-01-30 12:00:41,665 [main] INFO recon.ReconServer: Successfully stored SCM signed certificate, case:GETCERT.
recon_1     | 2023-01-30 12:00:43,437 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
recon_1     | 2023-01-30 12:00:49,444 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | WARNING: An illegal reflective access operation has occurred
recon_1     | WARNING: Illegal reflective access by org.jooq.tools.reflect.Reflect (file:/opt/hadoop/share/ozone/lib/jooq-3.11.10.jar) to constructor java.lang.invoke.MethodHandles$Lookup(java.lang.Class)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
om_1        | 
recon_1     | WARNING: Please consider reporting this to the maintainers of org.jooq.tools.reflect.Reflect
recon_1     | WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
recon_1     | WARNING: All illegal access operations will be denied in a future release
kdc_1       | Jan 30 12:26:19 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 00F0: 7B A2 C5 BA F3 8D 11 C6   B6 E9 D1 A7 C1 D1 7F D6  ................
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
om_1        | ]
recon_1     | 2023-01-30 12:00:52,251 [main] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1     | 2023-01-30 12:00:52,265 [main] INFO impl.ReconContainerMetadataManagerImpl: It took 0.011 seconds to initialized 0 records to KEY_CONTAINER table
recon_1     | 2023-01-30 12:00:52,287 [main] INFO persistence.DefaultDataSourceProvider: JDBC Url for Recon : jdbc:derby:/data/metadata/recon/ozone_recon_derby.db 
kdc_1       | Jan 30 12:26:24 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | 
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
kdc_1       | Jan 30 12:26:30 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_3  | ] from file:/data/metadata/dn/certs/279802483984.crt.
datanode_3  | 2023-01-30 12:00:42,739 [main] INFO client.DNCertificateClient: CertificateLifetimeMonitor for dn is started with first delay 29073557283 ms and interval 86400000 ms.
om_1        |   Algorithm: [SHA256withRSA]
datanode_2  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 2023-01-30 12:00:42,740 [main] INFO ozone.HddsDatanodeService: Successfully stored SCM signed certificate, case:GETCERT.
kdc_1       | Jan 30 12:26:36 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        |   Signature:
datanode_2  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 2023-01-30 12:00:42,894 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
kdc_1       | Jan 30 12:26:42 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:26:48 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       |   Key_CertSign
scm_1       |   Crl_Sign
kdc_1       | Jan 30 12:26:53 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:26:59 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
scm_1       | ]
scm_1       | 
datanode_2  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_2  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
om_1        | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
kdc_1       | Jan 30 12:27:05 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	... 15 more
datanode_3  | 2023-01-30 12:00:44,118 [main] INFO reflections.Reflections: Reflections took 887 ms to scan 2 urls, producing 100 keys and 224 values 
om_1        | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
kdc_1       | Jan 30 12:27:11 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 2023-01-30 12:01:18,517 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_3  | 2023-01-30 12:00:44,736 [main] INFO statemachine.DatanodeStateMachine: Datanode State Machine Task Thread Pool size 2
om_1        | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
kdc_1       | Jan 30 12:27:17 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
datanode_3  | 2023-01-30 12:00:45,988 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/hdds/scmUsed not found
om_1        | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
kdc_1       | Jan 30 12:27:23 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_3  | 2023-01-30 12:00:46,117 [main] INFO volume.HddsVolume: Creating HddsVolume: /data/hdds/hdds of storage type : DISK capacity : 89297309696
om_1        | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
datanode_1  | 2023-01-30 12:01:55,089 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: ConfigurationManager, init=-1: peers:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
kdc_1       | Jan 30 12:27:29 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
datanode_3  | 2023-01-30 12:00:46,132 [main] INFO volume.MutableVolumeSet: Added Volume : /data/hdds/hdds to VolumeSet
om_1        | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
datanode_1  | 2023-01-30 12:01:55,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
kdc_1       | Jan 30 12:27:34 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
datanode_3  | 2023-01-30 12:00:46,133 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/hdds/hdds
datanode_1  | 2023-01-30 12:01:55,090 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_1  | 2023-01-30 12:01:55,091 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
kdc_1       | Jan 30 12:27:40 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081363, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:27:43 kdc krb5kdc[8](info): AS_REQ (8 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23), camellia128-cts-cmac(25), camellia256-cts-cmac(26)}) 172.18.0.5: ISSUE: authtime 1675081663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
recon_1     | 2023-01-30 12:00:52,457 [main] INFO codegen.SqlDbUtils: Created derby database at jdbc:derby:/data/metadata/recon/ozone_recon_derby.db.
recon_1     | 2023-01-30 12:00:52,458 [main] INFO recon.ReconServer: Creating Recon Schema.
recon_1     | 2023-01-30 12:00:57,995 [main] INFO http.BaseHttpServer: Starting Web-server for recon at: http://0.0.0.0:9888
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
kdc_1       | Jan 30 12:27:49 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
kdc_1       | Jan 30 12:27:52 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
datanode_1  | 2023-01-30 12:01:55,091 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_1  | 2023-01-30 12:01:55,091 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
scm_1       | SubjectAlternativeName [
scm_1       |   IPAddress: 172.18.0.5
scm_1       | ]
scm_1       | 
kdc_1       | Jan 30 12:28:01 kdc krb5kdc[8](info): TGS_REQ (6 etypes {aes256-cts-hmac-sha1-96(18), aes128-cts-hmac-sha1-96(17), aes256-cts-hmac-sha384-192(20), aes128-cts-hmac-sha256-128(19), DEPRECATED:des3-cbc-sha1(16), DEPRECATED:arcfour-hmac(23)}) 172.18.0.5: ISSUE: authtime 1675081663, etypes {rep=aes256-cts-hmac-sha1-96(18), tkt=aes256-cts-hmac-sha1-96(18), ses=aes256-cts-hmac-sha1-96(18)}, testuser/scm@EXAMPLE.COM for om/om@EXAMPLE.COM
om_1        | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
om_1        | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
om_1        | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
om_1        | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
om_1        | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
om_1        | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
om_1        | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
om_1        | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
om_1        | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
om_1        | 
om_1        | ] from file:/data/metadata/om/certs/CA-255687037543.crt.
om_1        | 2023-01-30 12:01:12,160 [main] INFO security.OMCertificateClient: Added certificate [
om_1        | [
om_1        |   Version: V3
om_1        |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=om
om_1        |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
om_1        | 
om_1        |   Key:  Sun RSA public key, 2048 bits
datanode_1  | 2023-01-30 12:01:55,091 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:320)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:516)
om_1        |   params: null
scm_1       | ]
scm_1       |   Algorithm: [SHA256withRSA]
datanode_1  | 2023-01-30 12:01:55,093 [Command processor thread] INFO server.RaftServer: 6295590c-c30d-436f-ae9f-b085e438c72d: addNew group-D14D9BFCC8C3:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] returns group-D14D9BFCC8C3:java.util.concurrent.CompletableFuture@413b4546[Not completed]
om_1        |   modulus: 24334133391208150402817112443476631375269294579105963816956564612935821903331451732245578655749146818457946470276880774381905922187490581302768014229885757142781208280323765114485326296600810802221274760406139489207121608678360433241637194403139656206423595810852768175354094973153192070323635606416602015647065452740462972629570933287747327184178830786641488255802034997900334084054918355817343369067944194801847909168973840501835666372429990437728681108618657423261535681110185440928738070834070617523692147744038509621618303406088406567172332957921049042962214406593351125537123092302297022068107855699232242326767
scm_1       |   Signature:
scm_1       | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
datanode_1  | 2023-01-30 12:01:55,103 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2023-01-30 12:00:46,311 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/hdds/hdds
datanode_3  | 2023-01-30 12:00:46,408 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        |   public exponent: 65537
scm_1       | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
recon_1     | 2023-01-30 12:00:58,002 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_1  | 2023-01-30 12:01:55,103 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3  | 2023-01-30 12:00:46,413 [main] INFO fs.SaveSpaceUsageToFile: Cached usage info file /data/metadata/ratis/scmUsed not found
datanode_2  | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
scm_1       | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
recon_1     | 2023-01-30 12:00:58,007 [main] INFO http.BaseHttpServer: HttpAuthType: ozone.recon.http.auth.type = kerberos
datanode_1  | 2023-01-30 12:01:55,103 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3  | 2023-01-30 12:00:46,419 [main] INFO volume.MutableVolumeSet: Added Volume : /data/metadata/ratis to VolumeSet
datanode_2  | Caused by: java.util.concurrent.TimeoutException
om_1        |                To: Tue Jan 30 00:00:00 UTC 2024]
scm_1       | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
recon_1     | 2023-01-30 12:00:58,131 [main] INFO util.log: Logging initialized @79661ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_1  | 2023-01-30 12:01:55,104 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2023-01-30 12:00:46,419 [main] INFO volume.ThrottledAsyncChecker: Scheduling a check for /data/metadata/ratis
datanode_3  | 2023-01-30 12:00:46,420 [main] INFO volume.StorageVolumeChecker: Scheduled health check for volume /data/metadata/ratis
om_1        |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
scm_1       | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
recon_1     | 2023-01-30 12:00:58,830 [main] WARN http.HttpRequestLog: Jetty request log can only be enabled using Log4j
datanode_1  | 2023-01-30 12:01:55,104 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
datanode_2  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
scm_1       | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
recon_1     | 2023-01-30 12:00:58,902 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_1  | 2023-01-30 12:01:55,104 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3 does not exist. Creating ...
datanode_3  | 2023-01-30 12:00:46,607 [Thread-20] INFO ozoneimpl.ContainerReader: Finish verifying containers on volume /data/hdds/hdds
om_1        |   SerialNumber: [    41f3b398 93]
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
scm_1       | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
recon_1     | 2023-01-30 12:00:58,904 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context recon
datanode_1  | 2023-01-30 12:01:55,115 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3/in_use.lock acquired by nodename 7@5ffad95da0eb
datanode_3  | 2023-01-30 12:00:46,613 [main] INFO ozoneimpl.OzoneContainer: Build ContainerSet costs 0s
om_1        | 
datanode_2  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
datanode_2  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
recon_1     | 2023-01-30 12:00:58,917 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_1  | 2023-01-30 12:01:55,120 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3 has been successfully formatted.
datanode_3  | 2023-01-30 12:00:52,342 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for DNAudit to [].
om_1        | Certificate Extensions: 2
om_1        | [1]: ObjectId: 2.5.29.15 Criticality=true
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2023-01-30 12:00:58,918 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
recon_1     | 2023-01-30 12:00:58,934 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.recon.http.auth.kerberos.principal keytabKey: ozone.recon.http.auth.kerberos.keytab
datanode_1  | 2023-01-30 12:01:55,121 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-D14D9BFCC8C3: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2023-01-30 12:00:53,062 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm_1       | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
om_1        | KeyUsage [
om_1        |   DigitalSignature
recon_1     | 2023-01-30 12:00:59,722 [main] INFO tasks.ReconTaskControllerImpl: Registered task ContainerKeyMapperTask with controller.
datanode_1  | 2023-01-30 12:01:55,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2023-01-30 12:00:53,125 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig1-
scm_1       | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
datanode_2  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        |   Key_Encipherment
recon_1     | 2023-01-30 12:01:01,212 [main] INFO tasks.ReconTaskControllerImpl: Registered task FileSizeCountTask with controller.
recon_1     | 2023-01-30 12:01:01,232 [main] INFO tasks.ReconTaskControllerImpl: Registered task TableCountTask with controller.
datanode_3  | 2023-01-30 12:00:53,356 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
datanode_2  | 	... 1 more
om_1        |   Data_Encipherment
recon_1     | 2023-01-30 12:01:01,302 [main] INFO tasks.ReconTaskControllerImpl: Registered task NSSummaryTask with controller.
datanode_1  | 2023-01-30 12:01:55,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2023-01-30 12:00:53,639 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
scm_1       | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
scm_1       | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
scm_1       | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
recon_1     | 2023-01-30 12:01:01,466 [main] INFO ozone.OmUtils: ozone.om.internal.service.id is not defined, falling back to ozone.om.service.ids to find serviceID for OzoneManager if it is HA enabled cluster
datanode_1  | 2023-01-30 12:01:55,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-30 12:00:54,840 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
datanode_2  | 2023-01-30 12:01:47,592 [Command processor thread] INFO server.RaftServer: 01074a56-f4fb-4406-b467-549b4df46db9: addNew group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] returns group-CE3F4E13DA16:java.util.concurrent.CompletableFuture@4417f714[Not completed]
om_1        |   Key_Agreement
recon_1     | 2023-01-30 12:01:01,468 [main] INFO ozone.OmUtils: No OzoneManager ServiceID configured.
datanode_1  | 2023-01-30 12:01:55,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3  | 2023-01-30 12:00:54,856 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9857 (custom)
scm_1       | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
datanode_2  | 2023-01-30 12:01:47,672 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9: new RaftServerImpl for group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
om_1        | ]
recon_1     | 2023-01-30 12:01:06,061 [main] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2023-01-30 12:01:55,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2023-01-30 12:00:54,862 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm_1       | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
datanode_2  | 2023-01-30 12:01:47,677 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2023-01-30 12:01:47,679 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 2023-01-30 12:01:07,438 [main] WARN recon.ReconUtils: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2023-01-30 12:01:55,126 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2023-01-30 12:00:54,868 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9858 (custom)
scm_1       | 
om_1        | 
datanode_2  | 2023-01-30 12:01:47,680 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
recon_1     | 2023-01-30 12:01:08,022 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
datanode_1  | 2023-01-30 12:01:55,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2023-01-30 12:00:54,868 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/255687037543.crt.
om_1        | [2]: ObjectId: 2.5.29.17 Criticality=false
datanode_2  | 2023-01-30 12:01:47,680 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
recon_1     | 2023-01-30 12:01:08,022 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_1  | 2023-01-30 12:01:55,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2023-01-30 12:00:54,883 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9856 (custom)
scm_1       | 2023-01-30 12:00:28,460 [main] INFO client.SCMCertificateClient: Added certificate [
om_1        | SubjectAlternativeName [
datanode_2  | 2023-01-30 12:01:47,680 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
recon_1     | 2023-01-30 12:01:08,613 [main] WARN db.DBStoreBuilder: ozone.recon.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_1  | 2023-01-30 12:01:55,137 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3
datanode_3  | 2023-01-30 12:00:54,885 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32MB (=33554432) (custom)
scm_1       | [
om_1        |   IPAddress: 172.18.0.2
datanode_2  | 2023-01-30 12:01:47,682 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1     | 2023-01-30 12:01:09,170 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2023-01-30 12:00:54,890 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       |   Version: V3
om_1        |   Other-Name: Unrecognized ObjectIdentifier: 2.16.840.1.113730.3.1.34
recon_1     | 2023-01-30 12:01:09,438 [main] INFO reflections.Reflections: Reflections took 263 ms to scan 3 urls, producing 124 keys and 279 values 
datanode_2  | 2023-01-30 12:01:47,713 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: ConfigurationManager, init=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_3  | 2023-01-30 12:00:54,893 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 5MB (=5242880) (custom)
scm_1       |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
om_1        | ]
recon_1     | 2023-01-30 12:01:09,677 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
datanode_2  | 2023-01-30 12:01:47,715 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2023-01-30 12:01:47,734 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_3  | 2023-01-30 12:00:54,900 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
om_1        | 
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:47,736 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
recon_1     | 2023-01-30 12:01:09,776 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
datanode_3  | 2023-01-30 12:00:54,956 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_3  | 2023-01-30 12:00:55,015 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1        | ]
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2023-01-30 12:01:47,784 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
recon_1     | 2023-01-30 12:01:09,776 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
datanode_3  | 2023-01-30 12:00:55,018 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
scm_1       | 
om_1        |   Algorithm: [SHA256withRSA]
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_2  | 2023-01-30 12:01:47,796 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
recon_1     | 2023-01-30 12:01:09,776 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
datanode_3  | 2023-01-30 12:01:02,219 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
scm_1       |   Key:  Sun RSA public key, 2048 bits
om_1        |   Signature:
om_1        | 0000: 2B 27 92 FF 33 E5 92 8A   12 C1 22 4F 19 C7 D6 83  +'..3....."O....
om_1        | 0010: D8 EA 70 5E 1C B2 A7 A9   F5 8B 24 7B 41 8D 0B DE  ..p^......$.A...
recon_1     | 2023-01-30 12:01:09,784 [main] INFO node.SCMNodeManager: Entering startup safe mode.
datanode_3  | 2023-01-30 12:01:02,378 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
scm_1       |   params: null
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2023-01-30 12:01:47,798 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 0020: E2 DA 6A 48 52 1E 95 D3   EE 73 AA 5A 23 E2 AA 79  ..jHR....s.Z#..y
recon_1     | 2023-01-30 12:01:09,816 [main] INFO scm.ReconNodeManager: Loaded 0 nodes from node DB.
datanode_3  | 2023-01-30 12:01:02,379 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 20 (custom)
scm_1       |   modulus: 19547832136434300738326307742387562429456217686330175163176497706533133057088432510477102552712118247654129281016928756166884250456866669545530465832916053591768388319268519251388529020915964459767204260680473599011154314178110472478059979387302735304383500952133759725342083408969331778030672841448029437817395159809765427326783641946938297695073206054101256625025218393030285912390719907514240296454125497401961411836819507002530339011895755451651337787679015191316432844913579186332681131846508031685918772919804386100453270450800202301025326863368356625247169836688444668566051960380526446273221151226832923348641
datanode_1  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2023-01-30 12:01:48,071 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2023-01-30 12:01:48,079 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_2  | 2023-01-30 12:01:48,081 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
recon_1     | 2023-01-30 12:01:09,838 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       |   public exponent: 65537
datanode_1  | 2023-01-30 12:01:55,139 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
datanode_2  | 2023-01-30 12:01:48,082 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | 0030: CA 3A D8 AF E7 8F 3C 67   B9 62 BB AB 16 EC 53 D0  .:....<g.b....S.
datanode_3  | 2023-01-30 12:01:02,392 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
recon_1     | 2023-01-30 12:01:09,948 [main] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
datanode_1  | 2023-01-30 12:01:55,141 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:48,087 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1        | 0040: 15 1B C0 68 63 61 66 D3   74 ED 3B 52 C9 2E 4C 59  ...hcaf.t.;R..LY
datanode_3  | 2023-01-30 12:01:02,423 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
recon_1     | 2023-01-30 12:01:10,067 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
scm_1       |                To: Thu Mar 09 00:00:00 UTC 2028]
datanode_1  | 2023-01-30 12:01:55,143 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-30 12:01:48,087 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 does not exist. Creating ...
om_1        | 0050: 1A D0 22 9D C1 C5 AC 4D   09 10 0F 0B 49 CD 48 30  .."....M....I.H0
datanode_3  | 2023-01-30 12:01:02,448 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
recon_1     | 2023-01-30 12:01:10,177 [Socket Reader #1 for port 9891] INFO ipc.Server: Starting Socket Reader #1 for port 9891
scm_1       |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
datanode_1  | 2023-01-30 12:01:55,166 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_2  | 2023-01-30 12:01:48,107 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/in_use.lock acquired by nodename 6@2850eee4085e
om_1        | 0060: BA 23 3B C9 2D D3 49 08   B7 03 3B 00 ED D5 FE CE  .#;.-.I...;.....
datanode_3  | 2023-01-30 12:01:02,449 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
recon_1     | 2023-01-30 12:01:10,338 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
scm_1       |   SerialNumber: [    01]
datanode_1  | 2023-01-30 12:01:55,167 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection:   Response 0: 6295590c-c30d-436f-ae9f-b085e438c72d<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:FAIL-t1
datanode_1  | 2023-01-30 12:01:55,167 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection:   Response 1: 6295590c-c30d-436f-ae9f-b085e438c72d<-01074a56-f4fb-4406-b467-549b4df46db9#0:FAIL-t1
om_1        | 0070: 93 5D 50 EA D4 62 22 23   72 1A DB 2F 34 F2 A7 99  .]P..b"#r../4...
datanode_3  | 2023-01-30 12:01:02,498 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
recon_1     | 2023-01-30 12:01:11,020 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Recon server initialized successfully!
scm_1       | 
datanode_1  | 2023-01-30 12:01:55,168 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1 ELECTION round 0: result REJECTED
datanode_1  | 2023-01-30 12:01:55,170 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_2  | 2023-01-30 12:01:48,143 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 has been successfully formatted.
datanode_3  | 2023-01-30 12:01:02,508 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
recon_1     | 2023-01-30 12:01:11,026 [Listener at 0.0.0.0/9891] INFO recon.ReconServer: Starting Recon server
scm_1       | Certificate Extensions: 3
datanode_1  | 2023-01-30 12:01:55,170 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1
om_1        | 0080: 0D 52 91 51 7E 84 1F D5   31 6F E5 C1 78 A5 16 C9  .R.Q....1o..x...
datanode_2  | 2023-01-30 12:01:48,188 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-CE3F4E13DA16: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2023-01-30 12:01:02,783 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
datanode_3  | 2023-01-30 12:01:02,784 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 9855 (custom)
recon_1     | 2023-01-30 12:01:11,540 [Listener at 0.0.0.0/9891] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_1  | 2023-01-30 12:01:55,184 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
datanode_2  | 2023-01-30 12:01:48,195 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2023-01-30 12:01:03,008 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
recon_1     | 2023-01-30 12:01:11,656 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 0090: 36 00 FA F4 52 96 9A 7B   2E 1A C2 8E 4C B9 C6 D1  6...R.......L...
datanode_1  | 2023-01-30 12:01:55,338 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:01:48,235 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2023-01-30 12:01:03,008 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
scm_1       | BasicConstraints:[
recon_1     | 2023-01-30 12:01:11,656 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Recon metrics system started
recon_1     | 2023-01-30 12:01:13,902 [Listener at 0.0.0.0/9891] INFO http.HttpServer2: Jetty bound to port 9888
datanode_1  | 2023-01-30 12:01:55,338 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:01:48,244 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-30 12:01:03,008 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
scm_1       |   CA:true
recon_1     | 2023-01-30 12:01:13,913 [Listener at 0.0.0.0/9891] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
om_1        | 00A0: 22 6C 0C EC 6F D3 4B B1   36 2B F6 1C 07 04 AD 37  "l..o.K.6+.....7
datanode_1  | 2023-01-30 12:01:55,364 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2  | 2023-01-30 12:01:48,261 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_3  | 2023-01-30 12:01:03,009 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       |   PathLen:2147483647
recon_1     | 2023-01-30 12:01:14,583 [Listener at 0.0.0.0/9891] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 00B0: 17 E2 CB BA 7C 7C 70 49   44 D9 38 9D F0 ED F9 A0  ......pID.8.....
datanode_1  | 2023-01-30 12:01:55,364 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2023-01-30 12:01:48,264 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2023-01-30 12:01:03,038 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
scm_1       | ]
recon_1     | 2023-01-30 12:01:14,599 [Listener at 0.0.0.0/9891] INFO server.session: No SessionScavenger set, using defaults
om_1        | 00C0: 43 E8 2B FC 8A 8B 95 A6   FD 5A 32 A0 FA 0C B9 1D  C.+......Z2.....
datanode_1  | 2023-01-30 12:01:55,365 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:48,281 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:48,331 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 
om_1        | 00D0: F3 FE 94 69 38 3C 2C 31   C5 05 CD 8D C1 68 62 A1  ...i8<,1.....hb.
datanode_2  | 2023-01-30 12:01:48,337 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_3  | 2023-01-30 12:01:03,125 [c8ea7a3f-965d-439b-b69f-d2205a7da823-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xaaae6187] REGISTERED
datanode_1  | 2023-01-30 12:01:55,365 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
recon_1     | 2023-01-30 12:01:14,605 [Listener at 0.0.0.0/9891] INFO server.session: node0 Scavenging every 660000ms
om_1        | 00E0: E8 A5 54 20 F7 10 8F 43   59 4F AF A8 52 3D 07 83  ..T ...CYO..R=..
datanode_2  | 2023-01-30 12:01:48,383 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
datanode_3  | 2023-01-30 12:01:03,127 [c8ea7a3f-965d-439b-b69f-d2205a7da823-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xaaae6187] BIND: 0.0.0.0/0.0.0.0:9855
datanode_1  | 2023-01-30 12:01:55,365 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | KeyUsage [
scm_1       |   Key_CertSign
om_1        | 00F0: 3D E5 EA 0F 86 DB 55 95   00 D3 FD A8 11 EA BE 74  =.....U........t
datanode_2  | 2023-01-30 12:01:48,383 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2023-01-30 12:01:03,157 [c8ea7a3f-965d-439b-b69f-d2205a7da823-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xaaae6187, L:/0.0.0.0:9855] ACTIVE
datanode_1  | 2023-01-30 12:01:55,378 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: start as a follower, conf=-1: peers:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       |   Crl_Sign
recon_1     | 2023-01-30 12:01:15,090 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
om_1        | 
om_1        | ] from file:/data/metadata/om/certs/283261507731.crt.
om_1        | 2023-01-30 12:01:12,199 [main] INFO security.OMCertificateClient: CertificateLifetimeMonitor for om is started with first delay 29073527832 ms and interval 86400000 ms.
datanode_1  | 2023-01-30 12:01:55,378 [pool-24-thread-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | ]
scm_1       | 
recon_1     | 2023-01-30 12:01:15,109 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@12921ee1{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
recon_1     | 2023-01-30 12:01:15,123 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@615bd28b{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
recon_1     | 2023-01-30 12:01:16,689 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
datanode_1  | 2023-01-30 12:01:55,378 [pool-24-thread-1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState
recon_1     | 2023-01-30 12:01:16,723 [Listener at 0.0.0.0/9891] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/recon.keytab, for principal HTTP/recon@EXAMPLE.COM
recon_1     | 2023-01-30 12:01:22,884 [Listener at 0.0.0.0/9891] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@5d15c5f7{recon,/,file:///tmp/jetty-0_0_0_0-9888-ozone-recon-1_4_0-SNAPSHOT_jar-_-any-15355221104551504143/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-recon-1.4.0-SNAPSHOT.jar!/webapps/recon}
recon_1     | 2023-01-30 12:01:22,903 [Listener at 0.0.0.0/9891] INFO server.AbstractConnector: Started ServerConnector@3c89fdd8{HTTP/1.1, (http/1.1)}{0.0.0.0:9888}
datanode_3  | 2023-01-30 12:01:03,441 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER KeyStore reloading at 60000 millis.
scm_1       | SubjectAlternativeName [
recon_1     | 2023-01-30 12:01:22,904 [Listener at 0.0.0.0/9891] INFO server.Server: Started @104434ms
recon_1     | 2023-01-30 12:01:22,914 [Listener at 0.0.0.0/9891] INFO impl.MetricsSinkAdapter: Sink prometheus started
recon_1     | 2023-01-30 12:01:22,915 [Listener at 0.0.0.0/9891] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2023-01-30 12:01:03,504 [main] INFO ssl.PemFileBasedKeyStoresFactory: SERVER TrustStore reloading at 60000 millis.
datanode_3  | 2023-01-30 12:01:03,548 [main] INFO server.XceiverServerGrpc: GrpcServer channel type EpollServerSocketChannel
recon_1     | 2023-01-30 12:01:22,917 [Listener at 0.0.0.0/9891] INFO http.BaseHttpServer: HTTP server of recon listening at http://0.0.0.0:9888
recon_1     | 2023-01-30 12:01:22,917 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Starting Ozone Manager Service Provider.
recon_1     | 2023-01-30 12:01:22,932 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmDeltaRequest task 
scm_1       |   IPAddress: 172.18.0.5
scm_1       | ]
scm_1       | 
recon_1     | 2023-01-30 12:01:22,943 [Listener at 0.0.0.0/9891] INFO impl.OzoneManagerServiceProviderImpl: Registered OmSnapshotRequest task 
recon_1     | 2023-01-30 12:01:22,948 [Listener at 0.0.0.0/9891] INFO recovery.ReconOmMetadataManagerImpl: Starting ReconOMMetadataManagerImpl
recon_1     | 2023-01-30 12:01:22,948 [Listener at 0.0.0.0/9891] WARN recon.ReconUtils: ozone.recon.om.db.dir is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
datanode_2  | 2023-01-30 12:01:48,387 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
scm_1       | ]
recon_1     | 2023-01-30 12:01:22,949 [Listener at 0.0.0.0/9891] INFO tasks.ReconTaskControllerImpl: Starting Recon Task Controller.
datanode_1  | 2023-01-30 12:01:55,379 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D14D9BFCC8C3,id=6295590c-c30d-436f-ae9f-b085e438c72d
datanode_1  | 2023-01-30 12:01:55,379 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_3  | 2023-01-30 12:01:04,843 [main] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 279802483984
datanode_3  | 2023-01-30 12:01:04,870 [main] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 279802483984
recon_1     | 2023-01-30 12:01:22,964 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Recon ScmDatanodeProtocol RPC server is listening at /0.0.0.0:9891
datanode_1  | 2023-01-30 12:01:55,380 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2023-01-30 12:01:48,390 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:48,390 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2023-01-30 12:01:48,392 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2023-01-30 12:01:05,363 [main] INFO http.BaseHttpServer: Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
datanode_1  | 2023-01-30 12:01:55,380 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
om_1        | 2023-01-30 12:01:12,478 [main] WARN server.ServerUtils: ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2023-01-30 12:01:13,561 [main] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-30 12:01:24,224 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: Obtained 4 pipelines from SCM.
scm_1       |   Algorithm: [SHA256withRSA]
datanode_3  | 2023-01-30 12:01:05,364 [main] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2023-01-30 12:01:05,366 [main] INFO http.BaseHttpServer: HttpAuthType: hdds.datanode.http.auth.type = kerberos
om_1        | 2023-01-30 12:01:13,564 [main] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
om_1        | 2023-01-30 12:01:14,674 [main] INFO om.OzoneManager: S3 Multi-Tenancy is enabled
recon_1     | 2023-01-30 12:01:24,225 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Recon has 0 pipelines in house.
datanode_3  | 2023-01-30 12:01:05,572 [main] INFO util.log: Logging initialized @89266ms to org.eclipse.jetty.util.log.Slf4jLog
om_1        | 2023-01-30 12:01:14,693 [main] INFO om.OMMultiTenantManagerImpl: Loaded 0 tenants and 0 tenant users from the database
om_1        | 2023-01-30 12:01:14,842 [main] INFO security.OzoneSecretStore: Loaded 0 tokens
datanode_2  | 2023-01-30 12:01:48,403 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_2  | 2023-01-30 12:01:48,404 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_3  | 2023-01-30 12:01:06,586 [main] INFO http.HttpRequestLog: Http request log for http.requests.hddsDatanode is not defined
om_1        | 2023-01-30 12:01:14,849 [main] INFO security.OzoneDelegationTokenSecretManager: Loading token state into token manager.
recon_1     | 2023-01-30 12:01:24,243 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3 from SCM.
datanode_1  | 2023-01-30 12:01:55,380 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_1  | 2023-01-30 12:01:55,380 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-30 12:01:55,380 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2023-01-30 12:01:55,381 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3
datanode_1  | 2023-01-30 12:01:55,381 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3.
datanode_1  | 2023-01-30 12:01:59,683 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: receive requestVote(ELECTION, 01074a56-f4fb-4406-b467-549b4df46db9, group-CE3F4E13DA16, 2, (t:0, i:0))
recon_1     | 2023-01-30 12:01:24,433 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3, Nodes: 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.752Z[UTC]].
datanode_1  | 2023-01-30 12:01:59,683 [grpc-default-executor-1] INFO impl.VoteContext: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FOLLOWER: reject ELECTION from 01074a56-f4fb-4406-b467-549b4df46db9: our priority 1 > candidate's priority 0
datanode_2  | 2023-01-30 12:01:48,406 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2023-01-30 12:01:14,841 [OMRangerBGSyncService#0] WARN service.OMRangerBGSyncService: OzoneManagerRatisServer is not initialized yet
om_1        | 2023-01-30 12:01:15,203 [main] INFO om.OzoneManager: Created Volume s3v With Owner om required for S3Gateway operations.
om_1        | 2023-01-30 12:01:15,295 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2023-01-30 12:01:15,298 [main] WARN utils.OzoneManagerRatisUtils: ozone.om.ratis.snapshot.dir is not configured. Falling back to ozone.metadata.dirs config
om_1        | 2023-01-30 12:01:15,354 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
om_1        | 2023-01-30 12:01:15,411 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
om_1        | 2023-01-30 12:01:15,587 [main] INFO ratis.OzoneManagerRatisServer: Instantiating OM Ratis server with groupID: omServiceIdDefault and peers: om:9872
om_1        | 2023-01-30 12:01:15,652 [main] INFO ratis.OzoneManagerStateMachine: LastAppliedIndex is set from TransactionInfo from OM DB as (t:0, i:~)
om_1        | 2023-01-30 12:01:15,976 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
om_1        | 2023-01-30 12:01:16,029 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
om_1        | 2023-01-30 12:01:16,180 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
om_1        | 2023-01-30 12:01:16,547 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-30 12:01:16,563 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9872 (fallback to raft.grpc.server.port)
om_1        | 2023-01-30 12:01:16,571 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
om_1        | 2023-01-30 12:01:16,594 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9872 (fallback to raft.grpc.server.port)
om_1        | 2023-01-30 12:01:16,595 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
om_1        | 2023-01-30 12:01:16,595 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9872 (custom)
om_1        | 2023-01-30 12:01:16,598 [main] INFO server.GrpcService: raft.grpc.message.size.max = 33554432 (custom)
om_1        | 2023-01-30 12:01:16,616 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-30 12:01:16,622 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
om_1        | 2023-01-30 12:01:16,623 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 3000ms (default)
om_1        | 2023-01-30 12:01:16,646 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
om_1        | 2023-01-30 12:01:16,661 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
om_1        | 2023-01-30 12:01:16,677 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
om_1        | 2023-01-30 12:01:19,015 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
om_1        | 2023-01-30 12:01:19,083 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
om_1        | 2023-01-30 12:01:19,089 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
om_1        | 2023-01-30 12:01:19,089 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
om_1        | 2023-01-30 12:01:19,090 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
om_1        | 2023-01-30 12:01:19,116 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
om_1        | 2023-01-30 12:01:19,116 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
om_1        | 2023-01-30 12:01:19,154 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
om_1        | 2023-01-30 12:01:19,181 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
om_1        | 2023-01-30 12:01:19,286 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
om_1        | 2023-01-30 12:01:19,295 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
om_1        | 2023-01-30 12:01:19,528 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
om_1        | 2023-01-30 12:01:19,528 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
om_1        | 2023-01-30 12:01:19,534 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2023-01-30 12:01:19,535 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2023-01-30 12:01:19,560 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2023-01-30 12:01:19,606 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x2e3f9309] REGISTERED
om_1        | 2023-01-30 12:01:19,611 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x2e3f9309] BIND: 0.0.0.0/0.0.0.0:0
om_1        | 2023-01-30 12:01:19,616 [main] INFO server.RaftServer: om1: addNew group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] returns group-C5BA1605619E:java.util.concurrent.CompletableFuture@41a16eb3[Not completed]
om_1        | 2023-01-30 12:01:19,616 [main] INFO om.OzoneManager: OzoneManager Ratis server initialized at port 9872
om_1        | 2023-01-30 12:01:19,622 [om1-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0x2e3f9309, L:/0.0.0.0:41323] ACTIVE
om_1        | 2023-01-30 12:01:19,721 [pool-28-thread-1] INFO server.RaftServer$Division: om1: new RaftServerImpl for group-C5BA1605619E:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER] with OzoneManagerStateMachine:uninitialized
om_1        | 2023-01-30 12:01:19,729 [main] INFO om.OzoneManager: Creating RPC Server
om_1        | 2023-01-30 12:01:19,743 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2023-01-30 12:01:19,749 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
om_1        | 2023-01-30 12:01:19,749 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
om_1        | 2023-01-30 12:01:19,749 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120s (custom)
om_1        | 2023-01-30 12:01:19,749 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
om_1        | 2023-01-30 12:01:19,751 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
om_1        | 2023-01-30 12:01:19,794 [pool-28-thread-1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: ConfigurationManager, init=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2023-01-30 12:01:19,804 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2023-01-30 12:01:19,845 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2023-01-30 12:01:19,854 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1        | 2023-01-30 12:01:19,954 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 120s (custom)
datanode_2  | 2023-01-30 12:01:48,463 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:48,468 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-30 12:01:48,531 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2  | 2023-01-30 12:01:48,533 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_2  | 2023-01-30 12:01:48,534 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:48,575 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-30 12:01:48,579 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-30 12:01:48,592 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: start as a follower, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:01:48,595 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2023-01-30 12:01:48,600 [pool-24-thread-1] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_2  | 2023-01-30 12:01:48,621 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE3F4E13DA16,id=01074a56-f4fb-4406-b467-549b4df46db9
datanode_2  | 2023-01-30 12:01:48,625 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:01:48,628 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:01:48,631 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:48,634 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2023-01-30 12:01:48,636 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       |   Signature:
scm_1       | 0000: 36 C5 D1 86 75 86 C6 92   85 1C D5 55 A4 F2 21 9E  6...u......U..!.
scm_1       | 0010: 86 9B A0 BA 76 1B 64 FE   A1 68 A9 FC 69 41 48 4C  ....v.d..h..iAHL
scm_1       | 0020: 54 6C B2 61 C7 02 7A F8   0A 30 35 7A BA 6D E5 86  Tl.a..z..05z.m..
scm_1       | 0030: 19 B6 01 A8 B8 E7 F3 49   06 02 8B 8D C7 54 A9 93  .......I.....T..
scm_1       | 0040: 61 6A C7 22 08 2A 76 51   F2 28 C6 E1 4C F9 60 FE  aj.".*vQ.(..L.`.
scm_1       | 0050: 84 01 F0 12 9A D3 1B 50   17 13 3F A2 8A 01 28 ED  .......P..?...(.
scm_1       | 0060: CD 2A 0E 24 90 FA 21 12   3A 9F D8 AB 9C 78 AB F0  .*.$..!.:....x..
datanode_3  | 2023-01-30 12:01:06,631 [main] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_3  | 2023-01-30 12:01:06,650 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context hddsDatanode
datanode_3  | 2023-01-30 12:01:06,675 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 2023-01-30 12:01:06,676 [main] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 2023-01-30 12:01:06,679 [main] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.datanode.http.auth.kerberos.principal keytabKey: hdds.datanode.http.auth.kerberos.keytab
datanode_3  | 2023-01-30 12:01:06,924 [main] INFO http.HttpServer2: Jetty bound to port 9882
datanode_3  | 2023-01-30 12:01:06,937 [main] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 2023-01-30 12:01:07,165 [main] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 2023-01-30 12:01:07,167 [main] INFO server.session: No SessionScavenger set, using defaults
datanode_3  | 2023-01-30 12:01:07,173 [main] INFO server.session: node0 Scavenging every 660000ms
datanode_3  | 2023-01-30 12:01:07,380 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_3  | 2023-01-30 12:01:07,413 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ac64dc2{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
datanode_3  | 2023-01-30 12:01:07,416 [main] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@1621264e{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
datanode_2  | 2023-01-30 12:01:48,638 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2023-01-30 12:01:48,747 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
datanode_2  | 2023-01-30 12:01:48,865 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_2  | 2023-01-30 12:01:53,213 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
datanode_2  | 2023-01-30 12:01:53,634 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5037912696ns, electionTimeout:5002ms
datanode_2  | 2023-01-30 12:01:53,637 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_2  | 2023-01-30 12:01:53,655 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_2  | 2023-01-30 12:01:53,667 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_2  | 2023-01-30 12:01:53,668 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1
datanode_2  | 2023-01-30 12:01:53,721 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:01:53,804 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:01:53,804 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 0070: DC E0 AE 98 98 1C AF BE   64 E9 F7 38 D0 50 AB FC  ........d..8.P..
scm_1       | 0080: 49 C0 46 67 9B FE 7F 32   40 5D 0D D2 A7 33 98 F5  I.Fg...2@]...3..
scm_1       | 0090: 4B 53 49 2E D3 09 7F 90   82 AF 3C D6 C9 B9 17 C3  KSI.......<.....
scm_1       | 00A0: 85 2E 74 F7 F0 33 61 46   5C 1B 2D 34 99 10 05 3A  ..t..3aF\.-4...:
scm_1       | 00B0: 8E 13 F4 B8 B4 1C FA 9F   D3 A3 48 13 96 D4 D1 8A  ..........H.....
scm_1       | 00C0: 7E 0B DA B9 CC F4 50 C2   2F BB 30 3D 2B 26 0D 10  ......P./.0=+&..
scm_1       | 00D0: 0C 17 8F 81 6C 71 8B 8D   C4 A3 2A B1 66 03 E0 34  ....lq....*.f..4
scm_1       | 00E0: 29 2E 1E 6D D1 6F 6B 96   EB 10 93 F8 EE 15 A4 29  )..m.ok........)
scm_1       | 00F0: FB 95 24 91 2E 44 D5 26   C8 31 99 D5 FD 75 D5 E1  ..$..D.&.1...u..
scm_1       | 
recon_1     | 2023-01-30 12:01:24,471 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=4669bd40-3cd3-4bd5-be19-907eab7b746b from SCM.
recon_1     | 2023-01-30 12:01:24,479 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4669bd40-3cd3-4bd5-be19-907eab7b746b, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.798Z[UTC]].
recon_1     | 2023-01-30 12:01:24,483 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 from SCM.
recon_1     | 2023-01-30 12:01:24,493 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e8cbeba-21db-48a1-9ddc-ce3f4e13da16, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.716Z[UTC]].
recon_1     | 2023-01-30 12:01:24,495 [Listener at 0.0.0.0/9891] INFO scm.ReconPipelineManager: Adding new pipeline PipelineID=ab8a74f8-57b8-4ac7-9c21-c111afcbd229 from SCM.
recon_1     | 2023-01-30 12:01:24,499 [Listener at 0.0.0.0/9891] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ab8a74f8-57b8-4ac7-9c21-c111afcbd229, Nodes: c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.364Z[UTC]].
recon_1     | 2023-01-30 12:01:24,501 [Listener at 0.0.0.0/9891] INFO scm.ReconStorageContainerManagerFacade: SCM DB initialized
recon_1     | 2023-01-30 12:01:24,504 [Listener at 0.0.0.0/9891] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9891
recon_1     | 2023-01-30 12:01:24,512 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2023-01-30 12:01:24,529 [IPC Server listener on 9891] INFO ipc.Server: IPC Server listener on 9891: starting
recon_1     | 2023-01-30 12:01:24,983 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42474
recon_1     | 2023-01-30 12:01:25,018 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:01:25,179 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42736
datanode_1  | 2023-01-30 12:01:59,683 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:01074a56-f4fb-4406-b467-549b4df46db9
datanode_1  | 2023-01-30 12:01:59,683 [grpc-default-executor-1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
datanode_1  | 2023-01-30 12:01:59,685 [grpc-default-executor-1] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
datanode_1  | 2023-01-30 12:01:59,694 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-30 12:01:59,685 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState was interrupted
datanode_1  | 2023-01-30 12:01:59,694 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_1  | 2023-01-30 12:01:59,697 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16 replies to ELECTION vote request: 01074a56-f4fb-4406-b467-549b4df46db9<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t2. Peer's state: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16:t2, leader=null, voted=null, raftlog=Memoized:6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:02:00,407 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO impl.FollowerState: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5028913283ns, electionTimeout:5024ms
datanode_1  | 2023-01-30 12:02:00,407 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState
datanode_1  | 2023-01-30 12:02:00,407 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_1  | 2023-01-30 12:02:00,408 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2023-01-30 12:02:00,408 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2
datanode_1  | 2023-01-30 12:02:00,426 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2 ELECTION round 0: submit vote requests at term 1 for -1: peers:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:01:08,100 [main] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/dn.keytab, for principal HTTP/dn@EXAMPLE.COM
datanode_3  | 2023-01-30 12:01:08,145 [main] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@7b4b6dca{hddsDatanode,/,file:///tmp/jetty-0_0_0_0-9882-hdds-container-service-1_4_0-SNAPSHOT_jar-_-any-2706260261181536086/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-container-service-1.4.0-SNAPSHOT.jar!/webapps/hddsDatanode}
datanode_3  | 2023-01-30 12:01:08,226 [main] INFO server.AbstractConnector: Started ServerConnector@689504b1{HTTP/1.1, (http/1.1)}{0.0.0.0:9882}
datanode_3  | 2023-01-30 12:01:08,231 [main] INFO server.Server: Started @91928ms
datanode_3  | 2023-01-30 12:01:08,237 [main] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2023-01-30 12:01:08,245 [main] INFO impl.MetricsSystemImpl: Registered sink prometheus
datanode_3  | 2023-01-30 12:01:08,247 [main] INFO http.BaseHttpServer: HTTP server of hddsDatanode listening at http://0.0.0.0:9882
datanode_3  | 2023-01-30 12:01:08,275 [Datanode State Machine Daemon Thread] INFO statemachine.DatanodeStateMachine: Ozone container server started.
datanode_3  | 2023-01-30 12:01:08,580 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@141cb2b0] INFO util.JvmPauseMonitor: Starting JVM pause monitor
datanode_3  | 2023-01-30 12:01:09,011 [Datanode State Machine Task Thread - 0] INFO statemachine.SCMConnectionManager: Adding Recon Server : recon/172.18.0.6:9891
datanode_3  | 2023-01-30 12:01:09,069 [Datanode State Machine Task Thread - 0] INFO datanode.InitDatanodeState: DatanodeDetails is persisted to /data/datanode.id
datanode_3  | 2023-01-30 12:01:12,731 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO utils.DatanodeStoreCache: Added db /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-8e49aff5-e2d3-4b95-a8fd-23a9ad8df53f/container.db to cache
datanode_2  | 2023-01-30 12:01:53,817 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1-2] INFO server.GrpcServerProtocolClient: Build channel for 6295590c-c30d-436f-ae9f-b085e438c72d
datanode_2  | 2023-01-30 12:01:53,817 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1-1] INFO server.GrpcServerProtocolClient: Build channel for c8ea7a3f-965d-439b-b69f-d2205a7da823
datanode_2  | 2023-01-30 12:01:54,480 [grpc-default-executor-0] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: receive requestVote(ELECTION, 6295590c-c30d-436f-ae9f-b085e438c72d, group-CE3F4E13DA16, 1, (t:0, i:0))
datanode_2  | 2023-01-30 12:01:54,484 [grpc-default-executor-0] INFO impl.VoteContext: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-CANDIDATE: reject ELECTION from 6295590c-c30d-436f-ae9f-b085e438c72d: already has voted for 01074a56-f4fb-4406-b467-549b4df46db9 at current term 1
datanode_2  | 2023-01-30 12:01:54,573 [grpc-default-executor-0] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16 replies to ELECTION vote request: 6295590c-c30d-436f-ae9f-b085e438c72d<-01074a56-f4fb-4406-b467-549b4df46db9#0:FAIL-t1. Peer's state: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16:t1, leader=null, voted=01074a56-f4fb-4406-b467-549b4df46db9, raftlog=Memoized:01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:01:54,582 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_2  | 2023-01-30 12:01:54,582 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection:   Response 0: 01074a56-f4fb-4406-b467-549b4df46db9<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t1
datanode_2  | 2023-01-30 12:01:54,582 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1 ELECTION round 0: result REJECTED
datanode_2  | 2023-01-30 12:01:54,627 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from CANDIDATE to FOLLOWER at term 1 for REJECTED
datanode_2  | 2023-01-30 12:01:54,627 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1
datanode_2  | 2023-01-30 12:01:54,628 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection1] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_2  | 2023-01-30 12:01:54,637 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/CA-1.crt.
scm_1       | 2023-01-30 12:00:28,466 [main] INFO client.SCMCertificateClient: Added certificate [
scm_1       | [
scm_1       |   Version: V3
scm_1       |   Subject: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm-sub@scm
scm_1       |   Signature Algorithm: SHA256withRSA, OID = 1.2.840.113549.1.1.11
recon_1     | 2023-01-30 12:01:25,199 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:52954
recon_1     | 2023-01-30 12:01:25,203 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:01:25,227 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_1  | 2023-01-30 12:02:00,427 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2 ELECTION round 0: result PASSED (term=1)
datanode_1  | 2023-01-30 12:02:00,428 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2
datanode_1  | 2023-01-30 12:02:00,428 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
datanode_1  | 2023-01-30 12:02:00,431 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-D14D9BFCC8C3 with new leaderId: 6295590c-c30d-436f-ae9f-b085e438c72d
datanode_1  | 2023-01-30 12:02:00,456 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: change Leader from null to 6295590c-c30d-436f-ae9f-b085e438c72d at term 1 for becomeLeader, leader elected after 5337ms
datanode_1  | 2023-01-30 12:02:00,530 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_1  | 2023-01-30 12:02:00,593 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2023-01-30 12:02:00,598 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1  | 2023-01-30 12:02:00,632 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2023-01-30 12:01:12,753 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO volume.HddsVolume: SchemaV3 db is created and loaded at /data/hdds/hdds/CID-b04a1c74-af13-4571-b723-87e6e2d1e545/DS-8e49aff5-e2d3-4b95-a8fd-23a9ad8df53f/container.db for volume DS-8e49aff5-e2d3-4b95-a8fd-23a9ad8df53f
datanode_3  | 2023-01-30 12:01:12,755 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Attempting to start container services.
datanode_3  | 2023-01-30 12:01:12,789 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ozoneimpl.OzoneContainer: Scheduled background container scanners and the on-demand container scanner have been disabled.
datanode_3  | 2023-01-30 12:01:12,844 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO replication.ReplicationServer: ReplicationServer is started using port 9886
datanode_3  | 2023-01-30 12:01:12,847 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: Starting XceiverServerRatis c8ea7a3f-965d-439b-b69f-d2205a7da823
datanode_3  | 2023-01-30 12:01:12,970 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.RaftServer: c8ea7a3f-965d-439b-b69f-d2205a7da823: start RPC server
datanode_3  | 2023-01-30 12:01:12,983 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: c8ea7a3f-965d-439b-b69f-d2205a7da823: GrpcService started, listening on 9858
datanode_3  | 2023-01-30 12:01:12,985 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: c8ea7a3f-965d-439b-b69f-d2205a7da823: GrpcService started, listening on 9856
datanode_3  | 2023-01-30 12:01:12,995 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO server.GrpcService: c8ea7a3f-965d-439b-b69f-d2205a7da823: GrpcService started, listening on 9857
datanode_3  | 2023-01-30 12:01:13,053 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c8ea7a3f-965d-439b-b69f-d2205a7da823 is started using port 9858 for RATIS
datanode_3  | 2023-01-30 12:01:13,053 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c8ea7a3f-965d-439b-b69f-d2205a7da823 is started using port 9857 for RATIS_ADMIN
datanode_3  | 2023-01-30 12:01:13,053 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c8ea7a3f-965d-439b-b69f-d2205a7da823 is started using port 9856 for RATIS_SERVER
scm_1       | 
scm_1       |   Key:  Sun RSA public key, 2048 bits
scm_1       |   params: null
scm_1       |   modulus: 20177212669319789281122390499096998208508175923148602419063809284018013419023872302374117852886412502744322685895007101424092476423590357486812975792173271642726939488872337062613862392856781496354464985115788587480862083875048020160727867782232981042568167949299149392977998712500048545030072026293306220117390420775714823992698850819055125807794675576026665592276663348864085777207807177059193537811150644858120175055598044876632465607529735918175053287937561206043104748507452306241733004672146295076015939773119330052570269806174706079949618549668024921234168355129109309173441911522342354085360139881547972268481
recon_1     | 2023-01-30 12:01:42,952 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:01:42,953 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining full snapshot from Ozone Manager
recon_1     | 2023-01-30 12:01:43,900 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Got new checkpoint from OM : /data/metadata/om.snapshot.db_1675080102953
recon_1     | 2023-01-30 12:01:43,913 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-30 12:01:43,916 [pool-30-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-30 12:01:44,066 [pool-30-thread-1] INFO recovery.ReconOmMetadataManagerImpl: Created OM DB handle from snapshot at /data/metadata/om.snapshot.db_1675080102953.
datanode_2  | 2023-01-30 12:01:54,638 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:01:55,116 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16.
datanode_2  | 2023-01-30 12:01:55,132 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9: new RaftServerImpl for group-907EAB7B746B:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_2  | 2023-01-30 12:01:55,133 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
datanode_2  | 2023-01-30 12:01:55,133 [Command processor thread] INFO server.RaftServer: 01074a56-f4fb-4406-b467-549b4df46db9: addNew group-907EAB7B746B:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER] returns group-907EAB7B746B:java.util.concurrent.CompletableFuture@1b992cf1[Not completed]
datanode_2  | 2023-01-30 12:01:55,133 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_2  | 2023-01-30 12:01:55,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_2  | 2023-01-30 12:01:55,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_2  | 2023-01-30 12:01:55,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_2  | 2023-01-30 12:01:55,134 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
datanode_2  | 2023-01-30 12:01:55,135 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: ConfigurationManager, init=-1: peers:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_2  | 2023-01-30 12:01:55,136 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_2  | 2023-01-30 12:01:55,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2023-01-30 12:01:55,137 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2023-01-30 12:01:55,138 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_2  | 2023-01-30 12:01:55,139 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
datanode_2  | 2023-01-30 12:01:55,139 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_2  | 2023-01-30 12:01:55,141 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_2  | 2023-01-30 12:01:55,157 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       |   public exponent: 65537
scm_1       |   Validity: [From: Mon Jan 30 00:00:00 UTC 2023,
scm_1       |                To: Thu Mar 09 00:00:00 UTC 2028]
scm_1       |   Issuer: O=CID-b04a1c74-af13-4571-b723-87e6e2d1e545, OU=82e918d1-ff68-4821-a2f0-f9af71d19ea5, CN=scm@scm
scm_1       |   SerialNumber: [    3b882292 67]
scm_1       | 
scm_1       | Certificate Extensions: 3
scm_1       | [1]: ObjectId: 2.5.29.19 Criticality=true
scm_1       | BasicConstraints:[
scm_1       |   CA:true
datanode_1  | 2023-01-30 12:02:00,634 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2023-01-30 12:02:00,639 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2023-01-30 12:02:00,720 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2023-01-30 12:02:00,746 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2023-01-30 12:02:00,768 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderStateImpl
recon_1     | 2023-01-30 12:01:44,219 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Calling reprocess on Recon tasks.
recon_1     | 2023-01-30 12:01:44,224 [pool-52-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a reprocess run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:01:44,225 [pool-52-thread-2] INFO tasks.NSSummaryTaskWithLegacy: Completed a reprocess run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:01:44,780 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'reprocess' run of TableCountTask.
recon_1     | 2023-01-30 12:01:44,780 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: Starting a 'reprocess' run of ContainerKeyMapperTask.
recon_1     | 2023-01-30 12:01:44,782 [pool-31-thread-1] INFO impl.ReconContainerMetadataManagerImpl: KEY_CONTAINER Table is empty, initializing from CONTAINER_KEY Table ...
recon_1     | 2023-01-30 12:01:44,783 [pool-31-thread-1] INFO impl.ReconContainerMetadataManagerImpl: It took 0.0 seconds to initialized 0 records to KEY_CONTAINER table
recon_1     | 2023-01-30 12:01:44,804 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: Completed 'reprocess' of ContainerKeyMapperTask.
recon_1     | 2023-01-30 12:01:44,805 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: It took me 0.023 seconds to process 0 keys.
recon_1     | 2023-01-30 12:01:44,880 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Deleted 0 records from "FILE_COUNT_BY_SIZE"
recon_1     | 2023-01-30 12:01:44,924 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'reprocess' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:01:46,367 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:43514
recon_1     | 2023-01-30 12:01:46,376 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:01:46,403 [IPC Server handler 3 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6295590c-c30d-436f-ae9f-b085e438c72d
recon_1     | 2023-01-30 12:01:46,413 [IPC Server handler 3 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 6295590c-c30d-436f-ae9f-b085e438c72d{ip: 172.18.0.7, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279590402906, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-30 12:01:46,454 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 6295590c-c30d-436f-ae9f-b085e438c72d to Node DB.
recon_1     | 2023-01-30 12:01:46,517 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57020
recon_1     | 2023-01-30 12:01:46,533 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:01:46,537 [IPC Server handler 9 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/01074a56-f4fb-4406-b467-549b4df46db9
recon_1     | 2023-01-30 12:01:46,538 [IPC Server handler 9 on default port 9891] INFO node.SCMNodeManager: Registered Data node : 01074a56-f4fb-4406-b467-549b4df46db9{ip: 172.18.0.8, host: ozonesecure_datanode_2.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279961009839, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-30 12:01:46,538 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node 01074a56-f4fb-4406-b467-549b4df46db9 to Node DB.
recon_1     | 2023-01-30 12:01:46,752 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:47518
recon_1     | 2023-01-30 12:01:46,768 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:01:46,781 [IPC Server handler 99 on default port 9891] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c8ea7a3f-965d-439b-b69f-d2205a7da823
datanode_1  | 2023-01-30 12:02:00,895 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2023-01-30 12:01:13,053 [EndpointStateMachine task thread for scm/172.18.0.5:9861 - 0 ] INFO ratis.XceiverServerRatis: XceiverServerRatis c8ea7a3f-965d-439b-b69f-d2205a7da823 is started using port 9855 for RATIS_DATASTREAM
datanode_3  | 2023-01-30 12:01:13,054 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-c8ea7a3f-965d-439b-b69f-d2205a7da823: Started
datanode_3  | 2023-01-30 12:01:15,764 [EndpointStateMachine task thread for recon/172.18.0.6:9891 - 0 ] WARN statemachine.EndpointStateMachine: Unable to communicate to Recon server at recon:9891 for past 0 seconds.
datanode_3  | java.io.IOException: DestHost:destPort recon:9891 , LocalHost:localPort 51f838724954/172.18.0.4:0. Failed on local exception: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:40838 remote=recon/172.18.0.6:9891]
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
datanode_3  | 	at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
datanode_3  | 	at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
datanode_3  | 	at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913)
datanode_3  | 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1558)
datanode_2  | 2023-01-30 12:01:55,158 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_2  | 2023-01-30 12:01:55,159 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_2  | 2023-01-30 12:01:55,159 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_2  | 2023-01-30 12:01:55,161 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4669bd40-3cd3-4bd5-be19-907eab7b746b does not exist. Creating ...
datanode_2  | 2023-01-30 12:01:55,170 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4669bd40-3cd3-4bd5-be19-907eab7b746b/in_use.lock acquired by nodename 6@2850eee4085e
datanode_2  | 2023-01-30 12:01:55,176 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4669bd40-3cd3-4bd5-be19-907eab7b746b has been successfully formatted.
datanode_2  | 2023-01-30 12:01:55,183 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-907EAB7B746B: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_2  | 2023-01-30 12:01:55,183 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_2  | 2023-01-30 12:01:55,184 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_2  | 2023-01-30 12:01:55,184 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-30 12:02:01,037 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-LeaderElection2] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3: set configuration 0: peers:[6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:02:01,200 [6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-D14D9BFCC8C3-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3/current/log_inprogress_0
datanode_1  | 2023-01-30 12:02:04,713 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5027677801ns, electionTimeout:5018ms
datanode_1  | 2023-01-30 12:02:04,713 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState
datanode_1  | 2023-01-30 12:02:04,714 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_1  | 2023-01-30 12:02:04,714 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_1  | 2023-01-30 12:02:04,714 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3
datanode_1  | 2023-01-30 12:02:04,722 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3 ELECTION round 0: submit vote requests at term 3 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:02:04,723 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_1  | 2023-01-30 12:02:04,723 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 2023-01-30 12:01:19,972 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 300s (custom)
om_1        | 2023-01-30 12:01:19,986 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2023-01-30 12:01:20,427 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2023-01-30 12:01:20,432 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1        | 2023-01-30 12:01:20,435 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om_1        | 2023-01-30 12:01:20,438 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | 2023-01-30 12:01:20,439 [pool-28-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1        | 2023-01-30 12:01:21,525 [main] INFO reflections.Reflections: Reflections took 1665 ms to scan 8 urls, producing 23 keys and 546 values [using 2 cores]
om_1        | 2023-01-30 12:01:21,825 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2023-01-30 12:01:21,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Starting Socket Reader #1 for port 9862
om_1        | 2023-01-30 12:01:24,553 [Listener at om/9862] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
scm_1       |   PathLen:2147483647
scm_1       | ]
scm_1       | 
scm_1       | [2]: ObjectId: 2.5.29.15 Criticality=true
scm_1       | KeyUsage [
scm_1       |   DigitalSignature
scm_1       |   Key_Encipherment
scm_1       |   Data_Encipherment
scm_1       |   Key_Agreement
scm_1       |   Key_CertSign
scm_1       |   Crl_Sign
scm_1       | ]
datanode_1  | 2023-01-30 12:02:04,771 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3: ELECTION PASSED received 2 response(s) and 0 exception(s):
datanode_1  | 2023-01-30 12:02:04,772 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.LeaderElection:   Response 0: 6295590c-c30d-436f-ae9f-b085e438c72d<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:FAIL-t3
datanode_1  | 2023-01-30 12:02:04,773 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.LeaderElection:   Response 1: 6295590c-c30d-436f-ae9f-b085e438c72d<-01074a56-f4fb-4406-b467-549b4df46db9#0:OK-t3
datanode_1  | 2023-01-30 12:02:04,773 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.LeaderElection: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3 ELECTION round 0: result PASSED
datanode_1  | 2023-01-30 12:02:04,773 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: shutdown 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3
datanode_1  | 2023-01-30 12:02:04,773 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: changes role from CANDIDATE to LEADER at term 3 for changeToLeader
datanode_1  | 2023-01-30 12:02:04,774 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE3F4E13DA16 with new leaderId: 6295590c-c30d-436f-ae9f-b085e438c72d
datanode_1  | 2023-01-30 12:02:04,776 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: change Leader from null to 6295590c-c30d-436f-ae9f-b085e438c72d at term 3 for becomeLeader, leader elected after 17142ms
datanode_1  | 2023-01-30 12:02:04,776 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2023-01-30 12:01:24,588 [Listener at om/9862] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2023-01-30 12:01:24,590 [Listener at om/9862] INFO impl.MetricsSystemImpl: OzoneManager metrics system started
scm_1       | 
scm_1       | [3]: ObjectId: 2.5.29.17 Criticality=false
scm_1       | SubjectAlternativeName [
scm_1       |   IPAddress: 172.18.0.5
scm_1       | ]
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1455)
om_1        | 2023-01-30 12:01:24,701 [Listener at om/9862] INFO om.OzoneManager: OzoneManager RPC server is listening at om/172.18.0.2:9862
om_1        | 2023-01-30 12:01:24,701 [Listener at om/9862] INFO ratis.OzoneManagerRatisServer: Starting OzoneManagerRatisServer om1 at port 9872
om_1        | 2023-01-30 12:01:24,705 [om1-impl-thread1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e does not exist. Creating ...
om_1        | 2023-01-30 12:01:24,711 [om1-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/in_use.lock acquired by nodename 6@om
om_1        | 2023-01-30 12:01:24,740 [om1-impl-thread1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e has been successfully formatted.
om_1        | 2023-01-30 12:01:24,755 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2023-01-30 12:01:24,794 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2023-01-30 12:01:24,797 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-30 12:01:24,828 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1        | 2023-01-30 12:01:24,835 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:235)
datanode_3  | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:122)
datanode_3  | 	at com.sun.proxy.$Proxy44.submitRequest(Unknown Source)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.submitRequest(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:117)
datanode_3  | 	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.getVersion(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:133)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:69)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.endpoint.VersionEndpointTask.call(VersionEndpointTask.java:40)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.io.IOException: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:40838 remote=recon/172.18.0.6:9891]
recon_1     | 2023-01-30 12:01:46,781 [IPC Server handler 99 on default port 9891] INFO node.SCMNodeManager: Registered Data node : c8ea7a3f-965d-439b-b69f-d2205a7da823{ip: 172.18.0.4, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279802483984, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-30 12:01:46,783 [EventQueue-NewNodeForReconNewNodeHandler] INFO scm.ReconNodeManager: Adding new node c8ea7a3f-965d-439b-b69f-d2205a7da823 to Node DB.
recon_1     | 2023-01-30 12:01:48,183 [IPC Server handler 3 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_1.ozonesecure_default
recon_1     | 2023-01-30 12:01:48,194 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)
recon_1     | 2023-01-30 12:01:48,305 [IPC Server handler 5 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_2.ozonesecure_default
recon_1     | 2023-01-30 12:01:48,308 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)
recon_1     | 2023-01-30 12:01:48,858 [IPC Server handler 2 on default port 9891] INFO scm.ReconNodeManager: Sending ReregisterCommand() for ozonesecure_datanode_3.ozonesecure_default
recon_1     | 2023-01-30 12:01:48,867 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=ab8a74f8-57b8-4ac7-9c21-c111afcbd229 reported by c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4)
recon_1     | 2023-01-30 12:01:48,870 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ab8a74f8-57b8-4ac7-9c21-c111afcbd229, Nodes: c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c8ea7a3f-965d-439b-b69f-d2205a7da823, CreationTimestamp2023-01-30T12:01:15.364Z[UTC]] moved to OPEN state
recon_1     | 2023-01-30 12:01:50,295 [IPC Server handler 10 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_3.ozonesecure_default
recon_1     | 2023-01-30 12:01:50,297 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4)
datanode_1  | 2023-01-30 12:02:04,780 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2023-01-30 12:02:04,780 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_1  | 2023-01-30 12:02:04,781 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_1  | 2023-01-30 12:02:04,782 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_1  | 2023-01-30 12:02:04,782 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_1  | 2023-01-30 12:02:04,782 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_1  | 2023-01-30 12:02:04,782 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_1  | 2023-01-30 12:02:04,831 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2023-01-30 12:02:04,833 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-30 12:02:04,833 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2023-01-30 12:02:04,847 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2023-01-30 12:02:04,849 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2023-01-30 12:02:04,849 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 
scm_1       | ]
scm_1       |   Algorithm: [SHA256withRSA]
scm_1       |   Signature:
scm_1       | 0000: 71 F6 88 5B 67 58 80 61   61 81 71 CE 7B F2 58 76  q..[gX.aa.q...Xv
scm_1       | 0010: 15 44 5F 1A 2E 1E 77 BB   09 55 09 C2 BF 96 E1 A7  .D_...w..U......
scm_1       | 0020: A1 DB 15 A7 ED 54 62 34   B8 8D 2E CA 08 3A EE 65  .....Tb4.....:.e
scm_1       | 0030: 4B 4A CF 29 16 A6 49 D9   1C 91 45 DD D5 8C 51 A1  KJ.)..I...E...Q.
scm_1       | 0040: 4C 26 61 52 53 E9 F7 DC   71 FA DB 24 AA 17 92 BF  L&aRS...q..$....
scm_1       | 0050: DE BC 8D C2 3C 70 25 5C   44 3B 3E 67 3E 9A 39 80  ....<p%\D;>g>.9.
scm_1       | 0060: 0E 66 7E 21 15 C0 16 D6   13 A2 AC 7B DA 20 FA 83  .f.!......... ..
datanode_2  | 2023-01-30 12:01:55,184 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
datanode_2  | 2023-01-30 12:01:55,185 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | 2023-01-30 12:01:24,859 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2023-01-30 12:01:24,916 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2023-01-30 12:01:24,917 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | 2023-01-30 12:01:24,960 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new om1@group-C5BA1605619E-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e
om_1        | 2023-01-30 12:01:24,960 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2023-01-30 12:01:24,961 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2023-01-30 12:01:24,968 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2023-01-30 12:01:24,970 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1        | 2023-01-30 12:01:24,971 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2023-01-30 12:01:24,974 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2023-01-30 12:01:24,977 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2023-01-30 12:01:24,982 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2023-01-30 12:01:25,028 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798)
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)
datanode_3  | 	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)
datanode_3  | 	at org.apache.hadoop.ipc.Client.call(Client.java:1502)
datanode_3  | 	... 12 more
datanode_3  | Caused by: java.net.SocketTimeoutException: 5000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.18.0.4:40838 remote=recon/172.18.0.6:9891]
datanode_3  | 	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
datanode_3  | 	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
datanode_1  | 2023-01-30 12:02:04,849 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_1  | 2023-01-30 12:02:04,849 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_1  | 2023-01-30 12:02:04,869 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
datanode_1  | 2023-01-30 12:02:04,870 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_1  | 2023-01-30 12:02:04,870 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.element-limit = 1 (custom)
datanode_1  | 2023-01-30 12:02:04,871 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.leader.outstanding.appends.max = 128 (default)
datanode_1  | 2023-01-30 12:02:04,873 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 60s (custom)
datanode_1  | 2023-01-30 12:02:04,874 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_1  | 2023-01-30 12:02:04,875 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
datanode_1  | 2023-01-30 12:02:04,875 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.log.appender.wait-time.min = 10ms (default)
datanode_1  | 2023-01-30 12:02:04,897 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO impl.RoleInfo: 6295590c-c30d-436f-ae9f-b085e438c72d: start 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderStateImpl
datanode_1  | 2023-01-30 12:02:04,927 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker: Starting segment from index:0
datanode_1  | 2023-01-30 12:02:04,938 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/current/log_inprogress_0
datanode_1  | 2023-01-30 12:02:04,997 [6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LeaderElection3] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: set configuration 0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:02:05,394 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16: receive requestVote(ELECTION, c8ea7a3f-965d-439b-b69f-d2205a7da823, group-CE3F4E13DA16, 3, (t:0, i:0))
datanode_1  | 2023-01-30 12:02:05,395 [grpc-default-executor-1] INFO impl.VoteContext: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-LEADER: reject ELECTION from c8ea7a3f-965d-439b-b69f-d2205a7da823: already has voted for 6295590c-c30d-436f-ae9f-b085e438c72d at current term 3
datanode_1  | 2023-01-30 12:02:05,395 [grpc-default-executor-1] INFO server.RaftServer$Division: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16 replies to ELECTION vote request: c8ea7a3f-965d-439b-b69f-d2205a7da823<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t3. Peer's state: 6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16:t3, leader=6295590c-c30d-436f-ae9f-b085e438c72d, voted=6295590c-c30d-436f-ae9f-b085e438c72d, raftlog=Memoized:6295590c-c30d-436f-ae9f-b085e438c72d@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c0, conf=0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_1  | 2023-01-30 12:02:31,996 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:283261507731.
datanode_2  | 2023-01-30 12:01:55,188 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
scm_1       | 0070: 29 6E CE CE 9A B2 C8 F8   92 1D 8A 01 30 07 53 E5  )n..........0.S.
recon_1     | 2023-01-30 12:01:54,701 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4)
om_1        | 2023-01-30 12:01:25,029 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 	at java.base/java.io.FilterInputStream.read(FilterInputStream.java:133)
datanode_3  | 	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
scm_1       | 0080: 32 F3 EA CF E1 46 A4 FE   21 56 65 41 28 7A E7 2E  2....F..!VeA(z..
recon_1     | 2023-01-30 12:01:55,200 [IPC Server handler 10 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_2.ozonesecure_default
recon_1     | 2023-01-30 12:01:55,200 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=4669bd40-3cd3-4bd5-be19-907eab7b746b reported by 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)
om_1        | 2023-01-30 12:01:25,093 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_3  | 	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271)
datanode_2  | 2023-01-30 12:01:55,188 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
scm_1       | 0090: 32 DE 25 C6 EB AE 1A B9   E1 A2 B5 B6 C4 1A 8B BB  2.%.............
recon_1     | 2023-01-30 12:01:55,201 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4669bd40-3cd3-4bd5-be19-907eab7b746b, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:01074a56-f4fb-4406-b467-549b4df46db9, CreationTimestamp2023-01-30T12:01:15.798Z[UTC]] moved to OPEN state
recon_1     | 2023-01-30 12:01:55,202 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)
om_1        | 2023-01-30 12:01:25,093 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
datanode_3  | 	at java.base/java.io.DataInputStream.readInt(DataInputStream.java:392)
datanode_3  | 	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)
datanode_3  | 	at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367)
scm_1       | 00A0: 83 64 DD 7B 16 BD E7 D1   9A 59 BE 9D DB 3D BB 30  .d.......Y...=.0
om_1        | 2023-01-30 12:01:25,094 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
datanode_2  | 2023-01-30 12:01:55,191 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
datanode_2  | 2023-01-30 12:01:55,191 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4669bd40-3cd3-4bd5-be19-907eab7b746b
datanode_2  | 2023-01-30 12:01:55,193 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
scm_1       | 00B0: 84 6C A7 C0 FF 42 58 49   DC E3 32 1D 38 63 9A 3B  .l...BXI..2.8c.;
scm_1       | 00C0: 0E 1E 7F 4C A8 F0 9D 67   4F E5 59 9E D8 45 FF 95  ...L...gO.Y..E..
scm_1       | 00D0: 23 6A 95 11 48 B9 22 BD   29 8D 47 72 17 7E 2D AC  #j..H.".).Gr..-.
scm_1       | 00E0: BA 51 2B 08 D0 69 75 45   6F 71 3F BA 62 DC 9B C4  .Q+..iuEoq?.b...
datanode_2  | 2023-01-30 12:01:55,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
datanode_2  | 2023-01-30 12:01:55,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_2  | 2023-01-30 12:01:55,194 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
scm_1       | 00F0: 07 C1 0B C1 80 37 61 B6   8B 51 65 E3 4C DD 83 AA  .....7a..Qe.L...
scm_1       | 
om_1        | 2023-01-30 12:01:25,164 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
om_1        | 2023-01-30 12:01:25,164 [om1-impl-thread1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
om_1        | 2023-01-30 12:01:25,191 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: start as a follower, conf=-1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:01:25,195 [om1-impl-thread1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from      null to FOLLOWER at term 0 for startAsFollower
om_1        | 2023-01-30 12:01:25,206 [om1-impl-thread1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-FollowerState
om_1        | 2023-01-30 12:01:25,228 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-30 12:01:25,232 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-30 12:01:55,340 [IPC Server handler 8 on default port 9891] INFO scm.ReconNodeManager: Updating nodeDB for ozonesecure_datanode_1.ozonesecure_default
recon_1     | 2023-01-30 12:01:55,342 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/ONE PipelineID=b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3 reported by 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)
recon_1     | 2023-01-30 12:01:55,342 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3, Nodes: 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6295590c-c30d-436f-ae9f-b085e438c72d, CreationTimestamp2023-01-30T12:01:15.752Z[UTC]] moved to OPEN state
om_1        | 2023-01-30 12:01:25,239 [om1-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C5BA1605619E,id=om1
om_1        | 2023-01-30 12:01:25,248 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:55,196 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2023-01-30 12:01:25,249 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 400000 (default)
om_1        | 2023-01-30 12:01:25,250 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
om_1        | 2023-01-30 12:01:25,251 [om1-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = true (custom)
recon_1     | 2023-01-30 12:01:55,343 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)
recon_1     | 2023-01-30 12:02:00,405 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)
datanode_2  | 2023-01-30 12:01:55,197 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2023-01-30 12:01:25,275 [Listener at om/9862] INFO server.RaftServer: om1: start RPC server
om_1        | 2023-01-30 12:01:25,381 [Listener at om/9862] INFO server.GrpcService: om1: GrpcService started, listening on 9872
scm_1       | ] from file:/data/metadata/scm/sub-ca/certs/certificate.crt.
recon_1     | 2023-01-30 12:02:00,449 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)
datanode_2  | 2023-01-30 12:01:55,202 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
datanode_2  | 2023-01-30 12:01:55,202 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2023-01-30 12:01:25,398 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-om1: Started
om_1        | 2023-01-30 12:01:25,399 [Listener at om/9862] INFO om.OzoneManager: Starting OM block token secret manager
om_1        | 2023-01-30 12:01:25,402 [Listener at om/9862] INFO token.OzoneBlockTokenSecretManager: Updating current master key for generating tokens. Cert id 283261507731
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)
datanode_2  | 2023-01-30 12:01:55,204 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1       | 2023-01-30 12:00:28,472 [main] INFO client.SCMCertificateClient: CertificateLifetimeMonitor for scm/sub-ca is started with first delay 158673571531 ms and interval 86400000 ms.
om_1        | 2023-01-30 12:01:25,404 [Listener at om/9862] INFO om.OzoneManager: Starting OM delegation token secret manager
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)
scm_1       | 2023-01-30 12:00:28,636 [main] INFO security.UserGroupInformation: Login successful for user scm/scm@EXAMPLE.COM using keytab file scm.keytab. Keytab auto renewal enabled : false
recon_1     | 2023-01-30 12:02:04,794 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO scm.ReconPipelineReportHandler: Pipeline RATIS/THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 reported by 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)
recon_1     | 2023-01-30 12:02:04,794 [EventQueue-PipelineReportForReconPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e8cbeba-21db-48a1-9ddc-ce3f4e13da16, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:6295590c-c30d-436f-ae9f-b085e438c72d, CreationTimestamp2023-01-30T12:01:15.716Z[UTC]] moved to OPEN state
om_1        | 2023-01-30 12:01:25,404 [Listener at om/9862] INFO security.OzoneDelegationTokenSecretManager: Updating current master key for generating tokens. Cert id 283261507731
scm_1       | 2023-01-30 12:00:28,636 [main] INFO server.StorageContainerManager: SCM login successful.
recon_1     | 2023-01-30 12:02:24,691 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:49678
recon_1     | 2023-01-30 12:02:24,712 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:01:25,418 [Listener at om/9862] INFO om.OzoneManager: Version File has different layout version (3) than OM DB (null). That is expected if this OM has never been finalized to a newer layout version.
datanode_3  | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 2023-01-30 12:00:28,691 [main] WARN utils.HAUtils: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
om_1        | 2023-01-30 12:01:25,421 [Thread[Thread-16,5,main]] INFO security.OzoneDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
om_1        | 2023-01-30 12:01:25,557 [Listener at om/9862] INFO http.BaseHttpServer: Starting Web-server for ozoneManager at: http://0.0.0.0:9874
om_1        | 2023-01-30 12:01:25,557 [Listener at om/9862] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
datanode_3  | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
datanode_3  | 	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)
scm_1       | 2023-01-30 12:00:28,874 [main] WARN db.DBStoreBuilder: ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
scm_1       | 2023-01-30 12:00:29,297 [main] INFO net.NodeSchemaLoader: Loading schema from [file:/etc/hadoop/network-topology-default.xml, jar:file:/opt/hadoop/share/ozone/lib/hdds-common-1.4.0-SNAPSHOT.jar!/network-topology-default.xml]
scm_1       | 2023-01-30 12:00:29,298 [main] INFO net.NodeSchemaLoader: Loading network topology layer schema file
datanode_3  | 	... 15 more
datanode_3  | 2023-01-30 12:01:18,740 [Datanode State Machine Daemon Thread] ERROR datanode.RunningDatanodeState: Error in executing end point task.
datanode_3  | java.util.concurrent.ExecutionException: java.util.concurrent.TimeoutException
scm_1       | 2023-01-30 12:00:29,364 [main] INFO metrics.MetricRegistries: Loaded MetricRegistries class org.apache.ratis.metrics.impl.MetricRegistriesImpl
scm_1       | 2023-01-30 12:00:29,388 [main] INFO ha.SCMRatisServerImpl: starting Raft server for scm:82e918d1-ff68-4821-a2f0-f9af71d19ea5
scm_1       | 2023-01-30 12:00:29,419 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
scm_1       | 2023-01-30 12:00:29,427 [main] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig0-
recon_1     | 2023-01-30 12:02:30,446 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:53634
recon_1     | 2023-01-30 12:02:30,460 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:02:32,385 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45138
scm_1       | 2023-01-30 12:00:29,476 [main] INFO server.RaftServer: raft.rpc.type = GRPC (default)
datanode_2  | 2023-01-30 12:01:55,208 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_2  | 2023-01-30 12:01:55,247 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
datanode_2  | 2023-01-30 12:01:55,248 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:29,553 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-30 12:00:29,554 [main] INFO grpc.GrpcConfigKeys: raft.grpc.admin.port = 9894 (fallback to raft.grpc.server.port)
recon_1     | 2023-01-30 12:02:32,477 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:02:32,516 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure_datanode_1.ozonesecure_default.
recon_1     | 2023-01-30 12:02:32,576 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: New container #1 got from ozonesecure_datanode_2.ozonesecure_default.
recon_1     | 2023-01-30 12:02:32,665 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
scm_1       | 2023-01-30 12:00:29,555 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.host = null (fallback to raft.grpc.server.host)
scm_1       | 2023-01-30 12:00:29,556 [main] INFO grpc.GrpcConfigKeys: raft.grpc.client.port = 9894 (fallback to raft.grpc.server.port)
recon_1     | 2023-01-30 12:02:32,721 [FixedThreadPoolWithAffinityExecutor-0-0] INFO scm.ReconContainerManager: Successfully added container #1 to Recon.
datanode_2  | 2023-01-30 12:01:55,248 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:55,249 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-30 12:01:55,250 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-30 12:00:29,556 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.host = null (default)
scm_1       | 2023-01-30 12:00:29,557 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.port = 9894 (custom)
recon_1     | 2023-01-30 12:02:44,978 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:02:44,982 [pool-30-thread-1] INFO codec.RepeatedOmKeyInfoCodec: RepeatedOmKeyInfoCodec ignorePipeline = true
datanode_2  | 2023-01-30 12:01:55,250 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: start as a follower, conf=-1: peers:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:01:55,250 [pool-24-thread-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_2  | 2023-01-30 12:01:55,251 [pool-24-thread-1] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState
datanode_2  | 2023-01-30 12:01:55,251 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-907EAB7B746B,id=01074a56-f4fb-4406-b467-549b4df46db9
scm_1       | 2023-01-30 12:00:29,558 [main] INFO server.GrpcService: raft.grpc.message.size.max = 32m (=33554432) (custom)
recon_1     | 2023-01-30 12:02:44,982 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2023-01-30 12:01:25,557 [Listener at om/9862] INFO http.BaseHttpServer: HttpAuthType: ozone.om.http.auth.type = kerberos
datanode_2  | 2023-01-30 12:01:55,252 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
datanode_2  | 2023-01-30 12:01:55,254 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_2  | 2023-01-30 12:01:55,254 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2023-01-30 12:00:29,560 [main] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-30 12:02:44,982 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2023-01-30 12:01:25,638 [Listener at om/9862] INFO util.log: Logging initialized @39123ms to org.eclipse.jetty.util.log.Slf4jLog
datanode_2  | 2023-01-30 12:01:55,254 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
datanode_2  | 2023-01-30 12:01:55,255 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:01:55,258 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4669bd40-3cd3-4bd5-be19-907eab7b746b
scm_1       | 2023-01-30 12:00:29,561 [main] INFO server.GrpcService: raft.grpc.flow.control.window = 1MB (=1048576) (default)
recon_1     | 2023-01-30 12:02:44,982 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2023-01-30 12:01:25,982 [Listener at om/9862] INFO http.HttpRequestLog: Http request log for http.requests.ozoneManager is not defined
datanode_2  | 2023-01-30 12:01:55,258 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=4669bd40-3cd3-4bd5-be19-907eab7b746b.
datanode_2  | 2023-01-30 12:01:55,259 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:01:59,641 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5013318805ns, electionTimeout:5003ms
scm_1       | 2023-01-30 12:00:29,561 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.request.timeout = 30000ms (custom)
recon_1     | 2023-01-30 12:02:44,982 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
om_1        | 2023-01-30 12:01:26,008 [Listener at om/9862] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
datanode_2  | 2023-01-30 12:01:59,642 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:122)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191)
scm_1       | 2023-01-30 12:00:29,574 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.heartbeat.channel = true (default)
recon_1     | 2023-01-30 12:02:44,983 [pool-30-thread-1] INFO codec.OmKeyInfoCodec: OmKeyInfoCodec ignorePipeline = true
recon_1     | 2023-01-30 12:02:44,983 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-30 12:01:26,034 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context ozoneManager
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.computeNextContainerState(RunningDatanodeState.java:199)
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:239)
scm_1       | 2023-01-30 12:00:29,577 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.cached = true (default)
recon_1     | 2023-01-30 12:02:44,983 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 2 
recon_1     | 2023-01-30 12:02:45,059 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
om_1        | 2023-01-30 12:01:26,034 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.await(RunningDatanodeState.java:50)
scm_1       | 2023-01-30 12:00:29,578 [main] INFO grpc.GrpcConfigKeys: raft.grpc.server.async.request.thread.pool.size = 32 (default)
recon_1     | 2023-01-30 12:02:45,059 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
recon_1     | 2023-01-30 12:02:45,065 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2023-01-30 12:01:26,034 [Listener at om/9862] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.StateContext.execute(StateContext.java:661)
scm_1       | 2023-01-30 12:00:30,059 [main] INFO impl.DataStreamServerImpl: raft.datastream.type = NETTY (custom)
om_1        | 2023-01-30 12:01:26,044 [Listener at om/9862] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: ozone.om.http.auth.kerberos.principal keytabKey: ozone.om.http.auth.kerberos.keytab
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.startStateMachineThread(DatanodeStateMachine.java:320)
scm_1       | 2023-01-30 12:00:30,172 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.cached = false (default)
datanode_2  | 2023-01-30 12:01:59,642 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
datanode_2  | 2023-01-30 12:01:59,642 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2023-01-30 12:01:26,180 [Listener at om/9862] INFO http.HttpServer2: Jetty bound to port 9874
scm_1       | 2023-01-30 12:00:30,173 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.request.thread.pool.size = 32 (default)
datanode_2  | 2023-01-30 12:01:59,642 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2
datanode_2  | 2023-01-30 12:01:59,651 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2 ELECTION round 0: submit vote requests at term 2 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:01:26,190 [Listener at om/9862] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
datanode_3  | 	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:516)
scm_1       | 2023-01-30 12:00:30,173 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.async.write.thread.pool.size = 16 (default)
om_1        | 2023-01-30 12:01:26,329 [Listener at om/9862] INFO server.session: DefaultSessionIdManager workerName=node0
datanode_3  | 	at java.base/java.lang.Thread.run(Thread.java:829)
datanode_3  | Caused by: java.util.concurrent.TimeoutException
scm_1       | 2023-01-30 12:00:30,174 [main] INFO server.RaftServerConfigKeys: raft.server.data-stream.client.pool.size = 10 (default)
datanode_2  | 2023-01-30 12:01:59,660 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
recon_1     | 2023-01-30 12:02:45,066 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:02:45,260 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:204)
scm_1       | 2023-01-30 12:00:30,177 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.use-epoll = false (default)
datanode_2  | 2023-01-30 12:01:59,660 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
recon_1     | 2023-01-30 12:02:45,270 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2023-01-30 12:02:45,307 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:02:54,784 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered ContainerHealthTask task 
recon_1     | 2023-01-30 12:02:54,785 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting ContainerHealthTask Thread.
recon_1     | 2023-01-30 12:02:54,811 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Registered PipelineSyncTask task 
recon_1     | 2023-01-30 12:02:54,812 [Listener at 0.0.0.0/9891] INFO scm.ReconScmTask: Starting PipelineSyncTask Thread.
recon_1     | 2023-01-30 12:02:54,902 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 116 milliseconds to process 0 existing database records.
recon_1     | 2023-01-30 12:02:54,930 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2023-01-30 12:02:54,934 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 120 milliseconds.
recon_1     | 2023-01-30 12:02:54,947 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 45 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:01:26,329 [Listener at om/9862] INFO server.session: No SessionScavenger set, using defaults
scm_1       | 2023-01-30 12:00:30,178 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.boss-group.size = 0 (default)
scm_1       | 2023-01-30 12:00:30,184 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.worker-group.size = 0 (default)
scm_1       | 2023-01-30 12:00:30,185 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.server.tls.conf = GrpcTlsConfig0- (custom)
scm_1       | 2023-01-30 12:00:30,225 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.host = null (default)
recon_1     | 2023-01-30 12:03:02,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35136
om_1        | 2023-01-30 12:01:26,331 [Listener at om/9862] INFO server.session: node0 Scavenging every 660000ms
scm_1       | 2023-01-30 12:00:30,226 [main] INFO netty.NettyConfigKeys$DataStream: raft.netty.dataStream.port = 0 (default)
recon_1     | 2023-01-30 12:03:02,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:01:26,355 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/om.keytab, for principal HTTP/om@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:30,274 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.cached = true (default)
recon_1     | 2023-01-30 12:03:02,583 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41102
datanode_3  | 	at org.apache.hadoop.ozone.container.common.states.datanode.RunningDatanodeState.lambda$execute$0(RunningDatanodeState.java:157)
scm_1       | 2023-01-30 12:00:30,275 [main] INFO server.RaftServerConfigKeys: raft.server.threadpool.proxy.size = 0 (default)
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2: ELECTION REJECTED received 2 response(s) and 0 exception(s):
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection:   Response 0: 01074a56-f4fb-4406-b467-549b4df46db9<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:OK-t2
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection:   Response 1: 01074a56-f4fb-4406-b467-549b4df46db9<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t2
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2 ELECTION round 0: result REJECTED
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from CANDIDATE to FOLLOWER at term 2 for REJECTED
scm_1       | 2023-01-30 12:00:30,276 [main] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2
datanode_2  | 2023-01-30 12:01:59,711 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-LeaderElection2] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_2  | 2023-01-30 12:01:59,712 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:01:59,714 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:02:00,373 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO impl.FollowerState: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5122052172ns, electionTimeout:5113ms
datanode_2  | 2023-01-30 12:02:00,373 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState
datanode_2  | 2023-01-30 12:02:00,373 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
recon_1     | 2023-01-30 12:03:02,595 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-30 12:02:00,374 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2023-01-30 12:00:30,276 [main] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
scm_1       | 2023-01-30 12:00:30,279 [main] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
scm_1       | 2023-01-30 12:00:30,286 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: found a subdirectory /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545
recon_1     | 2023-01-30 12:03:02,807 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:48480
scm_1       | 2023-01-30 12:00:30,293 [main] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: addNew group-87E6E2D1E545:[] returns group-87E6E2D1E545:java.util.concurrent.CompletableFuture@44faa4f2[Not completed]
scm_1       | 2023-01-30 12:00:30,318 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc10f3e48] REGISTERED
datanode_3  | 	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
datanode_3  | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
scm_1       | 2023-01-30 12:00:30,319 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc10f3e48] BIND: 0.0.0.0/0.0.0.0:0
scm_1       | 2023-01-30 12:00:30,321 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-NettyServerStreamRpc-bossGroup--thread1] INFO logging.LoggingHandler: [id: 0xc10f3e48, L:/0.0.0.0:33951] ACTIVE
scm_1       | 2023-01-30 12:00:30,322 [pool-17-thread-1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: new RaftServerImpl for group-87E6E2D1E545:[] with SCMStateMachine:uninitialized
datanode_2  | 2023-01-30 12:02:00,375 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-FollowerState] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3
om_1        | 2023-01-30 12:01:26,359 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@106802ea{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 2023-01-30 12:01:26,361 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@4ff0706c{static,/static,jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
om_1        | 2023-01-30 12:01:26,686 [Listener at om/9862] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/om.keytab, for principal HTTP/om@EXAMPLE.COM
om_1        | 2023-01-30 12:01:26,703 [Listener at om/9862] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@2358443e{ozoneManager,/,file:///tmp/jetty-0_0_0_0-9874-ozone-manager-1_4_0-SNAPSHOT_jar-_-any-8280850314960505643/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/ozone-manager-1.4.0-SNAPSHOT.jar!/webapps/ozoneManager}
scm_1       | 2023-01-30 12:00:30,331 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5000ms (custom)
datanode_2  | 2023-01-30 12:02:00,391 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3 ELECTION round 0: submit vote requests at term 1 for -1: peers:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:02:00,392 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO impl.LeaderElection: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3 ELECTION round 0: result PASSED (term=1)
datanode_2  | 2023-01-30 12:02:00,392 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3
datanode_2  | 2023-01-30 12:02:00,393 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
recon_1     | 2023-01-30 12:03:02,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:03:32,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:52394
scm_1       | 2023-01-30 12:00:30,332 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
recon_1     | 2023-01-30 12:03:32,345 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-30 12:02:00,393 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-907EAB7B746B with new leaderId: 01074a56-f4fb-4406-b467-549b4df46db9
scm_1       | 2023-01-30 12:00:30,332 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 	... 1 more
datanode_3  | 2023-01-30 12:01:47,857 [Command processor thread] INFO server.RaftServer: c8ea7a3f-965d-439b-b69f-d2205a7da823: addNew group-C111AFCBD229:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER] returns group-C111AFCBD229:java.util.concurrent.CompletableFuture@750b6b67[Not completed]
recon_1     | 2023-01-30 12:03:32,584 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44622
recon_1     | 2023-01-30 12:03:32,591 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:03:32,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35330
scm_1       | 2023-01-30 12:00:30,332 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 120000ms (custom)
datanode_3  | 2023-01-30 12:01:47,994 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823: new RaftServerImpl for group-C111AFCBD229:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
datanode_3  | 2023-01-30 12:01:48,001 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
om_1        | 2023-01-30 12:01:26,733 [Listener at om/9862] INFO server.AbstractConnector: Started ServerConnector@ca60688{HTTP/1.1, (http/1.1)}{0.0.0.0:9874}
scm_1       | 2023-01-30 12:00:30,333 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-30 12:01:48,005 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
datanode_3  | 2023-01-30 12:01:48,006 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2023-01-30 12:01:48,007 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
datanode_3  | 2023-01-30 12:01:48,007 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-30 12:01:48,008 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
scm_1       | 2023-01-30 12:00:30,333 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1     | 2023-01-30 12:03:32,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:01:26,733 [Listener at om/9862] INFO server.Server: Started @40218ms
om_1        | 2023-01-30 12:01:26,747 [Listener at om/9862] INFO impl.MetricsSinkAdapter: Sink prometheus started
datanode_3  | 2023-01-30 12:01:48,082 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: ConfigurationManager, init=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_3  | 2023-01-30 12:01:48,087 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
datanode_3  | 2023-01-30 12:01:48,120 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2023-01-30 12:01:26,747 [Listener at om/9862] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2023-01-30 12:00:30,344 [pool-17-thread-1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: ConfigurationManager, init=-1: peers:[]|listeners:[], old=null, confs=<EMPTY_MAP>
datanode_3  | 2023-01-30 12:01:48,125 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_3  | 2023-01-30 12:01:48,207 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
datanode_3  | 2023-01-30 12:01:48,269 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2023-01-30 12:01:26,750 [Listener at om/9862] INFO http.BaseHttpServer: HTTP server of ozoneManager listening at http://0.0.0.0:9874
scm_1       | 2023-01-30 12:00:30,345 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/scm-ha] (custom)
datanode_3  | 2023-01-30 12:01:48,274 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
datanode_3  | 2023-01-30 12:01:48,551 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
datanode_3  | 2023-01-30 12:01:48,557 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
datanode_3  | 2023-01-30 12:01:48,576 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
datanode_3  | 2023-01-30 12:01:48,577 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2023-01-30 12:01:48,577 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
datanode_3  | 2023-01-30 12:01:48,578 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/ab8a74f8-57b8-4ac7-9c21-c111afcbd229 does not exist. Creating ...
om_1        | 2023-01-30 12:01:26,758 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_2  | 2023-01-30 12:02:00,393 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: change Leader from null to 01074a56-f4fb-4406-b467-549b4df46db9 at term 1 for becomeLeader, leader elected after 5254ms
datanode_3  | 2023-01-30 12:01:48,638 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/ab8a74f8-57b8-4ac7-9c21-c111afcbd229/in_use.lock acquired by nodename 7@51f838724954
datanode_3  | 2023-01-30 12:01:48,731 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/ab8a74f8-57b8-4ac7-9c21-c111afcbd229 has been successfully formatted.
datanode_3  | 2023-01-30 12:01:48,754 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-C111AFCBD229: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
scm_1       | 2023-01-30 12:00:30,350 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
datanode_2  | 2023-01-30 12:02:00,478 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
datanode_3  | 2023-01-30 12:01:48,768 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2023-01-30 12:01:48,841 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
datanode_3  | 2023-01-30 12:01:48,847 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-30 12:00:30,351 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
datanode_2  | 2023-01-30 12:02:00,535 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_3  | 2023-01-30 12:01:48,873 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
om_1        | 2023-01-30 12:01:26,765 [IPC Server listener on 9862] INFO ipc.Server: IPC Server listener on 9862: starting
om_1        | 2023-01-30 12:01:27,016 [Listener at om/9862] INFO om.TrashPolicyOzone: The configured checkpoint interval is 0 minutes. Using an interval of 1 minutes that is used for deletion instead
datanode_2  | 2023-01-30 12:02:00,542 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
datanode_3  | 2023-01-30 12:01:48,877 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
om_1        | 2023-01-30 12:01:27,020 [Listener at om/9862] INFO om.TrashPolicyOzone: Ozone Manager trash configuration: Deletion interval = 1 minutes, Emptier interval = 1 minutes.
om_1        | 2023-01-30 12:01:27,261 [Listener at om/9862] INFO om.GrpcOzoneManagerServer: GrpcOzoneManagerServer is started using port 8981
datanode_2  | 2023-01-30 12:02:00,562 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
datanode_3  | 2023-01-30 12:01:48,898 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2023-01-30 12:01:48,944 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2023-01-30 12:01:48,947 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1       | 2023-01-30 12:00:30,361 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 60s (default)
datanode_2  | 2023-01-30 12:02:00,562 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
datanode_3  | 2023-01-30 12:01:48,999 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/ab8a74f8-57b8-4ac7-9c21-c111afcbd229
om_1        | 2023-01-30 12:01:27,288 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6942ee48] INFO util.JvmPauseMonitor: Starting JVM pause monitor
om_1        | 2023-01-30 12:01:30,271 [om1@group-C5BA1605619E-FollowerState] INFO impl.FollowerState: om1@group-C5BA1605619E-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5065706544ns, electionTimeout:5036ms
scm_1       | 2023-01-30 12:00:30,366 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 60000ms (default)
datanode_2  | 2023-01-30 12:02:00,563 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
datanode_3  | 2023-01-30 12:01:49,003 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
datanode_3  | 2023-01-30 12:01:49,007 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1        | 2023-01-30 12:01:30,273 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-FollowerState
om_1        | 2023-01-30 12:01:30,273 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
om_1        | 2023-01-30 12:01:30,277 [om1@group-C5BA1605619E-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
om_1        | 2023-01-30 12:01:30,279 [om1@group-C5BA1605619E-FollowerState] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderElection1
datanode_3  | 2023-01-30 12:01:49,009 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2023-01-30 12:01:49,013 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
datanode_2  | 2023-01-30 12:02:00,693 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
datanode_2  | 2023-01-30 12:02:00,713 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
datanode_2  | 2023-01-30 12:02:00,741 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderStateImpl
datanode_2  | 2023-01-30 12:02:00,855 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2023-01-30 12:01:30,286 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[om1|rpc:om:9872|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:01:30,287 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.LeaderElection: om1@group-C5BA1605619E-LeaderElection1 ELECTION round 0: result PASSED (term=1)
datanode_3  | 2023-01-30 12:01:49,016 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
datanode_3  | 2023-01-30 12:01:49,031 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2023-01-30 12:01:30,288 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: shutdown om1@group-C5BA1605619E-LeaderElection1
om_1        | 2023-01-30 12:01:30,289 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2023-01-30 12:01:30,289 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: change Leader from null to om1 at term 1 for becomeLeader, leader elected after 10335ms
om_1        | 2023-01-30 12:01:30,306 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
om_1        | 2023-01-30 12:01:30,313 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2023-01-30 12:01:49,034 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
om_1        | 2023-01-30 12:01:30,328 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
om_1        | 2023-01-30 12:01:30,348 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
om_1        | 2023-01-30 12:01:30,348 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
om_1        | 2023-01-30 12:01:30,351 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
om_1        | 2023-01-30 12:01:30,365 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
datanode_3  | 2023-01-30 12:01:49,034 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
om_1        | 2023-01-30 12:01:30,367 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2023-01-30 12:01:30,370 [om1@group-C5BA1605619E-LeaderElection1] INFO impl.RoleInfo: om1: start om1@group-C5BA1605619E-LeaderStateImpl
om_1        | 2023-01-30 12:01:30,427 [om1@group-C5BA1605619E-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: Starting segment from index:0
om_1        | 2023-01-30 12:01:30,590 [om1@group-C5BA1605619E-LeaderElection1] INFO server.RaftServer$Division: om1@group-C5BA1605619E: set configuration 0: peers:[om1|rpc:om:9872|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:01:30,934 [om1@group-C5BA1605619E-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: om1@group-C5BA1605619E-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/bf265839-605b-3f16-9796-c5ba1605619e/current/log_inprogress_0
datanode_3  | 2023-01-30 12:01:49,111 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
datanode_2  | 2023-01-30 12:02:01,012 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-LeaderElection3] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B: set configuration 0: peers:[01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:02:01,195 [01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-907EAB7B746B-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4669bd40-3cd3-4bd5-be19-907eab7b746b/current/log_inprogress_0
datanode_2  | 2023-01-30 12:02:04,730 [grpc-default-executor-0] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: receive requestVote(ELECTION, 6295590c-c30d-436f-ae9f-b085e438c72d, group-CE3F4E13DA16, 3, (t:0, i:0))
datanode_2  | 2023-01-30 12:02:04,731 [grpc-default-executor-0] INFO impl.VoteContext: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FOLLOWER: accept ELECTION from 6295590c-c30d-436f-ae9f-b085e438c72d: our priority 0 <= candidate's priority 1
datanode_3  | 2023-01-30 12:01:49,117 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-30 12:01:31,137 [om1@group-C5BA1605619E-StateMachineUpdater] INFO ratis.OzoneManagerStateMachine: Received Configuration change notification from Ratis. New Peer list:
om_1        | [id: "om1"
om_1        | address: "om:9872"
datanode_2  | 2023-01-30 12:02:04,731 [grpc-default-executor-0] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: changes role from  FOLLOWER to FOLLOWER at term 3 for candidate:6295590c-c30d-436f-ae9f-b085e438c72d
datanode_2  | 2023-01-30 12:02:04,731 [grpc-default-executor-0] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: shutdown 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
datanode_3  | 2023-01-30 12:01:49,264 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:30,366 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
scm_1       | 2023-01-30 12:00:30,410 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
scm_1       | 2023-01-30 12:00:30,411 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
scm_1       | 2023-01-30 12:00:30,415 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
scm_1       | 2023-01-30 12:00:30,415 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
datanode_3  | 2023-01-30 12:01:49,266 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:30,416 [pool-17-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
scm_1       | 2023-01-30 12:00:30,419 [main] INFO ha.SCMSnapshotProvider: Initializing SCM Snapshot Provider
scm_1       | 2023-01-30 12:00:30,419 [main] WARN server.ServerUtils: Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
scm_1       | 2023-01-30 12:00:30,419 [main] WARN ha.SCMHAUtils: SCM snapshot dir is not configured. Falling back to ozone.metadata.dirs config
scm_1       | 2023-01-30 12:00:30,583 [main] INFO upgrade.AbstractLayoutVersionManager: Initializing Layout version manager with metadata layout = DATANODE_SCHEMA_V3 (version = 4), software layout = DATANODE_SCHEMA_V3 (version = 4)
datanode_3  | 2023-01-30 12:01:49,266 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2023-01-30 12:00:30,782 [main] INFO reflections.Reflections: Reflections took 170 ms to scan 3 urls, producing 124 keys and 279 values 
recon_1     | 2023-01-30 12:03:45,323 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:03:45,323 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:03:45,323 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 17 
recon_1     | 2023-01-30 12:03:45,368 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 22, SequenceNumber Lag from OM 0.
datanode_3  | 2023-01-30 12:01:49,308 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-30 12:00:30,870 [main] INFO ha.SequenceIdGenerator: upgrade localId to 111677748019200000
scm_1       | 2023-01-30 12:00:30,872 [main] INFO ha.SequenceIdGenerator: upgrade delTxnId to 0
datanode_3  | 2023-01-30 12:01:49,309 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
datanode_2  | 2023-01-30 12:02:04,732 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState was interrupted
datanode_2  | 2023-01-30 12:02:04,732 [grpc-default-executor-0] INFO impl.RoleInfo: 01074a56-f4fb-4406-b467-549b4df46db9: start 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState
recon_1     | 2023-01-30 12:03:45,369 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 22 records
recon_1     | 2023-01-30 12:03:45,377 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:03:45,378 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
datanode_2  | 2023-01-30 12:02:04,733 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_2  | 2023-01-30 12:02:04,733 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_2  | 2023-01-30 12:02:04,737 [grpc-default-executor-0] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16 replies to ELECTION vote request: 6295590c-c30d-436f-ae9f-b085e438c72d<-01074a56-f4fb-4406-b467-549b4df46db9#0:OK-t3. Peer's state: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16:t3, leader=null, voted=6295590c-c30d-436f-ae9f-b085e438c72d, raftlog=Memoized:01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:02:05,179 [01074a56-f4fb-4406-b467-549b4df46db9-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE3F4E13DA16 with new leaderId: 6295590c-c30d-436f-ae9f-b085e438c72d
datanode_3  | 2023-01-30 12:01:49,316 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: start as a follower, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:02:05,180 [01074a56-f4fb-4406-b467-549b4df46db9-server-thread1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: change Leader from null to 6295590c-c30d-436f-ae9f-b085e438c72d at term 3 for appendEntries, leader elected after 17398ms
datanode_2  | 2023-01-30 12:02:05,241 [01074a56-f4fb-4406-b467-549b4df46db9-server-thread1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: set configuration 0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_2  | 2023-01-30 12:02:05,246 [01074a56-f4fb-4406-b467-549b4df46db9-server-thread1] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker: Starting segment from index:0
datanode_2  | 2023-01-30 12:02:05,258 [01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/current/log_inprogress_0
datanode_3  | 2023-01-30 12:01:49,316 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: changes role from      null to FOLLOWER at term 0 for startAsFollower
datanode_3  | 2023-01-30 12:01:49,325 [pool-24-thread-1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState
datanode_3  | 2023-01-30 12:01:49,333 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-30 12:01:49,336 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-30 12:00:30,877 [main] INFO ha.SequenceIdGenerator: upgrade containerId to 0
scm_1       | 2023-01-30 12:00:30,879 [main] INFO ha.SequenceIdGenerator: Init the HA SequenceIdGenerator.
scm_1       | 2023-01-30 12:00:30,984 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
scm_1       | 2023-01-30 12:00:30,984 [main] WARN server.ServerUtils: ozone.scm.stale.node.interval value = 30000 is smaller than min = 90000 based on the key value of hdds.heartbeat.interval, reset to the min value 90000.
datanode_3  | 2023-01-30 12:01:49,353 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-C111AFCBD229,id=c8ea7a3f-965d-439b-b69f-d2205a7da823
recon_1     | 2023-01-30 12:03:45,576 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:03:45,577 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
recon_1     | 2023-01-30 12:03:45,587 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | startupRole: FOLLOWER
om_1        | ]
om_1        | 2023-01-30 12:01:43,128 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34661
recon_1     | 2023-01-30 12:04:02,313 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38836
datanode_2  | 2023-01-30 12:02:05,406 [grpc-default-executor-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16: receive requestVote(ELECTION, c8ea7a3f-965d-439b-b69f-d2205a7da823, group-CE3F4E13DA16, 3, (t:0, i:0))
om_1        | 2023-01-30 12:01:43,140 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:01:43,776 [qtp160479339-54] INFO utils.DBCheckpointServlet: Received request to obtain DB checkpoint snapshot
recon_1     | 2023-01-30 12:04:02,324 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_2  | 2023-01-30 12:02:05,407 [grpc-default-executor-1] INFO impl.VoteContext: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-FOLLOWER: reject ELECTION from c8ea7a3f-965d-439b-b69f-d2205a7da823: already has voted for 6295590c-c30d-436f-ae9f-b085e438c72d at current term 3
datanode_2  | 2023-01-30 12:02:05,412 [grpc-default-executor-1] INFO server.RaftServer$Division: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16 replies to ELECTION vote request: c8ea7a3f-965d-439b-b69f-d2205a7da823<-01074a56-f4fb-4406-b467-549b4df46db9#0:FAIL-t3. Peer's state: 01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16:t3, leader=6295590c-c30d-436f-ae9f-b085e438c72d, voted=6295590c-c30d-436f-ae9f-b085e438c72d, raftlog=Memoized:01074a56-f4fb-4406-b467-549b4df46db9@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c0, conf=0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-30 12:04:02,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41560
recon_1     | 2023-01-30 12:04:02,594 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:01:43,809 [qtp160479339-54] INFO db.RDBCheckpointManager: Created checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1675080103781 in 27 milliseconds
om_1        | 2023-01-30 12:01:43,849 [qtp160479339-54] INFO utils.DBCheckpointServlet: Time taken to write the checkpoint to response output stream: 37 milliseconds
om_1        | 2023-01-30 12:01:43,855 [qtp160479339-54] INFO db.RocksDBCheckpoint: Cleaning up RocksDB checkpoint at /data/metadata/db.checkpoints/om.db_checkpoint_1675080103781
datanode_2  | 2023-01-30 12:02:32,094 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:283261507731.
recon_1     | 2023-01-30 12:04:02,807 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:50992
recon_1     | 2023-01-30 12:04:02,827 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:04:32,323 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:60946
recon_1     | 2023-01-30 12:04:32,332 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:04:32,610 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36834
recon_1     | 2023-01-30 12:04:32,621 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:01:44,842 [OMRangerBGSyncService#0] INFO service.OMRangerBGSyncService: Executing Multi-Tenancy Ranger Sync: run # 1, attempt # 1. Ranger service version: 0, DB service version: -1
scm_1       | 2023-01-30 12:00:30,985 [main] WARN server.ServerUtils: ozone.scm.dead.node.interval value = 45000 is smaller than min = 180000 based on the key value of ozone.scm.stale.node.interval, reset to the min value 180000.
scm_1       | 2023-01-30 12:00:30,992 [main] INFO node.SCMNodeManager: Entering startup safe mode.
om_1        | 2023-01-30 12:01:44,843 [OMRangerBGSyncService#0] INFO service.OMRangerBGSyncService: No Ranger policy with label OzoneTenant received.
om_1        | 2023-01-30 12:02:27,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39053
om_1        | 2023-01-30 12:02:27,653 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:02:28,439 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:vol1 for user:testuser
scm_1       | 2023-01-30 12:00:31,017 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRandom
scm_1       | 2023-01-30 12:00:31,022 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
recon_1     | 2023-01-30 12:04:32,818 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43836
om_1        | 2023-01-30 12:02:28,517 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: vol1
datanode_3  | 2023-01-30 12:01:49,360 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
scm_1       | 2023-01-30 12:00:31,037 [main] INFO pipeline.PipelineStateManagerImpl: No pipeline exists in current db
recon_1     | 2023-01-30 12:04:32,836 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:02:39,993 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45395
datanode_3  | 2023-01-30 12:01:49,360 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
scm_1       | 2023-01-30 12:00:31,092 [main] INFO algorithms.LeaderChoosePolicyFactory: Create leader choose policy of type org.apache.hadoop.hdds.scm.pipeline.leader.choose.algorithms.MinLeaderCountChoosePolicy
recon_1     | 2023-01-30 12:04:45,603 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2023-01-30 12:02:40,015 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:02:45,005 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41561
scm_1       | 2023-01-30 12:00:31,093 [main] INFO algorithms.ContainerPlacementPolicyFactory: Create container placement policy of type org.apache.hadoop.hdds.scm.container.placement.algorithms.SCMContainerPlacementRackScatter
datanode_3  | 2023-01-30 12:01:49,365 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2023-01-30 12:00:31,106 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineCreator.
recon_1     | 2023-01-30 12:04:45,603 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 2023-01-30 12:02:45,013 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:49,368 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om_1        | 2023-01-30 12:03:06,815 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41839
datanode_3  | 2023-01-30 12:01:49,481 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=ab8a74f8-57b8-4ac7-9c21-c111afcbd229
scm_1       | 2023-01-30 12:00:31,106 [main] INFO pipeline.BackgroundPipelineCreator: Starting RatisPipelineUtilsThread.
recon_1     | 2023-01-30 12:04:45,603 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 39 
om_1        | 2023-01-30 12:03:06,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:49,482 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS ONE PipelineID=ab8a74f8-57b8-4ac7-9c21-c111afcbd229.
scm_1       | 2023-01-30 12:00:31,111 [main] INFO BackgroundPipelineScrubber: Starting BackgroundPipelineScrubber Service.
scm_1       | 2023-01-30 12:00:31,114 [main] INFO ha.SCMServiceManager: Registering service BackgroundPipelineScrubber.
recon_1     | 2023-01-30 12:04:45,635 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 11, SequenceNumber diff: 26, SequenceNumber Lag from OM 0.
om_1        | 2023-01-30 12:03:07,657 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72719-source for user:testuser
datanode_3  | 2023-01-30 12:01:49,483 [Command processor thread] INFO server.RaftServer: c8ea7a3f-965d-439b-b69f-d2205a7da823: addNew group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] returns group-CE3F4E13DA16:java.util.concurrent.CompletableFuture@3a2488d9[Not completed]
scm_1       | 2023-01-30 12:00:31,125 [main] INFO ExpiredContainerReplicaOpScrubber: Starting ExpiredContainerReplicaOpScrubber Service.
recon_1     | 2023-01-30 12:04:45,635 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 26 records
datanode_3  | 2023-01-30 12:01:49,508 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823: new RaftServerImpl for group-CE3F4E13DA16:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER] with ContainerStateMachine:uninitialized
scm_1       | 2023-01-30 12:00:31,125 [main] INFO ha.SCMServiceManager: Registering service ExpiredContainerReplicaOpScrubber.
recon_1     | 2023-01-30 12:04:45,641 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 2023-01-30 12:03:12,456 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37573
datanode_3  | 2023-01-30 12:01:49,509 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.min = 5s (custom)
scm_1       | 2023-01-30 12:00:31,199 [main] INFO algorithms.PipelineChoosePolicyFactory: Create pipeline choose policy of type org.apache.hadoop.hdds.scm.pipeline.choose.algorithms.RandomPipelineChoosePolicy
recon_1     | 2023-01-30 12:04:45,641 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 2023-01-30 12:03:12,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:03:13,306 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72719-target for user:testuser
datanode_3  | 2023-01-30 12:01:49,510 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.timeout.max = 5200ms (custom)
scm_1       | 2023-01-30 12:00:31,233 [main] INFO ha.SCMServiceManager: Registering service SCMBlockDeletingService.
recon_1     | 2023-01-30 12:04:45,808 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-30 12:03:17,948 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37725
scm_1       | 2023-01-30 12:00:31,347 [main] INFO replication.ReplicationManager: Starting Replication Monitor Thread.
datanode_3  | 2023-01-30 12:01:49,512 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.sleep.time = 25ms (default)
datanode_3  | 2023-01-30 12:01:49,513 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.rpc.slowness.timeout = 300s (custom)
om_1        | 2023-01-30 12:03:17,980 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:04:45,808 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2023-01-30 12:00:31,367 [main] INFO ha.SCMServiceManager: Registering service ReplicationManager.
scm_1       | 2023-01-30 12:00:31,370 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:00:31,392 [main] INFO safemode.ContainerSafeModeRule: containers with one replica threshold count 0
scm_1       | 2023-01-30 12:00:31,397 [main] INFO safemode.HealthyPipelineSafeModeRule: Total pipeline count is 0, healthy pipeline threshold count is 1
datanode_3  | 2023-01-30 12:01:49,514 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.leaderelection.leader.step-down.wait-time = 10s (default)
datanode_3  | 2023-01-30 12:01:49,515 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.sleep.deviation.threshold = 300ms (default)
recon_1     | 2023-01-30 12:04:45,809 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:05:02,313 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44452
datanode_3  | 2023-01-30 12:01:49,515 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: ConfigurationManager, init=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null, confs=<EMPTY_MAP>
om_1        | 2023-01-30 12:03:18,784 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-bucket of layout LEGACY in volume: 72719-source
om_1        | 2023-01-30 12:03:23,748 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:32963
scm_1       | 2023-01-30 12:00:31,399 [main] INFO safemode.OneReplicaPipelineSafeModeRule: Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
datanode_3  | 2023-01-30 12:01:49,517 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.dir = [/data/metadata/ratis] (custom)
om_1        | 2023-01-30 12:03:23,771 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:05:02,327 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:31,474 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
om_1        | 2023-01-30 12:03:32,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40315
recon_1     | 2023-01-30 12:05:02,578 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:49504
datanode_3  | 2023-01-30 12:01:49,521 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.corruption.policy = EXCEPTION (default)
om_1        | 2023-01-30 12:03:32,969 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:03:33,729 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-bucket of layout LEGACY in volume: 72719-source
recon_1     | 2023-01-30 12:05:02,582 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:49,522 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.storage.free-space.min = 0MB (=0) (default)
om_1        | 2023-01-30 12:03:38,642 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42205
scm_1       | 2023-01-30 12:00:31,481 [main] INFO authority.DefaultCAServer: CertificateServer validation is successful
recon_1     | 2023-01-30 12:05:02,807 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51598
datanode_3  | 2023-01-30 12:01:49,524 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.notification.no-leader.timeout = 300s (custom)
om_1        | 2023-01-30 12:03:38,665 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:31,483 [main] INFO server.StorageContainerManager: Storing sub-ca certificate serialId 255687037543 on primary SCM
recon_1     | 2023-01-30 12:05:02,812 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:49,525 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.expirytime = 600000ms (custom)
om_1        | 2023-01-30 12:03:39,587 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: readable-link of layout LEGACY in volume: 72719-target
scm_1       | 2023-01-30 12:00:31,495 [main] INFO server.StorageContainerManager: Storing root certificate serialId 1
recon_1     | 2023-01-30 12:05:32,321 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35360
datanode_3  | 2023-01-30 12:01:49,526 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.retrycache.statistics.expirytime = 100?s (default)
om_1        | 2023-01-30 12:03:44,725 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46005
scm_1       | 2023-01-30 12:00:31,535 [main] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 200, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2023-01-30 12:05:32,331 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:49,536 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.install.snapshot.enabled = false (custom)
om_1        | 2023-01-30 12:03:44,759 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:31,577 [Socket Reader #1 for port 9961] INFO ipc.Server: Starting Socket Reader #1 for port 9961
scm_1       | 2023-01-30 12:00:32,563 [Listener at 0.0.0.0/9961] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
datanode_3  | 2023-01-30 12:01:49,539 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.cached = true (default)
om_1        | 2023-01-30 12:03:45,349 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33515
scm_1       | 2023-01-30 12:00:32,575 [Listener at 0.0.0.0/9961] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
recon_1     | 2023-01-30 12:05:32,603 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:32822
datanode_3  | 2023-01-30 12:01:49,540 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.server.size = 0 (default)
om_1        | 2023-01-30 12:03:45,357 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:32,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Starting Socket Reader #1 for port 9861
recon_1     | 2023-01-30 12:05:32,631 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:49,540 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.cached = true (default)
om_1        | 2023-01-30 12:03:45,696 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: unreadable-link of layout LEGACY in volume: 72719-target
scm_1       | 2023-01-30 12:00:32,656 [Listener at 0.0.0.0/9861] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
recon_1     | 2023-01-30 12:05:32,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:55432
datanode_3  | 2023-01-30 12:01:49,540 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.threadpool.client.size = 0 (default)
om_1        | 2023-01-30 12:03:49,952 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38759
om_1        | 2023-01-30 12:03:49,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:05:32,822 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:49,543 [pool-24-thread-1] INFO storage.RaftStorageDirectory: The storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 does not exist. Creating ...
recon_1     | 2023-01-30 12:05:45,832 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-30 12:00:32,679 [Listener at 0.0.0.0/9861] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
om_1        | 2023-01-30 12:03:50,782 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link-to-unreadable-bucket of layout LEGACY in volume: 72719-target
datanode_3  | 2023-01-30 12:01:49,546 [pool-24-thread-1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/in_use.lock acquired by nodename 7@51f838724954
recon_1     | 2023-01-30 12:05:45,833 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-30 12:00:32,693 [Socket Reader #1 for port 9863] INFO ipc.Server: Starting Socket Reader #1 for port 9863
om_1        | 2023-01-30 12:03:55,751 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46263
datanode_3  | 2023-01-30 12:01:49,552 [pool-24-thread-1] INFO storage.RaftStorage: Storage directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 has been successfully formatted.
datanode_3  | 2023-01-30 12:01:49,553 [pool-24-thread-1] INFO ratis.ContainerStateMachine: group-CE3F4E13DA16: The snapshot info is null. Setting the last applied indexto:(t:0, i:~)
datanode_3  | 2023-01-30 12:01:49,566 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
datanode_3  | 2023-01-30 12:01:49,572 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
scm_1       | 2023-01-30 12:00:32,751 [Listener at 0.0.0.0/9863] INFO audit.AuditLogger: Refresh DebugCmdSet for SCMAudit to [].
scm_1       | 2023-01-30 12:00:32,763 [Listener at 0.0.0.0/9863] INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 10000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
datanode_3  | 2023-01-30 12:01:49,573 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
datanode_3  | 2023-01-30 12:01:49,575 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
scm_1       | 2023-01-30 12:00:32,764 [Socket Reader #1 for port 9860] INFO ipc.Server: Starting Socket Reader #1 for port 9860
recon_1     | 2023-01-30 12:05:45,833 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 65 
om_1        | 2023-01-30 12:03:55,800 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:32,922 [Listener at 0.0.0.0/9860] INFO ha.SCMServiceManager: Registering service ContainerBalancer.
scm_1       | 2023-01-30 12:00:32,924 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: 
recon_1     | 2023-01-30 12:05:45,905 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
scm_1       | Container Balancer status:
recon_1     | 2023-01-30 12:05:45,905 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
recon_1     | 2023-01-30 12:05:45,916 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:05:45,917 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:05:46,147 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:05:46,149 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
datanode_3  | 2023-01-30 12:01:49,575 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
datanode_3  | 2023-01-30 12:01:49,576 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
datanode_3  | 2023-01-30 12:01:49,578 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
datanode_3  | 2023-01-30 12:01:49,582 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
scm_1       | Key                            Value
scm_1       | Running                        true
scm_1       | Container Balancer Configuration values:
scm_1       | Key                                                Value
datanode_3  | 2023-01-30 12:01:49,582 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: new c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
recon_1     | 2023-01-30 12:05:46,166 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:06:02,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50938
recon_1     | 2023-01-30 12:06:02,329 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | Threshold                                          10
scm_1       | Max Datanodes to Involve per Iteration(percent)    20
scm_1       | Max Size to Move per Iteration                     500GB
scm_1       | Max Size Entering Target per Iteration             26GB
datanode_3  | 2023-01-30 12:01:49,583 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 4294967296 (custom)
recon_1     | 2023-01-30 12:06:02,581 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:49168
recon_1     | 2023-01-30 12:06:02,596 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | Max Size Leaving Source per Iteration              26GB
scm_1       | 
scm_1       | 2023-01-30 12:00:32,924 [Listener at 0.0.0.0/9860] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=false}.
scm_1       | 2023-01-30 12:00:32,927 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:9860
scm_1       | 2023-01-30 12:00:32,935 [Listener at 0.0.0.0/9860] INFO ha.SCMRatisServerImpl: starting ratis server 0.0.0.0:9894
recon_1     | 2023-01-30 12:06:02,807 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:54664
scm_1       | 2023-01-30 12:00:32,948 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO storage.RaftStorageDirectory: Lock on /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/in_use.lock acquired by nodename 7@scm
datanode_3  | 2023-01-30 12:01:49,583 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 1024 (custom)
om_1        | 2023-01-30 12:04:01,351 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44073
recon_1     | 2023-01-30 12:06:02,830 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:32,969 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO storage.RaftStorage: Read RaftStorageMetadata{term=1, votedFor=82e918d1-ff68-4821-a2f0-f9af71d19ea5} from /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/raft-meta
datanode_3  | 2023-01-30 12:01:49,584 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 1048576 (custom)
om_1        | 2023-01-30 12:04:01,387 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:06:32,329 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35312
recon_1     | 2023-01-30 12:06:32,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:33,028 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: set configuration 0: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:04:07,313 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44801
datanode_3  | 2023-01-30 12:01:49,587 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 16384 (custom)
recon_1     | 2023-01-30 12:06:32,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40178
scm_1       | 2023-01-30 12:00:33,034 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.use.memory = false (default)
om_1        | 2023-01-30 12:04:07,341 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:49,587 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
recon_1     | 2023-01-30 12:06:32,586 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:33,049 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.gap = 1000000 (custom)
om_1        | 2023-01-30 12:04:12,473 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45473
om_1        | 2023-01-30 12:04:12,494 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:49,589 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
datanode_3  | 2023-01-30 12:01:49,590 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
recon_1     | 2023-01-30 12:06:32,809 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:35282
om_1        | 2023-01-30 12:04:18,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42549
scm_1       | 2023-01-30 12:00:33,049 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
recon_1     | 2023-01-30 12:06:32,826 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:04:18,347 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:49,591 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
scm_1       | 2023-01-30 12:00:33,053 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.read.timeout = 1000ms (default)
recon_1     | 2023-01-30 12:06:46,183 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 2023-01-30 12:04:23,876 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35967
datanode_3  | 2023-01-30 12:01:49,601 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 1048576 (custom)
scm_1       | 2023-01-30 12:00:33,055 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.preservation.log.num = 0 (default)
scm_1       | 2023-01-30 12:00:33,064 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
recon_1     | 2023-01-30 12:06:46,184 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:06:46,184 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 82 
datanode_3  | 2023-01-30 12:01:49,608 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
scm_1       | 2023-01-30 12:00:33,079 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.num.max = 2 (custom)
om_1        | 2023-01-30 12:04:23,900 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:06:46,214 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
datanode_3  | 2023-01-30 12:01:50,284 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-c8ea7a3f-965d-439b-b69f-d2205a7da823: Detected pause in JVM or host machine (eg GC): pause of approximately 655015255ns.
datanode_3  | GC pool 'ParNew' had collection(s): count=1 time=84ms
om_1        | 2023-01-30 12:04:24,587 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: dangling-link of layout LEGACY in volume: 72719-target
recon_1     | 2023-01-30 12:06:46,218 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
datanode_3  | GC pool 'ConcurrentMarkSweep' had collection(s): count=1 time=580ms
scm_1       | 2023-01-30 12:00:33,081 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.cache.size.max = 200MB (=209715200) (default)
om_1        | 2023-01-30 12:04:29,037 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43791
recon_1     | 2023-01-30 12:06:46,226 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2023-01-30 12:01:50,289 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:33,094 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: new 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker for RaftStorageImpl:Storage Directory /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545
om_1        | 2023-01-30 12:04:29,057 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:06:46,226 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-30 12:00:33,096 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.byte-limit = 64MB (=67108864) (default)
om_1        | 2023-01-30 12:04:35,324 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37957
recon_1     | 2023-01-30 12:06:46,436 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
datanode_3  | 2023-01-30 12:01:50,312 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
scm_1       | 2023-01-30 12:00:33,097 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.queue.element-limit = 4096 (default)
om_1        | 2023-01-30 12:04:35,350 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:06:46,437 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
datanode_3  | 2023-01-30 12:01:50,312 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = true (custom)
scm_1       | 2023-01-30 12:00:33,099 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.segment.size.max = 4194304 (custom)
om_1        | 2023-01-30 12:04:36,113 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link1 of layout LEGACY in volume: 72719-target
recon_1     | 2023-01-30 12:06:46,437 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2023-01-30 12:01:50,312 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-30 12:00:33,100 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.preallocated.size = 4194304 (custom)
om_1        | 2023-01-30 12:04:40,749 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33953
recon_1     | 2023-01-30 12:07:02,316 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:56280
datanode_3  | 2023-01-30 12:01:50,312 [pool-24-thread-1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
scm_1       | 2023-01-30 12:00:33,102 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.force.sync.num = 128 (default)
om_1        | 2023-01-30 12:04:40,766 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:07:02,335 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:50,313 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: start as a follower, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-30 12:00:33,103 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync = true (default)
om_1        | 2023-01-30 12:04:41,449 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 72719-source
recon_1     | 2023-01-30 12:07:02,566 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:53424
datanode_3  | 2023-01-30 12:01:50,313 [pool-24-thread-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: changes role from      null to FOLLOWER at term 0 for startAsFollower
scm_1       | 2023-01-30 12:00:33,104 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout = 10s (default)
scm_1       | 2023-01-30 12:00:33,104 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
recon_1     | 2023-01-30 12:07:02,576 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:50,317 [pool-24-thread-1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
scm_1       | 2023-01-30 12:00:33,132 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.write.buffer.size = 64KB (=65536) (default)
om_1        | 2023-01-30 12:04:45,616 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:32989
recon_1     | 2023-01-30 12:07:02,803 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:49424
datanode_3  | 2023-01-30 12:01:50,322 [pool-24-thread-1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-CE3F4E13DA16,id=c8ea7a3f-965d-439b-b69f-d2205a7da823
scm_1       | 2023-01-30 12:00:33,132 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
om_1        | 2023-01-30 12:04:45,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:07:02,814 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:50,323 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2023-01-30 12:04:46,526 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46085
scm_1       | 2023-01-30 12:00:33,355 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.unsafe-flush.enabled = false (default)
recon_1     | 2023-01-30 12:07:32,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:37680
datanode_3  | 2023-01-30 12:01:50,323 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
datanode_3  | 2023-01-30 12:01:50,323 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = 5 (custom)
scm_1       | 2023-01-30 12:00:33,356 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.async-flush.enabled = false (default)
recon_1     | 2023-01-30 12:07:32,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:50,324 [pool-24-thread-1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
om_1        | 2023-01-30 12:04:46,549 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:33,356 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.statemachine.data.caching.enabled = false (default)
recon_1     | 2023-01-30 12:07:32,586 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:50566
recon_1     | 2023-01-30 12:07:32,608 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:04:55,768 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42525
scm_1       | 2023-01-30 12:00:33,381 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: set configuration 0: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-30 12:07:32,813 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44888
datanode_3  | 2023-01-30 12:01:50,325 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-30 12:04:55,787 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:33,382 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.LogSegment: Successfully read 1 entries from segment file /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/log_inprogress_0
recon_1     | 2023-01-30 12:07:32,826 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
datanode_3  | 2023-01-30 12:01:50,333 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-30 12:01:50,371 [Command processor thread] INFO ratis.XceiverServerRatis: Created group PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16
scm_1       | 2023-01-30 12:00:33,392 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: flushIndex: setUnconditionally 0 -> 0
recon_1     | 2023-01-30 12:07:46,461 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
datanode_3  | 2023-01-30 12:01:50,446 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
om_1        | 2023-01-30 12:05:04,493 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34359
scm_1       | 2023-01-30 12:00:33,399 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: safeCacheEvictIndex: setUnconditionally 0 -> -1
recon_1     | 2023-01-30 12:07:46,461 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
datanode_3  | 2023-01-30 12:01:53,323 [Command processor thread] INFO netty.NettyConfigKeys$DataStream: setTlsConf GrpcTlsConfig2-
om_1        | 2023-01-30 12:05:04,514 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:33,500 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: start as a follower, conf=0: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-30 12:00:33,501 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from      null to FOLLOWER at term 1 for startAsFollower
scm_1       | 2023-01-30 12:00:33,503 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState
datanode_3  | 2023-01-30 12:01:54,429 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO impl.FollowerState: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5104403484ns, electionTimeout:5086ms
datanode_3  | 2023-01-30 12:01:54,461 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState
datanode_3  | 2023-01-30 12:01:54,515 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: changes role from  FOLLOWER to CANDIDATE at term 0 for changeToCandidate
datanode_3  | 2023-01-30 12:01:54,532 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
datanode_3  | 2023-01-30 12:01:54,532 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-FollowerState] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1
datanode_3  | 2023-01-30 12:01:54,640 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO impl.LeaderElection: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1 ELECTION round 0: submit vote requests at term 1 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
om_1        | 2023-01-30 12:05:13,574 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45045
recon_1     | 2023-01-30 12:07:46,461 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 93 
scm_1       | 2023-01-30 12:00:33,507 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO util.JmxRegister: Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-87E6E2D1E545,id=82e918d1-ff68-4821-a2f0-f9af71d19ea5
datanode_3  | 2023-01-30 12:01:54,644 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO impl.LeaderElection: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1 ELECTION round 0: result PASSED (term=1)
om_1        | 2023-01-30 12:05:13,591 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:07:46,487 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 14, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:07:46,487 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 14 records
scm_1       | 2023-01-30 12:00:33,509 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.enabled = true (custom)
om_1        | 2023-01-30 12:05:22,854 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40079
recon_1     | 2023-01-30 12:07:46,493 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2023-01-30 12:01:54,645 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1
scm_1       | 2023-01-30 12:00:33,509 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.auto.trigger.threshold = 1000 (custom)
om_1        | 2023-01-30 12:05:22,881 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:07:46,496 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:07:46,708 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:07:46,708 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
datanode_3  | 2023-01-30 12:01:54,647 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: changes role from CANDIDATE to LEADER at term 1 for changeToLeader
om_1        | 2023-01-30 12:05:28,770 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44241
scm_1       | 2023-01-30 12:00:33,510 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.snapshot.retention.file.num = -1 (default)
recon_1     | 2023-01-30 12:07:46,709 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
datanode_3  | 2023-01-30 12:01:54,648 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-C111AFCBD229 with new leaderId: c8ea7a3f-965d-439b-b69f-d2205a7da823
om_1        | 2023-01-30 12:05:28,803 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:33,511 [82e918d1-ff68-4821-a2f0-f9af71d19ea5-impl-thread1] INFO server.RaftServerConfigKeys: raft.server.log.purge.upto.snapshot.index = false (default)
recon_1     | 2023-01-30 12:07:54,949 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
datanode_3  | 2023-01-30 12:01:54,650 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: change Leader from null to c8ea7a3f-965d-439b-b69f-d2205a7da823 at term 1 for becomeLeader, leader elected after 6446ms
om_1        | 2023-01-30 12:05:35,228 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35613
scm_1       | 2023-01-30 12:00:33,514 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5000ms (fallback to raft.server.rpc.timeout.min)
recon_1     | 2023-01-30 12:07:54,958 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 9 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:05:35,254 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:54,737 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
recon_1     | 2023-01-30 12:07:54,989 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
scm_1       | 2023-01-30 12:00:33,514 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
om_1        | 2023-01-30 12:05:40,938 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42329
om_1        | 2023-01-30 12:05:40,956 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:05:45,859 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45107
datanode_3  | 2023-01-30 12:01:54,794 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2023-01-30 12:07:54,992 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 42 milliseconds.
scm_1       | 2023-01-30 12:00:33,515 [Listener at 0.0.0.0/9860] INFO server.RaftServer: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start RPC server
om_1        | 2023-01-30 12:05:45,883 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:54,795 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 1024 M (=1073741824) (custom)
recon_1     | 2023-01-30 12:08:02,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:55744
scm_1       | 2023-01-30 12:00:33,541 [Listener at 0.0.0.0/9860] INFO server.GrpcService: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: GrpcService started, listening on 9894
om_1        | 2023-01-30 12:05:47,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39079
datanode_3  | 2023-01-30 12:01:54,921 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 180s (custom)
recon_1     | 2023-01-30 12:08:02,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:33,543 [JvmPauseMonitor0] INFO util.JvmPauseMonitor: JvmPauseMonitor-82e918d1-ff68-4821-a2f0-f9af71d19ea5: Started
om_1        | 2023-01-30 12:05:47,704 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:54,921 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 2023-01-30 12:08:02,582 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:56940
scm_1       | 2023-01-30 12:00:33,555 [Listener at 0.0.0.0/9860] INFO ha.SCMHAManagerImpl:  scm role is FOLLOWER peers [82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]
scm_1       | 2023-01-30 12:00:33,555 [Listener at 0.0.0.0/9860] INFO ha.InterSCMGrpcService: Starting SCM Grpc Service at port 9895
datanode_3  | 2023-01-30 12:01:54,922 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
recon_1     | 2023-01-30 12:08:02,603 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:08:02,817 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45592
om_1        | 2023-01-30 12:05:53,593 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44115
datanode_3  | 2023-01-30 12:01:54,963 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 1024 (custom)
recon_1     | 2023-01-30 12:08:02,824 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:33,568 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: Starting token manager
om_1        | 2023-01-30 12:05:53,623 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:05:59,599 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42509
recon_1     | 2023-01-30 12:08:32,300 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42044
scm_1       | 2023-01-30 12:00:33,568 [Listener at 0.0.0.0/9860] INFO token.ContainerTokenSecretManager: Updating current master key for generating tokens. Cert id 255687037543
om_1        | 2023-01-30 12:05:59,617 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:54,983 [grpc-default-executor-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: receive requestVote(ELECTION, 01074a56-f4fb-4406-b467-549b4df46db9, group-CE3F4E13DA16, 1, (t:0, i:0))
recon_1     | 2023-01-30 12:08:32,357 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:06:05,638 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38169
om_1        | 2023-01-30 12:06:05,664 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:06:11,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44271
scm_1       | 2023-01-30 12:00:33,687 [Listener at 0.0.0.0/9860] INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
datanode_3  | 2023-01-30 12:01:54,990 [grpc-default-executor-1] INFO impl.VoteContext: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FOLLOWER: accept ELECTION from 01074a56-f4fb-4406-b467-549b4df46db9: our priority 0 <= candidate's priority 0
recon_1     | 2023-01-30 12:08:32,571 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:45458
om_1        | 2023-01-30 12:06:11,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:54,994 [grpc-default-executor-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: changes role from  FOLLOWER to FOLLOWER at term 1 for candidate:01074a56-f4fb-4406-b467-549b4df46db9
datanode_3  | 2023-01-30 12:01:54,994 [grpc-default-executor-1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
recon_1     | 2023-01-30 12:08:32,580 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:06:17,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42913
datanode_3  | 2023-01-30 12:01:54,996 [grpc-default-executor-3] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: receive requestVote(ELECTION, 6295590c-c30d-436f-ae9f-b085e438c72d, group-CE3F4E13DA16, 1, (t:0, i:0))
datanode_3  | 2023-01-30 12:01:54,996 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState was interrupted
datanode_3  | 2023-01-30 12:01:55,002 [grpc-default-executor-1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
datanode_3  | 2023-01-30 12:01:55,005 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2023-01-30 12:06:17,570 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:08:32,800 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58760
datanode_3  | 2023-01-30 12:01:55,021 [grpc-default-executor-1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16 replies to ELECTION vote request: 01074a56-f4fb-4406-b467-549b4df46db9<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:OK-t1. Peer's state: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16:t1, leader=null, voted=01074a56-f4fb-4406-b467-549b4df46db9, raftlog=Memoized:c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:01:55,010 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
om_1        | 2023-01-30 12:06:23,448 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34235
om_1        | 2023-01-30 12:06:23,484 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:55,025 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-30 12:00:33,702 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
om_1        | 2023-01-30 12:06:29,887 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37697
om_1        | 2023-01-30 12:06:29,912 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:01:55,033 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderStateImpl
datanode_3  | 2023-01-30 12:01:55,033 [grpc-default-executor-3] INFO impl.VoteContext: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FOLLOWER: reject ELECTION from 6295590c-c30d-436f-ae9f-b085e438c72d: already has voted for 01074a56-f4fb-4406-b467-549b4df46db9 at current term 1
datanode_3  | 2023-01-30 12:01:55,065 [grpc-default-executor-3] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16 replies to ELECTION vote request: 6295590c-c30d-436f-ae9f-b085e438c72d<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:FAIL-t1. Peer's state: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16:t1, leader=null, voted=01074a56-f4fb-4406-b467-549b4df46db9, raftlog=Memoized:c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:01:55,295 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2023-01-30 12:01:55,377 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-LeaderElection1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229: set configuration 0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:01:55,422 [Command processor thread] INFO commandhandler.CreatePipelineCommandHandler: Created Pipeline RATIS THREE PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16.
datanode_3  | 2023-01-30 12:01:55,622 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-C111AFCBD229-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/ab8a74f8-57b8-4ac7-9c21-c111afcbd229/current/log_inprogress_0
datanode_3  | 2023-01-30 12:01:59,670 [grpc-default-executor-2] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: receive requestVote(ELECTION, 01074a56-f4fb-4406-b467-549b4df46db9, group-CE3F4E13DA16, 2, (t:0, i:0))
datanode_3  | 2023-01-30 12:01:59,670 [grpc-default-executor-2] INFO impl.VoteContext: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FOLLOWER: accept ELECTION from 01074a56-f4fb-4406-b467-549b4df46db9: our priority 0 <= candidate's priority 0
datanode_3  | 2023-01-30 12:01:59,670 [grpc-default-executor-2] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: changes role from  FOLLOWER to FOLLOWER at term 2 for candidate:01074a56-f4fb-4406-b467-549b4df46db9
recon_1     | 2023-01-30 12:08:32,804 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:33,702 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: StorageContainerManager metrics system started
om_1        | 2023-01-30 12:06:36,002 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44029
recon_1     | 2023-01-30 12:08:46,727 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:08:46,727 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-30 12:00:34,167 [Listener at 0.0.0.0/9860] INFO server.SCMClientProtocolServer: RPC server for Client  is listening at /0.0.0.0:9860
scm_1       | 2023-01-30 12:00:34,168 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2023-01-30 12:01:59,671 [grpc-default-executor-2] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
recon_1     | 2023-01-30 12:08:46,728 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 107 
scm_1       | 2023-01-30 12:00:34,169 [IPC Server listener on 9860] INFO ipc.Server: IPC Server listener on 9860: starting
scm_1       | 2023-01-30 12:00:34,203 [Listener at 0.0.0.0/9860] INFO server.StorageContainerManager: ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:9863
datanode_3  | 2023-01-30 12:01:59,671 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState was interrupted
recon_1     | 2023-01-30 12:08:46,771 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 17, SequenceNumber Lag from OM 0.
om_1        | 2023-01-30 12:06:36,020 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:34,204 [Listener at 0.0.0.0/9860] INFO server.SCMBlockProtocolServer: RPC server for Block Protocol is listening at /0.0.0.0:9863
scm_1       | 2023-01-30 12:00:34,205 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
datanode_3  | 2023-01-30 12:01:59,671 [grpc-default-executor-2] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
recon_1     | 2023-01-30 12:08:46,771 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 17 records
om_1        | 2023-01-30 12:06:36,816 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link2 of layout LEGACY in volume: 72719-target
om_1        | 2023-01-30 12:06:41,320 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38645
scm_1       | 2023-01-30 12:00:34,205 [IPC Server listener on 9863] INFO ipc.Server: IPC Server listener on 9863: starting
scm_1       | 2023-01-30 12:00:34,459 [Listener at 0.0.0.0/9860] INFO server.SCMSecurityProtocolServer: Starting RPC server for SCMSecurityProtocolServer. is listening at /0.0.0.0:9961
datanode_3  | 2023-01-30 12:01:59,688 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-30 12:01:59,689 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
scm_1       | 2023-01-30 12:00:34,462 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
recon_1     | 2023-01-30 12:08:46,777 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
datanode_3  | 2023-01-30 12:01:59,691 [grpc-default-executor-2] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16 replies to ELECTION vote request: 01074a56-f4fb-4406-b467-549b4df46db9<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:OK-t2. Peer's state: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16:t2, leader=null, voted=01074a56-f4fb-4406-b467-549b4df46db9, raftlog=Memoized:c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:02:00,526 [JvmPauseMonitor0] WARN util.JvmPauseMonitor: JvmPauseMonitor-c8ea7a3f-965d-439b-b69f-d2205a7da823: Detected pause in JVM or host machine (eg GC): pause of approximately 128916584ns. No GCs detected.
datanode_3  | 2023-01-30 12:02:04,704 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO impl.FollowerState: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5012455108ns, electionTimeout:5006ms
scm_1       | 2023-01-30 12:00:34,462 [IPC Server listener on 9961] INFO ipc.Server: IPC Server listener on 9961: starting
scm_1       | 2023-01-30 12:00:34,480 [Listener at 0.0.0.0/9860] INFO server.SCMUpdateServiceGrpcServer: SCMUpdateService starting
scm_1       | 2023-01-30 12:00:35,445 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25bc36] INFO util.JvmPauseMonitor: Starting JVM pause monitor
scm_1       | 2023-01-30 12:00:35,584 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34939
scm_1       | 2023-01-30 12:00:35,600 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:38471
om_1        | 2023-01-30 12:06:41,338 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:06:42,110 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:link2 in volume:72719-target
recon_1     | 2023-01-30 12:08:46,779 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
scm_1       | 2023-01-30 12:00:35,659 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Starting Web-server for scm at: http://0.0.0.0:9876
datanode_3  | 2023-01-30 12:02:04,707 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
scm_1       | 2023-01-30 12:00:35,661 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: Hadoop Security Enabled: true Ozone Security Enabled: true Ozone HTTP Security Enabled: true 
datanode_3  | 2023-01-30 12:02:04,707 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: changes role from  FOLLOWER to CANDIDATE at term 2 for changeToCandidate
datanode_3  | 2023-01-30 12:02:04,707 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
recon_1     | 2023-01-30 12:08:46,922 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-30 12:00:35,678 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HttpAuthType: hdds.scm.http.auth.type = kerberos
datanode_3  | 2023-01-30 12:02:04,707 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2
datanode_3  | 2023-01-30 12:02:04,719 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2 ELECTION round 0: submit vote requests at term 3 for -1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
recon_1     | 2023-01-30 12:08:46,922 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
scm_1       | 2023-01-30 12:00:35,684 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:207)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:06:46,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:34923
om_1        | 2023-01-30 12:06:46,209 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:06:47,106 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33033
om_1        | 2023-01-30 12:06:47,132 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:06:47,833 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket3 of layout LEGACY in volume: 72719-target
om_1        | 2023-01-30 12:06:52,432 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34835
datanode_3  | 2023-01-30 12:02:04,745 [grpc-default-executor-2] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: receive requestVote(ELECTION, 6295590c-c30d-436f-ae9f-b085e438c72d, group-CE3F4E13DA16, 3, (t:0, i:0))
scm_1       | 2023-01-30 12:00:35,716 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:00:35,834 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:50626
datanode_3  | 2023-01-30 12:02:04,746 [grpc-default-executor-2] INFO impl.VoteContext: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-CANDIDATE: reject ELECTION from 6295590c-c30d-436f-ae9f-b085e438c72d: already has voted for c8ea7a3f-965d-439b-b69f-d2205a7da823 at current term 3
datanode_3  | 2023-01-30 12:02:04,746 [grpc-default-executor-2] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16 replies to ELECTION vote request: 6295590c-c30d-436f-ae9f-b085e438c72d<-c8ea7a3f-965d-439b-b69f-d2205a7da823#0:FAIL-t3. Peer's state: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16:t3, leader=null, voted=c8ea7a3f-965d-439b-b69f-d2205a7da823, raftlog=Memoized:c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLog:OPENED:c-1, conf=-1: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:02:04,787 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2-1] INFO server.GrpcServerProtocolClient: Build channel for 01074a56-f4fb-4406-b467-549b4df46db9
datanode_3  | 2023-01-30 12:02:04,788 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.min = 5s (fallback to raft.server.rpc.timeout.min)
datanode_3  | 2023-01-30 12:02:04,800 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO server.RaftServerConfigKeys: raft.server.rpc.first-election.timeout.max = 5200ms (fallback to raft.server.rpc.timeout.max)
datanode_3  | 2023-01-30 12:02:04,805 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2-2] INFO server.GrpcServerProtocolClient: Build channel for 6295590c-c30d-436f-ae9f-b085e438c72d
om_1        | 2023-01-30 12:06:52,458 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:06:53,173 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketCreateRequest: Bucket creation failed for bucket:bucket3 in volume:72719-target
om_1        | BUCKET_ALREADY_EXISTS org.apache.hadoop.ozone.om.exceptions.OMException: Bucket already exist
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketCreateRequest.validateAndUpdateCache(OMBucketCreateRequest.java:207)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:08:46,943 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:09:02,326 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54628
recon_1     | 2023-01-30 12:09:02,338 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:09:02,599 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:51958
recon_1     | 2023-01-30 12:09:02,667 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:09:02,841 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:56804
scm_1       | 2023-01-30 12:00:35,841 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:58582
scm_1       | 2023-01-30 12:00:35,843 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41404
datanode_3  | 2023-01-30 12:02:05,182 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: changes role from CANDIDATE to FOLLOWER at term 3 for appendEntries
datanode_3  | 2023-01-30 12:02:05,182 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: shutdown c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2
scm_1       | 2023-01-30 12:00:35,876 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41083
om_1        | 2023-01-30 12:06:58,675 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46287
om_1        | 2023-01-30 12:06:58,709 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
datanode_3  | 2023-01-30 12:02:05,183 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO impl.RoleInfo: c8ea7a3f-965d-439b-b69f-d2205a7da823: start c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-FollowerState
scm_1       | 2023-01-30 12:00:35,908 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-30 12:00:35,913 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 2023-01-30 12:07:05,068 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35119
om_1        | 2023-01-30 12:07:05,086 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:05,731 [IPC Server handler 6 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have READ permission to access bucket Volume:72719-target Bucket:unreadable-link 
scm_1       | 2023-01-30 12:00:35,937 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
om_1        | 2023-01-30 12:07:10,860 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35627
recon_1     | 2023-01-30 12:09:02,874 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:09:32,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50334
scm_1       | 2023-01-30 12:00:35,955 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-30 12:00:35,994 [Listener at 0.0.0.0/9860] INFO util.log: Logging initialized @9900ms to org.eclipse.jetty.util.log.Slf4jLog
scm_1       | 2023-01-30 12:00:36,354 [Listener at 0.0.0.0/9860] INFO http.HttpRequestLog: Http request log for http.requests.scm is not defined
scm_1       | 2023-01-30 12:00:36,361 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#11 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:58582
datanode_3  | 2023-01-30 12:02:05,197 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO ratis.XceiverServerRatis: Leader change notification received for group: group-CE3F4E13DA16 with new leaderId: 6295590c-c30d-436f-ae9f-b085e438c72d
datanode_3  | 2023-01-30 12:02:05,197 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: change Leader from null to 6295590c-c30d-436f-ae9f-b085e438c72d at term 3 for appendEntries, leader elected after 15672ms
recon_1     | 2023-01-30 12:09:32,328 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:09:32,583 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42762
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
datanode_3  | 2023-01-30 12:02:05,343 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO server.RaftServer$Division: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16: set configuration 0: peers:[c8ea7a3f-965d-439b-b69f-d2205a7da823|rpc:172.18.0.4:9856|admin:172.18.0.4:9857|client:172.18.0.4:9858|dataStream:172.18.0.4:9855|priority:0|startupRole:FOLLOWER, 01074a56-f4fb-4406-b467-549b4df46db9|rpc:172.18.0.8:9856|admin:172.18.0.8:9857|client:172.18.0.8:9858|dataStream:172.18.0.8:9855|priority:0|startupRole:FOLLOWER, 6295590c-c30d-436f-ae9f-b085e438c72d|rpc:172.18.0.7:9856|admin:172.18.0.7:9857|client:172.18.0.7:9858|dataStream:172.18.0.7:9855|priority:1|startupRole:FOLLOWER]|listeners:[], old=null
datanode_3  | 2023-01-30 12:02:05,346 [c8ea7a3f-965d-439b-b69f-d2205a7da823-server-thread1] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker: Starting segment from index:0
datanode_3  | 2023-01-30 12:02:05,359 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-SegmentedRaftLogWorker: created new log segment /data/metadata/ratis/4e8cbeba-21db-48a1-9ddc-ce3f4e13da16/current/log_inprogress_0
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
datanode_3  | 2023-01-30 12:02:05,425 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2: ELECTION REJECTED received 1 response(s) and 0 exception(s):
datanode_3  | 2023-01-30 12:02:05,425 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection:   Response 0: c8ea7a3f-965d-439b-b69f-d2205a7da823<-6295590c-c30d-436f-ae9f-b085e438c72d#0:FAIL-t3
datanode_3  | 2023-01-30 12:02:05,425 [c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2] INFO impl.LeaderElection: c8ea7a3f-965d-439b-b69f-d2205a7da823@group-CE3F4E13DA16-LeaderElection2 ELECTION round 0: result REJECTED
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 2023-01-30 12:07:10,884 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:16,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36049
om_1        | 2023-01-30 12:07:16,997 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser2/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2023-01-30 12:07:17,776 [IPC Server handler 28 on default port 9862] WARN om.OzoneManager: User testuser2/scm@EXAMPLE.COM doesn't have LIST permission to access bucket Volume:72719-source Bucket:unreadable-bucket Key:
om_1        | 2023-01-30 12:07:23,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34581
recon_1     | 2023-01-30 12:09:32,605 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
datanode_3  | 2023-01-30 12:02:32,368 [ChunkWriter-1-0] INFO client.DNCertificateClient: Getting certificate with certSerialId:283261507731.
recon_1     | 2023-01-30 12:09:32,801 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45012
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-30 12:09:32,812 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:09:46,950 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-30 12:00:36,370 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#9 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:41083
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 2023-01-30 12:09:46,951 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:09:46,952 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 124 
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 2023-01-30 12:07:23,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:24,126 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop2 of layout LEGACY in volume: 72719-target
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 2023-01-30 12:07:29,420 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42347
om_1        | 2023-01-30 12:07:29,452 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:30,355 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop3 of layout LEGACY in volume: 72719-target
recon_1     | 2023-01-30 12:09:46,993 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:09:46,993 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 2023-01-30 12:07:35,797 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39795
recon_1     | 2023-01-30 12:09:46,996 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:09:46,997 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:09:47,207 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:09:47,207 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-30 12:09:47,208 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-30 12:07:35,818 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:36,586 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: loop1 of layout LEGACY in volume: 72719-target
recon_1     | 2023-01-30 12:10:02,304 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:33526
recon_1     | 2023-01-30 12:10:02,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:10:02,577 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37386
recon_1     | 2023-01-30 12:10:02,592 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:10:02,815 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46316
recon_1     | 2023-01-30 12:10:02,842 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:10:32,321 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:56218
om_1        | 2023-01-30 12:07:41,709 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37813
om_1        | 2023-01-30 12:07:41,748 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:46,476 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40641
om_1        | 2023-01-30 12:07:46,479 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:47,275 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37859
om_1        | 2023-01-30 12:07:47,302 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:07:48,014 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link3 of layout LEGACY in volume: 72719-target
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
recon_1     | 2023-01-30 12:10:32,331 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:07:52,641 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34095
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-30 12:10:32,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:45410
om_1        | 2023-01-30 12:07:52,669 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
recon_1     | 2023-01-30 12:10:32,591 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:08:00,012 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
recon_1     | 2023-01-30 12:10:32,816 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60310
recon_1     | 2023-01-30 12:10:32,832 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 2023-01-30 12:10:47,214 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-30 12:10:47,215 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:00:36,375 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:10:47,215 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 135 
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:00:36,376 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#11 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:41404
recon_1     | 2023-01-30 12:10:47,254 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
recon_1     | 2023-01-30 12:10:47,256 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
recon_1     | 2023-01-30 12:10:47,260 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
recon_1     | 2023-01-30 12:10:47,261 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:10:47,437 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:10:47,439 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:10:47,446 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-30 12:11:02,310 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:36210
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:11:02,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-30 12:11:02,579 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42070
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-30 12:11:02,585 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:11:02,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42958
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 2023-01-30 12:08:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-30 12:11:02,829 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
recon_1     | 2023-01-30 12:11:32,306 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47032
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-30 12:11:32,311 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:36,379 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.4:50626
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:11:32,589 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58894
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-30 12:11:32,592 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:11:32,805 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46978
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
recon_1     | 2023-01-30 12:11:32,841 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:11:47,456 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:08:00,015 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-30 12:11:47,456 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
recon_1     | 2023-01-30 12:11:47,456 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 148 
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-30 12:11:47,486 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:11:47,486 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-30 12:11:47,491 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 2023-01-30 12:11:47,491 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
recon_1     | 2023-01-30 12:11:47,591 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:00:36,423 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.hdds.server.http.HttpServer2$QuotingInputFilter)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:00:36,433 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context scm
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:11:47,593 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
scm_1       | 2023-01-30 12:00:36,433 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context logs
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:00:36,434 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Added filter authentication (class=org.apache.hadoop.security.authentication.server.AuthenticationFilter) to context static
recon_1     | 2023-01-30 12:11:47,597 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:08:01,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42329
om_1        | 2023-01-30 12:08:01,608 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:36,440 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Initialize spnego with host: 0.0.0.0 userKey: hdds.scm.http.auth.kerberos.principal keytabKey: hdds.scm.http.auth.kerberos.keytab
om_1        | 2023-01-30 12:08:10,906 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38309
scm_1       | 2023-01-30 12:00:36,526 [Listener at 0.0.0.0/9860] INFO http.HttpServer2: Jetty bound to port 9876
om_1        | 2023-01-30 12:08:10,928 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:08:16,025 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:32893
scm_1       | 2023-01-30 12:00:36,529 [Listener at 0.0.0.0/9860] INFO server.Server: jetty-9.4.49.v20220914; built: 2022-09-14T01:07:36.601Z; git: 4231a3b2e4cb8548a412a789936d640a97b1aa0a; jvm 11.0.14.1+1-LTS
scm_1       | 2023-01-30 12:00:36,617 [Listener at 0.0.0.0/9860] INFO server.session: DefaultSessionIdManager workerName=node0
om_1        | 2023-01-30 12:08:16,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:12:02,326 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38466
scm_1       | 2023-01-30 12:00:36,617 [Listener at 0.0.0.0/9860] INFO server.session: No SessionScavenger set, using defaults
recon_1     | 2023-01-30 12:12:02,337 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:12:02,585 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:48546
recon_1     | 2023-01-30 12:12:02,600 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:08:22,183 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41895
recon_1     | 2023-01-30 12:12:02,812 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39014
recon_1     | 2023-01-30 12:12:02,820 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:12:32,314 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54670
om_1        | 2023-01-30 12:08:22,204 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:12:32,321 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:08:28,078 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42909
om_1        | 2023-01-30 12:08:28,108 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:08:28,945 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: link4 of layout LEGACY in volume: 72719-target
om_1        | 2023-01-30 12:08:33,924 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45535
scm_1       | 2023-01-30 12:00:36,619 [Listener at 0.0.0.0/9860] INFO server.session: node0 Scavenging every 660000ms
recon_1     | 2023-01-30 12:12:32,577 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39000
om_1        | 2023-01-30 12:08:33,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:08:34,731 [OM StateMachine ApplyTransaction Thread - 0] ERROR bucket.OMBucketSetPropertyRequest: Setting bucket property failed for bucket:link4 in volume:72719-target
om_1        | NOT_SUPPORTED_OPERATION org.apache.hadoop.ozone.om.exceptions.OMException: Cannot set property on link
recon_1     | 2023-01-30 12:12:32,613 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:12:32,810 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40640
om_1        | 	at org.apache.hadoop.ozone.om.request.bucket.OMBucketSetPropertyRequest.validateAndUpdateCache(OMBucketSetPropertyRequest.java:147)
om_1        | 	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handleWriteRequest(OzoneManagerRequestHandler.java:317)
scm_1       | 2023-01-30 12:00:36,636 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
scm_1       | 2023-01-30 12:00:36,640 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@c62d08a{logs,/logs,file:///var/log/hadoop/,AVAILABLE}
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.runCommand(OzoneManagerStateMachine.java:533)
om_1        | 	at org.apache.hadoop.ozone.om.ratis.OzoneManagerStateMachine.lambda$1(OzoneManagerStateMachine.java:324)
recon_1     | 2023-01-30 12:12:32,826 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:12:47,610 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:12:47,611 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:12:47,611 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 166 
recon_1     | 2023-01-30 12:12:47,647 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:12:47,648 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
recon_1     | 2023-01-30 12:12:47,652 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:12:47,652 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:12:47,796 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:12:47,798 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
recon_1     | 2023-01-30 12:12:47,803 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:12:54,959 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2023-01-30 12:12:54,965 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 5 milliseconds for processing 1 containers.
recon_1     | 2023-01-30 12:12:55,021 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2023-01-30 12:12:55,024 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 22 milliseconds.
scm_1       | 2023-01-30 12:00:36,641 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7c4a7770{static,/static,jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/static,AVAILABLE}
scm_1       | 2023-01-30 12:00:36,757 [Listener at 0.0.0.0/9860] INFO server.KerberosAuthenticationHandler: Using keytab /etc/security/keytabs/scm.keytab, for principal HTTP/scm@EXAMPLE.COM
om_1        | 	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
recon_1     | 2023-01-30 12:13:02,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45382
recon_1     | 2023-01-30 12:13:02,309 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:02,585 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46360
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
recon_1     | 2023-01-30 12:13:02,599 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:02,808 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37896
recon_1     | 2023-01-30 12:13:02,812 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:32,313 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42818
recon_1     | 2023-01-30 12:13:32,343 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:32,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35112
recon_1     | 2023-01-30 12:13:32,581 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:32,822 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40258
recon_1     | 2023-01-30 12:13:32,842 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:13:47,810 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:13:47,811 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:13:47,811 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 184 
recon_1     | 2023-01-30 12:13:47,839 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
om_1        | 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:00:36,771 [Listener at 0.0.0.0/9860] INFO handler.ContextHandler: Started o.e.j.w.WebAppContext@304f4888{scm,/,file:///tmp/jetty-0_0_0_0-9876-hdds-server-scm-1_4_0-SNAPSHOT_jar-_-any-902764956633539764/webapp/,AVAILABLE}{jar:file:/opt/hadoop/share/ozone/lib/hdds-server-scm-1.4.0-SNAPSHOT.jar!/webapps/scm}
scm_1       | 2023-01-30 12:00:36,782 [Listener at 0.0.0.0/9860] INFO server.AbstractConnector: Started ServerConnector@50c8a382{HTTP/1.1, (http/1.1)}{0.0.0.0:9876}
scm_1       | 2023-01-30 12:00:36,787 [Listener at 0.0.0.0/9860] INFO server.Server: Started @10693ms
om_1        | 2023-01-30 12:08:40,024 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36381
scm_1       | 2023-01-30 12:00:36,791 [Listener at 0.0.0.0/9860] INFO impl.MetricsSinkAdapter: Sink prometheus started
scm_1       | 2023-01-30 12:00:36,791 [Listener at 0.0.0.0/9860] INFO impl.MetricsSystemImpl: Registered sink prometheus
scm_1       | 2023-01-30 12:00:36,793 [Listener at 0.0.0.0/9860] INFO http.BaseHttpServer: HTTP server of scm listening at http://0.0.0.0:9876
om_1        | 2023-01-30 12:08:40,051 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:08:45,680 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41375
om_1        | 2023-01-30 12:08:45,706 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:38,384 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#10 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.6:41083
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
om_1        | 2023-01-30 12:08:46,752 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42911
om_1        | 2023-01-30 12:08:46,764 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 2023-01-30 12:08:51,191 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41377
om_1        | 2023-01-30 12:08:51,220 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:08:51,968 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:40768-without-scheme for user:testuser
om_1        | 2023-01-30 12:08:56,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46507
om_1        | 2023-01-30 12:08:56,945 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:09:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
recon_1     | 2023-01-30 12:13:47,839 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
recon_1     | 2023-01-30 12:13:47,842 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:13:47,843 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:13:47,933 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:13:47,934 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-30 12:13:47,934 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:14:02,309 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:36874
recon_1     | 2023-01-30 12:14:02,318 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:14:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:54924
recon_1     | 2023-01-30 12:14:02,582 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:14:02,808 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:48164
recon_1     | 2023-01-30 12:14:02,818 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:14:32,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50718
recon_1     | 2023-01-30 12:14:32,327 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:14:32,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39996
recon_1     | 2023-01-30 12:14:32,577 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:14:32,832 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:57562
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:14:32,836 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:00:38,407 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.7:58582
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:14:47,957 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:14:47,958 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:14:47,958 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 203 
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:09:00,012 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
recon_1     | 2023-01-30 12:14:47,985 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:14:47,985 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:14:48,002 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:14:48,002 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:14:48,135 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:14:48,136 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-30 12:14:48,136 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:15:02,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44960
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-30 12:00:38,419 [IPC Server handler 0 on default port 9961] INFO ipc.Server: IPC Server handler 0 on default port 9961, call Call#0 Retry#13 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.4:50626
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
recon_1     | 2023-01-30 12:15:02,325 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:02,594 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42476
recon_1     | 2023-01-30 12:15:02,612 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:02,815 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:59218
recon_1     | 2023-01-30 12:15:02,821 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:32,308 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:57384
recon_1     | 2023-01-30 12:15:32,330 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:32,571 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58362
recon_1     | 2023-01-30 12:15:32,598 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:32,827 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60728
recon_1     | 2023-01-30 12:15:32,848 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:15:48,155 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:15:48,155 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:15:48,155 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 214 
recon_1     | 2023-01-30 12:15:48,188 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-30 12:15:48,188 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2023-01-30 12:15:48,194 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-30 12:15:48,195 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:15:48,308 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:15:48,309 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
om_1        | 2023-01-30 12:09:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:15:48,325 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:16:02,312 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:37390
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:00:38,424 [IPC Server handler 1 on default port 9961] INFO ipc.Server: IPC Server handler 1 on default port 9961, call Call#0 Retry#12 org.apache.hadoop.hdds.protocol.SCMSecurityProtocol.submitRequest from 172.18.0.8:41404
scm_1       | org.apache.hadoop.hdds.ratis.ServerNotLeaderException: Server:82e918d1-ff68-4821-a2f0-f9af71d19ea5 is not the leader. Could not determine the leader node.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:16:02,321 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:16:02,572 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57826
recon_1     | 2023-01-30 12:16:02,574 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:16:02,828 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46788
recon_1     | 2023-01-30 12:16:02,834 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:16:32,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50594
recon_1     | 2023-01-30 12:16:32,321 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 	at org.apache.hadoop.hdds.ratis.ServerNotLeaderException.convertToNotLeaderException(ServerNotLeaderException.java:109)
scm_1       | 	at org.apache.hadoop.hdds.scm.ha.RatisUtil.checkRatisException(RatisUtil.java:246)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:16:32,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34012
scm_1       | 	at org.apache.hadoop.hdds.scm.protocol.SCMSecurityProtocolServerSideTranslatorPB.submitRequest(SCMSecurityProtocolServerSideTranslatorPB.java:93)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 	at org.apache.hadoop.hdds.protocol.proto.SCMSecurityProtocolProtos$SCMSecurityProtocolService$2.callBlockingMethod(SCMSecurityProtocolProtos.java:16080)
recon_1     | 2023-01-30 12:16:32,575 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:09:03,396 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38019
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server.processCall(ProtobufRpcEngine.java:465)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:578)
scm_1       | 	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)
scm_1       | 	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)
scm_1       | 	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)
scm_1       | 	at java.base/java.security.AccessController.doPrivileged(Native Method)
scm_1       | 	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
scm_1       | 	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
scm_1       | 	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)
scm_1       | 2023-01-30 12:00:38,714 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.FollowerState: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState: change to CANDIDATE, lastRpcElapsedTime:5211097322ns, electionTimeout:5198ms
scm_1       | 2023-01-30 12:00:38,715 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState
scm_1       | 2023-01-30 12:00:38,717 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from  FOLLOWER to CANDIDATE at term 1 for changeToCandidate
scm_1       | 2023-01-30 12:00:38,720 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO server.RaftServerConfigKeys: raft.server.leaderelection.pre-vote = false (custom)
scm_1       | 2023-01-30 12:00:38,720 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-FollowerState] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1
scm_1       | 2023-01-30 12:00:38,732 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.LeaderElection: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1 ELECTION round 0: submit vote requests at term 2 for 0: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-30 12:00:38,733 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.LeaderElection: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1 ELECTION round 0: result PASSED (term=2)
scm_1       | 2023-01-30 12:00:38,734 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: shutdown 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1
scm_1       | 2023-01-30 12:00:38,734 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: changes role from CANDIDATE to LEADER at term 2 for changeToLeader
scm_1       | 2023-01-30 12:00:38,734 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO ha.SCMStateMachine: current SCM becomes leader of term 2.
scm_1       | 2023-01-30 12:00:38,734 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO ha.SCMContext: update <isLeader,term> from <false,0> to <true,2>
scm_1       | 2023-01-30 12:00:38,741 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: change Leader from null to 82e918d1-ff68-4821-a2f0-f9af71d19ea5 at term 2 for becomeLeader, leader elected after 8373ms
scm_1       | 2023-01-30 12:00:38,751 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.staging.catchup.gap = 1000 (default)
scm_1       | 2023-01-30 12:00:38,757 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2023-01-30 12:00:38,758 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.byte-limit = 64MB (=67108864) (default)
scm_1       | 2023-01-30 12:00:38,765 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout = 10s (default)
scm_1       | 2023-01-30 12:00:38,765 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.timeout.denomination = 1s (default)
recon_1     | 2023-01-30 12:16:32,842 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52604
recon_1     | 2023-01-30 12:16:32,849 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:09:03,426 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:38,766 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.watch.element-limit = 65536 (default)
scm_1       | 2023-01-30 12:00:38,772 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.element-limit = 4096 (default)
scm_1       | 2023-01-30 12:00:38,773 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServerConfigKeys: raft.server.write.follower.gap.ratio.max = -1.0 (default)
om_1        | 2023-01-30 12:09:09,783 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36055
scm_1       | 2023-01-30 12:00:38,776 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO impl.RoleInfo: 82e918d1-ff68-4821-a2f0-f9af71d19ea5: start 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderStateImpl
scm_1       | 2023-01-30 12:00:38,781 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: Rolling segment log-0_0 to index:0
scm_1       | 2023-01-30 12:00:38,786 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: Rolled log segment from /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/log_inprogress_0 to /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/log_0-0
om_1        | 2023-01-30 12:09:09,820 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:38,806 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-LeaderElection1] INFO server.RaftServer$Division: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545: set configuration 1: peers:[82e918d1-ff68-4821-a2f0-f9af71d19ea5|rpc:scm:9894|admin:|client:|dataStream:|priority:0|startupRole:FOLLOWER]|listeners:[], old=null
scm_1       | 2023-01-30 12:00:38,816 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker] INFO segmented.SegmentedRaftLogWorker: 82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-SegmentedRaftLogWorker: created new log segment /data/metadata/scm-ha/b04a1c74-af13-4571-b723-87e6e2d1e545/current/log_inprogress_1
scm_1       | 2023-01-30 12:00:38,827 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO ha.SCMContext: update <isLeaderReady> from <false> to <true>
scm_1       | 2023-01-30 12:00:38,828 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO pipeline.BackgroundPipelineCreator: Service BackgroundPipelineCreator transitions to RUNNING.
scm_1       | 2023-01-30 12:00:38,832 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:00:38,833 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.ContainerSafeModeRule: Refreshed one replica container threshold 0, currentThreshold 0
scm_1       | 2023-01-30 12:00:38,833 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.OneReplicaPipelineSafeModeRule: Refreshed Total pipeline count is 0, pipeline's with at least one datanode reported threshold count is 0
recon_1     | 2023-01-30 12:16:48,355 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:16:48,356 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-30 12:00:38,833 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO server.SCMDatanodeProtocolServer: ScmDatanodeProtocol RPC server for DataNodes is listening at /0.0.0.0:9861
om_1        | 2023-01-30 12:09:15,022 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33633
om_1        | 2023-01-30 12:09:15,048 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:38,839 [IPC Server Responder] INFO ipc.Server: IPC Server Responder: starting
om_1        | 2023-01-30 12:09:20,562 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46437
scm_1       | 2023-01-30 12:00:38,847 [IPC Server listener on 9861] INFO ipc.Server: IPC Server listener on 9861: starting
recon_1     | 2023-01-30 12:16:48,356 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 227 
om_1        | 2023-01-30 12:09:20,588 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:40,484 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 5ffad95da0eb, UUID: 6295590c-c30d-436f-ae9f-b085e438c72d
recon_1     | 2023-01-30 12:16:48,400 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 21, SequenceNumber Lag from OM 0.
om_1        | 2023-01-30 12:09:21,412 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 40768-without-scheme
scm_1       | 2023-01-30 12:00:40,489 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for RECON recon, UUID: 81c60e16-fb9b-46a0-871b-d6d3193e2696
scm_1       | 2023-01-30 12:00:41,344 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:00:41,346 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.SCMSafeModeManager: ContainerSafeModeRule rule is successfully validated
om_1        | 2023-01-30 12:09:26,225 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34045
scm_1       | 2023-01-30 12:00:41,346 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.SCMSafeModeManager: AtleastOneDatanodeReportedRule rule is successfully validated
om_1        | 2023-01-30 12:09:26,253 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:16:48,403 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 21 records
scm_1       | 2023-01-30 12:00:41,376 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:09:32,227 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35643
recon_1     | 2023-01-30 12:16:48,407 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-30 12:00:41,415 [IPC Server handler 0 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 51f838724954, UUID: c8ea7a3f-965d-439b-b69f-d2205a7da823
om_1        | 2023-01-30 12:09:32,280 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:09:38,843 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35925
om_1        | 2023-01-30 12:09:38,864 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:00:41,586 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
om_1        | 2023-01-30 12:09:44,914 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39987
recon_1     | 2023-01-30 12:16:48,408 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:16:48,504 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:16:48,506 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 5 OM DB update event(s).
recon_1     | 2023-01-30 12:16:48,520 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:17:02,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:53224
recon_1     | 2023-01-30 12:17:02,316 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:02,593 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:52242
recon_1     | 2023-01-30 12:17:02,621 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:02,813 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37116
recon_1     | 2023-01-30 12:17:02,819 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:32,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:53530
recon_1     | 2023-01-30 12:17:32,319 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:32,576 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:34374
recon_1     | 2023-01-30 12:17:32,580 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:32,803 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44660
scm_1       | 2023-01-30 12:00:41,644 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for dn 2850eee4085e, UUID: 01074a56-f4fb-4406-b467-549b4df46db9
om_1        | 2023-01-30 12:09:44,929 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:17:32,820 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:17:48,526 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-30 12:00:41,741 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:00:42,069 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
recon_1     | 2023-01-30 12:17:48,527 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:17:48,527 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 248 
om_1        | 2023-01-30 12:09:46,965 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40773
om_1        | 2023-01-30 12:09:46,985 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:17:48,570 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:17:48,571 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
om_1        | 2023-01-30 12:09:50,672 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44757
om_1        | 2023-01-30 12:09:50,689 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:09:56,777 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42067
om_1        | 2023-01-30 12:09:56,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:00:45,064 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:40253
recon_1     | 2023-01-30 12:17:48,579 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:00:45,068 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
recon_1     | 2023-01-30 12:17:48,579 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:00:45,075 [IPC Server handler 1 on default port 9961] INFO server.SCMSecurityProtocolServer: Processing CSR for om om, UUID: 8d70b0e5-5362-4052-a850-bd9140200400
scm_1       | 2023-01-30 12:00:45,172 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:00:46,379 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:00:51,382 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:00:56,383 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:01,392 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:01:06,392 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:17:48,697 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:01:09,098 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:39449
recon_1     | 2023-01-30 12:17:48,698 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:01:09,155 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1     | 2023-01-30 12:17:48,704 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:01:10,498 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42374
recon_1     | 2023-01-30 12:17:54,966 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:10:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
recon_1     | 2023-01-30 12:17:54,970 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 3 milliseconds for processing 1 containers.
recon_1     | 2023-01-30 12:17:55,056 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:17:55,070 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 42 milliseconds.
recon_1     | 2023-01-30 12:18:02,314 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:53908
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:01:10,656 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:55848
scm_1       | 2023-01-30 12:01:10,690 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:01:10,850 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:01:10,945 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58358
scm_1       | 2023-01-30 12:01:10,977 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:01:11,399 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:14,982 [IPC Server handler 0 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/6295590c-c30d-436f-ae9f-b085e438c72d
scm_1       | 2023-01-30 12:01:14,995 [IPC Server handler 25 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/c8ea7a3f-965d-439b-b69f-d2205a7da823
scm_1       | 2023-01-30 12:01:15,108 [IPC Server handler 25 on default port 9861] INFO node.SCMNodeManager: Registered Data node : c8ea7a3f-965d-439b-b69f-d2205a7da823{ip: 172.18.0.4, host: ozonesecure_datanode_3.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279802483984, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2023-01-30 12:01:15,137 [IPC Server handler 27 on default port 9861] INFO net.NetworkTopologyImpl: Added a new node: /default-rack/01074a56-f4fb-4406-b467-549b4df46db9
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:18:02,328 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:18:02,600 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42280
recon_1     | 2023-01-30 12:18:02,602 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:18:02,811 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:59146
recon_1     | 2023-01-30 12:18:02,824 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:18:32,305 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:55246
recon_1     | 2023-01-30 12:18:32,313 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:18:32,583 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57484
recon_1     | 2023-01-30 12:18:32,600 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:18:32,802 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60172
scm_1       | 2023-01-30 12:01:15,192 [IPC Server handler 27 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 01074a56-f4fb-4406-b467-549b4df46db9{ip: 172.18.0.8, host: ozonesecure_datanode_2.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279961009839, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
scm_1       | 2023-01-30 12:01:15,192 [IPC Server handler 0 on default port 9861] INFO node.SCMNodeManager: Registered Data node : 6295590c-c30d-436f-ae9f-b085e438c72d{ip: 172.18.0.7, host: ozonesecure_datanode_1.ozonesecure_default, ports: [REPLICATION=9886, RATIS=9858, RATIS_ADMIN=9857, RATIS_SERVER=9856, RATIS_DATASTREAM=9855, STANDALONE=9859], networkLocation: /default-rack, certSerialId: 279590402906, persistedOpState: null, persistedOpStateExpiryEpochSec: 0}
recon_1     | 2023-01-30 12:18:32,811 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:01:15,286 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-30 12:01:15,292 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-30 12:01:15,293 [EventQueue-NewNodeForNewNodeHandler] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-30 12:01:15,232 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 1 DataNodes registered, 3 required.
scm_1       | 2023-01-30 12:01:15,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 2 DataNodes registered, 3 required.
recon_1     | 2023-01-30 12:18:48,712 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:18:48,713 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-30 12:01:15,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. 3 DataNodes registered, 3 required.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:10:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-30 12:18:48,713 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 263 
recon_1     | 2023-01-30 12:18:48,745 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 16, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:18:48,745 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 16 records
recon_1     | 2023-01-30 12:18:48,753 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:18:48,753 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:18:48,879 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:18:48,879 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-30 12:18:48,879 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:19:02,343 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54210
recon_1     | 2023-01-30 12:19:02,351 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:19:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41212
recon_1     | 2023-01-30 12:19:02,575 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:19:02,808 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46744
recon_1     | 2023-01-30 12:19:02,811 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:19:32,327 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:57090
recon_1     | 2023-01-30 12:19:32,337 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:19:32,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37810
recon_1     | 2023-01-30 12:19:32,581 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:01:15,345 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: DataNodeSafeModeRule rule is successfully validated
scm_1       | 2023-01-30 12:01:15,346 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO safemode.SCMSafeModeManager: All SCM safe mode pre check rules have passed
scm_1       | 2023-01-30 12:01:15,346 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=false} to SafeModeStatus{safeModeStatus=true, preCheckPassed=true}.
scm_1       | 2023-01-30 12:01:15,346 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO pipeline.BackgroundPipelineCreator: trigger a one-shot run on RatisPipelineUtilsThread.
scm_1       | 2023-01-30 12:01:15,381 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=ab8a74f8-57b8-4ac7-9c21-c111afcbd229 to datanode:c8ea7a3f-965d-439b-b69f-d2205a7da823
scm_1       | 2023-01-30 12:01:15,667 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: ab8a74f8-57b8-4ac7-9c21-c111afcbd229, Nodes: c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.364Z[UTC]].
scm_1       | 2023-01-30 12:01:15,673 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:15,716 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 to datanode:01074a56-f4fb-4406-b467-549b4df46db9
scm_1       | 2023-01-30 12:01:15,729 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 to datanode:6295590c-c30d-436f-ae9f-b085e438c72d
scm_1       | 2023-01-30 12:01:15,730 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4e8cbeba-21db-48a1-9ddc-ce3f4e13da16 to datanode:c8ea7a3f-965d-439b-b69f-d2205a7da823
scm_1       | 2023-01-30 12:01:15,749 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4e8cbeba-21db-48a1-9ddc-ce3f4e13da16, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.716Z[UTC]].
scm_1       | 2023-01-30 12:01:15,749 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:15,752 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3 to datanode:6295590c-c30d-436f-ae9f-b085e438c72d
scm_1       | 2023-01-30 12:01:15,776 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3, Nodes: 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.752Z[UTC]].
scm_1       | 2023-01-30 12:01:15,781 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:15,795 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:01:15,798 [RatisPipelineUtilsThread - 0] INFO pipeline.RatisPipelineProvider: Sending CreatePipelineCommand for pipeline:PipelineID=4669bd40-3cd3-4bd5-be19-907eab7b746b to datanode:01074a56-f4fb-4406-b467-549b4df46db9
scm_1       | 2023-01-30 12:01:15,811 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO pipeline.PipelineStateManagerImpl: Created pipeline Pipeline[ Id: 4669bd40-3cd3-4bd5-be19-907eab7b746b, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:, CreationTimestamp2023-01-30T12:01:15.798Z[UTC]].
scm_1       | 2023-01-30 12:01:15,811 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:15,821 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:01:16,400 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:19,897 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35361
scm_1       | 2023-01-30 12:01:20,015 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:01:21,400 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:23,075 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35021
scm_1       | 2023-01-30 12:01:23,092 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:01:26,404 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:31,405 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:19:32,833 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39044
recon_1     | 2023-01-30 12:19:32,837 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:19:48,893 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:10:02,587 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43857
om_1        | 2023-01-30 12:10:02,625 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:08,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36249
om_1        | 2023-01-30 12:10:08,513 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:17,119 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35487
om_1        | 2023-01-30 12:10:17,137 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:26,100 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37287
om_1        | 2023-01-30 12:10:26,130 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:35,636 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40111
om_1        | 2023-01-30 12:10:35,654 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:45,204 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34745
recon_1     | 2023-01-30 12:19:48,893 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:19:48,893 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 279 
recon_1     | 2023-01-30 12:19:48,938 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 19, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:19:48,938 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 19 records
recon_1     | 2023-01-30 12:19:48,946 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:19:48,946 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:19:49,066 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:19:49,066 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
recon_1     | 2023-01-30 12:19:49,066 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 2023-01-30 12:10:45,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:47,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42965
om_1        | 2023-01-30 12:10:47,241 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:01:32,417 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41997
scm_1       | 2023-01-30 12:01:32,438 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:01:36,406 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:41,192 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42253
scm_1       | 2023-01-30 12:01:41,236 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:01:41,407 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:45,830 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:01:46,404 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46056
scm_1       | 2023-01-30 12:01:46,407 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:46,415 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:01:46,541 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58744
recon_1     | 2023-01-30 12:20:02,302 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:52466
recon_1     | 2023-01-30 12:20:02,310 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:20:02,589 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:53882
recon_1     | 2023-01-30 12:20:02,605 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:20:02,824 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:53362
recon_1     | 2023-01-30 12:20:02,835 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:20:32,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:39738
recon_1     | 2023-01-30 12:20:32,318 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:20:32,572 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42710
recon_1     | 2023-01-30 12:20:32,577 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:10:51,231 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35137
om_1        | 2023-01-30 12:10:51,259 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:10:57,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35817
om_1        | 2023-01-30 12:10:57,172 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:01:46,556 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:01:46,766 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:57918
scm_1       | 2023-01-30 12:01:46,782 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:01:48,869 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: ab8a74f8-57b8-4ac7-9c21-c111afcbd229, Nodes: c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:c8ea7a3f-965d-439b-b69f-d2205a7da823, CreationTimestamp2023-01-30T12:01:15.364Z[UTC]] moved to OPEN state
scm_1       | 2023-01-30 12:01:48,937 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:48,947 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:01:49,575 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2023-01-30 12:20:32,815 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58094
recon_1     | 2023-01-30 12:20:32,828 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:20:49,073 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:20:49,073 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:20:49,074 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 298 
recon_1     | 2023-01-30 12:20:49,118 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:20:49,119 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2023-01-30 12:20:49,127 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:20:49,127 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-30 12:01:51,410 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:54,708 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:01:55,195 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4669bd40-3cd3-4bd5-be19-907eab7b746b, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:01074a56-f4fb-4406-b467-549b4df46db9, CreationTimestamp2023-01-30T12:01:15.798Z[UTC]] moved to OPEN state
scm_1       | 2023-01-30 12:01:55,216 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:55,234 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
recon_1     | 2023-01-30 12:20:49,195 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:20:49,195 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 2023-01-30 12:11:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-30 12:20:49,196 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:21:02,305 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:43282
recon_1     | 2023-01-30 12:21:02,309 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:21:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39704
recon_1     | 2023-01-30 12:21:02,578 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:21:02,804 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37822
recon_1     | 2023-01-30 12:21:02,806 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:21:32,316 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:51840
recon_1     | 2023-01-30 12:21:32,331 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:21:32,579 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58226
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:01:55,360 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: b94b867f-ed1a-49ec-8fd7-d14d9bfcc8c3, Nodes: 6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7), ReplicationConfig: RATIS/ONE, State:ALLOCATED, leaderId:6295590c-c30d-436f-ae9f-b085e438c72d, CreationTimestamp2023-01-30T12:01:15.752Z[UTC]] moved to OPEN state
scm_1       | 2023-01-30 12:01:55,375 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 0, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:01:55,383 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:01:56,411 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:01:57,580 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33043
scm_1       | 2023-01-30 12:01:57,617 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:02:00,403 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:02:00,456 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:02:01,411 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:04,797 [EventQueue-PipelineReportForPipelineReportHandler] INFO pipeline.PipelineManagerImpl: Pipeline Pipeline[ Id: 4e8cbeba-21db-48a1-9ddc-ce3f4e13da16, Nodes: 01074a56-f4fb-4406-b467-549b4df46db9(ozonesecure_datanode_2.ozonesecure_default/172.18.0.8)6295590c-c30d-436f-ae9f-b085e438c72d(ozonesecure_datanode_1.ozonesecure_default/172.18.0.7)c8ea7a3f-965d-439b-b69f-d2205a7da823(ozonesecure_datanode_3.ozonesecure_default/172.18.0.4), ReplicationConfig: RATIS/THREE, State:ALLOCATED, leaderId:6295590c-c30d-436f-ae9f-b085e438c72d, CreationTimestamp2023-01-30T12:01:15.716Z[UTC]] moved to OPEN state
scm_1       | 2023-01-30 12:02:04,797 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 0, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:02:04,808 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] INFO safemode.HealthyPipelineSafeModeRule: Refreshed total pipeline count is 1, healthy pipeline threshold count is 1
scm_1       | 2023-01-30 12:02:04,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM in safe mode. Healthy pipelines reported count is 1, required healthy pipeline reported count is 1
scm_1       | 2023-01-30 12:02:04,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: HealthyPipelineSafeModeRule rule is successfully validated
scm_1       | 2023-01-30 12:02:04,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: ScmSafeModeManager, all rules are successfully validated
scm_1       | 2023-01-30 12:02:04,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO safemode.SCMSafeModeManager: SCM exiting safe mode.
scm_1       | 2023-01-30 12:02:04,818 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ha.SCMContext: Update SafeModeStatus from SafeModeStatus{safeModeStatus=true, preCheckPassed=true} to SafeModeStatus{safeModeStatus=false, preCheckPassed=true}.
recon_1     | 2023-01-30 12:21:32,595 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:21:32,861 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44064
recon_1     | 2023-01-30 12:21:32,896 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:11:00,011 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:21:49,204 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:21:49,204 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:21:49,205 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 311 
recon_1     | 2023-01-30 12:21:49,249 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 7, SequenceNumber diff: 15, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:21:49,249 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 15 records
recon_1     | 2023-01-30 12:21:49,256 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:21:49,257 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:21:49,324 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:21:49,326 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 4 OM DB update event(s).
recon_1     | 2023-01-30 12:21:49,341 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:22:02,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46576
scm_1       | 2023-01-30 12:02:04,819 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO BackgroundPipelineScrubber: Service BackgroundPipelineScrubber transitions to RUNNING.
scm_1       | 2023-01-30 12:02:04,819 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO ExpiredContainerReplicaOpScrubber: Service ExpiredContainerReplicaOpScrubber transitions to RUNNING.
scm_1       | 2023-01-30 12:02:04,819 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] INFO replication.ReplicationManager: Service ReplicationManager transitions to RUNNING.
scm_1       | 2023-01-30 12:02:04,842 [EventQueue-OpenPipelineForHealthyPipelineSafeModeRule] WARN balancer.ContainerBalancer: Could not find persisted configuration for ContainerBalancer when checking if ContainerBalancer should run. ContainerBalancer should not run now.
scm_1       | 2023-01-30 12:02:06,412 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:07,119 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41481
scm_1       | 2023-01-30 12:02:07,157 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for HTTP/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:02:11,412 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:15,833 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:02:16,412 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:21,413 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:24,533 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41785
scm_1       | 2023-01-30 12:02:24,552 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:02:24,707 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45690
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:22:02,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:11:07,073 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33835
om_1        | 2023-01-30 12:11:07,091 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:15,741 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36021
om_1        | 2023-01-30 12:11:15,770 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:21,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41237
om_1        | 2023-01-30 12:11:21,304 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:26,471 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43787
om_1        | 2023-01-30 12:11:26,492 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:35,157 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41201
om_1        | 2023-01-30 12:11:35,177 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:41,081 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34035
om_1        | 2023-01-30 12:11:41,099 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:47,182 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40047
recon_1     | 2023-01-30 12:22:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38540
recon_1     | 2023-01-30 12:22:02,581 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:22:02,823 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60018
recon_1     | 2023-01-30 12:22:02,826 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:22:32,315 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:56414
recon_1     | 2023-01-30 12:22:32,332 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:22:32,573 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38468
recon_1     | 2023-01-30 12:22:32,581 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:02:24,718 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:02:26,414 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:28,637 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:36373
scm_1       | 2023-01-30 12:02:28,646 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:02:28,678 [IPC Server handler 91 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for containerId, change lastId from 0 to 1000.
scm_1       | 2023-01-30 12:02:28,737 [82e918d1-ff68-4821-a2f0-f9af71d19ea5@group-87E6E2D1E545-StateMachineUpdater] WARN ha.SequenceIdGenerator: Failed to allocate a batch for localId, expected lastId is 0, actual lastId is 111677748019200000.
scm_1       | 2023-01-30 12:02:28,744 [IPC Server handler 91 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for localId, change lastId from 111677748019200000 to 111677748019201000.
scm_1       | 2023-01-30 12:02:30,428 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36110
recon_1     | 2023-01-30 12:22:32,830 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:47612
recon_1     | 2023-01-30 12:22:32,843 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:22:49,363 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:22:49,363 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:22:49,363 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 326 
recon_1     | 2023-01-30 12:22:49,412 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:22:49,412 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2023-01-30 12:22:49,415 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:22:49,415 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:22:49,465 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:22:49,466 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 1 OM DB update event(s).
om_1        | 2023-01-30 12:11:47,209 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:47,466 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35241
om_1        | 2023-01-30 12:11:47,481 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:53,181 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34273
scm_1       | 2023-01-30 12:02:30,438 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:02:31,414 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:32,060 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:39788
scm_1       | 2023-01-30 12:02:32,076 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-30 12:02:32,155 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57850
scm_1       | 2023-01-30 12:02:32,176 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-30 12:02:32,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:40006
scm_1       | 2023-01-30 12:02:32,432 [Socket Reader #1 for port 9961] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52506
scm_1       | 2023-01-30 12:02:32,440 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:02:32,478 [Socket Reader #1 for port 9961] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.protocol.SCMSecurityProtocol
scm_1       | 2023-01-30 12:02:36,415 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:40,764 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:43941
scm_1       | 2023-01-30 12:02:40,790 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:02:41,415 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:11:53,216 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:11:58,896 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38285
om_1        | 2023-01-30 12:11:58,914 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:22:49,469 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:22:54,971 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
recon_1     | 2023-01-30 12:22:54,975 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
recon_1     | 2023-01-30 12:22:55,102 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
recon_1     | 2023-01-30 12:22:55,105 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 31 milliseconds.
recon_1     | 2023-01-30 12:23:02,304 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:55780
recon_1     | 2023-01-30 12:23:02,307 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:23:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:59794
recon_1     | 2023-01-30 12:23:02,573 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:23:02,809 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:49332
recon_1     | 2023-01-30 12:23:02,817 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:12:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:02:45,835 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:02:46,416 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:51,416 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:02:54,868 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33027
scm_1       | 2023-01-30 12:02:54,917 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
scm_1       | 2023-01-30 12:02:56,416 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:01,417 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:02,334 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47234
scm_1       | 2023-01-30 12:03:02,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-30 12:23:32,307 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:56246
recon_1     | 2023-01-30 12:23:32,324 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:23:32,579 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:56276
recon_1     | 2023-01-30 12:23:32,588 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:23:32,807 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:49784
recon_1     | 2023-01-30 12:23:32,812 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:23:49,480 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:23:49,481 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:23:49,481 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 339 
recon_1     | 2023-01-30 12:23:49,504 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 11, SequenceNumber Lag from OM 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:03:02,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41252
scm_1       | 2023-01-30 12:03:02,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:03:02,830 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58622
scm_1       | 2023-01-30 12:03:02,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:03:06,417 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:11,417 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:15,837 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:03:16,418 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:21,418 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:23:49,504 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 11 records
recon_1     | 2023-01-30 12:23:49,507 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:23:49,507 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:23:49,584 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:23:49,585 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:12:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:23:49,585 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:24:02,303 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:33066
scm_1       | 2023-01-30 12:03:24,601 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:40671
scm_1       | 2023-01-30 12:03:24,612 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:03:26,418 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:31,419 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:32,356 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54628
scm_1       | 2023-01-30 12:03:32,365 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:03:32,574 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44796
recon_1     | 2023-01-30 12:24:02,315 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:02,572 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40174
recon_1     | 2023-01-30 12:24:02,586 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:02,815 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37736
recon_1     | 2023-01-30 12:24:02,822 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:32,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46794
recon_1     | 2023-01-30 12:24:32,329 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:32,589 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:60226
recon_1     | 2023-01-30 12:24:32,619 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:32,816 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40904
recon_1     | 2023-01-30 12:24:32,830 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:24:49,591 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:24:49,592 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:24:49,594 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 350 
recon_1     | 2023-01-30 12:24:49,639 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 5, SequenceNumber diff: 13, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:24:49,639 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 13 records
recon_1     | 2023-01-30 12:24:49,642 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:24:49,643 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:24:49,716 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
recon_1     | 2023-01-30 12:24:49,717 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 2 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:03:32,590 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:03:32,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:47088
scm_1       | 2023-01-30 12:03:32,842 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:03:36,420 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:41,420 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:45,845 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:03:46,421 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:51,421 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:03:56,422 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:12:04,464 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40731
om_1        | 2023-01-30 12:12:04,485 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:10,253 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36997
om_1        | 2023-01-30 12:12:10,283 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:15,975 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46851
om_1        | 2023-01-30 12:12:16,005 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:21,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41271
om_1        | 2023-01-30 12:12:21,576 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:27,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36243
om_1        | 2023-01-30 12:12:27,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:33,140 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37375
scm_1       | 2023-01-30 12:04:01,422 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:02,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:55868
scm_1       | 2023-01-30 12:04:02,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:02,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57754
scm_1       | 2023-01-30 12:04:02,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:02,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36048
scm_1       | 2023-01-30 12:04:02,833 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:06,423 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:11,424 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:15,848 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:04:16,424 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:24:49,722 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:25:02,308 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:41188
recon_1     | 2023-01-30 12:25:02,312 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:02,581 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:50730
recon_1     | 2023-01-30 12:25:02,592 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:02,814 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40026
recon_1     | 2023-01-30 12:25:02,828 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:32,304 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35068
recon_1     | 2023-01-30 12:25:32,316 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:32,590 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36458
om_1        | 2023-01-30 12:12:33,169 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:38,780 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46285
om_1        | 2023-01-30 12:12:38,810 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:44,072 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45501
om_1        | 2023-01-30 12:12:44,097 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:47,625 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45105
om_1        | 2023-01-30 12:12:47,639 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:12:49,794 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33935
om_1        | 2023-01-30 12:12:49,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:04:21,425 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:26,425 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:31,425 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:04:32,343 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47030
scm_1       | 2023-01-30 12:04:32,370 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:32,594 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38404
scm_1       | 2023-01-30 12:04:32,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:32,844 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45270
scm_1       | 2023-01-30 12:04:32,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:04:36,426 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:25:32,598 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:32,809 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51530
recon_1     | 2023-01-30 12:25:32,816 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:25:49,733 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
recon_1     | 2023-01-30 12:25:49,734 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:25:49,734 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 363 
recon_1     | 2023-01-30 12:25:49,776 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
recon_1     | 2023-01-30 12:25:49,776 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
recon_1     | 2023-01-30 12:25:49,782 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
recon_1     | 2023-01-30 12:25:49,785 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:25:49,899 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
om_1        | 2023-01-30 12:12:54,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41747
om_1        | 2023-01-30 12:12:54,949 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:13:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-30 12:25:49,900 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:04:41,426 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:25:49,904 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:04:45,849 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:26:02,314 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:60598
scm_1       | 2023-01-30 12:04:46,426 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:26:02,326 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:04:47,444 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:33879
scm_1       | 2023-01-30 12:04:47,450 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
recon_1     | 2023-01-30 12:26:02,570 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40308
recon_1     | 2023-01-30 12:26:02,575 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:26:02,823 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41500
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-30 12:26:02,846 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:04:51,427 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:26:32,317 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44510
scm_1       | 2023-01-30 12:04:56,427 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:26:32,320 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:05:01,428 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:26:32,580 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:42124
scm_1       | 2023-01-30 12:05:02,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46472
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-30 12:26:32,605 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:05:02,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:26:32,804 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45326
scm_1       | 2023-01-30 12:05:02,586 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44552
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-30 12:26:32,807 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:05:02,609 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-30 12:26:49,913 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-30 12:05:02,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:50464
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:26:49,913 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
scm_1       | 2023-01-30 12:05:02,839 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
recon_1     | 2023-01-30 12:26:49,913 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 381 
scm_1       | 2023-01-30 12:05:05,345 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:44391
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
recon_1     | 2023-01-30 12:26:49,963 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 8, SequenceNumber diff: 18, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-30 12:05:05,352 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
recon_1     | 2023-01-30 12:26:49,963 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 18 records
scm_1       | 2023-01-30 12:05:06,429 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:26:49,970 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-30 12:05:11,429 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:26:49,971 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
scm_1       | 2023-01-30 12:05:15,851 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:26:50,062 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-30 12:05:16,429 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-30 12:26:50,063 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 3 OM DB update event(s).
scm_1       | 2023-01-30 12:05:21,430 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:26:50,066 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
recon_1     | 2023-01-30 12:27:02,313 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:57764
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:05:26,431 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:27:02,324 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:05:31,431 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:27:02,578 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58018
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:05:32,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54756
recon_1     | 2023-01-30 12:27:02,583 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:05:32,348 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:05:32,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:54276
recon_1     | 2023-01-30 12:27:02,812 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46374
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:05:32,627 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-30 12:27:02,821 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
recon_1     | 2023-01-30 12:27:32,311 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46788
scm_1       | 2023-01-30 12:05:32,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:56228
recon_1     | 2023-01-30 12:27:32,314 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:05:32,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-30 12:27:32,588 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:56042
om_1        | 2023-01-30 12:13:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:05:36,432 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:27:32,605 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:05:41,432 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
recon_1     | 2023-01-30 12:27:32,805 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40818
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:05:45,864 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
recon_1     | 2023-01-30 12:27:32,808 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:05:46,432 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
recon_1     | 2023-01-30 12:27:50,080 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Syncing data from Ozone Manager.
scm_1       | 2023-01-30 12:05:51,433 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
recon_1     | 2023-01-30 12:27:50,080 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Obtaining delta updates from Ozone Manager
recon_1     | 2023-01-30 12:27:50,080 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: OriginalFromSequenceNumber : 399 
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
recon_1     | 2023-01-30 12:27:50,123 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Number of updates received from OM : 6, SequenceNumber diff: 16, SequenceNumber Lag from OM 0.
scm_1       | 2023-01-30 12:05:56,434 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
recon_1     | 2023-01-30 12:27:50,124 [pool-30-thread-1] INFO impl.OzoneManagerServiceProviderImpl: Delta updates received from OM : 1 loops, 16 records
scm_1       | 2023-01-30 12:06:01,434 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
recon_1     | 2023-01-30 12:27:50,128 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithFSO: Completed a process run of NSSummaryTaskWithFSO
scm_1       | 2023-01-30 12:06:02,317 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:34600
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
recon_1     | 2023-01-30 12:27:50,128 [pool-31-thread-1] INFO tasks.NSSummaryTaskWithLegacy: Completed a process run of NSSummaryTaskWithLegacy
recon_1     | 2023-01-30 12:27:50,216 [pool-31-thread-1] INFO tasks.TableCountTask: Completed a 'process' run of TableCountTask.
scm_1       | 2023-01-30 12:06:02,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
recon_1     | 2023-01-30 12:27:50,216 [pool-31-thread-1] INFO tasks.ContainerKeyMapperTask: ContainerKeyMapperTask successfully processed 0 OM DB update event(s).
scm_1       | 2023-01-30 12:06:02,576 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39504
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
recon_1     | 2023-01-30 12:27:50,216 [pool-31-thread-1] INFO tasks.FileSizeCountTask: Completed a 'process' run of FileSizeCountTask.
scm_1       | 2023-01-30 12:06:02,589 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:06:02,801 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36678
recon_1     | 2023-01-30 12:27:54,976 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 1 milliseconds to process 0 existing database records.
scm_1       | 2023-01-30 12:06:02,827 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:06:06,435 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
recon_1     | 2023-01-30 12:27:54,978 [ContainerHealthTask] INFO fsck.ContainerHealthTask: Container Health task thread took 2 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:06:11,435 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
recon_1     | 2023-01-30 12:27:55,155 [PipelineSyncTask] INFO scm.ReconPipelineManager: Recon has 4 pipelines in house.
scm_1       | 2023-01-30 12:06:15,870 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:13:00,331 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35475
recon_1     | 2023-01-30 12:27:55,161 [PipelineSyncTask] INFO scm.PipelineSyncTask: Pipeline sync Thread took 30 milliseconds.
scm_1       | 2023-01-30 12:06:16,436 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:00,358 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:27:55,484 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:59778
scm_1       | 2023-01-30 12:06:21,437 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:01,000 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:40768-without-scheme for user:testuser
om_1        | 2023-01-30 12:13:06,300 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43881
recon_1     | 2023-01-30 12:27:55,521 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
om_1        | 2023-01-30 12:13:06,354 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:06:25,479 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:40491
recon_1     | 2023-01-30 12:27:55,524 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: New container #2 got from ozonesecure_datanode_1.ozonesecure_default.
om_1        | 2023-01-30 12:13:12,573 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34431
scm_1       | 2023-01-30 12:06:25,495 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:06:25,537 [IPC Server handler 49 on default port 9863] INFO ha.SequenceIdGenerator: Allocate a batch for delTxnId, change lastId from 0 to 1000.
recon_1     | 2023-01-30 12:27:55,535 [FixedThreadPoolWithAffinityExecutor-9-0] INFO scm.ReconContainerManager: Successfully added container #2 to Recon.
scm_1       | 2023-01-30 12:06:26,437 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:12,598 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
recon_1     | 2023-01-30 12:28:02,606 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41960
scm_1       | 2023-01-30 12:06:31,438 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:18,475 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35163
recon_1     | 2023-01-30 12:28:02,614 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:06:32,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45950
scm_1       | 2023-01-30 12:06:32,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:06:32,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:50566
recon_1     | 2023-01-30 12:28:02,806 [Socket Reader #1 for port 9891] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51502
scm_1       | 2023-01-30 12:06:32,598 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:06:32,807 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:48484
scm_1       | 2023-01-30 12:06:32,817 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
recon_1     | 2023-01-30 12:28:02,825 [Socket Reader #1 for port 9891] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.ReconDatanodeProtocol
scm_1       | 2023-01-30 12:06:36,438 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:06:41,438 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:06:45,872 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:13:18,496 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:06:46,440 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:06:51,440 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:19,217 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 40768-without-scheme
scm_1       | 2023-01-30 12:06:56,441 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
om_1        | 2023-01-30 12:13:24,362 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43601
scm_1       | 2023-01-30 12:07:01,441 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Manager is not ready to run until 300000ms after safemode exit
scm_1       | 2023-01-30 12:07:02,336 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44770
scm_1       | 2023-01-30 12:07:02,349 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:24,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:02,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57724
scm_1       | 2023-01-30 12:07:02,593 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:29,999 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46811
scm_1       | 2023-01-30 12:07:02,808 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44622
om_1        | 2023-01-30 12:13:30,027 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:02,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:36,200 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38893
scm_1       | 2023-01-30 12:07:06,443 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:13:36,225 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:13:41,250 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41943
scm_1       | 2023-01-30 12:07:11,444 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:13:41,298 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:13:46,840 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46537
scm_1       | 2023-01-30 12:07:15,875 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:07:16,445 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:21,447 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:26,449 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:31,369 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:07:31,394 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:13:46,861 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:31,450 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:13:47,826 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:33945
scm_1       | 2023-01-30 12:07:32,336 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:37140
om_1        | 2023-01-30 12:13:47,834 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:32,341 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:52,280 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33883
scm_1       | 2023-01-30 12:07:32,620 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:51262
om_1        | 2023-01-30 12:13:52,308 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:32,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:53,155 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-with-host for user:testuser
scm_1       | 2023-01-30 12:07:32,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58636
om_1        | 2023-01-30 12:13:58,184 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33531
scm_1       | 2023-01-30 12:07:32,846 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:13:58,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:07:36,453 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:07:41,453 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:45,876 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:07:46,454 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:51,456 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:07:53,374 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:33119
scm_1       | 2023-01-30 12:07:53,383 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:07:54,972 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42085
scm_1       | 2023-01-30 12:07:54,983 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:07:56,458 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:08:01,370 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:08:01,396 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:08:01,458 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:08:02,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35150
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:08:02,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:08:02,579 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:54148
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:08:02,581 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:08:02,800 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:49932
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:08:02,808 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:08:06,460 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:08:11,461 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:08:15,878 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:08:16,462 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:08:21,463 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:08:26,464 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:08:31,370 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:08:31,396 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:08:31,465 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:08:32,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:52146
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:08:32,362 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:08:32,599 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41096
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:08:32,610 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:08:32,805 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52778
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:08:32,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:08:36,465 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:08:41,466 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:08:45,879 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:08:46,467 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:14:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:08:51,468 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:08:56,470 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:09:01,370 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:09:01,396 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:09:01,471 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:09:02,345 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35998
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:09:02,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:09:02,636 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46982
scm_1       | 2023-01-30 12:09:02,676 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:09:02,832 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32914
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:09:02,842 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:09:06,472 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:09:11,473 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:09:15,881 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:09:16,474 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:09:21,475 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:09:26,476 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:14:04,274 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45917
om_1        | 2023-01-30 12:14:04,294 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:14:10,082 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33525
om_1        | 2023-01-30 12:14:10,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:14:15,806 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42153
om_1        | 2023-01-30 12:14:15,829 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:14:22,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39899
om_1        | 2023-01-30 12:14:22,377 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:14:23,157 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 72137-with-host
om_1        | 2023-01-30 12:14:28,213 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44903
scm_1       | 2023-01-30 12:09:31,371 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:14:28,242 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:09:31,396 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:14:34,368 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37651
scm_1       | 2023-01-30 12:09:31,477 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:34,393 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:09:32,344 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:44672
om_1        | 2023-01-30 12:14:40,500 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41393
scm_1       | 2023-01-30 12:09:32,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:14:40,519 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:09:32,644 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33174
scm_1       | 2023-01-30 12:09:32,648 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:09:32,820 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52500
scm_1       | 2023-01-30 12:09:32,833 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:09:36,478 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:09:41,479 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:46,674 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37685
scm_1       | 2023-01-30 12:09:45,884 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:14:46,701 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:09:46,480 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:47,970 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:38241
scm_1       | 2023-01-30 12:09:51,481 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:47,981 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:09:56,482 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:10:01,371 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:14:52,358 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34669
scm_1       | 2023-01-30 12:10:01,398 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:14:52,392 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:10:01,483 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:14:57,803 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43087
scm_1       | 2023-01-30 12:10:02,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42982
om_1        | 2023-01-30 12:14:57,822 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:10:02,349 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:15:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:10:02,604 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46712
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:02,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:10:02,821 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51658
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:02,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:06,485 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:10:09,232 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:36135
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:10:09,245 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:10:11,487 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:10:15,886 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:10:16,488 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:10:21,489 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:10:26,490 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:10:26,927 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:38757
om_1        | 2023-01-30 12:15:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:10:26,937 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:10:31,371 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:31,399 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:31,490 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:10:32,338 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50816
scm_1       | 2023-01-30 12:10:32,351 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:10:32,596 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37236
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:10:32,635 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:10:32,835 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58556
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:10:32,848 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:10:36,492 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:10:41,492 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:10:45,890 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:10:46,493 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:10:51,494 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:10:56,495 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:10:58,097 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:38295
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:10:58,106 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:11:01,374 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:11:01,399 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:11:01,496 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:11:02,330 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38952
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:11:02,338 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:11:02,604 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44220
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:11:02,613 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:11:02,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:53406
scm_1       | 2023-01-30 12:11:02,831 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:11:06,497 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:11:11,497 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:03,559 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33915
scm_1       | 2023-01-30 12:11:15,893 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:15:03,583 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:16,500 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:10,028 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34717
scm_1       | 2023-01-30 12:11:21,501 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:10,052 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:25,460 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:34337
om_1        | 2023-01-30 12:15:18,480 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33955
scm_1       | 2023-01-30 12:11:25,464 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-30 12:15:18,506 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:26,501 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:26,974 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34413
scm_1       | 2023-01-30 12:11:31,374 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:15:26,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:31,400 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:15:36,127 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38973
scm_1       | 2023-01-30 12:11:31,502 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:36,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:32,329 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47030
om_1        | 2023-01-30 12:15:44,710 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38769
scm_1       | 2023-01-30 12:11:32,342 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:15:44,734 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:32,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36696
om_1        | 2023-01-30 12:15:48,166 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:37553
om_1        | 2023-01-30 12:15:48,183 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:32,608 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:15:50,816 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38341
scm_1       | 2023-01-30 12:11:32,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36048
scm_1       | 2023-01-30 12:11:32,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:11:36,503 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:50,838 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:41,504 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:11:45,896 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:15:56,302 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40177
scm_1       | 2023-01-30 12:11:46,506 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:15:56,326 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:11:51,509 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:11:56,509 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:12:01,375 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:12:01,400 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:16:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:12:01,510 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:12:02,309 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:53410
scm_1       | 2023-01-30 12:12:02,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:12:02,606 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33624
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:02,618 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:02,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52932
scm_1       | 2023-01-30 12:12:02,828 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:06,511 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:12:11,512 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:12:15,897 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:12:16,518 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 6 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:12:21,519 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:12:25,459 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:34659
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:12:25,469 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:12:26,520 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:12:31,375 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:16:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:12:31,401 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:12:31,523 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:12:32,326 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:40358
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:32,333 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:32,578 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57936
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:12:32,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:12:32,814 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:32968
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:12:32,825 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:12:36,524 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:12:41,526 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:12:45,899 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:12:46,527 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:12:51,528 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:12:55,013 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:41485
scm_1       | 2023-01-30 12:12:55,017 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:12:56,529 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:16:00,007 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:13:01,376 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:13:01,401 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:13:01,530 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:13:02,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:40596
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:13:02,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:13:02,590 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:52122
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:13:02,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:13:02,824 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42970
scm_1       | 2023-01-30 12:13:02,843 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:13:06,531 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:13:11,531 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:13:15,901 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:13:16,532 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:13:21,533 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:13:26,534 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:13:31,376 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:16:06,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41729
om_1        | 2023-01-30 12:16:06,066 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:31,402 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:16:14,354 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35891
om_1        | 2023-01-30 12:16:14,378 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:31,535 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:16:20,151 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41575
om_1        | 2023-01-30 12:16:20,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:32,321 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50780
om_1        | 2023-01-30 12:16:25,710 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34595
om_1        | 2023-01-30 12:16:25,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:16:34,644 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33621
scm_1       | 2023-01-30 12:13:32,355 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:16:34,679 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:16:40,209 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39881
scm_1       | 2023-01-30 12:13:32,600 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:51440
om_1        | 2023-01-30 12:16:40,234 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:16:46,142 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33897
scm_1       | 2023-01-30 12:13:32,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:16:46,162 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:16:48,367 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42987
om_1        | 2023-01-30 12:16:48,370 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:32,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40234
om_1        | 2023-01-30 12:16:51,852 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36243
om_1        | 2023-01-30 12:16:51,872 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:32,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:16:57,973 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40049
scm_1       | 2023-01-30 12:13:36,538 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:16:57,992 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:13:41,548 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 9 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:13:45,904 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:17:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:13:46,548 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:13:51,549 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:13:56,551 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:01,377 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:14:01,402 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:14:01,552 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:02,315 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47096
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:14:02,337 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:14:02,599 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:47258
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:14:02,607 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:14:02,825 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:52874
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:14:02,830 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:14:06,553 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:14:11,555 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:14:15,907 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:14:16,556 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:21,557 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:14:26,557 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:31,377 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:14:31,402 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:14:31,559 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:14:32,331 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:46784
scm_1       | 2023-01-30 12:14:32,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:14:32,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:59584
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:14:32,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:14:32,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:53044
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:14:32,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:14:36,559 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:14:41,564 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:45,910 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:14:46,565 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:14:51,567 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:14:56,569 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:01,378 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:15:01,403 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:15:01,570 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:02,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:53480
scm_1       | 2023-01-30 12:15:02,309 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:15:02,597 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:36094
scm_1       | 2023-01-30 12:15:02,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:15:02,826 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:41542
scm_1       | 2023-01-30 12:15:02,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:15:06,571 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:10,842 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:35933
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:15:10,852 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:15:11,572 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:15:15,912 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:15:16,573 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:15:21,574 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:26,575 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:15:27,698 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:38623
scm_1       | 2023-01-30 12:15:27,702 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:15:31,378 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:15:31,404 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:15:31,576 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:32,335 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45436
scm_1       | 2023-01-30 12:15:32,343 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:15:32,568 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41846
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:15:32,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:15:32,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45846
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:15:32,860 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:15:36,577 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:15:41,578 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:45,914 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:15:46,579 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:51,580 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:15:56,580 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:15:57,313 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:41787
scm_1       | 2023-01-30 12:15:57,319 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:16:01,379 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:16:01,404 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:16:01,581 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:02,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:59348
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:16:02,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:16:02,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:51608
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:16:02,616 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:16:02,818 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:54312
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:16:02,826 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:16:06,582 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:16:11,583 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:15,916 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:16:16,583 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:03,440 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37477
scm_1       | 2023-01-30 12:16:21,585 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:25,468 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:36385
scm_1       | 2023-01-30 12:16:25,487 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:16:26,585 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:31,379 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:17:03,460 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:16:31,404 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:16:31,586 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:09,056 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45245
scm_1       | 2023-01-30 12:16:32,332 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:40022
scm_1       | 2023-01-30 12:16:32,343 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:16:32,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:59016
scm_1       | 2023-01-30 12:16:32,596 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:17:09,081 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:16:32,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:50032
scm_1       | 2023-01-30 12:16:32,836 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:17:14,813 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44633
scm_1       | 2023-01-30 12:16:36,587 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:41,588 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:14,835 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:16:45,917 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:16:46,590 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:20,305 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43505
scm_1       | 2023-01-30 12:16:51,590 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:16:56,591 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:20,330 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:01,380 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:17:01,405 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:17:26,183 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41259
scm_1       | 2023-01-30 12:17:01,592 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:02,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:37172
om_1        | 2023-01-30 12:17:26,206 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:02,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:17:02,595 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:51168
om_1        | 2023-01-30 12:17:31,591 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33003
scm_1       | 2023-01-30 12:17:02,625 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:17:02,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42500
om_1        | 2023-01-30 12:17:31,622 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:02,845 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:17:06,593 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:38,126 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34641
scm_1       | 2023-01-30 12:17:11,593 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:15,919 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:17:38,148 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:16,594 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:21,595 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:43,913 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35955
scm_1       | 2023-01-30 12:17:25,463 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:33639
scm_1       | 2023-01-30 12:17:25,474 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-30 12:17:43,944 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:26,596 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:31,380 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:17:48,543 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44811
scm_1       | 2023-01-30 12:17:31,405 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:17:31,596 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:48,554 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:32,328 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35758
scm_1       | 2023-01-30 12:17:32,339 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:17:50,234 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37443
scm_1       | 2023-01-30 12:17:32,588 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:37736
scm_1       | 2023-01-30 12:17:32,595 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:17:32,841 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:39166
om_1        | 2023-01-30 12:17:50,262 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:32,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:17:36,597 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:17:55,716 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45083
scm_1       | 2023-01-30 12:17:41,598 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:45,920 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:17:55,740 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:17:46,599 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:17:51,600 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:17:55,042 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45305
scm_1       | 2023-01-30 12:17:55,052 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:17:56,602 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:01,381 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:18:01,406 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:18:01,603 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:18:02,305 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45358
scm_1       | 2023-01-30 12:18:02,308 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:18:02,589 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:56486
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:18:02,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:18:02,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:40580
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:18:02,828 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:18:06,604 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:18:11,604 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:15,922 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:18:16,605 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:21,606 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:18:26,608 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:31,381 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:18:31,406 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:18:31,608 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:32,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:34362
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:18:32,328 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:18:32,583 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:46998
scm_1       | 2023-01-30 12:18:32,591 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:18:32,817 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:45514
scm_1       | 2023-01-30 12:18:32,818 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:18:36,609 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:41,610 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:18:45,926 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:18:46,611 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:18:51,613 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:18:56,614 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:19:01,382 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:19:01,407 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:19:01,615 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:02,309 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:55444
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:19:02,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:02,585 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:60222
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:19:02,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:02,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:58722
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:19:02,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:06,616 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:11,619 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:19:15,928 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:19:16,621 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:19:21,622 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:26,624 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:19:31,382 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:19:31,407 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:19:31,624 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:32,333 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:48060
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:19:32,346 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:32,597 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:44842
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:19:32,601 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:32,848 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:37128
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:19:32,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:19:36,625 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:19:41,626 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:45,929 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:19:46,626 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:19:51,627 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:19:56,628 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:01,383 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:20:01,407 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:20:01,629 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:02,311 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:54152
scm_1       | 2023-01-30 12:20:02,317 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:20:02,609 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33926
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:20:02,612 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:20:02,806 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:54190
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:20:02,834 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:20:06,630 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:11,632 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:20:15,931 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:20:16,633 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:20:21,634 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:26,636 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:31,383 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:20:31,408 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:20:31,636 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:32,307 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:35894
scm_1       | 2023-01-30 12:20:32,320 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:20:32,577 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:38640
scm_1       | 2023-01-30 12:20:32,599 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:20:32,812 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:44648
scm_1       | 2023-01-30 12:20:32,823 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:20:36,637 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:41,638 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:20:45,932 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:20:46,639 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:20:51,641 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:20:56,642 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:01,384 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:21:01,408 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:21:01,643 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:21:02,319 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:43386
scm_1       | 2023-01-30 12:21:02,323 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:21:02,583 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40994
scm_1       | 2023-01-30 12:21:02,591 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:21:02,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:46622
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:21:02,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:21:06,644 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:01,217 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44161
scm_1       | 2023-01-30 12:21:09,429 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:37357
scm_1       | 2023-01-30 12:21:09,439 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-30 12:18:01,240 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:21:11,645 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:15,936 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:18:01,911 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-with-host for user:testuser
scm_1       | 2023-01-30 12:21:16,646 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:21,647 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:26,648 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:06,987 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43129
scm_1       | 2023-01-30 12:21:31,384 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:21:31,409 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:21:31,649 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:07,010 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:21:32,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:45342
scm_1       | 2023-01-30 12:21:32,347 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:13,311 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43989
scm_1       | 2023-01-30 12:21:32,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:45976
scm_1       | 2023-01-30 12:21:32,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:13,328 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:21:32,872 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60890
scm_1       | 2023-01-30 12:21:32,903 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:19,342 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34147
scm_1       | 2023-01-30 12:21:36,649 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:41,650 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:45,937 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:18:19,367 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:21:46,651 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:21:51,654 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:20,156 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 72137-with-host
scm_1       | 2023-01-30 12:21:56,656 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:22:01,384 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:22:01,409 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:18:25,221 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41761
scm_1       | 2023-01-30 12:22:01,667 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 4 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:25,256 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:02,324 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:42000
om_1        | 2023-01-30 12:18:31,870 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34497
scm_1       | 2023-01-30 12:22:02,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:31,896 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:02,603 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35518
om_1        | 2023-01-30 12:18:38,822 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33581
scm_1       | 2023-01-30 12:22:02,615 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:38,846 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:18:48,127 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35063
scm_1       | 2023-01-30 12:22:02,836 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:60350
om_1        | 2023-01-30 12:18:48,176 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:02,844 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:18:48,725 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:46269
scm_1       | 2023-01-30 12:22:06,667 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:48,735 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:11,670 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:50,630 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38413
scm_1       | 2023-01-30 12:22:15,940 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:22:16,671 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:50,652 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:21,680 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:56,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44905
scm_1       | 2023-01-30 12:22:26,681 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:18:56,375 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:22:31,385 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:18:57,093 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-with-errors for user:testuser
scm_1       | 2023-01-30 12:22:31,409 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:19:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:22:31,682 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:22:32,316 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:50422
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:22:32,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:22:32,582 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:41270
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:22:32,593 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:22:32,822 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51198
scm_1       | 2023-01-30 12:22:32,844 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:22:33,687 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:42419
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:22:33,693 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:22:36,683 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:22:41,684 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:22:45,941 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:22:46,685 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:22:51,686 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:22:55,087 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35865
om_1        | 2023-01-30 12:19:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:22:55,097 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:22:56,687 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:01,386 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:01,410 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:01,687 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:23:02,313 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:51200
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:23:02,324 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:23:02,580 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:35768
scm_1       | 2023-01-30 12:23:02,592 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:23:02,827 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:48206
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:23:02,831 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:23:06,689 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:23:11,689 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:23:15,946 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:23:16,690 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:19:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:23:21,691 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:23:26,692 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:31,387 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:31,410 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:23:31,692 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:23:32,366 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:38484
scm_1       | 2023-01-30 12:23:32,371 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:23:32,603 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:49490
scm_1       | 2023-01-30 12:23:32,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:23:32,819 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36484
scm_1       | 2023-01-30 12:23:32,821 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:23:36,693 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:23:41,694 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:23:45,947 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:23:46,695 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:23:51,696 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:23:56,697 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:19:02,084 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39909
om_1        | 2023-01-30 12:19:02,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:10,894 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33095
scm_1       | 2023-01-30 12:24:01,387 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:24:01,410 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:24:01,698 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:02,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:51278
scm_1       | 2023-01-30 12:24:02,331 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:24:02,573 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:39430
scm_1       | 2023-01-30 12:24:02,593 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:24:02,804 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:51278
scm_1       | 2023-01-30 12:24:02,814 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:24:06,700 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:11,701 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:14,404 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:35837
scm_1       | 2023-01-30 12:24:14,410 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:24:15,948 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:24:16,702 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:21,703 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:19:10,924 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:11,618 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bucket1 of layout LEGACY in volume: 72137-with-errors
om_1        | 2023-01-30 12:19:16,478 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40077
om_1        | 2023-01-30 12:19:16,510 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:25,583 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43379
om_1        | 2023-01-30 12:19:25,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:31,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44097
om_1        | 2023-01-30 12:19:31,270 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:24:26,704 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:31,369 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:43507
scm_1       | 2023-01-30 12:24:31,372 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:24:31,388 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:24:31,411 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:24:31,705 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:32,340 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:37728
scm_1       | 2023-01-30 12:24:32,350 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:24:32,624 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:56752
scm_1       | 2023-01-30 12:24:32,634 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:24:32,841 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:57104
om_1        | 2023-01-30 12:19:37,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40787
om_1        | 2023-01-30 12:19:37,308 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:38,013 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-acls for user:testuser
om_1        | 2023-01-30 12:19:42,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39895
om_1        | 2023-01-30 12:19:42,758 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:48,766 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41049
om_1        | 2023-01-30 12:19:48,789 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:19:48,902 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45589
om_1        | 2023-01-30 12:19:48,929 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:24:32,849 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:19:54,248 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45567
scm_1       | 2023-01-30 12:24:36,705 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:19:54,270 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:24:41,706 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:45,951 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:20:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:24:46,707 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:24:51,708 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:24:56,709 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:25:00,966 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:34331
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:00,973 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:25:01,388 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:01,411 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:25:01,710 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:02,318 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:48500
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:25:02,330 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:25:02,601 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:48972
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:25:02,606 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:25:02,828 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:42052
om_1        | 2023-01-30 12:20:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:25:02,833 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:06,710 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:25:11,711 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:25:15,952 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:25:16,712 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:20:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:25:21,713 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:25,473 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:37413
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:25:25,482 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:25:26,715 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:25:31,389 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:25:31,412 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:25:31,716 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:20:00,214 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43033
scm_1       | 2023-01-30 12:25:32,306 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:32930
om_1        | 2023-01-30 12:20:00,243 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:20:05,698 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41721
scm_1       | 2023-01-30 12:25:32,334 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:20:05,723 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:20:11,352 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40567
scm_1       | 2023-01-30 12:25:32,607 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:40660
om_1        | 2023-01-30 12:20:11,373 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:32,653 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:20:16,679 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44191
om_1        | 2023-01-30 12:20:16,703 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:32,818 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:53802
om_1        | 2023-01-30 12:20:23,095 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38943
om_1        | 2023-01-30 12:20:23,120 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:32,832 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:20:23,881 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 72137-acls
om_1        | 2023-01-30 12:20:28,510 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35617
scm_1       | 2023-01-30 12:25:36,717 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:20:28,530 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:20:34,426 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37597
om_1        | 2023-01-30 12:20:34,461 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:41,717 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:20:35,136 [OM StateMachine ApplyTransaction Thread - 0] ERROR acl.OMBucketAddAclRequest: Add acl [user:superuser1:rwxy[ACCESS]] to path /72137-acls/bb1 failed, because acl already exist
om_1        | 2023-01-30 12:20:39,522 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37679
scm_1       | 2023-01-30 12:25:45,954 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:20:39,555 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:20:45,929 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44851
scm_1       | 2023-01-30 12:25:46,718 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:20:45,954 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:20:49,097 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:45865
om_1        | 2023-01-30 12:20:49,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:51,719 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:20:51,194 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44971
om_1        | 2023-01-30 12:20:51,219 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:25:56,719 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:20:57,298 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44555
om_1        | 2023-01-30 12:20:57,324 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:26:01,389 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:21:00,006 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:26:01,412 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:26:01,720 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:26:02,332 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:52944
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:26:02,340 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:26:02,584 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:33082
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
scm_1       | 2023-01-30 12:26:02,589 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:26:02,823 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:47164
om_1        | 2023-01-30 12:21:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
scm_1       | 2023-01-30 12:26:02,853 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:26:06,720 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:26:11,721 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:26:15,956 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:26:16,721 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:26:21,723 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:26:25,468 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:35437
om_1        | 2023-01-30 12:21:00,013 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:26:25,470 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
scm_1       | 2023-01-30 12:26:26,725 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:26:31,390 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:26:31,412 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:26:31,725 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:26:32,323 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:34070
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:26:32,325 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:26:32,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:57174
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
scm_1       | 2023-01-30 12:26:32,602 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:21:02,735 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43935
om_1        | 2023-01-30 12:21:02,755 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:26:32,815 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:43764
om_1        | 2023-01-30 12:21:08,577 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40397
om_1        | 2023-01-30 12:21:08,599 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:26:32,822 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:21:17,122 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37199
om_1        | 2023-01-30 12:21:17,144 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:26:36,727 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:21:22,836 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34275
om_1        | 2023-01-30 12:21:22,858 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:26:41,728 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:21:28,346 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42075
om_1        | 2023-01-30 12:21:28,369 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:21:34,186 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37235
om_1        | 2023-01-30 12:21:34,207 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:21:39,679 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34043
scm_1       | 2023-01-30 12:26:45,960 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 2023-01-30 12:21:39,701 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:21:45,567 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42151
scm_1       | 2023-01-30 12:26:46,729 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:21:45,592 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:21:49,218 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:32891
scm_1       | 2023-01-30 12:26:51,731 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:21:49,222 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:21:51,483 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33113
scm_1       | 2023-01-30 12:26:56,732 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:21:51,509 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:27:01,390 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:21:57,541 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39519
scm_1       | 2023-01-30 12:27:01,412 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:21:57,568 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:27:01,733 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 2023-01-30 12:22:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:27:02,327 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:59610
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
scm_1       | 2023-01-30 12:27:02,335 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:27:02,591 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:43540
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:02,600 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:02,831 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:36750
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:02,835 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:27:06,734 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:27:11,734 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:27:15,962 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:27:16,735 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
scm_1       | 2023-01-30 12:27:21,737 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:27:26,737 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:22:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
scm_1       | 2023-01-30 12:27:31,391 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:22:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
scm_1       | 2023-01-30 12:27:31,413 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
scm_1       | 2023-01-30 12:27:31,738 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
scm_1       | 2023-01-30 12:27:32,314 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:47262
scm_1       | 2023-01-30 12:27:32,336 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:32,592 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:58138
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:32,604 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
scm_1       | 2023-01-30 12:27:32,816 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:50516
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
scm_1       | 2023-01-30 12:27:32,820 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
scm_1       | 2023-01-30 12:27:36,739 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
scm_1       | 2023-01-30 12:27:41,739 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
scm_1       | 2023-01-30 12:27:45,963 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:27:46,740 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
scm_1       | 2023-01-30 12:27:51,741 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 1 containers.
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
scm_1       | 2023-01-30 12:27:53,002 [Socket Reader #1 for port 9863] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:39481
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:22:03,392 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35169
scm_1       | 2023-01-30 12:27:53,005 [Socket Reader #1 for port 9863] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.ScmBlockLocationProtocol
om_1        | 2023-01-30 12:22:03,417 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:27:55,141 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:42521
om_1        | 2023-01-30 12:22:09,878 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45183
scm_1       | 2023-01-30 12:27:55,149 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2023-01-30 12:22:09,897 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:27:55,462 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.7:39262
om_1        | 2023-01-30 12:22:15,501 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40501
scm_1       | 2023-01-30 12:27:55,520 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
om_1        | 2023-01-30 12:22:15,529 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:27:56,745 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 2 milliseconds for processing 2 containers.
scm_1       | 2023-01-30 12:28:01,391 [Under Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
om_1        | 2023-01-30 12:22:21,316 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46349
scm_1       | 2023-01-30 12:28:01,413 [Over Replicated Processor] INFO replication.UnhealthyReplicationProcessor: Processed 0 containers with health state counts {},failed processing 0
scm_1       | 2023-01-30 12:28:01,745 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
om_1        | 2023-01-30 12:22:21,339 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:28:02,293 [Socket Reader #1 for port 9860] INFO ipc.Server: Auth successful for om/om@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.2:39239
om_1        | 2023-01-30 12:22:26,781 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41217
om_1        | 2023-01-30 12:22:26,804 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:22:32,802 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43995
om_1        | 2023-01-30 12:22:32,857 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:22:41,916 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34989
scm_1       | 2023-01-30 12:28:02,303 [Socket Reader #1 for port 9860] INFO authorize.ServiceAuthorizationManager: Authorization successful for om/om@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.hdds.scm.protocol.StorageContainerLocationProtocol
om_1        | 2023-01-30 12:22:41,942 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
scm_1       | 2023-01-30 12:28:02,598 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.8:47898
scm_1       | 2023-01-30 12:28:02,605 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:28:02,829 [Socket Reader #1 for port 9861] INFO ipc.Server: Auth successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.4:57880
scm_1       | 2023-01-30 12:28:02,839 [Socket Reader #1 for port 9861] INFO authorize.ServiceAuthorizationManager: Authorization successful for dn/dn@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.protocol.StorageContainerDatanodeProtocol
scm_1       | 2023-01-30 12:28:06,747 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm_1       | 2023-01-30 12:28:11,748 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 1 milliseconds for processing 2 containers.
scm_1       | 2023-01-30 12:28:15,964 [RatisPipelineUtilsThread - 0] WARN pipeline.PipelinePlacementPolicy: Pipeline creation failed due to no sufficient healthy datanodes. Required 3. Found 0.
scm_1       | 2023-01-30 12:28:16,748 [ReplicationMonitor] INFO replication.ReplicationManager: Replication Monitor Thread took 0 milliseconds for processing 2 containers.
om_1        | 2023-01-30 12:22:47,812 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42263
om_1        | 2023-01-30 12:22:47,836 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:22:49,381 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:35051
om_1        | 2023-01-30 12:22:49,394 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:22:53,519 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43925
om_1        | 2023-01-30 12:22:53,534 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:22:54,275 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-without-host for user:testuser
om_1        | 2023-01-30 12:22:59,281 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39141
om_1        | 2023-01-30 12:22:59,309 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:23:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:23:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:23:05,714 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37737
om_1        | 2023-01-30 12:23:05,736 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:12,429 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:32923
om_1        | 2023-01-30 12:23:12,463 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:18,297 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33473
om_1        | 2023-01-30 12:23:18,323 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:24,240 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34883
om_1        | 2023-01-30 12:23:24,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:25,008 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 72137-without-host
om_1        | 2023-01-30 12:23:29,688 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39253
om_1        | 2023-01-30 12:23:29,715 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:35,606 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41707
om_1        | 2023-01-30 12:23:35,626 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:41,711 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43505
om_1        | 2023-01-30 12:23:41,729 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:48,067 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:36707
om_1        | 2023-01-30 12:23:48,094 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:49,491 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:37947
om_1        | 2023-01-30 12:23:49,500 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:23:54,278 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40441
om_1        | 2023-01-30 12:23:54,304 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:24:00,009 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:24:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:24:01,012 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:34145
om_1        | 2023-01-30 12:24:01,040 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:07,359 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35077
om_1        | 2023-01-30 12:24:07,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:13,459 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44285
om_1        | 2023-01-30 12:24:13,495 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:22,188 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45199
om_1        | 2023-01-30 12:24:22,210 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:30,544 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41641
om_1        | 2023-01-30 12:24:30,566 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:40,138 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43025
om_1        | 2023-01-30 12:24:40,161 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:48,907 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:45747
om_1        | 2023-01-30 12:24:48,934 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:49,614 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:43603
om_1        | 2023-01-30 12:24:49,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:24:54,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42201
om_1        | 2023-01-30 12:24:54,558 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:00,008 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:25:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:25:00,010 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:25:00,041 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37889
om_1        | 2023-01-30 12:25:00,067 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:09,388 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:43325
om_1        | 2023-01-30 12:25:09,412 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:18,112 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44175
om_1        | 2023-01-30 12:25:18,142 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:23,461 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42599
om_1        | 2023-01-30 12:25:23,486 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:29,021 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39193
om_1        | 2023-01-30 12:25:29,047 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:38,162 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:46785
om_1        | 2023-01-30 12:25:38,185 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:43,943 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:38499
om_1        | 2023-01-30 12:25:43,961 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:49,325 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42659
om_1        | 2023-01-30 12:25:49,346 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:49,754 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:39615
om_1        | 2023-01-30 12:25:49,764 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:25:55,340 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33053
om_1        | 2023-01-30 12:25:55,360 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:26:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:26:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:26:01,224 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39509
om_1        | 2023-01-30 12:26:01,258 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:07,350 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40837
om_1        | 2023-01-30 12:26:07,381 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:13,042 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42487
om_1        | 2023-01-30 12:26:13,072 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:19,105 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41221
om_1        | 2023-01-30 12:26:19,128 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:24,557 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35591
om_1        | 2023-01-30 12:26:24,585 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:30,578 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44337
om_1        | 2023-01-30 12:26:30,604 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:36,818 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42679
om_1        | 2023-01-30 12:26:36,842 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:42,644 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:39335
om_1        | 2023-01-30 12:26:42,658 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:48,113 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44813
om_1        | 2023-01-30 12:26:48,140 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:49,939 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:40193
om_1        | 2023-01-30 12:26:49,955 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:54,027 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33687
om_1        | 2023-01-30 12:26:54,069 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:26:59,536 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:37865
om_1        | 2023-01-30 12:26:59,559 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:00,005 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:27:00,025 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:27:00,025 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:27:05,598 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:44985
om_1        | 2023-01-30 12:27:05,634 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:06,436 [OM StateMachine ApplyTransaction Thread - 0] INFO volume.OMVolumeCreateRequest: created volume:72137-without-host for user:testuser
om_1        | 2023-01-30 12:27:11,403 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:40479
om_1        | 2023-01-30 12:27:11,429 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:17,349 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42405
om_1        | 2023-01-30 12:27:17,368 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:23,135 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35129
om_1        | 2023-01-30 12:27:23,166 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:23,922 [OM StateMachine ApplyTransaction Thread - 0] INFO bucket.OMBucketCreateRequest: created bucket: bb1 of layout LEGACY in volume: 72137-without-host
om_1        | 2023-01-30 12:27:29,069 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35895
om_1        | 2023-01-30 12:27:29,102 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:34,988 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:42791
om_1        | 2023-01-30 12:27:35,009 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:40,524 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:33307
om_1        | 2023-01-30 12:27:40,557 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:49,417 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:41417
om_1        | 2023-01-30 12:27:49,456 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:50,093 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.6:44137
om_1        | 2023-01-30 12:27:50,103 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for recon/recon@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:27:52,149 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35959
om_1        | 2023-01-30 12:27:52,165 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
om_1        | 2023-01-30 12:28:00,002 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop1, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:28:00,003 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop2, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:28:00,004 [Trash Emptier] ERROR om.TrashOzoneFileSystem: Couldn't perform fs operation fs.listStatus()/fs.exists()
om_1        | DETECTED_LOOP_IN_BUCKET_LINKS org.apache.hadoop.ozone.om.exceptions.OMException: Detected loop in bucket links. Bucket name: loop3, Volume name: 72719-target
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:110)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:127)
om_1        | 	at org.apache.hadoop.ozone.om.OzoneManagerUtils.getBucketLayout(OzoneManagerUtils.java:84)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getOzoneFileStatus(KeyManagerImpl.java:1246)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1219)
om_1        | 	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1194)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getFileStatus(TrashOzoneFileSystem.java:282)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.exists(TrashOzoneFileSystem.java:338)
om_1        | 	at org.apache.hadoop.ozone.om.TrashOzoneFileSystem.getTrashRoots(TrashOzoneFileSystem.java:318)
om_1        | 	at org.apache.hadoop.ozone.om.TrashPolicyOzone$Emptier.run(TrashPolicyOzone.java:313)
om_1        | 	at java.base/java.lang.Thread.run(Thread.java:829)
om_1        | 2023-01-30 12:28:01,546 [Socket Reader #1 for port 9862] INFO ipc.Server: Auth successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) from 172.18.0.5:35883
om_1        | 2023-01-30 12:28:01,573 [Socket Reader #1 for port 9862] INFO authorize.ServiceAuthorizationManager: Authorization successful for testuser/scm@EXAMPLE.COM (auth:KERBEROS) for protocol=interface org.apache.hadoop.ozone.om.protocol.OzoneManagerProtocol
